{
  "meta": {
    "last_updated": "2026-02-22T23:22:37.332959Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223857.htm",
        "posted_at": "2026-02-15",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215225541.htm",
        "posted_at": "2026-02-16",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-renewable-biological-catalyst-potential-wastewater.html",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "posted_at": "2026-02-17",
        "score": 5.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005717.htm",
        "posted_at": "2026-02-18",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "posted_at": "2026-02-19",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-machine-central-problem-quantum-chemistry.html",
        "posted_at": "2026-02-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260220010830.htm",
        "posted_at": "2026-02-20",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-impact-glass-evidence-cosmic-collision.html",
        "posted_at": "2026-02-20",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-qa-gas-fermentation-game-changer.html",
        "posted_at": "2026-02-21",
        "score": 9.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040818.htm",
        "posted_at": "2026-02-21",
        "score": 5.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260221000307.htm",
        "posted_at": "2026-02-22",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-cosmic-curveball-distant-planet-formation.html",
        "posted_at": "2026-02-22",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/",
        "posted_at": "2026-02-15",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "posted_at": "2026-02-16",
        "score": 33.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2501.05454",
        "posted_at": "2026-02-16",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-02-17",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.14299",
        "posted_at": "2026-02-17",
        "score": 21.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
        "posted_at": "2026-02-17",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/17/india-bids-to-attract-over-200b-in-ai-infrastructure-investment-by-2028/",
        "posted_at": "2026-02-17",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-02-18",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2510.22391",
        "posted_at": "2026-02-18",
        "score": 18.6,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2510.25867",
        "posted_at": "2026-02-19",
        "score": 19.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-02-19",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/19/1133360/microsoft-has-a-new-plan-to-prove-whats-real-and-whats-ai-online/",
        "posted_at": "2026-02-19",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/19/web-summit-qatar-read-ai-lucidya-notetakers-customer-support/",
        "posted_at": "2026-02-19",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-02-20",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.16320",
        "posted_at": "2026-02-20",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-20",
        "score": 4.8,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/20/peak-xv-raises-1-3b-doubles-down-on-ai-as-global-vc-rivalry-in-india-heats-up/",
        "posted_at": "2026-02-20",
        "score": 4.6,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "posted_at": "2026-02-21",
        "score": 19.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.16745",
        "posted_at": "2026-02-21",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/20/inscope-nabs-14-5m-to-solve-the-pain-of-financial-reporting/",
        "posted_at": "2026-02-21",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/",
        "posted_at": "2026-02-21",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-02-22",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-22",
        "score": 7.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/",
        "posted_at": "2026-02-22",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/20/openai-says-18-to-24-year-olds-account-for-nearly-50-of-chatgpt-usage-in-india/",
        "posted_at": "2026-02-22",
        "score": 3.6,
        "tags": [
          "boundary_crossing"
        ]
      }
    ],
    "education": [
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.2,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://erichlof.github.io/THREE.js-PathTracing-Renderer/",
        "posted_at": "2026-02-16",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-being-a-madman-for-8-minutes.html",
        "posted_at": "2026-02-16",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/nz-is-slowly-slipping-on-the-global-corruption-index-is-is-time-for-an-anti-corruption-agency-275781",
        "posted_at": "2026-02-17",
        "score": 3.8,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://fuji.halfof8.com/",
        "posted_at": "2026-02-17",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.historytoday.com/archive/first-global-empire",
        "posted_at": "2026-02-18",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/why-some-people-think-in-words.html",
        "posted_at": "2026-02-18",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "posted_at": "2026-02-19",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/the-ancient-egyptian-book-of-the-dead-a-guidebook-for-surviving-the-afterlife.html",
        "posted_at": "2026-02-19",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-02-20",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.bbc.com/news/live/c0l9r67drg7t",
        "posted_at": "2026-02-20",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "posted_at": "2026-02-21",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/vivaldis-four-seasons-performed-on-original-baroque-instruments.html",
        "posted_at": "2026-02-21",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "posted_at": "2026-02-22",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.citriniresearch.com/p/2028gic",
        "posted_at": "2026-02-22",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "posted_at": "2026-02-15",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-recycling-strategies-fungi-affect-forests.html",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "posted_at": "2026-02-16",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-honey-bees-precisely-previously-thought.html",
        "posted_at": "2026-02-17",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "posted_at": "2026-02-17",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-fungus-species-genes-threatens-coffee.html",
        "posted_at": "2026-02-18",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005714.htm",
        "posted_at": "2026-02-18",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "posted_at": "2026-02-19",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-unique-path-poxviruses.html",
        "posted_at": "2026-02-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260218044628.htm",
        "posted_at": "2026-02-20",
        "score": 6.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-20",
        "score": 5.2,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-body-cold-menthol-cool.html",
        "posted_at": "2026-02-21",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223904.htm",
        "posted_at": "2026-02-21",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-22",
        "score": 6.8,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-bed-bugs-kryptonite-parasites-surfaces.html",
        "posted_at": "2026-02-22",
        "score": 4.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "posted_at": "2026-02-15",
        "score": 12.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/are-the-mysteries-of-quantum-mechanics-beginning-to-dissolve-20260213/",
        "posted_at": "2026-02-15",
        "score": 4.1,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-02-16",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/pulsar-found-near-the-center-of-the-milky-way-could-test-einsteins-theories-1267701/",
        "posted_at": "2026-02-16",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/2014/09/design-package-2014/",
        "posted_at": "2026-02-17",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "posted_at": "2026-02-18",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "posted_at": "2026-02-19",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/the-biophysical-world-inside-a-jam-packed-cell-20260218/",
        "posted_at": "2026-02-19",
        "score": 4.7,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "posted_at": "2026-02-20",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/hell-heron-new-dinosaur-species-with-a-head-mounted-sword-discovered-in-africa-1269018/",
        "posted_at": "2026-02-20",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/odilia-alvarado-kissimmee",
        "posted_at": "2026-02-21",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.wired.com/story/ai-weiwei-gets-artsy-fartsy-about-surveillance/",
        "posted_at": "2026-02-21",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-02-22",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/louvre-hit-with-12-million-ticket-fraud-scheme-180988236/",
        "posted_at": "2026-02-22",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://www.scmp.com/week-asia/health-environment/article/3343458/malaysia-says-no-e-waste-dumping-can-its-ban-stop-global-trade?utm_source=rss_feed",
        "posted_at": "2026-02-15",
        "score": 5.7,
        "tags": [
          "transformation",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-02-16",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
        "posted_at": "2026-02-17",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-02-17",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-02-18",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/kidde-ring-new-smoke-alarm-2026/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-02-19",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://arstechnica.com/science/2026/02/newly-hatched-chickens-form-the-same-sound-association-we-do/",
        "posted_at": "2026-02-19",
        "score": 3.4,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.scmp.com/economy/global-economy/article/3344156/china-defends-wtos-most-favoured-nation-principle-after-us-eu-challenge-rule?utm_source=rss_feed",
        "posted_at": "2026-02-20",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/meet-scotlands-whisky-sniffing-robot-dog/",
        "posted_at": "2026-02-20",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-02-21",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/trump-imposes-new-tariffs-following-supreme-court-ruling/",
        "posted_at": "2026-02-21",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-02-22",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/world/united-states-canada/article/3344236/trump-sends-great-hospital-boat-treat-sick-people-greenland?utm_source=rss_feed",
        "posted_at": "2026-02-22",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://dev.to/videosdeti/add-nix-to-your-project-one-file-zero-setup-drama-4cl4",
        "posted_at": "2026-02-15",
        "score": 9.5,
        "tags": [
          "transformation",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/julcasans/redacta-elevating-video-content-with-github-copilot-cli-kc9",
        "posted_at": "2026-02-15",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/nautechsystems/nautilus_trader",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/moonshine-ai/moonshine",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/cli-driven-component-deployment-pushing-code-to-production-in-one-command-for-visual-page-builders-279o",
        "posted_at": "2026-02-17",
        "score": 10.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/ruvnet/wifi-densepose",
        "posted_at": "2026-02-17",
        "score": 8.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/edge-rendering-vs-server-side-rendering-performance-trade-offs-explained-lmg",
        "posted_at": "2026-02-18",
        "score": 10.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/thanasistraitsis/flutter-sticky-bottom-button-beyond-the-floatingactionbutton-2i7o",
        "posted_at": "2026-02-18",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/uenyioha/prompting-techniques-that-actually-work-lessons-from-automating-architecture-analysis-57al",
        "posted_at": "2026-02-19",
        "score": 16.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/resizer/i-built-a-privacy-first-image-resizer-that-runs-entirely-in-your-browser-5dnp",
        "posted_at": "2026-02-19",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/ukgksl/how-snooki-accidentally-invented-the-influencer-era-p19",
        "posted_at": "2026-02-20",
        "score": 13.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://alexalejandre.com/programming/steve-klabnik-interview/",
        "posted_at": "2026-02-20",
        "score": 12.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/vxcontrol/pentagi",
        "posted_at": "2026-02-21",
        "score": 15.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/hypertextcoffeepot/activity-in-wonderland-distributed-tracing-with-opentelemetry-and-net-2ehe",
        "posted_at": "2026-02-21",
        "score": 11.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/huckler/pcworkman-168-when-quick-fix-took-3-weeks-data-engine-ai-context-70-performance-2d9l",
        "posted_at": "2026-02-22",
        "score": 12.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/qa-leaders/anatomy-of-a-schema-drift-incident-5-real-patterns-that-break-production-274l",
        "posted_at": "2026-02-22",
        "score": 10.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "title": "Scientists discover gene that could save bananas from deadly Panama disease",
        "summary": "A major breakthrough could help save the world’s bananas from a devastating disease. Scientists have discovered the exact genetic region in a wild banana that provides resistance to Fusarium wilt Subtropical Race 4 — a destructive strain that threatens Cavendish bananas worldwide. While this wild banana isn’t edible, the discovery gives breeders a powerful genetic roadmap to develop future bananas that are both delicious and naturally protected from this deadly pathogen.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 09:43:15 EST",
        "fetched_at": "2026-02-22T23:21:39.749557Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260220010830.htm",
        "title": "Oxford breakthrough could make lithium-ion batteries charge faster and last much longer",
        "summary": "Oxford researchers have found a way to visualize one of the most hidden — yet critical — components inside lithium-ion batteries. By tagging polymer binders with traceable markers, they revealed how these tiny materials are distributed at the nanoscale and how that affects charging speed and durability. Small manufacturing adjustments reduced internal resistance by up to 40%, potentially unlocking fastcer charging. The technique could help improve both today’s batteries and next-generation designs.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 20 Feb 2026 03:18:56 EST",
        "fetched_at": "2026-02-22T23:21:39.749505Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040818.htm",
        "title": "Scientists just mapped mysterious earthquakes deep inside Earth",
        "summary": "Scientists at Stanford have unveiled the first-ever global map of rare earthquakes that rumble deep within Earth’s mantle rather than its crust. Long debated and notoriously difficult to confirm, these elusive quakes turn out to cluster in regions like the Himalayas and near the Bering Strait. By developing a breakthrough method that distinguishes mantle quakes using subtle differences in seismic waves, researchers identified hundreds of these hidden tremors worldwide.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 20 Feb 2026 08:05:28 EST",
        "fetched_at": "2026-02-22T23:21:39.749524Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "title": "This new blood test could detect cancer before it shows up on scans",
        "summary": "A new light-based sensor can spot incredibly tiny amounts of cancer biomarkers in blood, raising the possibility of earlier and simpler cancer detection. The technology merges DNA nanotechnology, CRISPR, and quantum dots to generate a clear signal from just a few molecules. In lung cancer tests, it worked even in real patient serum samples. Researchers hope it could eventually power portable blood tests for cancer and other diseases.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 20:48:34 EST",
        "fetched_at": "2026-02-22T23:21:39.749696Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005717.htm",
        "title": "Breakthrough CRISPR system could reverse antibiotic resistance crisis",
        "summary": "Antibiotic resistance is racing toward a global crisis, with “superbugs” projected to cause over 10 million deaths annually by 2050. Now, scientists at UC San Diego have unveiled a powerful new CRISPR-based tool that doesn’t just fight resistant bacteria—it can actively strip away their drug resistance. Inspired by gene drives used in insects, the technology spreads a genetic “fix” through bacterial populations, even inside stubborn biofilms that shield microbes from antibiotics.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 18 Feb 2026 03:08:21 EST",
        "fetched_at": "2026-02-22T23:21:39.749663Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040745.htm",
        "title": "Scientists finally explain why chronic constipation treatments often fail",
        "summary": "A newly discovered bacterial duo may be the hidden cause of chronic constipation. The two microbes break down the colon’s protective mucus layer, leaving stool dry and hard — a problem traditional laxatives don’t fix. Parkinson’s patients, who often struggle with constipation years before tremors appear, have higher levels of these bacteria. Blocking the bacteria’s mucus-destroying enzyme prevented constipation in mice, hinting at a new treatment strategy.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 08:46:05 EST",
        "fetched_at": "2026-02-22T23:21:39.749561Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260218044628.htm",
        "title": "New map reveals where lethal scorpions are most likely to strike",
        "summary": "Scientists have developed a powerful new way to forecast where some of the world’s most dangerous scorpions are likely to be found. By combining fieldwork in Africa with advanced computer modeling, the team discovered that soil type is the strongest factor shaping where many lethal species live, while temperature patterns also play a key role.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 18 Feb 2026 23:36:03 EST",
        "fetched_at": "2026-02-22T23:21:39.749566Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044003.htm",
        "title": "Lab grown human spinal cord heals after injury in major breakthrough",
        "summary": "Researchers have built a realistic human mini spinal cord in the lab and used it to simulate traumatic injury. The model reproduced key damage seen in real spinal cord injuries, including inflammation and scar formation. After treatment with fast moving “dancing molecules,” nerve fibers began growing again and scar tissue shrank. The results suggest the therapy could eventually help repair spinal cord damage.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 07:41:25 EST",
        "fetched_at": "2026-02-22T23:21:39.749691Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260221000321.htm",
        "title": "Common pneumonia bacterium may fuel Alzheimer’s disease",
        "summary": "A common bacterium best known for causing pneumonia and sinus infections may also play a surprising role in Alzheimer’s disease. Researchers found that Chlamydia pneumoniae can invade the retina and brain, where it sparks inflammation, nerve cell death, and the buildup of amyloid-beta—the hallmark protein linked to Alzheimer’s. Higher levels of the bacterium were found in people with Alzheimer’s, especially those carrying the high-risk APOE4 gene, and were tied to more severe cognitive decline.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 21 Feb 2026 00:43:23 EST",
        "fetched_at": "2026-02-22T23:21:39.749468Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          }
        ],
        "structural_score": 7,
        "timeliness_score": 4,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.1,
        "temp_score_trend": 4.9
      },
      {
        "url": "https://phys.org/news/2026-02-language-barriers-international-diffusion-knowledge.html",
        "title": "Language barriers slow down the international diffusion of knowledge, study finds",
        "summary": "Rapid technological and scientific advances have fueled a huge wave of innovation over the past decades. The speed of global innovation is known to be dependent on the exchange of knowledge and skills between different nations worldwide.",
        "source": "phys.org",
        "published": "Sun, 22 Feb 2026 14:10:01 EST",
        "fetched_at": "2026-02-22T23:21:41.043115Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 7,
        "timeliness_score": 3,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 5.799999999999999,
        "temp_score_trend": 4.199999999999999
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
        "summary": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers — Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>",
        "source": "venturebeat.com",
        "published": "Thu, 22 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805375Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 13
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 41,
        "timeliness_score": 3,
        "final_score": 22.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "source": "venturebeat.com",
        "published": "Fri, 16 Jan 2026 14:01:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805395Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 39,
        "timeliness_score": 3,
        "final_score": 21.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "source": "venturebeat.com",
        "published": "Wed, 07 Jan 2026 20:00:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805433Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 3,
        "final_score": 17.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "source": "venturebeat.com",
        "published": "Mon, 19 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805388Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 3,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805438Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "source": "venturebeat.com",
        "published": "Tue, 13 Jan 2026 13:00:00 GMT",
        "fetched_at": "2026-02-22T23:21:29.805423Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 3,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "title": "Researchers have figured out how to make airplanes fly on landfill gas",
        "summary": "Specially designed efficient catalysts are at the heart of a reactor that makes sustainable aviation fuels from methane-rich gases created when waste decomposes",
        "source": "www.anthropocenemagazine.org",
        "published": "Thu, 12 Feb 2026 13:00:16 +0000",
        "fetched_at": "2026-02-22T23:21:33.664227Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "value_redefinition",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://techcrunch.com/2026/02/20/peak-xv-raises-1-3b-doubles-down-on-ai-as-global-vc-rivalry-in-india-heats-up/",
        "title": "Peak XV raises $1.3B, doubles down on AI as global VC rivalry in India heats up",
        "summary": "Peak XV says most of its new capital will target India as the firm prioritizes AI, fintech and cross-border bets while navigating recent partner departures.",
        "source": "techcrunch.com",
        "published": "Fri, 20 Feb 2026 15:10:40 +0000",
        "fetched_at": "2026-02-22T23:21:30.849189Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 7,
        "timeliness_score": 4,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://techcrunch.com/2026/02/20/inscope-nabs-14-5m-to-solve-the-pain-of-financial-reporting/",
        "title": "InScope nabs $14.5M to solve the pain of financial reporting",
        "summary": "The startup, founded by accountants who worked at Flexport, Miro, Hopin and Thrive Global, automates the difficulties of prepping financial statements.",
        "source": "techcrunch.com",
        "published": "Fri, 20 Feb 2026 19:24:57 +0000",
        "fetched_at": "2026-02-22T23:21:30.849170Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 4,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
        "title": "Why the Moltbook frenzy was like Pokémon",
        "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;",
        "source": "www.technologyreview.com",
        "published": "Mon, 09 Feb 2026 17:02:56 +0000",
        "fetched_at": "2026-02-22T23:21:28.625261Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          }
        ],
        "structural_score": 3,
        "timeliness_score": 5,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "title": "How one California school came together to pack 20,000 meals for the holidays",
        "summary": "At an Elk Grove high school in Sacramento County, students worked a night in the cafeteria to combat global food insecurity.",
        "source": "edsource.org",
        "published": "Mon, 08 Dec 2025 08:03:00 +0000",
        "fetched_at": "2026-02-22T23:21:56.112732Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "title": "Fresno Unified error skews state teacher data, analysis shows",
        "summary": "A mistake made by a staff member deflated claims that the state added 3,000 new teachers to its ranks between 2020 and 2024.",
        "source": "edsource.org",
        "published": "Tue, 19 Aug 2025 19:26:35 +0000",
        "fetched_at": "2026-02-22T23:21:56.113638Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 2
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "title": "Rethinking screen time in California classrooms",
        "summary": "Effective instruction requires a balance between traditional methods and digital engagement. Here's what school districts, families and the state must do.",
        "source": "edsource.org",
        "published": "Tue, 20 Jan 2026 02:58:44 +0000",
        "fetched_at": "2026-02-22T23:21:56.112135Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 3,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "title": "The path to universal preschool in California: Avoiding past mistakes",
        "summary": "California is expanding its transitional kindergarten (TK) to a universal prekindergarten (UPK) system, and must learn from the mistakes of the 1971 federal effort to create a universal early care and education system, which was vetoed by President Nixon.",
        "source": "edsource.org",
        "published": "Tue, 23 Dec 2025 07:03:30 +0000",
        "fetched_at": "2026-02-22T23:21:56.112364Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "title": "California schools prepare to introduce universal reading screening",
        "summary": "A quick screening test will be administered to all students in kindergarten through second grade to detect possible reading difficulties, but it is not intended to be a final diagnosis.",
        "source": "edsource.org",
        "published": "Tue, 20 May 2025 07:05:00 +0000",
        "fetched_at": "2026-02-22T23:21:56.114300Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "title": "As we expand universal preschool access, let’s ensure teachers mirror their students’ ethnicity",
        "summary": "Author&#8217;s original hed: As Universal Preschool Access Expands to Reach More Families of Color, So Do Inequitable Practices Such as Racial Bias, Exclusionary Discipline and Lack of Cultural Representation, Leading to a Crisis for Black Boys As California progresses toward universal preschool access, the need increases for training, hiring and retaining early childhood male educators who are racially and ethnically representative of the children... <span class=\"read-more\"><a href=\"https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393\">read more</a></span>",
        "source": "edsource.org",
        "published": "Tue, 09 Jul 2024 15:53:36 +0000",
        "fetched_at": "2026-02-22T23:21:56.116734Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "title": "Survey: Californians are worried about student health, lukewarm toward a state school bond",
        "summary": "The annual Public Policy Institute of California survey on education issues found wide support for universal TK and teaching about slavery but divisions on transgender issues.",
        "source": "edsource.org",
        "published": "Thu, 11 Apr 2024 05:11:37 +0000",
        "fetched_at": "2026-02-22T23:21:56.117349Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://live.xweather.com/",
        "title": "Xweather Live – Interactive global vector weather map",
        "summary": "<a href=\"https://news.ycombinator.com/item?id=47111626\">Comments</a>",
        "source": "news.ycombinator.com",
        "published": "Sun, 22 Feb 2026 15:12:15 +0000",
        "fetched_at": "2026-02-22T23:22:04.515013Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2026/supporting-new-teachers-retention/750763",
        "title": "How districts can fix the teacher ‘support shortage’",
        "summary": "California's teacher workforce is recovering, but retention is still a challenge, and districts need to invest in comprehensive support systems to ensure teachers stay in the profession and thrive.",
        "source": "edsource.org",
        "published": "Mon, 09 Feb 2026 23:38:55 +0000",
        "fetched_at": "2026-02-22T23:21:56.111908Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "title": "Federal appeals court pauses ruling on student gender identity disclosure in California",
        "summary": "An appeals court panel wrote that it is “skeptical” of the lower court’s decision, which would challenge policies adopted by 598 of the state’s nearly 1,000 local school districts.",
        "source": "edsource.org",
        "published": "Thu, 08 Jan 2026 00:04:46 +0000",
        "fetched_at": "2026-02-22T23:21:56.112242Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      }
    ],
    "mycotech": [
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003638",
        "title": "Metabolic modeling reveals determinants of prebiotic and probiotic treatment efficacy across multiple human intervention trials",
        "summary": "<p>by Nick Quinn-Bohmann, Alex V. Carr, Sean M. Gibbons</p>\n\nPrebiotic, probiotic, and combined (synbiotic) interventions often show variable outcomes across individuals, driven by complex interactions between introduced biotics, the endogenous microbiota, and the host diet. Predicting individual-specific success or failure of probiotic and prebiotic therapies remains a major challenge. Here, we leverage microbial community-scale metabolic models (MCMMs) to predict probiotic engraftment and microbiota-mediated short-chain fatty acid (SCFA) production in response to probiotic and prebiotic interventions. Using data from two human clinical trial cohorts, testing a five-strain probiotic combined with the prebiotic inulin designed to improve metabolic health and an eight-strain probiotic designed to treat recurrent <i>Clostridioides difficile</i> infections, respectively, we show that MCMM-predicted engraftment largely agrees with measurements, achieving 75%–80% accuracy. Engraftment probabilities varied across taxa. MCMMs captured treatment-driven shifts in predicted SCFA production, and higher model-predicted growth rates of <i>Akkermansia muciniphila</i> were negatively associated with glucose area under the curve (AUC) in the first trial, providing clues about the mechanisms underlying treatment efficacy. Extending these models to a third human cohort undergoing a healthy diet and lifestyle intervention revealed substantial inter-individual variability in predicted responses to increasing dietary fiber, which were significantly associated with baseline-to-follow-up changes in cardiometabolic health markers. Finally, our simulation results suggested that personalized prebiotic selection may further enhance probiotic efficacy. Together, these findings demonstrate the potential of metabolic modeling to guide personalized microbiome-mediated interventions.",
        "source": "journals.plos.org",
        "published": "2026-02-19T14:00:00Z",
        "fetched_at": "2026-02-22T23:22:10.380774Z",
        "tags": [
          {
            "name": "transformation",
            "score": 8
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "title": "Scientists discover gene that could save bananas from deadly Panama disease",
        "summary": "A major breakthrough could help save the world’s bananas from a devastating disease. Scientists have discovered the exact genetic region in a wild banana that provides resistance to Fusarium wilt Subtropical Race 4 — a destructive strain that threatens Cavendish bananas worldwide. While this wild banana isn’t edible, the discovery gives breeders a powerful genetic roadmap to develop future bananas that are both delicious and naturally protected from this deadly pathogen.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 09:43:15 EST",
        "fetched_at": "2026-02-22T23:22:09.263115Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "title": "A hidden Aloe vera compound takes aim at Alzheimer’s",
        "summary": "Scientists have uncovered promising clues that compounds found in Aloe vera could play a role in fighting Alzheimer’s disease. Using advanced computer modeling, researchers discovered that beta-sitosterol—a natural plant compound—strongly interacts with two key enzymes involved in memory loss and cognitive decline. The compound showed stability, strong binding, and favorable safety indicators, making it a standout candidate for future drug development.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 08 Feb 2026 07:57:41 EST",
        "fetched_at": "2026-02-22T23:22:09.263263Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003631",
        "title": "Recurrent mutations in the stress regulator Cap1 reveal a trade-off between azole resistance and oxidative stress response in <i>Candida albicans</i>",
        "summary": "<p>by Xin Zhou, Audrey Hilk, Norma V. Solis, Nancy Scott, Christopher Zajac, Scott G. Filler, Anna Selmecki</p>\n\nDrug resistance is a critical challenge in treating life-threatening fungal infections. Here, we uncover a mechanism of acquired azole resistance in <i>Candida albicans</i> through mutations in <i>CAP1</i>, encoding a conserved fungal transcription factor that mediates the oxidative stress response. We analyzed 300 clinical isolates and identified 25 distinct <i>CAP1</i> missense or nonsense mutations, with many occurring within the DNA-binding domain. We identified two nearly identical <i>CAP1</i> heterozygous nonsense mutations, one in an isolate obtained from a bloodstream infection and one in a population of cells undergoing adaptation to fluconazole <i>in vitro</i>. Both <i>CAP1</i> nonsense mutations resulted in loss of the C-terminal nuclear export signal, leading to nuclear retention of Cap1 and subsequent activation of genes associated with the oxidative stress response and drug transport. The <i>CAP1</i> C-terminal truncations conferred significant fitness advantages in the presence of fluconazole, both <i>in vitro</i> and in a murine model of candidiasis. Strikingly, we discovered a therapeutic vulnerability: azole concentrations above the minimal inhibitory concentration were fungicidal to mutants with the <i>CAP1</i> C-terminal truncation. The fungicidal effect was attributed to both elevated azole-induced reactive oxygen species and a compromised oxidative stress response in Cap1-truncated cells. Our results provide novel characterization of <i>de novo</i> <i>CAP1</i> point mutations emerging in both laboratory and clinical contexts, elucidate the mechanisms underlying Cap1-regulated stress responses, and reveal a potential therapeutic target for overcoming drug resistance in <i>C. albicans</i> infections.",
        "source": "journals.plos.org",
        "published": "2026-02-02T14:00:00Z",
        "fetched_at": "2026-02-22T23:22:10.380886Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 14,
        "timeliness_score": 1,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "title": "This weird deep-sea creature was named by thousands of people online",
        "summary": "A newly discovered deep-sea creature has become an unlikely Internet star. After appearing in a popular YouTube video, a rare chiton found nearly three miles beneath the ocean surface sparked a global naming effort, drawing more than 8,000 suggestions from people around the world. Scientists ultimately chose the name Ferreiraella populi, meaning “of the people,” honoring the public that helped bring it into the scientific record.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 07 Feb 2026 23:32:36 EST",
        "fetched_at": "2026-02-22T23:22:09.263254Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "title": "This tiny molecular trick makes spider silk almost unbreakable",
        "summary": "Scientists have cracked a key mystery behind spider silk’s legendary strength and flexibility. They discovered that tiny molecular interactions act like natural glue, holding silk proteins together as they transform from liquid into incredibly tough fibers. This same process helps create silk that’s stronger than steel by weight and tougher than Kevlar.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 01:22:10 EST",
        "fetched_at": "2026-02-22T23:22:09.263267Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://phys.org/news/2026-02-body-cold-menthol-cool.html",
        "title": "How your body senses cold—and why menthol feels cool",
        "summary": "When you step outside on a winter morning or pop a mint into your mouth, a tiny molecular sensor in your body springs into action, alerting your brain to the sensation of cold. Scientists have now captured the first detailed images of this sensor at work, revealing exactly how it detects both actual cold and the perceived cool of menthol, a compound derived from mint plants.",
        "source": "phys.org",
        "published": "Sat, 21 Feb 2026 08:00:09 EST",
        "fetched_at": "2026-02-22T23:22:08.108858Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260218044628.htm",
        "title": "New map reveals where lethal scorpions are most likely to strike",
        "summary": "Scientists have developed a powerful new way to forecast where some of the world’s most dangerous scorpions are likely to be found. By combining fieldwork in Africa with advanced computer modeling, the team discovered that soil type is the strongest factor shaping where many lethal species live, while temperature patterns also play a key role.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 18 Feb 2026 23:36:03 EST",
        "fetched_at": "2026-02-22T23:22:09.263120Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "title": "Researchers have figured out how to make airplanes fly on landfill gas",
        "summary": "Specially designed efficient catalysts are at the heart of a reactor that makes sustainable aviation fuels from methane-rich gases created when waste decomposes",
        "source": "www.anthropocenemagazine.org",
        "published": "Thu, 12 Feb 2026 13:00:16 +0000",
        "fetched_at": "2026-02-22T23:22:11.747159Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "value_redefinition",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003577",
        "title": "Piriform seizures mediated by the piriform-entorhino-dentate circuit induce brain-wide functional reorganization in mice",
        "summary": "<p>by Yan Tao, Yuxin Zhao, Wenqi Zhong, Jiajia Zhang, Hongyan Zhu, Xutao Zhu, Zikun Wang, Na Wang, Liqin Yang, Fuqiang Xu, Ruiqi Wu</p>\n\nSystematic identification of global epileptic reorganization and critical seizure-controlling circuits is essential for comprehending epilepsy pathophysiology and for developing network-guided targeted therapies. The piriform cortex (PC) is a recognized epileptogenic region, but how its hyperactivity reshapes whole-brain dynamics and which specific circuits mediate seizures remains unclear. Through multimodal integration of optogenetics, fMRI, electrophysiology, Ca<sup>2+</sup> imaging, neural tracing, and circuit-specific manipulation, we mapped the whole-brain dynamics following optogenetic stimulation of PC and identified the fundamental circuit governing piriform seizures. We observed pronounced generalized seizures in mice via repeated optogenetic stimulation of PC <i>Vglut1</i>+ neurons. Optogenetic kindling of PC<sup>Vglut1</sup> induced widespread blood-oxygen-level-dependent (BOLD) signal hyperactivation and resting-state functional connectivity (rsFC) alterations, notably sustained hyperactivation in the lateral entorhinal cortex (Lent) and enhanced PC-Lent rsFC. Chronic elimination of Lent neurons receiving PC projections significantly decreased the Lent-dentate gyrus (DG) rsFC. Disruption of the PC-Lent or Lent-DG circuit effectively suppressed PC-stimulation-triggered seizures and brain-wide hyperactivation. Our findings demonstrate the dominant role of the PC<sup>Vglut1</sup>-Lent<sup>glut</sup>-DG circuit in mediating piriform seizures and driving their resulting brain-wide functional reorganization, offering new insights for targeted epilepsy treatments.",
        "source": "journals.plos.org",
        "published": "2026-02-12T14:00:00Z",
        "fetched_at": "2026-02-22T23:22:10.380825Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 1,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "title": "Inside Thomas Edison’s Botanical Laboratory",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>Thomas Edison and his family had a ritual. Every winter, they would leave freezing cold New Jersey and head down to Fort Myers, Florida. Back then, Fort Myers was out there. Think swamps and mosquitoes. It was actually easier to get around by boat than over land.</p>\n<p>The Edisons would do vacation stuff: go fishing, go on boat rides, collect interesting plants. And in 1914, they invited a different branch of American inventing royalty to join them. That year, Henry Ford, of the Model T Ford, came down to Florida with his wife, Clara.</p>\n<p>Ford must have been psyched because Edison was actually his hero. They’d met briefly years before at a conference when Ford was still a low-level employee at an Edison company. Now they were meeting on something like equal terms.</p>\n<p>So to celebrate the occasion, Ford had some Model Ts shipped down to Fort Myers. Everyone went out joyriding around the swamps. The cars flooded, their campsite got soaked. Clara Ford was really afraid of snakes, and there were snakes everywhere. Henry tried to scare them away by shooting off a pistol. Needless to say, it was a trip.</p>\n<p>But soon, once the smoke from Ford’s pistol had cleared and the Model Ts had dried out, Edison and Ford would become more than just travel buddies. They were actually about to embark on an enormous inventing project, a project that would turn Edison’s Florida house into a full-fledged botanical laboratory and would become the last great obsession of Edison’s life.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. Today’s episode is brought to you in partnership with Fort Myers – Islands, Beaches and Neighborhoods. Maybe when you think of Henry Ford and Thomas Edison, you think technology, cars, light bulbs, electricity. But the success of both of their inventions depended on plants. That is why they had come to Florida: to experiment.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106299/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Plants were actually the reason Thomas Edison had fallen in love with Fort Myers in the first place. Around 30 years before that camping trip with Ford, Edison was working away in his Menlo Park lab on one of his most famous projects.</p>\n<p><strong>Karen Maxwell:</strong> Many people are under the misimpression he invented the light bulb. He actually perfected it.</p>\n<p><strong>Kelly: </strong>This is Karen Maxwell. She’s the horticulture director at the Edison and Ford Winter Estates.</p>\n<p><strong>Karen: </strong>So, at this time, there are about 20 different varieties of incandescent light bulbs, but none of them burned for very long.</p>\n<p><strong>Kelly:</strong> The problem was this teeny tiny piece inside the bulb called a filament. When electricity passes through, the filament heats up and glows and we get light. But none of these early filaments could glow long enough to make a practical light bulb.</p>\n<p>So Edison set out to change that, testing thousands and thousands of different materials. Cotton, platinum, cedar, and finally, bamboo.</p>\n<p><strong>Karen: </strong>And he had his team—I’m glad I wasn’t one of them then—they stayed up and did shifts to record how long it burned. That filament burned for 1,200 hours. And that made the incandescent light bulb a national product.</p>\n<p><strong>Kelly:</strong> Edison, already a famous inventor, was now a legend. But by the end of the project, his personal life was a mess.</p>\n<p><strong>Karen:</strong> He was 38 years old, burned out, and had lost his first wife, Mary. Three children. His doctor says, Thomas, you need to go south, take a vacation, and take a break. He ends up arriving in St. Augustine during the winter and finds that is really too cold. It didn’t meet what his doctor had prescribed. So one of his friends takes him further down the river and they end up going by the property, which is currently today what we know as the Edison and Ford Winter Estates. What does he see but stands of bamboo growing along the riverside? He bought it on the spot.</p>\n<p><strong>Kelly:</strong> Edison remarried, and soon he and his second wife, Mina, started transforming the Florida property and its stand of bamboo into their wintertime home away from home. Edison even had an old laboratory shipped down from New Jersey in case inspiration struck while he was on vacation. You know, his lab away from lab.</p>\n<p>At first, he did some experimenting with bamboo, but then in 1905, the invention of the tungsten filament for the light bulb made the bamboo one obsolete. Soon enough, though, he would have another project to focus on.</p>\n<p>After the Fords joined the Edison family vacation in 1914, it was time for Ford to invite Edison on a trip. They went to San Francisco, and Ford introduced Edison to some friends: a botanist named Luther Burbank, who was interested in plant hybridization, and the tire magnate, Harvey Firestone, of Firestone Tires. It wasn’t long before their conversation turned to rubber.</p>\n<p>And the thing was, in order to make cars, you needed tires, and in order to make tires, you needed rubber. Back then, there was no such thing as synthetic rubber. All of it came from plants. Most natural rubber was grown in Southeast Asia, in British and Dutch colonies, and that meant the British and Dutch set rubber prices. The crew became convinced that America needed its own domestic rubber supply. Edison got to work right away.</p>\n<p><strong>Karen:</strong> So he starts looking for a product that can grow quickly, produce latex. Latex is what makes rubber. Latex is a milky white substance. If you break open the stem, out comes a sticky white milky product. That is latex and that is the basis of all natural rubber.</p>\n<p>Over 17,000 plants are brought in and studied. There were botanists, volunteers, they even engaged the Union Pacific Railroad, who instructed every section chief to collect any plants growing along their extensive miles of right-of-way and forward them to Edison’s laboratory.</p>\n<p><strong>Kelly:</strong> The Florida House essentially became a latex distilling factory. Today, if you visit, you can still see a lot of these plants that Edison was experimenting on. There’s a spiny vine called crown of thorns, which looks like a cactus; a scrubby desert shrub called guayule, which is native to Mexico; and the most spectacular specimen, or at least the biggest, was the banyan tree.</p>\n<p><strong>Karen:</strong> It’s been in place for 100 years. And over the years, it’s grown extensively. We’ve had to maintain trimming so it doesn’t just eat up the buildings. The first impression people have is they’re looking at a forest of trees.</p>\n<p><strong>Kelly</strong>: Today, the tree covers nearly an entire acre of land. It’s the largest banyan tree in the continental U.S. But unfortunately for Edison, it just did not produce enough latex.</p>\n<p><strong>Karen:</strong> In 1928, he discovers, right here in his backyard, the plant that produces the most latex is goldenrod.</p>\n<p><strong>Kelly: </strong>Goldenrod is a very fast-growing weed with yellow flowers. Looks a lot like ragweed. So Edison ripped out rows and rows of his wife Mina’s citrus trees to plant goldenrod, which I’m sure she wasn’t thrilled about.</p>\n<p><strong>Karen:</strong> He mows them all down and he transforms their estate-like atmosphere to just a conglomeration of disorderly beds with markers and irrigation ditches all around, 500 plots of yellow goldenrod. And as you can imagine, that did little to kindle her enthusiasm for his work.</p>\n<p><strong>Kelly:</strong> Speaking of Mina’s view of his work, she was annoyed about the citrus trees, yes, but she was also worried about her husband’s health. Edison was in his 80s now and still keeping pretty long hours.</p>\n<p>Mina wrote, “He thinks of nothing else now. He has no time for anything else, no recreation,” and, “Everything turned to rubber in the family. We talked rubber, thought rubber, dreamed rubber.”</p>\n<p>There was also some tension between her and Henry Ford. For one thing, Ford had bought the house right next door. That’s why the museum today is known as the Edison and Ford Estates. And another thing: Ford had convinced Edison to let him dismantle his Florida lab and ship it up to Michigan. Because Ford wanted to start a museum dedicated to American innovation, and he said he simply needed his hero’s lab. Mina was not too happy about this. Though, with the help of Ford and Firestone, Edison did end up building a brand new botanical lab.</p>\n<p>Still, by the end of the 1920s, Edison’s health got worse. He came down with pneumonia and by the fall of 1931 was bedridden in New Jersey. At one point on his deathbed, as he was slipping in and out of consciousness, someone came in with a package sent from the Florida house.</p>\n<p>Inside was a small piece of rubber made from Edison’s goldenrod plants. According to biographer Michele Albion, he had a moment of lucidity, and then sunk into a coma. Just a few days later, he died on October 18th, 1931. The Edison family kept the botanical research lab going until 1934, when it was transferred over to the Department of Agriculture.</p>\n<p><strong>Karen:</strong> But it turned out his vision of the importance became true because when World War II came about, Japan captured Malaysia, Singapore, and most of the Pacific Rim rubber plantations.</p>\n<p><strong>Kelly: </strong>During the war, there were serious rubber shortages in the U.S. The government rationed gasoline and lowered speed limits just to make tires last longer.</p>\n<p><strong>Karen:</strong> But it was shortly after that that synthetic rubber ended the goldenrod destiny. That was in 1944. And It was pretty much what Tungsten did for his carbonized bamboo filament, the synthetic rubber did to his goldenrod rubber research. But he was right. I mean, he kept people going in the right direction. Without that foundation, we probably wouldn’t have been here today.</p>\n<p><strong>Kelly: </strong>Today, the Ford and Edison Winter Estates are combined into one big museum property. You can spend hours wandering around the grounds and seeing many of the plants that we talked about in this episode. The bamboo, the goldenrod, the banyan tree, and of course, the botanical laboratory itself.</p>\n<p><strong>Karen: </strong>It’s a 21-acre paradise of discovery for people that enjoy gardens and enjoy the different textures, the structures, the colors. There’s something blooming every single day. Many, many things.</p>\n<p><strong>Kelly:</strong> In our episode description, we will post a link to more info about visiting the Edison and Ford winter estates. And if you enjoyed today’s show, check out another episode of ours called <a href=\"https://www.atlasobscura.com/articles/podcast-fordlandia\">Fordlandia</a>. It’s all about Henry Ford’s very unsuccessful attempt to start an industrial rubber town in Brazil.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. This episode was produced by Amanda McGowan. The production team for this episode includes Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Jerome Campbell, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 28 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042271Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "title": "Atlas Obscura’s Guide to Sun Valley, Idaho’s Most Fascinating Places",
        "summary": "<p>From top to bottom, Sun Valley is full of surprises. Only in this fascinating pocket of central Idaho can you experience an annual heritage festival that parades thousands of sheep from the mountains to Main Street by day, then discover some of the darkest night skies in the world for mind-blowing star gazing.</p>\n<p>In between, you’ll relax in a botanical garden’s meditative nook, and visit the gravesite of one of the world’s most notable writers and explore a moon-like national park full of caves and lava flows. Enjoy this guide to 10 wonderful ways to start your Sun Valley adventure.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">The Roundhouse</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106296/image.jpg\" width=\"auto\" /></figure>\n<p>The Roundhouse, a staple of Sun Valley Resort since 1939, elevates any dining experience—literally. Located 7,700 feet above sea level on Bald Mountain, the restaurant has been a featured fine dining spot since 1939, and is open seasonally, December through March. The octagonal restaurant, featuring 46 windows, is only accessible only by gondola, and the sweeping views of the entire valley make the views as impressive as the menu. Inside oozes with a ski chalet-style, cozy ambiance, especially the four-sided fireplace. A popular starter, the Fondue For Two, comes with artisan bread, Granny Smith apples, grapes, and gherkins. You can also add specialty meats and vegetables for an extra charge. A Wagyu burger, lobster rolls, scallops, and elk Swedish meatballs all make the menu here.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Central Idaho Dark Sky Reserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106289/image.jpg\" width=\"auto\" /></figure>\n<p>Grab your tent and experience the awe-inspiring wonder of Central Idaho’s starry, night sky in the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/the-dark-skies-of-sun-valley-id/\">Central Idaho Dark Sky Reserve</a>. One of the last remaining areas of this level of nighttime natural darkness in the world, the reserve encompasses just under 1,500 miles of public lands inside the Sawtooth National Forest. Certified by the International Dark Sky Association in 2017, and given its highest “gold tier” status, the reserve features an ultra-dark core, plus dark periphery that helps protect the central dark area. Meteor showers, lunar eclipses, spring equinox and the summer solstice are just a few of the many public viewing events held at the reserve annually. The protected wilderness areas under these dark skies are also home to a stunning array of wildlife, including bears, wolverines, elk, wolves, and sandhill cranes.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Trailing of the Sheep</strong> <strong>Festival</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106286/image.jpg\" width=\"auto\" /></figure>\n<p>Each fall, a woolly throng of sheep, roughly 1,200 in all, parade down the main street of Ketchum, Idaho, for the <a href=\"https://visitsunvalley.com/events/annual-trailing-of-the-sheep-festival/\">Trailing of the Sheep Festival</a>. The treasured annual event commemorates the time-honored migration of sheep from Idaho’s high mountain summer pastures to the warmer, grazing and lambing grounds found farther south. For five days, the community celebrates the history, culture, and traditions of the region’s longstanding sheep ranchers, which include Basques, Peruvians, and Scots. Signature events include lamb-centered culinary classes, woolmaking workshops, a heritage fair, and national sheepdog trials. The 2026 festival is October 7-11.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Craters of the Moon National Monument and Preserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106287/image.jpg\" width=\"auto\" /></figure>\n<p>A trip to Central Idaho’s Snake River Plain is just about as close to the moon as most of us will ever get. Aptly described as “a weird and scenic landscape” by President Calvin Coolidge when he established the 750,000-acre federally protected site in 1924, the <a href=\"https://www.atlasobscura.com/places/craters-of-the-moon-national-monument-and-preserve\">Craters of the Moon National Monument and Preserve</a> features a vast, lunar-like landscape of lava flows, cinder cones, and sagebrush. The unique environment was created thousands of years ago by a series of major eruptions along the 52-mile stretch of deep cracks in the Earth’s crust called the Great Rift. For generations, the park has garnered attention and profound fascination, and the wild terrain even served as a training ground for Apollo astronauts in the 1960s. Today, explorers enjoy discovering the park’s many lava tube caves and trails, and viewing the impressive overlooks while driving along the 7-mile Loop Road. Nature lovers and photographers also flock to the park for its surprising diversity of birds and other wildlife, plus it’s a designated dark sky park.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>Sun Valley Museum of Art</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106293/image.jpg\" width=\"auto\" /></figure>\n<p>In downtown Ketchum, the <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> is just one of the many ways to explore the rich culture of the region—off the slopes. Now an integral part of Sun Valley’s arts and culture community, this free museum opened in 1971 and has grown to feature works from greats like Andy Warhol to important pieces from local and regional artists. Equal parts museum and educational hub, the center also features interesting lecture series, live music, films, and hands-on art classes and workshops throughout the year. The exhibit, \"Hidden Gems: Idaho Collects,\" brings art held in private collections in the region into public view through February 28, 2026. The exhibit aims to illuminate the region's community through the art they make and collect</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">Pioneer Saloon</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106285/image.jpg\" width=\"auto\" /></figure>\n<p>One part time capsule, one part fine dining, the Pioneer Saloon is a beloved go-to for Ketchum locals and visitors alike. Located on Main Street, and affectionately called “the Pio,” the <a href=\"https://visitsunvalley.com/dining-shopping/the-pioneer-saloon/\">Pioneer Saloon</a> opened in the 1940s as a casino, despite gambling being outlawed in Idaho. Originally called the Commercial Club, the gambling hub closed its doors after just a few years, and the American Legion turned it into a meeting hall. For a short time, the facility also served as a dry goods store until, in 1950, a man named Whitey Hirschman, turned it back into a casino. Containing decades of local lore and history, the saloon won a 2025 James Beard America's Classics Award. Today, the menu consists of hearty steaks, prime rib, ribs, and seafood, including Idaho trout. Order the signature “Jim Spud,” and you’ll get a hot baked potato with teriyaki beef, cheese, and other toppings. There’s even a “Hemingway Margarita” that pays homage to the famed author whose final resting place is in Sun Valley. Amid the rustic décor inside, you’ll find antiques and artifacts, including Hemingway’s hunting rifle, Western posters and artwork, a Native American canoe and arrowheads, and more.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ernest Hemingway’s Grave</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106288/image.jpg\" width=\"auto\" /></figure>\n<p>Despite Ernest Hemingway’s flamboyant, hard-living nature, the <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">famed writer’s final resting place</a> is a simple slab in a Sun Valley cemetery. Known for his heavy drinking, hunting, and womanizing lifestyle, Hemingway lived all over, from Spain and Cuba to Florida, penning works like, “The Sun Also Rises,” “For Whom the Bell Tolls,” and the Pulitzer Prize-awarded “The Old Man and the Sea.” He visited central Idaho many times before moving to the area prior to his death in 1961. Placed alongside his wife, Mary, under two towering spruce trees, the grave is a modest rectangular marker including just the writer’s name and dates of birth and death. In addition to the expected flowers, fans also pay respects by leaving behind booze bottles, coins, matches, and pens.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Sawtooth Botanical Garden</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106297/image.jpg\" width=\"auto\" /></figure>\n<p>For a serene escape, head to the <a href=\"https://visitsunvalley.com/services/sawtooth-botanical-garden\">Sawtooth Botanical Garden</a> in Ketchum. Located on five acres, the garden, which is also an educational non profit, centers on five major display gardens that represent the varied biomes in central Idaho. One must-see feature is the colorful Tibetan prayer wheel in the Garden of Infinite Compassion. It’s the only such wheel commissioned and blessed by the Dalai Lama in North America and the only one powered by flowing water. The 1,100-pound wheel is said to symbolize peace, healing and the dissemination prayers when turned.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Wood River Museum of History &amp; Culture</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106283/image.jpg\" width=\"auto\" /></figure>\n<p>This free cultural museum in downtown Ketchum celebrates the rich and varied history of central Idaho, from its native people and immigrants to the iconic Bald Mountain and its effect on the local landscape. One exhibit at the <a href=\"https://visitsunvalley.com/to-do/wood-river-museum-of-history-and-culture/\">Wood River Museum</a>, “A Writer in the New Country: Hemingway in 1939,” highlights Ernest Hemingway’s first trip to Sun Valley, a place that was dear to the writer up until his death in 1961. Sheep shears, a telegraph key, and vintage skis are all part of the interactive Cabinet of Wonders, which houses important regional artifacts. At the museum’s entrance, another exhibit honors the Shoshone-Bannock native peoples, who first inhabited central Idaho.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ore Wagon Museum</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106298/image.jpg\" width=\"auto\" /></figure>\n<p>This <a href=\"https://visitsunvalley.com/events/ore-wagon-museum/\">history museum in Ketchum</a> highlights the importance of ore wagons during the region’s rich mining boom of the 1880s. These sturdy wagons, donated to the museum by the Lewis family, whose Fast Freight Line was integral in transporting silver ore from remote mines to in-town railheads, are reportedly the only of their kind in existence. In honor of its mining roots, the city hosts a heritage festival, Wagon Days, every Labor Day weekend. The beloved event features live music, food vendors, cultural presentations, and culminates with the Big Hitch, a parade of these historic, non-motorized vehicles that served as the backbone of the region’s economy before the development of the railroads.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 26 Jan 2026 14:00:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042281Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042294Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "title": "Pedro Rodriguez Is on a Quest for Freshness",
        "summary": "<p>When Pedro Rodriguez is in his Kissimmee, Florida restaurant, Sajoma Latin Fusion, he makes sure to check in on the kitchen. And when he does, there’s a rule that all of his cooks must follow.</p>\n<p>“I better not catch you with anything that’s artificial,” he says. Sajoma’s sancocho, for example, is made from scratch, not with bouillon, which many cooks use to build flavor quickly.</p>\n<p>The approach has paid off. Sajoma has developed an avid following in Central Florida for its approach to Latin cuisine, rooted in good ingredients and creative cooking. Pedro, gregarious and perceptive with a quick smile and a salt and pepper beard, is proud of his brainchild. He’s a grocery supplier by trade; the restaurant business is relatively new for him.</p>\n<p>Sajoma is Pedro’s most personal project yet, the capstone of a lifelong obsession with good food and good produce. And it all started on his family’s farm.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106304/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Feeding Off the Land</h3>\n<p>Until the age of 12, Pedro grew up in the town of San Jose de las Matas in the Dominican Republic. The municipality is known for its natural beauty and mineral water. “It’s almost like one of the greenest towns there,” he says. Sajoma, as the town is called for short, boasts dramatic hills, lush vegetation, and rolling rivers.</p>\n<p>And even in a beautiful town, Pedro lived a particularly idyllic life. His family owned a 120-acre farm with animals like cows, chickens, and goats, and crops including rice, beans, coffee, and yams. “We pretty much used to feed off the land,” he says. Beef was one of the only basic foodstuffs that he recalls leaving their property to obtain.</p>\n<p>The family home sat on the top of a hill. From there, Pedro could see a 360-degree view of mountains, greenery, and livestock grazing in the meadow. After school, he would hang around the house and play with the animals on their property.</p>\n<p>The men who worked for his family would hunt for crabs in caves. Pedro would go with them on their hunts, but he would watch from the side, apprehensive, as they stuck their bare hands into the darkness for huge, snapping crabs. He enjoyed the result, though: a dish called locrio where stewed crab meat releases its flavors into brown rice.</p>\n<p>Pedro grew up loving food, and it’s easy to see why. His mother was—and still is—a great cook who can turn any ingredient into a special meal. And she had the pick of ingredients in their family home. Milk from their own cows, yams dug up from their own soil. Pedro remembers his mother cooking cerdo guisado, or stewed pork, with onions and cubanelle peppers; and pasta with cooked green bananas.</p>\n<p>“The food was, like, unexplainably good, because everything was natural,” Pedro says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106305/image.jpg\" width=\"auto\" /></figure>\n<p>Twenty years ago in New York City, Pedro met his wife, Marisol, who was born in the U.S. to Dominican parents. When they were dating, she cooked him a meal that was, somehow, even better than his mother’s cooking. Pedro went home and told his mother; she was thrilled that her son had found a worthy match. And Marisol shares her in-laws’ dedication to natural cooking. “She does not use anything artificial,” Pedro says. “She’s very big on that.” That means no bouillon, and no pre-made seasonings, like the dried adobo mix that supermarkets sell.</p>\n<p>With Sajoma, Pedro’s goal was to let good ingredients sing without any additives. Customers have taken notice. Pedro says that when he walks the floor of the restaurant, diners tell him, “I literally feel like I’m eating this at home.”</p>\n<p>He believes this is testament to the power of simple cooking with no shortcuts. “Sometimes people think that you could force flavor. You don’t force flavor,” Pedro insists. With natural ingredients, “Flavor is very easy to accomplish.”</p>\n<h3 class=\"article-second-subheading-pre-rd\">From the Dominican Republic to the World</h3>\n<p>If the Rodriguez family farm was Pedro’s first culinary education, the multicultural restaurants of New York were his second. When Pedro was 12, his parents moved to New York and sent Pedro, his brother, and his sister to the city of Santiago to live with his grandparents. When Pedro was 14, his parents brought their children to the Big Apple.</p>\n<p>One might think moving from verdant island to concrete jungle would be difficult. For Pedro, it wasn’t.</p>\n<p>He received a warm welcome from his extended family, most of whom had settled in New York by the time he and his siblings got there. His first summer in New York, relatives toured him and his siblings around to the city’s parks and botanic garden. He loved the communal culture of 1980s Brooklyn, where he would wile away the day outdoors, playing ball on the streets and hanging out with his cousins. When Pedro’s mother offered to send him back to the Dominican Republic the following winter, he declined.</p>\n<p>Chief among these new experiences were the city’s food offerings. A family member blew Pedro’s mind when he took him for his first glazed donut. “I was like, ‘Holy shit!’” He remembers. “Where has this been all my life?”</p>\n<p>Pedro had a similar reaction to his first Chinese meal. Before he learned to speak English, his cousin took him to a restaurant where the staff spoke fluent Spanish with customers before calling out orders to the kitchen in Chinese. Pedro and his cousin bought fried rice with a half chicken and tostones, or fried plantains, and ate it outside on one of their stoops. “I fell in love with that,” he says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106306/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Starting Small and Expanding Slowly</h3>\n<p>The excited, food-loving child is very much alive in 53-year-old Pedro. He describes with equal relish his recent meal at a Peruvian restaurant as well as the locrio he ate on his family’s farm growing up. But food is also his business. In addition to Sajoma Latin Fusion in Kissimmee, Pedro owns four restaurants in New York and runs a fleet of trucks that he says supply most of New York City’s independent grocers. When asked about his secret to success in business, he uses a distinctly Dominican analogy: “I compare it to baseball players.”</p>\n<p>Many baseball players grow up playing on poorly kept fields. A ball might hit a rock, and smack you in the face. “It’s harder when you’re in the minor leagues,” he says. But, “You got to make sure that you could do that. Because once you go to the majors, the field is perfect now.”</p>\n<p>The message: “Start small,” he says, master your craft, and expand slowly.</p>\n<p>For Pedro, starting small meant working at his uncle’s grocery stores in Far Rockaway, Queens during high school. On Saturdays, he traveled with him to produce markets to stock the store. When Pedro graduated high school, he decided that he would rather spend the next few years growing a business. “What do I know at the time and what do I like at the time? Produce,” he says.</p>\n<p>So Pedro bought a van, and started delivering groceries to supermarkets, drawing on the connections he had built while working for his uncle. Soon, he bought a large truck, then two trucks. Today, he runs a fleet of 20 trucks.</p>\n<p>The road has not been easy. His equivalent of errant baseballs that threaten to hit you in the face were snowstorms that he had to fight through to deliver groceries. For years, he worked 18-hour shifts, rain, shine or snow. “I’d come home and eat, sleep for three or four hours, and go right back out there,” he remembers. He has since stepped back from physically driving trucks and delivering produce, but still helms the business.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106307/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">A Foothold in Florida</h3>\n<p>Over the years, many family members of Pedro’s have moved to Kissimmee. A friend told him about an open lot, wondering whether Pedro would be interested in opening a restaurant there. When Pedro saw the place, disparate threads of his life knit together: his childhood spent eating fresh produce on a Dominican farm; his exposure to cuisines from every corner of the world in New York; the New York hustle that had become his way of being.</p>\n<p>“Oh my god, this is perfect,” he remembers thinking after laying eyes on the space. He wanted to build a restaurant that combined fresh ingredients, Latin American cuisine, international influences, and New York service. And he would name it “Sajoma,” after the town that started his journey.</p>\n<p>After a period of renovation and menu-tweaking, Pedro opened Sajoma Latin Fusion in August of 2022. The restaurant’s interior is sleek and spacious, with an outdoor patio and plush couches. The team makes sure the produce is fresh, hand-picking it themselves from local independent supermarkets rather than large suppliers. Sajoma’s menu dances between Latin America—especially the Caribbean—and other parts of the world, like Europe, Asia, and North America. Their tuna tartare comes on a bed of guacamole and corn chips; their burger is topped with sweet plantains; and their sancocho is made from scratch with no additives.</p>\n<p>A pair of elderly Puerto Rican ladies recently visited the restaurant and made a point of telling Pedro how much they appreciated the sancocho. “We’ve had something like this at a house,” they told him. But “we have never tried anything like this at a restaurant.” They would spread the word to their family, they said.</p>\n<p>The word, it seems, has already gotten out. The restaurant has a loyal and growing following, and it becomes a party on weekends, when DJs and bands play salsa, bachata, merengue, and more.</p>\n<p>Much of Pedro’s work has been helping the team emulate the type of prompt, attentive service that one finds at a restaurant in New York. Achieving that has taken a lot of repetition, but they’ve pulled it off. “I’m just so proud, you know?” he says.</p>\n<p>Pedro says he approaches restaurant ownership as an eater, not a cook. He is actually not much of a chef, having been blessed with great cooking in his mother’s and wife’s kitchens, and in restaurants around the world.</p>\n<p>He constantly tries new restaurants, and he acts as the president of a group of around 40 New York supermarket industry professionals that call themselves the “Friday club” because they meet up at restaurants for food and wine every Friday. It’s easy to see why he would be named president: He knows good food and has the gift of gab.</p>\n<p>Pedro’s love of conversation and a good time is part of what draws him to the restaurant business, and when he is not checking on the kitchen at Sajoma, he is walking the floor, entertaining guests. He knows what it is to work hard all week and turn to a restaurant to provide delicious food and a space to connect with friends.</p>\n<p>“I don’t have to know how to cook,” in order to run a good restaurant, he says. “I have to know how to eat.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 30 Jan 2026 13:15:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042267Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "title": "Why Did Henry Ford Build a Midwestern Town in the Amazon Rainforest?",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Elah Feder: </strong>Johanna, do you ever buy lottery tickets?</p>\n<p><strong>Johanna Mayer:</strong> No, never. Not a lottery ticket kind of gal.</p>\n<p><strong>Elah:</strong> I actually just got shamed by the man selling me lottery tickets for wasting my money.</p>\n<p><strong>Johanna: </strong>You buy lottery tickets?</p>\n<p><strong>Elah: </strong>I do buy lottery tickets. And I think what I really like about it is fantasizing that, you know, if I have enough money, I will finally be able to do whatever I want.</p>\n<p><strong>Johanna: </strong>And this is the appeal of being a multimillionaire, Elah.</p>\n<p><strong>Elah:</strong> Right, right.</p>\n<p><strong>Johanna:</strong> You’re not the first one to have this impulse.</p>\n<p><strong>Elah: </strong>I have this crazy, wild notion that money will give me power. And the story that we’re going to talk about today is about a lot of things. But one of them is a lesson about how even with unlimited money, from time to time, the world refuses to do your bidding. So I want to take you back to the 1920s and tell you about Henry Ford. The 1920s was a time when Henry Ford was incredibly wealthy. Classic story. He started off as a simple Michigan farm boy, started tinkering. And then in 1908, he created the Model T, the first ever affordable mass-produced car, which made him incredibly rich. But it also reshaped America in the process. He decided that well-paid workers weren’t going to quit, so he brought in higher wages. He also brought in the eight-hour workday.</p>\n<p><strong>Johanna: </strong>It’s funny, I was just talking last weekend with my partner about Ford a little bit, where we were like, he is the reason that we have a car-centric society. But he was surprisingly good to his workers. Complicated figure.</p>\n<p><strong>Elah: </strong>He started off good to his workers. We’ll get there. But in the late 1920s, Ford, despite all of his wealth, he was forced to cave on a couple of pretty big things. He was forced to finally update his cars after years of resisting even a simple color change. Even more humiliating, a defamation suit forced him to apologize to Jewish people, which was very difficult for him because he loved talking about Jews before that. So in the late ’20s, Ford was realizing he was not all-powerful. But then in 1927, an incredible opportunity presented itself. A real chance to enact his vision of society, maybe without having to compromise this time. It was a place called Fordlândia in Brazil. And it didn’t quite make the biography on the Ford website for reasons that I think will soon become clear.</p>\n<p>I’m Johanna Mayer, and this is <em>Atlas Obscura</em>.</p>\n<p>And I’m Elah Feder. And today, the story of Fordlândia, Henry Ford’s attempt to build a wholesome Midwestern town in the Amazon rainforest.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/105971/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Johanna: </strong>Okay, I am intrigued. Why the rainforest? Why did Ford decide to build his vision of utopia in the Amazon rainforest?</p>\n<p><strong>Elah: </strong>So, it didn’t start out with a town. It started with rubber. So, as you know, cars need rubber for tires, for hoses. Today, most rubber is synthetic. The 1920s, it pretty much all came from rubber trees.</p>\n<p><strong>Johanna: </strong>So I did know this, and I can picture a rubber tree, which I think has a lot of big roots and like a wide trunk and stuff.</p>\n<p><strong>Elah:</strong> Massive.</p>\n<p><strong>Johanna:</strong> But I have never understood exactly how you get rubber from these trees.</p>\n<p><strong>Elah:</strong> It’s not too complicated. Ancient Mesoamericans figured this out. All you need to do is injure the tree.</p>\n<p><strong>Johanna:</strong> It saps it out?</p>\n<p><strong>Elah:</strong> It’s not technically sap. It’s another substance that oozes out of the tree. It kind of looks like coconut milk. It’s sticky and white and full of defense compounds. And that substance is called latex. So if you peel the bark of a rubber tree and let the latex drip out into a bucket, and then you dry it out, you get this bendy, bouncy material that we call rubber. So Ford decides he’s going to grow these rubber trees where they came from: the Amazon rainforest in Brazil.</p>\n<p><strong>Johanna: </strong>Seems like a solid plan.</p>\n<p><strong>Elah:</strong> It does seem that way. I should say it wasn’t actually Ford’s idea. He was actually being courted pretty aggressively by Brazilians. There was a Brazilian diplomat who really wanted to bring Ford to Brazil. There was a wealthy Brazilian businessman. And the idea was that bringing Ford, this wealthy industrialist, could potentially revive a really impoverished region, the northeast of Brazil.</p>\n<p>Ford very quickly agreed, and the company acquired 2.5 million acres of land, which they called Fordlândia. So, Fordlândia was on the east side of the Tapajos River, which is a tributary of the Amazon. This land is really deep in the rainforest. There were no roads, no railways. It took about 18 hours by boat to get there from the nearest city.</p>\n<p>So just imagine your classic kind of jungle. Towering trees, thick vines, tons of insects, birds, thousands of species, and, of course, rubber trees.</p>\n<p><strong>Johanna:</strong> Okay, goal is to create a rubber plantation. Makes sense to go to the Amazon. The part that I’m snagging on is the Midwestern town aspect.</p>\n<p><strong>Elah:</strong> Right.</p>\n<p><strong>Johanna:</strong> How does that come in?</p>\n<p><strong>Elah:</strong> So, a plantation obviously doesn’t run itself. It needs people. You need people to tap the trees, harvest the rubber. And then you need other people to feed those people, provide medical care. If you have families coming with the workers, then you’re going to need schools. You might need entertainment. You really need a whole town.</p>\n<p>And at Fordlândia, that’s what Ford created. Although not Ford himself, Ford didn’t go to Brazil. He had a crew of Ford company men who were dedicated to making this place according to Henry Ford’s vision.</p>\n<p><strong>Johanna:</strong> It’s how it usually goes.</p>\n<p><strong>Elah:</strong> So the town itself, it took a little bit of time to build. People started showing up well before there was a town. People who needed work came, and they brought their families. So they needed a place to live. They slapped together temporary shelters using planks from packing crates for walls and palm leaves for roofs.</p>\n<p>But within a couple of years, there was the start of a recognizable American-style town. They had a power plant, a hospital, a neighborhood with wooden houses with sidewalks and street lamps. A little later would come tennis courts, a dance hall, a movie theater, a golf course.</p>\n<p>But this was not just a lovely oasis in the Amazon. Because Henry Ford was a man with very particular ideas about how a society should be run. So increasingly, as he got older, he had this nostalgia for his old pastoral life. But at the same time, he hated cows.</p>\n<p><strong>Johanna:</strong> What’s wrong with cows?</p>\n<p><strong>Elah:</strong> Well, he thought they were very crude and inefficient machines. And he thought—</p>\n<p><strong>Johanna: </strong>Was—</p>\n<p><strong>Elah:</strong> Sorry, go ahead. I don’t think he was vegetarian.</p>\n<p><strong>Johanna:</strong> That’s what I was going to ask, yeah.</p>\n<p><strong>Elah:</strong> But he was a big fan of soy.</p>\n<p><strong>Johanna:</strong> Okay.</p>\n<p><strong>Elah: </strong>One time he built a full soy body. He had a suit made out of soy fibers.</p>\n<p><strong>Johanna:</strong> This is a whole other podcast episode.</p>\n<p><strong>Elah:</strong> The cow thing kind of threw me for a loop. But some of his ideas were actually really good. Like we mentioned, he thought people should be well paid, shouldn’t work super long hours. He also thought it was important that people be healthy. So he didn’t think they should drink or smoke. But he took this wholesome lifestyle thing a little far. He thought, for example, that dancing was good, but should not involve too much touching.</p>\n<p><strong>Johanna:</strong> No sexy dancing allowed.</p>\n<p><strong>Elah:</strong> Yes. Too many people were sexy dancing, which he blamed on Jewish people. So …</p>\n<p><strong>Johanna: </strong>What?</p>\n<p><strong>Elah:</strong> You’re welcome for that. I’m sure a lot of us have our own idiosyncratic spin on what makes a good life. The difference between Henry Ford and most of us is that he actually had the power to make his vision happen, to fashion a world in his image. This is not necessarily a good power for everyone to have.</p>\n<p>Henry Ford didn’t just encourage good habits and provide healthy food to his workers. He forced these things on them, not just in Fordlândia, but in all of his facilities. But as you can imagine, workers in the Amazon did not get the royal treatment.</p>\n<p>They were supposed to eat Henry Ford prescribed healthy meals at the company mess hall. They had to report any sexually transmitted infections to the company or risk getting caught at random STI inspections. They were not allowed to drink. A team of men would actually do spot searches of people’s homes and confiscate any alcohol that they found.</p>\n<p><strong>Johanna:</strong> It strikes me that this may not be the best route to creating the utopian society that you desire. The difference between Ford’s utopian society, Fordlândia, and a lot of other ones that come up throughout history is that in other utopian societies, people are signing up. They’re actively joining them of their own volition because they supposedly believe in some sort of common vision. Not the case here.</p>\n<p><strong>Elah: </strong>People just came to make rubber and get a paycheck. They did not come to have every aspect of their lives controlled. There were also unique challenges in the Amazon that Ford’s men did not anticipate. It turns out that you cannot just build an American town exactly as it is in America, wherever you want.</p>\n<p><strong>Johanna:</strong> Wait, you can’t?</p>\n<p><strong>Elah: </strong>Yeah. Revise life plan. For example, the houses that they had built. People were used to these houses with dirt floors and thatched roofs. These new houses had concrete floors and metal roofs. It impressed the journalists that visited, but they were unbearably hot in this climate. You do not want to be cooking under a metal roof, and you want good airflow. The Ford company provided free medical care for the workers, at least.</p>\n<p><strong>Johanna: </strong>Sounds good.</p>\n<p><strong>Elah:</strong> Despite that, a lot of people died. It is hard going in the Amazon. Both the American families and the Brazilian workers, a lot of people died of tropical diseases. People were being bitten by vipers when they were trying to clear jungle. This one guy whose job was to saw timber, he ended up preparing a lot of the wood they needed for coffins. He estimated they were averaging a death a day.</p>\n<p>In 1930, so just two years into the project, frustrations were at an all-time high. Ford’s men were also realizing that they weren’t really doing a good job of keeping people in line. In December of that year, 1930, one of Ford’s officials decides they need to make a change. Ford, as you know, wanted people to eat healthy. Apparently, he prescribed that people eat oatmeal and canned peaches for breakfast.</p>\n<p><strong>Johanna: </strong>That sounds good.</p>\n<p><strong>Elah: </strong>And rice and whole wheat bread for dinner. But—</p>\n<p><strong>Johanna:</strong> Sounds less good.</p>\n<p><strong>Elah: </strong>People wanted to eat whatever they wanted. And so they were getting food elsewhere. And this Ford employee decided that the solution was to feed them food from the cafeteria and deduct it from their wages.</p>\n<p>And that is when people snapped. It started when a guy named Manuel Caetano de Jesus, who was a brick mason, he decided to confront a payroll worker in the dining hall. And Manuel was yelling at him in Portuguese, which apparently this guy did not understand. But then Manuel hands him his badge, which he did understand. And this payroll worker’s reaction is to laugh.</p>\n<p>And that’s when the whole place erupts. People are suddenly smashing plates, pots, sinks, and they go and find all the Ford cars and smash them up. According to one person who was there, people started chanting “Brazil for Brazilians, kill all the Americans.” This was a massive riot across Fordlândia. And by the time that things calm down, the place is basically in ruins.</p>\n<p><strong>Johanna:</strong> Is that it? Is that the end of Fordlândia?</p>\n<p><strong>Elah:</strong> Weirdly not. Somehow.</p>\n<p><strong>Johanna:</strong> Incredible.</p>\n<p><strong>Elah:</strong> Yeah. So they end up firing most of the workers, but keep a skeleton crew and start to rebuild. And a few years later, they end up acquiring another plot of land nearby and building a second town and more plantations. And Fordlândia chugs along. The bigger problem, at least for the Ford company, is not that the workers hate them. It’s that Fordlândia isn’t actually doing the one thing it’s supposed to do, which is produce rubber.</p>\n<p><strong>Johanna: </strong>God, this has been such a journey, I forgot that they were supposed to be producing rubber this whole time.</p>\n<p><strong>Elah: </strong>That was the point of all of this. So it does take time, right? And they’d had many false starts. You know, they planted trees in the dry season. That didn’t work well. But eventually they get it together. And by 1940, they have three million trees planted across 30,000 acres of land.</p>\n<p><strong>Johanna:</strong> Whoa.</p>\n<p><strong>Elah:</strong> But here’s the thing. It turns out Brazil is not actually the best place to grow Brazilian rubber trees.</p>\n<p><strong>Johanna: </strong>What?</p>\n<p><strong>Elah: </strong>Because Brazil, the place the trees are native to, also has all of the trees’ natural enemies.</p>\n<p><strong>Johanna:</strong> Ah, interesting.</p>\n<p><strong>Elah: </strong>When trees are scattered throughout a forest, the trees manage to grow okay. But then imagine you are a rubber tree-eating bug or fungus, and you come upon all of these rubber trees jam-packed together in one place. You are going to come out and feast. You’re going to reproduce. You’re going to hop from tree to tree. It’s a massive buffet.</p>\n<p><strong>Johanna:</strong> Like, here we are!</p>\n<p><strong>Elah:</strong> Yeah. So by 1940, 70 percent of Fordlândia’s rubber trees were infected with a fungal blight. They get through that. But then in 1942, they’re hit with caterpillars.</p>\n<p><strong>Johanna:</strong> Dun, dun, dun.</p>\n<p><strong>Elah:</strong> I mean, caterpillars had always been a problem. But for a few years, the workers managed to keep them at bay. But in 1942, there is a total caterpillar explosion that they just can’t keep up with. And just as the situation was starting to get under control, they were hit with a second wave of fungal blight. And combined, it’s a pretty fatal blow. And just a few years later, in November of 1945, the company decides it is time to abandon this project. Apparently, they did not give the local workers much notice. Many Brazilians didn’t even know the Americans were leaving until the day they got on the ships. And that was how they found out they were unemployed.</p>\n<p><strong>Johanna: </strong>Oh, my God.</p>\n<p><strong>Elah: </strong>Yeah. By this point, Ford himself was over 80. He wasn’t doing well. And two years later, he died.</p>\n<p><strong>Johanna: </strong>You said that they just picked up and left and got on ships. What happened to the town? Are the buildings still there? Does anyone still live there? What happened to Fordlândia? <strong>Elah:</strong> So a lot of the story I’ve told you is based on a book by Greg Grandin called <a href=\"https://us.macmillan.com/books/9780312429621/fordlandia/\"><em>Fordlandia</em></a>, which came out in 2009. When he visited, a lot of the old structures were there. The old factory buildings, the sawmill, the warehouse, they’re kind of falling apart but standing. And a few of the old houses were there, too, apparently full of bats and just covered in guano.</p>\n<p>And back when Greg Grandin visited, one of the main sources of income was cattle ranching. Apparently, there were cows grazing on the old golf course. The old tennis courts had been turned into cattle stalls. And the hillsides that used to be planted with rubber trees were turned into pasture land for cows.</p>\n<p><strong>Johanna: </strong>Yes, justice for the cows. This was a totally fascinating story, Elah. Thank you.</p>\n<p><strong>Elah: </strong>Thanks for having me, Johanna. The town of Fordlândia is still around. And since Greg Grandin’s visit, it’s had a bit of a resurgence. An estimated 3,000 people live there. There’s now a tall Catholic church, a guest house, a bar, a restaurant. And scattered throughout, crumbling remains of Henry Ford’s failed American town.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Stitcher Studios. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 27 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042276Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "title": "Tiquira",
        "summary": "<p><img alt=\"\" height=\"200\" src=\"https://img.atlasobscura.com/AVz4e7Gut8Wj5dEAKjG4GdVeQ-Naog6rw3iXhMFXb0k/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy9mMjk5/MWM1Mi05NDFkLTRk/ODYtYjMxZC0xZTU1/OTI0ZjI2M2Q3MDUx/Mzk4NTM2MTc1YzZh/ZDhfRFNDMDk5MTUu/SlBH.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Indigenous Brazilians have fermented alcoholic beverages from the cassava root for thousands of years. These beer-like beverages go by names like </span><em><span style=\"font-weight: 400;\">cauim</span></em><span style=\"font-weight: 400;\">, </span><em><span style=\"font-weight: 400;\">caxiri</span></em><span style=\"font-weight: 400;\">, and </span><em><span style=\"font-weight: 400;\">tarubá</span></em><span style=\"font-weight: 400;\">. Fermentation is an important step in cassava processing—the raw root has chemicals that can turn into cyanide in the human body. Native peoples found that a bit of human saliva and some naturally occurring yeast could eliminate these toxins and improve the nutritious value of the tuber. When the technology of distillation arrived to the Munim River region (now in Maranhão), locals who already drank lightly alcoholic cassava beverages began to distill them. </span><em><span style=\"font-weight: 400;\">Tiquira</span></em><span style=\"font-weight: 400;\"> was born. </span></p>\n<p><span style=\"font-weight: 400;\">The name <em>tiquira</em> is likely derived from the Tupi word </span><em><span style=\"font-weight: 400;\">tykyre </span></em><span style=\"font-weight: 400;\">meaning \"to drip.\" But it is a curiosity that the spirit has flourished in only one Brazilian state, Maranhão. Margot Stinglwagner, founder of </span><a href=\"https://www.guaajatiquira.com/en/index.html\"><span style=\"font-weight: 400;\">Guaaja Tiquira</span></a><span style=\"font-weight: 400;\">, the first modern brand to produce the spirit starting in 2016, says “It’s a spirit that is also unknown in Brazil. A few people have heard about tiquira—but usually only people who have gone to Maranhão once.” Accordingly, the state moved to declare the spirit as a piece of Cultural and Intangible Heritage </span><a href=\"https://www.al.ma.leg.br/noticias/48515\"><span style=\"font-weight: 400;\">in September 2023</span></a><span style=\"font-weight: 400;\">. </span></p>\n<p><span style=\"font-weight: 400;\">Part of the reason that tiquira has remained so isolated is that cachaça, Brazil’s rum, is far easier to produce. Because the rum comes from sugarcane, the sugar for fermentation is already there. “With cassava, you don’t have sugar,” Stinglwagner explains. “You must first transform the carbohydrates into sugar and then you can ferment and distill it.” To achieve this end, Guaaja Tiquira uses food enzymes instead of the traditional human saliva. Guaaja also differs from other distillers because they use full cassava roots where most tiquira moonshiners rely on processed </span><em><span style=\"font-weight: 400;\">farinha de mandioca</span></em><span style=\"font-weight: 400;\">, or cassava flour. </span></p>\n<p><span style=\"font-weight: 400;\">“The majority of people produce it illegally,” laughs Stinglwagner. “The state does nothing about it.” Outside of the urban center, tiquira is invariably a homemade product. Generally, tiquira makers don’t separate the \"heads\" (the first drops of liquor from a distillation, which contain harsher alcohols including toxic methanol and other pungent and volatile flavor compounds) from the \"tails\" (the final liquid produced from distillation, which has a low alcohol content and can have unwelcome bitter flavors), meaning the spirit is stronger and may contain more toxins and impurities. Some even macerate marijuana into the combined spirit to produce the doubly-illicit <em>tiquiconha</em>.</span></p>\n<p><span style=\"font-weight: 400;\">Maranhenses believe that you cannot get wet or bathe after drinking tiquira, lest you become faint or dizzy. Zelinda Machado de Castro e Lima, one of the great chroniclers of folk culture in Maranhão, has recorded other traditions surrounding the drink. Firstly, it is typical to pierce a cashew with a toothpick and soak it in a glass of tiquira for several hours. It is then sucked as a sort of boozy lollipop. She also writes about the belief that those drinking coffee should avoid tiquira, while locals say that fishermen on the coast used the liquor to sanitize wounds incurred on the job. </span></p>\n<p><span style=\"font-weight: 400;\">Finally, there is the curious question of the color of tiquira. In the tourist markets of São Luís, the spirit is always blushing a translucent violet. “They say that the color of tiquira is from tangerine leaves, but we tried to do it and the color from the leaves is not stable,” says Stinglwagner. “It is also not a strong color. The norms and laws for tiquira prohibit the addition of the leaves.” The violet color may be artificial (perhaps from food dyes), but some tiquiras do have a citrusy flavor. </span></p>\n<p><span style=\"font-weight: 400;\">Tiquira today is still largely relegated to the world of moonshining, but with the government’s recognition of the spirit and new legitimate ventures like that of Guaaja Tiquira, Brazil could be seeing more of the cassava liquor outside of its home in Maranhão. </span></p>\n<p><span style=\"font-weight: 400;\">“All the people say to me, ‘What is this new spirit?,’” says Stinglwagner. “I say, ‘It’s not a new spirit, it’s the oldest spirit from Brazil.’”</span></p>\n<p><strong>Know Before You Go</strong></p>\n<p>Tiquira is widely available in the downtown markets of São Luís, Maranhão. Both the local Mercado Central and touristic Mercado das Tulhas have many vendors selling tiquira. The commercial brand, Guaaja Tiquira, is also available in São Luís at Empório Fribal, in addition to Copacabana Palace and Fairmont Hotel in Rio de Janeiro, and Mocotó Bar e Restaurante in São Paulo. </p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 03 Apr 2024 19:17:00 -0400",
        "fetched_at": "2026-02-22T23:22:18.042303Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/odilia-alvarado-kissimmee",
        "title": "How La Mexicana Became a Kissimmee Institution",
        "summary": "<p>Though Odilia Alvarado is responsible for 80 employees, the first people she attends to in the mornings are her children. Every day by 8:00 a.m., she drops her 8-year-old daughter and 10-year-old son off at school. Then it’s off to La Mexicana Restaurant, or the nearby affiliated bakery, for breakfast service.</p>\n<p>In the last three decades, Odilia has helped her mother, father, siblings, aunts, and uncles, build a series of Mexican food businesses that have taken Central Florida by storm, usually under the moniker “La Mexicana.” In 2011, she and her husband struck out on their own and opened the first Kissimmee outpost of La Mexicana. Today, she runs a restaurant, supermarket, tortilleria, bakery, and ice cream shop in Kissimmee that can barely keep up with demand for their delicious treats.</p>\n<p>If you ask Odilia, she’ll attribute her success to her faith in God, and her tight family that has supported her every step of the way. Her dedication to perfecting dishes inspired by the southwestern region of Mexico hasn’t hurt, either.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106355/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">From the Mountains of Mexico to Central Florida</h3>\n<p>Odilia Alvarado spent her early childhood in the town of Tenanguillo de las Cañas in the mountainous state of Guerrero. To buy groceries or clothing in the larger town nearby, her family would travel by car down a dirt road that took 20 minutes to traverse. But the rural setting came with upsides too, like the widespread practice of home-growing fresh herbs and vegetables, which Odilia believes is a big part of what makes the region’s cuisine so special.</p>\n<p>Odilia also draws inspiration from her grandmother, Angela Guadarrama Millan: a prodigious cook who supplied many of the recipes that made La Mexicana locally famous.</p>\n<p>She remembers hiking up rocky mountains with her grandmother to reach her vegetable patch, where she cultivated beans. Angela would harvest the beans, clean them, cook them, and grind them down in a molino, a mortar and pestle. She would then stuff the ground beans into homemade corn dough that she would toast on a comal, a traditional Mexican griddle, to make gorditas. The gorditas, plus a homemade salsa picante made from tomatillos and dried chiles de arbol would make up many of their meals.</p>\n<p>“We would eat really good,” said Odilia. “That’s all we’d eat, mainly.” They would also have the occasional bean soup, flavored with the medicinal-tasting epazote herb and lapped up with tortillas.</p>\n<p>When Odilia was around six years old, her mother, Paulina Cervantes, and father, Alejandrino Honorato Guadarrama, left their hometown to stake out a home for the family in the United States. Odilia, the second-oldest and the only girl among eight children, spent a year living with her grandmother and her older brother. A year later, Odilia’s parents brought Odilia and her older brother to Apopka, Florida. Odilia remembers being happy to be reunited with her parents, and the world taking on a sheen of novelty.</p>\n<p>Odilia was seven when she arrived, and she initially struggled in her new school, where there was limited support for Spanish-speaking students. But she soon transferred to a school with a bilingual education program. “My brain just started to pop up,” she remembers. She started soaking up English and getting good grades. In her first year in the new school, she made honor roll and won a trip to Disney World, an experience that she describes as “magical.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106300/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">The Birth of a Restaurant Family</h3>\n<p>When Odilia was twelve, she and Paulina started cooking tacos de barbacoa, a slow cooked, richly-spiced shredded beef, on weekends. Odilia was in charge of making the tortillas by hand with a mechanical stamp. They would sell them to her Alejandrino’s colleagues at his job at a greenhouse. The tacos were a hit, and customers started asking for Paulina to bring the tacos to their soccer and basketball games.</p>\n<p>When Odilia was 14, the Alvarados opened a brick-and-mortar taqueria called La Mexicana in a plaza in Apopka. It was a family business: Odilia’s mother and grandmother prepared the meat, Alejandrino and Odilia’s uncle made the tortillas, and Odilia would chop the garnishes before preparing the tacos with her cousins.</p>\n<p>People clamored for their carnitas, carne asada, pollo, and, most of all, Odilia’s grandmother’s adobada, pork chunks marinated in a complex, spicy red sauce. “We had lines and lines of people waiting for the food, for the tacos,” Odilia says.</p>\n<p>From that first taquería, the Alvarado family sprang a bunch of other iterations of La Mexicana across Central Florida. Different branches were operated by different family members who would work closely together, and it expanded to encompass tortilla-making, baking, ice cream, and Mexican groceries. Odilia worked hard alongside her parents and brothers. Along the way, she discovered that she loved cooking. “Even when I was making the tortillas,” Odilia says, she was in her happy place. Today, she cooks dinner for her husband and kids after work, often inspired by videos on Facebook and Instagram that advertise the dishes in restaurants and Mexican pueblos. She says it’s worth it to cook for her family, even though she owns a restaurant that could easily supply them with cooked meals. “When you see them eat and they like your food,” she says, “I feel more happy.”</p>\n<p>In 2011, Odilia and her husband were working together with Odilia’s mother, father, and two brothers in the family’s Orlando location. “We didn’t fit there anymore,” Odilia says. Her younger brother came across a space for rent in a shopping plaza in Kissimmee, but he didn’t yet have the money for it. “You go—you try over there,” he told his sister.</p>\n<p>Odilia and her husband opened up the Kissimmee branch of La Mexicana in December 2011. Their original plan was to open a taquería, but Odilia’s father Alejandrino said that they should take a shot at opening a supermarket and a restaurant, like they had opened in Orlando. She was intimidated, but he encouraged them. “If you’re going to go for it, go for something big. You don’t go for something small,” Odilia remembers Alejandrino telling her.</p>\n<p>So Odilia went for it, opening a supermarket with a small restaurant in a 2,000-square-foot space.</p>\n<p>“We were scared at the beginning, because we were starting to struggle,” she remembers. The first two years were rough. Odilia and her husband would do much of the cooking themselves, and would often spend their entire days in the restaurant.</p>\n<p>Odilia emerged from the first hard years, and eventually was able to expand the supermarket, and open a tortilleria and bakery.</p>\n<p>Odilia took her creative leap with the opening of a large, colorful, full-service sit-down restaurant a few years ago. This time, she didn’t need any convincing from her father: she and her husband spearheaded the process from start to finish. She drew a sketch of what she wanted the restaurant to look like, and handed it to an architect. She and her husband sourced decorative animals and hand-carved tables from Mexico. The space is playful and colorful with an emphasis on the natural world, because “it brings you back to Mexico” and evokes fresh, natural food.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106301/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Secrets to Success</h3>\n<p>Over the years, Odilia’s father has developed a few rules to success. “Clean area, good service, and good food. The three main things that we always keep in mind,” Odilia says. She and her staff remember customers’ names and make sure to always be friendly.</p>\n<p>As for the food, she uses recipes from the matriarchs that form the backbone of the La Mexicana empire. She helps create the restaurant’s menu, but she isn’t usually in the kitchen cooking for customers. Her kitchen prepares nopales, or prickly pear cactus, according to her grandmother’s method; and a healthy green juice according to her mother’s recipe that also includes its fair share of nopal.</p>\n<p>The restaurant serves a wide range of Mexican dishes, from rich soups to crispy tacos. Many of them have their roots in Guerrero, such as their golden-fried quesadillas and their green and red salsas. The tacos de birria, a choice of goat or beef stewed in a rich consummé, are a customer favorite.</p>\n<p>Odilia says that when it comes to her success, faith is a major factor. For as long as Odilia can remember, her family has believed that “if you have God in your life, you’re good,” she says. She keeps an image of the Virgin Mary in each of her businesses, to protect her family and bring them blessings.</p>\n<p>Odilia thanks her family for helping her achieve her goals. Her husband, whom she met when she served him at La Mexicana in Orlando, has been a constant support as well. He jokes that he picked the right wife—someone who could make his belly happy.</p>\n<p>But the truth is that he helps her, too. He takes initiative and is constantly strategic and ambitious about the restaurant. At the same time, he encourages Odilia’s ideas. If she and her partner did not have such good teamwork, “we would not have what we have,” she said.</p>\n<p>She is also thankful for the mentorship of her father and other family members. “I have learned a lot from my dad and my family,” she says. These lessons are “something that you want to pass on to your kids.”</p>\n<p>Odilia has seven children, and it seems as if her third child may follow in her footsteps and become an entrepreneur. “She looks like she wants to open her own business,” Odilia says. “It makes me very proud.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 20 Feb 2026 12:36:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042197Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042299Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/visiting-every-museum-in-new-york-city-a-q-a-with-jane-august",
        "title": "Visiting every museum in New York City",
        "summary": "<p>Jane August has made it her mission to visit every museum in New York City and five years in, she’s still discovering new ones. What began as a pandemic-era way to leave the house has turned into a sprawling, spreadsheet-powered project that’s connected her to hidden institutions, museum professionals, and a growing community of fellow culture lovers. Known as \"the museum girl\" among her fans, August documents her explorations across multiple <a href=\"https://www.janeaugust.co/every-museum-in-nyc\" rel=\"noopener noreferrer\" target=\"_blank\">social channels,</a> where she has amassed thousands of followers, and has even launched a <a href=\"https://podcasts.apple.com/us/podcast/the-next-stop-is-with-jane-august/id1740787173\" rel=\"noopener noreferrer\" target=\"_blank\">podcast.</a></p>\n<p>Atlas Obscura Executive Editor Emma Patti spoke with August about how the quest began, what’s surprised her most, and how to explore New York like a museum insider.</p>\n<p><strong>Atlas Obscura: </strong>How did this quest to visit every museum in New York City even begin?</p>\n<p><strong>Jane August:</strong> I was furloughed during the pandemic. I work in live music, bars, and venues, and suddenly all of that stopped. In the fall of 2020, some friends and I went to the Brooklyn Museum, because museums were really the only cultural spaces that had reopened.</p>\n<p>By that winter, I was like, I need to leave my house. I need to do <em>something</em> this year. All the things I usually did—shows, parties, places where people gather—weren’t options. Museums were one of the only places you could go alone and still feel like you were doing something meaningful.</p>\n<p>I thought, “There can’t be that many museums. Maybe I’ll visit them all and be done in a year or two.” That was five years ago.</p>\n<p><strong>AO:</strong> Were you surprised by how long it’s taken?</p>\n<p><strong>August:</strong> Completely. I originally thought there were maybe 150 or 160 museums in the city. I’m at about 150 visited now, so I <em>should</em> be done.</p>\n<p>But museums keep appearing. Some come out of the woodwork and say, “We don’t really post online—we’re kind of a secret museum.” Others reopen, or I’m still trying to figure out if they even exist. I’m emailing board members and stalking LinkedIn trying to confirm whether a place is real or permanently closed. The spreadsheet keeps growing.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106345/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> When you started, did you imagine this would turn into such a public project? </p>\n<p><strong>August:</strong> Not at all. Like everyone else in 2020, I was playing around on TikTok. I realized people liked New York City content, and I thought maybe some people would be interested in this project.</p>\n<p>I didn’t expect it to become my identity. I didn’t expect to be introduced as “the museum girl,” or for museum-going to become part of my brand. That part really surprised me.</p>\n<p><strong>AO:</strong> Do you visit museums outside New York the same way?</p>\n<p><strong>August:</strong> Not on this scale. When I travel, I go to museums I <em>want</em> to see. I don’t feel obligated. That’s actually when I enjoy museums the most—when I’m not thinking about how I’ll document it or explain it to other people.</p>\n<p><strong>AO:</strong> After visiting so many museums, do you have favorites?</p>\n<p><strong>August:</strong> Picking favorites is hard when you’ve been to so many. But the ones I return to a lot include Poster House—it wasn’t even on my radar at first, and now I take everyone there.</p>\n<p>I love the Museum of the City of New York and New-York Historical Society. I realized early on that I like history museums more than art museums. I just love learning things.</p>\n<p>The Museum of the Moving Image is a favorite, especially for film and TV. I also love the Nicholas Roerich Museum, the Transit Museum, the Red Hook Pinball Museum, and the Brooklyn Seltzer Museum.</p>\n<p>And then there are the big ones—the Guggenheim, the Whitney—where I now sometimes get to experience them when they’re empty or after hours. That still feels surreal.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106341/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Have any museums totally surprised you?</p>\n<p><strong>August:</strong> Definitely. The Maritime Industry Museum at Fort Schuyler was a big one. There were no photos online, and it took me over two hours to get there. I thought, “If this is one small room, I’m going to be devastated.”</p>\n<p>But it was huge. We got lost inside. It’s in a fort and covers every nautical thing you can imagine. My parents work in the maritime industry, so it was especially meaningful.</p>\n<p>I was also surprised by the New York Sign Museum, which is inside an operating sign shop, and by the Salvador Mundi Museum in Brooklyn. That one really made me think about what <em>counts</em> as a museum—it has a gift shop, a café, rotating exhibits, and events, just scaled way down. It’s almost conceptual art about museums themselves.</p>\n<p><strong>AO:</strong> How do you keep track of all this?</p>\n<p><strong>August:</strong> I have a very intense spreadsheet. I studied stage management in college, so spreadsheets are my love language.</p>\n<p>It tracks every museum, when it’s open, the neighborhood, whether I’ve contacted them, when I visited, who I went with, whether I’ve posted the video yet. Some entries are marked in red because they’re still a mystery: “Do they exist? Find out.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106342/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Do people send you tips now?</p>\n<p><strong>August:</strong> All the time. That’s how a lot of this has grown. Museum founders DM me, followers tell me about new openings, and organizations reach out when they start doing exhibitions.</p>\n<p>Sometimes I also just find museums by dragging around Google Maps. I’ll be walking to work and realize, “Wait—that’s a museum I didn’t know existed.” Then it goes on the list.</p>\n<p><strong>AO:</strong> Has this connected you to the museum world in unexpected ways?</p>\n<p><strong>August:</strong> Absolutely. I’ve met so many people in museum marketing, social media, and public engagement, and they all seem to move between institutions. Suddenly I’m being invited to places because I know someone from somewhere else.</p>\n<p>A lot of these people also have their own art practices or side projects, and I love being able to highlight that through my platform or my podcast.</p>\n<p><strong>AO:</strong> Speaking of which—how did your podcast come about?</p>\n<p><strong>August:</strong> I had a radio show in college, and I missed interviewing people. Through this museum project, I kept meeting fascinating people, but I only had a short window to tell their stories.</p>\n<p>The podcast lets me expand beyond museums. I’ve had theater people, musicians, authors—people whose stories don’t fit neatly into one niche.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106344/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Any tips for visiting museums?</p>\n<p><strong>August:</strong> I go in completely blind. I don’t research much beforehand, and I like being surprised. I wander.</p>\n<p>My one consistent rule is: always go to the gift shop. I buy a postcard at every museum. I send one to my mom, and whoever I go with has to send one to me. If I go alone, I’ll mail one to myself.</p>\n<p>Postcards are my way of documenting what I’ve seen. I have a giant box full of them.</p>\n<p><strong>AO:</strong> If someone had one day to explore museums in a single New York neighborhood, where should they go?</p>\n<p><strong>August:</strong> Prospect Park and Crown Heights are great—you’ve got the Brooklyn Museum, the Botanic Garden, and Lefferts Historic House.</p>\n<p>The Lower East Side is another favorite. You can do the Tenement Museum, the International Center of Photography, and the new Automatic Photo Booth Museum, plus a bunch of smaller institutions nearby.</p>\n<p>Lower Manhattan is underrated for museums, especially National Park Service sites—and you can get Junior Ranger badges at any age, which I love.</p>\n<p>And Staten Island’s Snug Harbor is basically a museum campus with multiple institutions in one beautiful area.</p>\n<p>Honestly, museums are everywhere in New York. Even after five years, I’m still finding new ones.</p>\n<hr style=\"border: 1px solid black;\" />\n<p>Jane also appeared on the Atlas Obscura podcast. Listen to her episode here.</p>\n<p></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 10 Feb 2026 08:00:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042258Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://www.atlasobscura.com/articles/the-obscura-society",
        "title": "Welcome to The Obscura Society",
        "summary": "<p>What if Atlas Obscura wasn't just a guide, but also a doorway? The Obscura Society invites you into a living, digital world where stories respond, environments listen and curiosity shapes the experience itself.</p>\n<p>Designed as a living, digital space, The Obscura Society is always on. Guests can drop in from anywhere, at any time, to meet others, share discoveries and take part in unfolding stories, whether they’re visiting through a mobile device, personal computer or VR headset.</p>\n<p>At the heart of The Obscura Society is an AI bartender who welcomes every guest. Like a great local bar anywhere in the world, they serve imaginative, global drinks such as: Fröccs, Horchata Lojana, Panther Milk, Nectar Soda, Cheese Tea, the Pegu Club Cocktail and more! Share the surprising stories and learn about the cultural origins behind them, all drawn from Atlas Obscura’s vast archive of curiosities.</p>\n<p>Surrounding visitors of the world is a richly layered space inspired by real places across the globe. Photographs from Atlas Obscura contributors line the walls, while an interactive world map gives you access to the full Atlas Obscura database. From here, portals open into the complete Atlas Obscura VR app, along with pathways to books, articles and other Atlas Obscura experiences.</p>\n<p>It's an evolving digital world that will continue to change over time as your experience also evolves with each visit to The Obscura Society. Every session offers new conversations, discoveries and opportunities to connect with others as you explore the endlessly strange, wondrous and unexpected stories that define Atlas Obscura.</p>\n<p></p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 02 Feb 2026 00:46:00 -0500",
        "fetched_at": "2026-02-22T23:22:18.042262Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-02-22T23:20:59.581180Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-02-22T23:20:59.581587Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-02-22T23:20:59.580878Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-02-22T23:20:59.582687Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-02-22T23:20:59.582137Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.scmp.com/news/china/military/article/3344256/chinas-type-095-nuclear-submarine-spotted-first-time-new-satellite-images?utm_source=rss_feed",
        "title": "China’s Type 095 nuclear submarine spotted for first time in new satellite images",
        "summary": "China has launched its first next-generation Type 095 nuclear-powered attack submarine (SSN), according to satellite imagery analysed by defence experts.\nIt marks a significant leap as Beijing ramps up the underwater arms race to challenge US naval dominance in technology and production.\nImages captured between February 9 and 12 showed the vessel being fitted out at the Bohai Shipyard in Huludao, Liaoning province, according to Janes and Naval News.\nDefence analysts said the pictures revealed a...",
        "source": "www.scmp.com",
        "published": "Sun, 22 Feb 2026 14:00:09 +0000",
        "fetched_at": "2026-02-22T23:20:53.298303Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-02-22T23:20:59.582986Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-02-22T23:20:59.583099Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-02-22T23:20:59.586344Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/27/huawei-vivo-and-oppo-help-establish-first-global-fast-charging-standard-under-itu/",
        "title": "Huawei, vivo, and OPPO help establish first global fast-charging standard under ITU",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/charger-marcus-urbenz-4xMAiJZPQXI-unsplash.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>The International Telecommunication Union (ITU) has approved and released L.1004, a universal fast-charging standard for mobile terminals co-authored by China’s CAICT with Huawei, vivo, and OPPO. The standard enables cross-brand and cross-device fast charging and is intended to reduce charger duplication and electronic waste. [TechNode reporting]",
        "source": "technode.com",
        "published": "Mon, 27 Oct 2025 10:51:44 +0000",
        "fetched_at": "2026-02-22T23:20:59.581674Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/vxcontrol/pentagi",
        "title": "vxcontrol/pentagi",
        "summary": "<p>✨ Fully autonomous AI Agents system capable of performing complex penetration testing tasks</p><hr /><h1>PentAGI</h1> \n<div align=\"center\" style=\"font-size: 1.5em; margin: 20px 0;\"> \n <strong>P</strong>enetration testing \n <strong>A</strong>rtificial \n <strong>G</strong>eneral \n <strong>I</strong>ntelligence \n</div> \n<br /> \n<div align=\"center\"> \n <blockquote> \n  <p>🚀 <strong>Join the Community!</strong> Connect with security researchers, AI enthusiasts, and fellow ethical hackers. Get support, share insights, and stay updated with the latest PentAGI developments.</p> \n </blockquote> \n <p><a href=\"https://discord.gg/2xrMh7qX6m\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;logoColor=white\" /></a>⠀<a href=\"https://t.me/+Ka9i6CNwe71hMWQy\"><img alt=\"Telegram\" src=\"https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&amp;logoColor=white\" /></a></p> \n</div> \n<h2>📖 Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-overview\">Overview</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-features\">Features</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-api-access\">API Access</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-advanced-setup\">Advanced Setup</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-development\">Development</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-testing-llm-agents\">Testing LLM Agents</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-embedding-configuration-and-testing\">Embedding Configuration and Testing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-function-testing-with-ftester\">Function Testing with ftester</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#%EF%B8%8F-building\">Building</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-credits\">Credits</a></li> \n <li><a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/#-license\">License</a></li> \n</ul> \n<h2>🎯 Overview</h2> \n<p>PentAGI is an innovative tool for automated security testing that leverages cutting-edge artificial intelligence technologies. The project is designed for information security professionals, researchers, and enthusiasts who need a powerful and flexible solution for conducting penetration tests.</p> \n<p>You can watch the video <strong>PentAGI overview</strong>: <a href=\"https://youtu.be/R70x5Ddzs1o\"><img alt=\"PentAGI Overview Video\" src=\"https://github.com/user-attachments/assets/0828dc3e-15f1-4a1d-858e-9696a146e478\" /></a></p> \n<h2>✨ Features</h2> \n<ul> \n <li>🛡️ Secure &amp; Isolated. All operations are performed in a sandboxed Docker environment with complete isolation.</li> \n <li>🤖 Fully Autonomous. AI-powered agent that automatically determines and executes penetration testing steps.</li> \n <li>🔬 Professional Pentesting Tools. Built-in suite of 20+ professional security tools including nmap, metasploit, sqlmap, and more.</li> \n <li>🧠 Smart Memory System. Long-term storage of research results and successful approaches for future use.</li> \n <li>📚 Knowledge Graph Integration. Graphiti-powered knowledge graph using Neo4j for semantic relationship tracking and advanced context understanding.</li> \n <li>🔍 Web Intelligence. Built-in browser via <a href=\"https://hub.docker.com/r/vxcontrol/scraper\">scraper</a> for gathering latest information from web sources.</li> \n <li>🔎 External Search Systems. Integration with advanced search APIs including <a href=\"https://tavily.com\">Tavily</a>, <a href=\"https://traversaal.ai\">Traversaal</a>, <a href=\"https://www.perplexity.ai\">Perplexity</a>, <a href=\"https://duckduckgo.com/\">DuckDuckGo</a>, <a href=\"https://programmablesearchengine.google.com/\">Google Custom Search</a>, and <a href=\"https://searxng.org\">Searxng</a> for comprehensive information gathering.</li> \n <li>👥 Team of Specialists. Delegation system with specialized AI agents for research, development, and infrastructure tasks.</li> \n <li>📊 Comprehensive Monitoring. Detailed logging and integration with Grafana/Prometheus for real-time system observation.</li> \n <li>📝 Detailed Reporting. Generation of thorough vulnerability reports with exploitation guides.</li> \n <li>📦 Smart Container Management. Automatic Docker image selection based on specific task requirements.</li> \n <li>📱 Modern Interface. Clean and intuitive web UI for system management and monitoring.</li> \n <li>🔌 Comprehensive APIs. Full-featured REST and GraphQL APIs with Bearer token authentication for automation and integration.</li> \n <li>💾 Persistent Storage. All commands and outputs are stored in PostgreSQL with <a href=\"https://hub.docker.com/r/vxcontrol/pgvector\">pgvector</a> extension.</li> \n <li>🎯 Scalable Architecture. Microservices-based design supporting horizontal scaling.</li> \n <li>🏠 Self-Hosted Solution. Complete control over your deployment and data.</li> \n <li>🔑 Flexible Authentication. Support for various LLM providers (<a href=\"https://platform.openai.com/\">OpenAI</a>, <a href=\"https://www.anthropic.com/\">Anthropic</a>, <a href=\"https://ollama.com/\">Ollama</a>, <a href=\"https://aws.amazon.com/bedrock/\">AWS Bedrock</a>, <a href=\"https://ai.google.dev/\">Google AI/Gemini</a>, <a href=\"https://deepinfra.com/\">Deep Infra</a>, <a href=\"https://openrouter.ai/\">OpenRouter</a>, <a href=\"https://www.deepseek.com/en\">DeepSeek</a>), <a href=\"https://platform.moonshot.ai/\">Moonshot</a> and custom configurations.</li> \n <li>🔐 API Token Authentication. Secure Bearer token system for programmatic access to REST and GraphQL APIs.</li> \n <li>⚡ Quick Deployment. Easy setup through <a href=\"https://docs.docker.com/compose/\">Docker Compose</a> with comprehensive environment configuration.</li> \n</ul> \n<h2>🏗️ Architecture</h2> \n<h3>System Context</h3> \n<pre><code class=\"language-mermaid\">flowchart TB\n    classDef person fill:#08427B,stroke:#073B6F,color:#fff\n    classDef system fill:#1168BD,stroke:#0B4884,color:#fff\n    classDef external fill:#666666,stroke:#0B4884,color:#fff\n\n    pentester[\"👤 Security Engineer\n    (User of the system)\"]\n\n    pentagi[\"✨ PentAGI\n    (Autonomous penetration testing system)\"]\n\n    target[\"🎯 target-system\n    (System under test)\"]\n    llm[\"🧠 llm-provider\n    (OpenAI/Anthropic/Ollama/Bedrock/Gemini/Custom)\"]\n    search[\"🔍 search-systems\n    (Google/DuckDuckGo/Tavily/Traversaal/Perplexity/Searxng)\"]\n    langfuse[\"📊 langfuse-ui\n    (LLM Observability Dashboard)\"]\n    grafana[\"📈 grafana\n    (System Monitoring Dashboard)\"]\n\n    pentester --&gt; |Uses HTTPS| pentagi\n    pentester --&gt; |Monitors AI HTTPS| langfuse\n    pentester --&gt; |Monitors System HTTPS| grafana\n    pentagi --&gt; |Tests Various protocols| target\n    pentagi --&gt; |Queries HTTPS| llm\n    pentagi --&gt; |Searches HTTPS| search\n    pentagi --&gt; |Reports HTTPS| langfuse\n    pentagi --&gt; |Reports HTTPS| grafana\n\n    class pentester person\n    class pentagi system\n    class target,llm,search,langfuse,grafana external\n\n    linkStyle default stroke:#ffffff,color:#ffffff\n</code></pre> \n<details> \n <b>🔄 Container Architecture</b> (click to expand) \n <pre><code class=\"language-mermaid\">graph TB\n    subgraph Core Services\n        UI[Frontend UI&lt;br/&gt;React + TypeScript]\n        API[Backend API&lt;br/&gt;Go + GraphQL]\n        DB[(Vector Store&lt;br/&gt;PostgreSQL + pgvector)]\n        MQ[Task Queue&lt;br/&gt;Async Processing]\n        Agent[AI Agents&lt;br/&gt;Multi-Agent System]\n    end\n\n    subgraph Knowledge Graph\n        Graphiti[Graphiti&lt;br/&gt;Knowledge Graph API]\n        Neo4j[(Neo4j&lt;br/&gt;Graph Database)]\n    end\n\n    subgraph Monitoring\n        Grafana[Grafana&lt;br/&gt;Dashboards]\n        VictoriaMetrics[VictoriaMetrics&lt;br/&gt;Time-series DB]\n        Jaeger[Jaeger&lt;br/&gt;Distributed Tracing]\n        Loki[Loki&lt;br/&gt;Log Aggregation]\n        OTEL[OpenTelemetry&lt;br/&gt;Data Collection]\n    end\n\n    subgraph Analytics\n        Langfuse[Langfuse&lt;br/&gt;LLM Analytics]\n        ClickHouse[ClickHouse&lt;br/&gt;Analytics DB]\n        Redis[Redis&lt;br/&gt;Cache + Rate Limiter]\n        MinIO[MinIO&lt;br/&gt;S3 Storage]\n    end\n\n    subgraph Security Tools\n        Scraper[Web Scraper&lt;br/&gt;Isolated Browser]\n        PenTest[Security Tools&lt;br/&gt;20+ Pro Tools&lt;br/&gt;Sandboxed Execution]\n    end\n\n    UI --&gt; |HTTP/WS| API\n    API --&gt; |SQL| DB\n    API --&gt; |Events| MQ\n    MQ --&gt; |Tasks| Agent\n    Agent --&gt; |Commands| PenTest\n    Agent --&gt; |Queries| DB\n    Agent --&gt; |Knowledge| Graphiti\n    Graphiti --&gt; |Graph| Neo4j\n\n    API --&gt; |Telemetry| OTEL\n    OTEL --&gt; |Metrics| VictoriaMetrics\n    OTEL --&gt; |Traces| Jaeger\n    OTEL --&gt; |Logs| Loki\n\n    Grafana --&gt; |Query| VictoriaMetrics\n    Grafana --&gt; |Query| Jaeger\n    Grafana --&gt; |Query| Loki\n\n    API --&gt; |Analytics| Langfuse\n    Langfuse --&gt; |Store| ClickHouse\n    Langfuse --&gt; |Cache| Redis\n    Langfuse --&gt; |Files| MinIO\n\n    classDef core fill:#f9f,stroke:#333,stroke-width:2px,color:#000\n    classDef knowledge fill:#ffa,stroke:#333,stroke-width:2px,color:#000\n    classDef monitoring fill:#bbf,stroke:#333,stroke-width:2px,color:#000\n    classDef analytics fill:#bfb,stroke:#333,stroke-width:2px,color:#000\n    classDef tools fill:#fbb,stroke:#333,stroke-width:2px,color:#000\n\n    class UI,API,DB,MQ,Agent core\n    class Graphiti,Neo4j knowledge\n    class Grafana,VictoriaMetrics,Jaeger,Loki,OTEL monitoring\n    class Langfuse,ClickHouse,Redis,MinIO analytics\n    class Scraper,PenTest tools\n</code></pre> \n</details> \n<details> \n <b>📊 Entity Relationship</b> (click to expand) \n <pre><code class=\"language-mermaid\">erDiagram\n    Flow ||--o{ Task : contains\n    Task ||--o{ SubTask : contains\n    SubTask ||--o{ Action : contains\n    Action ||--o{ Artifact : produces\n    Action ||--o{ Memory : stores\n\n    Flow {\n        string id PK\n        string name \"Flow name\"\n        string description \"Flow description\"\n        string status \"active/completed/failed\"\n        json parameters \"Flow parameters\"\n        timestamp created_at\n        timestamp updated_at\n    }\n\n    Task {\n        string id PK\n        string flow_id FK\n        string name \"Task name\"\n        string description \"Task description\"\n        string status \"pending/running/done/failed\"\n        json result \"Task results\"\n        timestamp created_at\n        timestamp updated_at\n    }\n\n    SubTask {\n        string id PK\n        string task_id FK\n        string name \"Subtask name\"\n        string description \"Subtask description\"\n        string status \"queued/running/completed/failed\"\n        string agent_type \"researcher/developer/executor\"\n        json context \"Agent context\"\n        timestamp created_at\n        timestamp updated_at\n    }\n\n    Action {\n        string id PK\n        string subtask_id FK\n        string type \"command/search/analyze/etc\"\n        string status \"success/failure\"\n        json parameters \"Action parameters\"\n        json result \"Action results\"\n        timestamp created_at\n    }\n\n    Artifact {\n        string id PK\n        string action_id FK\n        string type \"file/report/log\"\n        string path \"Storage path\"\n        json metadata \"Additional info\"\n        timestamp created_at\n    }\n\n    Memory {\n        string id PK\n        string action_id FK\n        string type \"observation/conclusion\"\n        vector embedding \"Vector representation\"\n        text content \"Memory content\"\n        timestamp created_at\n    }\n</code></pre> \n</details> \n<details> \n <b>🤖 Agent Interaction</b> (click to expand) \n <pre><code class=\"language-mermaid\">sequenceDiagram\n    participant O as Orchestrator\n    participant R as Researcher\n    participant D as Developer\n    participant E as Executor\n    participant VS as Vector Store\n    participant KB as Knowledge Base\n\n    Note over O,KB: Flow Initialization\n    O-&gt;&gt;VS: Query similar tasks\n    VS--&gt;&gt;O: Return experiences\n    O-&gt;&gt;KB: Load relevant knowledge\n    KB--&gt;&gt;O: Return context\n\n    Note over O,R: Research Phase\n    O-&gt;&gt;R: Analyze target\n    R-&gt;&gt;VS: Search similar cases\n    VS--&gt;&gt;R: Return patterns\n    R-&gt;&gt;KB: Query vulnerabilities\n    KB--&gt;&gt;R: Return known issues\n    R-&gt;&gt;VS: Store findings\n    R--&gt;&gt;O: Research results\n\n    Note over O,D: Planning Phase\n    O-&gt;&gt;D: Plan attack\n    D-&gt;&gt;VS: Query exploits\n    VS--&gt;&gt;D: Return techniques\n    D-&gt;&gt;KB: Load tools info\n    KB--&gt;&gt;D: Return capabilities\n    D--&gt;&gt;O: Attack plan\n\n    Note over O,E: Execution Phase\n    O-&gt;&gt;E: Execute plan\n    E-&gt;&gt;KB: Load tool guides\n    KB--&gt;&gt;E: Return procedures\n    E-&gt;&gt;VS: Store results\n    E--&gt;&gt;O: Execution status\n</code></pre> \n</details> \n<details> \n <b>🧠 Memory System</b> (click to expand) \n <pre><code class=\"language-mermaid\">graph TB\n    subgraph \"Long-term Memory\"\n        VS[(Vector Store&lt;br/&gt;Embeddings DB)]\n        KB[Knowledge Base&lt;br/&gt;Domain Expertise]\n        Tools[Tools Knowledge&lt;br/&gt;Usage Patterns]\n    end\n\n    subgraph \"Working Memory\"\n        Context[Current Context&lt;br/&gt;Task State]\n        Goals[Active Goals&lt;br/&gt;Objectives]\n        State[System State&lt;br/&gt;Resources]\n    end\n\n    subgraph \"Episodic Memory\"\n        Actions[Past Actions&lt;br/&gt;Commands History]\n        Results[Action Results&lt;br/&gt;Outcomes]\n        Patterns[Success Patterns&lt;br/&gt;Best Practices]\n    end\n\n    Context --&gt; |Query| VS\n    VS --&gt; |Retrieve| Context\n\n    Goals --&gt; |Consult| KB\n    KB --&gt; |Guide| Goals\n\n    State --&gt; |Record| Actions\n    Actions --&gt; |Learn| Patterns\n    Patterns --&gt; |Store| VS\n\n    Tools --&gt; |Inform| State\n    Results --&gt; |Update| Tools\n\n    VS --&gt; |Enhance| KB\n    KB --&gt; |Index| VS\n\n    classDef ltm fill:#f9f,stroke:#333,stroke-width:2px,color:#000\n    classDef wm fill:#bbf,stroke:#333,stroke-width:2px,color:#000\n    classDef em fill:#bfb,stroke:#333,stroke-width:2px,color:#000\n\n    class VS,KB,Tools ltm\n    class Context,Goals,State wm\n    class Actions,Results,Patterns em\n</code></pre> \n</details> \n<details> \n <b>🔄 Chain Summarization</b> (click to expand) \n <p>The chain summarization system manages conversation context growth by selectively summarizing older messages. This is critical for preventing token limits from being exceeded while maintaining conversation coherence.</p> \n <pre><code class=\"language-mermaid\">flowchart TD\n    A[Input Chain] --&gt; B{Needs Summarization?}\n    B --&gt;|No| C[Return Original Chain]\n    B --&gt;|Yes| D[Convert to ChainAST]\n    D --&gt; E[Apply Section Summarization]\n    E --&gt; F[Process Oversized Pairs]\n    F --&gt; G[Manage Last Section Size]\n    G --&gt; H[Apply QA Summarization]\n    H --&gt; I[Rebuild Chain with Summaries]\n    I --&gt; J{Is New Chain Smaller?}\n    J --&gt;|Yes| K[Return Optimized Chain]\n    J --&gt;|No| C\n\n    classDef process fill:#bbf,stroke:#333,stroke-width:2px,color:#000\n    classDef decision fill:#bfb,stroke:#333,stroke-width:2px,color:#000\n    classDef output fill:#fbb,stroke:#333,stroke-width:2px,color:#000\n\n    class A,D,E,F,G,H,I process\n    class B,J decision\n    class C,K output\n</code></pre> \n <p>The algorithm operates on a structured representation of conversation chains (ChainAST) that preserves message types including tool calls and their responses. All summarization operations maintain critical conversation flow while reducing context size.</p> \n <h3>Global Summarizer Configuration Options</h3> \n <table> \n  <thead> \n   <tr> \n    <th>Parameter</th> \n    <th>Environment Variable</th> \n    <th>Default</th> \n    <th>Description</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>Preserve Last</td> \n    <td><code>SUMMARIZER_PRESERVE_LAST</code></td> \n    <td><code>true</code></td> \n    <td>Whether to keep all messages in the last section intact</td> \n   </tr> \n   <tr> \n    <td>Use QA Pairs</td> \n    <td><code>SUMMARIZER_USE_QA</code></td> \n    <td><code>true</code></td> \n    <td>Whether to use QA pair summarization strategy</td> \n   </tr> \n   <tr> \n    <td>Summarize Human in QA</td> \n    <td><code>SUMMARIZER_SUM_MSG_HUMAN_IN_QA</code></td> \n    <td><code>false</code></td> \n    <td>Whether to summarize human messages in QA pairs</td> \n   </tr> \n   <tr> \n    <td>Last Section Size</td> \n    <td><code>SUMMARIZER_LAST_SEC_BYTES</code></td> \n    <td><code>51200</code></td> \n    <td>Maximum byte size for last section (50KB)</td> \n   </tr> \n   <tr> \n    <td>Max Body Pair Size</td> \n    <td><code>SUMMARIZER_MAX_BP_BYTES</code></td> \n    <td><code>16384</code></td> \n    <td>Maximum byte size for a single body pair (16KB)</td> \n   </tr> \n   <tr> \n    <td>Max QA Sections</td> \n    <td><code>SUMMARIZER_MAX_QA_SECTIONS</code></td> \n    <td><code>10</code></td> \n    <td>Maximum QA pair sections to preserve</td> \n   </tr> \n   <tr> \n    <td>Max QA Size</td> \n    <td><code>SUMMARIZER_MAX_QA_BYTES</code></td> \n    <td><code>65536</code></td> \n    <td>Maximum byte size for QA pair sections (64KB)</td> \n   </tr> \n   <tr> \n    <td>Keep QA Sections</td> \n    <td><code>SUMMARIZER_KEEP_QA_SECTIONS</code></td> \n    <td><code>1</code></td> \n    <td>Number of recent QA sections to keep without summarization</td> \n   </tr> \n  </tbody> \n </table> \n <h3>Assistant Summarizer Configuration Options</h3> \n <p>Assistant instances can use customized summarization settings to fine-tune context management behavior:</p> \n <table> \n  <thead> \n   <tr> \n    <th>Parameter</th> \n    <th>Environment Variable</th> \n    <th>Default</th> \n    <th>Description</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>Preserve Last</td> \n    <td><code>ASSISTANT_SUMMARIZER_PRESERVE_LAST</code></td> \n    <td><code>true</code></td> \n    <td>Whether to preserve all messages in the assistant's last section</td> \n   </tr> \n   <tr> \n    <td>Last Section Size</td> \n    <td><code>ASSISTANT_SUMMARIZER_LAST_SEC_BYTES</code></td> \n    <td><code>76800</code></td> \n    <td>Maximum byte size for assistant's last section (75KB)</td> \n   </tr> \n   <tr> \n    <td>Max Body Pair Size</td> \n    <td><code>ASSISTANT_SUMMARIZER_MAX_BP_BYTES</code></td> \n    <td><code>16384</code></td> \n    <td>Maximum byte size for a single body pair in assistant context (16KB)</td> \n   </tr> \n   <tr> \n    <td>Max QA Sections</td> \n    <td><code>ASSISTANT_SUMMARIZER_MAX_QA_SECTIONS</code></td> \n    <td><code>7</code></td> \n    <td>Maximum QA sections to preserve in assistant context</td> \n   </tr> \n   <tr> \n    <td>Max QA Size</td> \n    <td><code>ASSISTANT_SUMMARIZER_MAX_QA_BYTES</code></td> \n    <td><code>76800</code></td> \n    <td>Maximum byte size for assistant's QA sections (75KB)</td> \n   </tr> \n   <tr> \n    <td>Keep QA Sections</td> \n    <td><code>ASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS</code></td> \n    <td><code>3</code></td> \n    <td>Number of recent QA sections to preserve without summarization</td> \n   </tr> \n  </tbody> \n </table> \n <p>The assistant summarizer configuration provides more memory for context retention compared to the global settings, preserving more recent conversation history while still ensuring efficient token usage.</p> \n <h3>Summarizer Environment Configuration</h3> \n <pre><code class=\"language-bash\"># Default values for global summarizer logic\nSUMMARIZER_PRESERVE_LAST=true\nSUMMARIZER_USE_QA=true\nSUMMARIZER_SUM_MSG_HUMAN_IN_QA=false\nSUMMARIZER_LAST_SEC_BYTES=51200\nSUMMARIZER_MAX_BP_BYTES=16384\nSUMMARIZER_MAX_QA_SECTIONS=10\nSUMMARIZER_MAX_QA_BYTES=65536\nSUMMARIZER_KEEP_QA_SECTIONS=1\n\n# Default values for assistant summarizer logic\nASSISTANT_SUMMARIZER_PRESERVE_LAST=true\nASSISTANT_SUMMARIZER_LAST_SEC_BYTES=76800\nASSISTANT_SUMMARIZER_MAX_BP_BYTES=16384\nASSISTANT_SUMMARIZER_MAX_QA_SECTIONS=7\nASSISTANT_SUMMARIZER_MAX_QA_BYTES=76800\nASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS=3\n</code></pre> \n</details> \n<p>The architecture of PentAGI is designed to be modular, scalable, and secure. Here are the key components:</p> \n<ol> \n <li> <p><strong>Core Services</strong></p> \n  <ul> \n   <li>Frontend UI: React-based web interface with TypeScript for type safety</li> \n   <li>Backend API: Go-based REST and GraphQL APIs with Bearer token authentication for programmatic access</li> \n   <li>Vector Store: PostgreSQL with pgvector for semantic search and memory storage</li> \n   <li>Task Queue: Async task processing system for reliable operation</li> \n   <li>AI Agent: Multi-agent system with specialized roles for efficient testing</li> \n  </ul> </li> \n <li> <p><strong>Knowledge Graph</strong></p> \n  <ul> \n   <li>Graphiti: Knowledge graph API for semantic relationship tracking and contextual understanding</li> \n   <li>Neo4j: Graph database for storing and querying relationships between entities, actions, and outcomes</li> \n   <li>Automatic capturing of agent responses and tool executions for building comprehensive knowledge base</li> \n  </ul> </li> \n <li> <p><strong>Monitoring Stack</strong></p> \n  <ul> \n   <li>OpenTelemetry: Unified observability data collection and correlation</li> \n   <li>Grafana: Real-time visualization and alerting dashboards</li> \n   <li>VictoriaMetrics: High-performance time-series metrics storage</li> \n   <li>Jaeger: End-to-end distributed tracing for debugging</li> \n   <li>Loki: Scalable log aggregation and analysis</li> \n  </ul> </li> \n <li> <p><strong>Analytics Platform</strong></p> \n  <ul> \n   <li>Langfuse: Advanced LLM observability and performance analytics</li> \n   <li>ClickHouse: Column-oriented analytics data warehouse</li> \n   <li>Redis: High-speed caching and rate limiting</li> \n   <li>MinIO: S3-compatible object storage for artifacts</li> \n  </ul> </li> \n <li> <p><strong>Security Tools</strong></p> \n  <ul> \n   <li>Web Scraper: Isolated browser environment for safe web interaction</li> \n   <li>Pentesting Tools: Comprehensive suite of 20+ professional security tools</li> \n   <li>Sandboxed Execution: All operations run in isolated containers</li> \n  </ul> </li> \n <li> <p><strong>Memory Systems</strong></p> \n  <ul> \n   <li>Long-term Memory: Persistent storage of knowledge and experiences</li> \n   <li>Working Memory: Active context and goals for current operations</li> \n   <li>Episodic Memory: Historical actions and success patterns</li> \n   <li>Knowledge Base: Structured domain expertise and tool capabilities</li> \n   <li>Context Management: Intelligently manages growing LLM context windows using chain summarization</li> \n  </ul> </li> \n</ol> \n<p>The system uses Docker containers for isolation and easy deployment, with separate networks for core services, monitoring, and analytics to ensure proper security boundaries. Each component is designed to scale horizontally and can be configured for high availability in production environments.</p> \n<h2>🚀 Quick Start</h2> \n<h3>System Requirements</h3> \n<ul> \n <li>Docker and Docker Compose</li> \n <li>Minimum 2 vCPU</li> \n <li>Minimum 4GB RAM</li> \n <li>20GB free disk space</li> \n <li>Internet access for downloading images and updates</li> \n</ul> \n<h3>Using Installer (Recommended)</h3> \n<p>PentAGI provides an interactive installer with a terminal-based UI for streamlined configuration and deployment. The installer guides you through system checks, LLM provider setup, search engine configuration, and security hardening.</p> \n<p><strong>Supported Platforms:</strong></p> \n<ul> \n <li><strong>Linux</strong>: amd64 <a href=\"https://pentagi.com/downloads/linux/amd64/installer-latest.zip\">download</a> | arm64 <a href=\"https://pentagi.com/downloads/linux/arm64/installer-latest.zip\">download</a></li> \n <li><strong>Windows</strong>: amd64 <a href=\"https://pentagi.com/downloads/windows/amd64/installer-latest.zip\">download</a></li> \n <li><strong>macOS</strong>: amd64 (Intel) <a href=\"https://pentagi.com/downloads/darwin/amd64/installer-latest.zip\">download</a> | arm64 (M-series) <a href=\"https://pentagi.com/downloads/darwin/arm64/installer-latest.zip\">download</a></li> \n</ul> \n<p><strong>Quick Installation (Linux amd64):</strong></p> \n<pre><code class=\"language-bash\"># Create installation directory\nmkdir -p pentagi &amp;&amp; cd pentagi\n\n# Download installer\nwget -O installer.zip https://pentagi.com/downloads/linux/amd64/installer-latest.zip\n\n# Extract\nunzip installer.zip\n\n# Run interactive installer\n./installer\n</code></pre> \n<p><strong>Prerequisites &amp; Permissions:</strong></p> \n<p>The installer requires appropriate privileges to interact with the Docker API for proper operation. By default, it uses the Docker socket (<code>/var/run/docker.sock</code>) which requires either:</p> \n<ul> \n <li> <p><strong>Option 1 (Recommended for production):</strong> Run the installer as root:</p> <pre><code class=\"language-bash\">sudo ./installer\n</code></pre> </li> \n <li> <p><strong>Option 2 (Development environments):</strong> Grant your user access to the Docker socket by adding them to the <code>docker</code> group:</p> <pre><code class=\"language-bash\"># Add your user to the docker group\nsudo usermod -aG docker $USER\n\n# Log out and log back in, or activate the group immediately\nnewgrp docker\n\n# Verify Docker access (should run without sudo)\ndocker ps\n</code></pre> <p>⚠️ <strong>Security Note:</strong> Adding a user to the <code>docker</code> group grants root-equivalent privileges. Only do this for trusted users in controlled environments. For production deployments, consider using rootless Docker mode or running the installer with sudo.</p> </li> \n</ul> \n<p>The installer will:</p> \n<ol> \n <li><strong>System Checks</strong>: Verify Docker, network connectivity, and system requirements</li> \n <li><strong>Environment Setup</strong>: Create and configure <code>.env</code> file with optimal defaults</li> \n <li><strong>Provider Configuration</strong>: Set up LLM providers (OpenAI, Anthropic, Gemini, Bedrock, Ollama, Custom)</li> \n <li><strong>Search Engines</strong>: Configure DuckDuckGo, Google, Tavily, Traversaal, Perplexity, Searxng</li> \n <li><strong>Security Hardening</strong>: Generate secure credentials and configure SSL certificates</li> \n <li><strong>Deployment</strong>: Start PentAGI with docker-compose</li> \n</ol> \n<p><strong>For Production &amp; Enhanced Security:</strong></p> \n<p>For production deployments or security-sensitive environments, we <strong>strongly recommend</strong> using a distributed two-node architecture where worker operations are isolated on a separate server. This prevents untrusted code execution and network access issues on your main system.</p> \n<p>👉 <strong>See detailed guide</strong>: <a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/examples/guides/worker_node.md\">Worker Node Setup</a></p> \n<p>The two-node setup provides:</p> \n<ul> \n <li><strong>Isolated Execution</strong>: Worker containers run on dedicated hardware</li> \n <li><strong>Network Isolation</strong>: Separate network boundaries for penetration testing</li> \n <li><strong>Security Boundaries</strong>: Docker-in-Docker with TLS authentication</li> \n <li><strong>OOB Attack Support</strong>: Dedicated port ranges for out-of-band techniques</li> \n</ul> \n<h3>Manual Installation</h3> \n<ol> \n <li>Create a working directory or clone the repository:</li> \n</ol> \n<pre><code class=\"language-bash\">mkdir pentagi &amp;&amp; cd pentagi\n</code></pre> \n<ol start=\"2\"> \n <li>Copy <code>.env.example</code> to <code>.env</code> or download it:</li> \n</ol> \n<pre><code class=\"language-bash\">curl -o .env https://raw.githubusercontent.com/vxcontrol/pentagi/master/.env.example\n</code></pre> \n<ol start=\"3\"> \n <li>Touch examples files (<code>example.custom.provider.yml</code>, <code>example.ollama.provider.yml</code>) or download it:</li> \n</ol> \n<pre><code class=\"language-bash\">curl -o example.custom.provider.yml https://raw.githubusercontent.com/vxcontrol/pentagi/master/examples/configs/custom-openai.provider.yml\ncurl -o example.ollama.provider.yml https://raw.githubusercontent.com/vxcontrol/pentagi/master/examples/configs/ollama-llama318b.provider.yml\n</code></pre> \n<ol start=\"4\"> \n <li>Fill in the required API keys in <code>.env</code> file.</li> \n</ol> \n<pre><code class=\"language-bash\"># Required: At least one of these LLM providers\nOPEN_AI_KEY=your_openai_key\nANTHROPIC_API_KEY=your_anthropic_key\nGEMINI_API_KEY=your_gemini_key\n\n# Optional: AWS Bedrock provider (enterprise-grade models)\nBEDROCK_REGION=us-east-1\nBEDROCK_ACCESS_KEY_ID=your_aws_access_key\nBEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key\n\n# Optional: Local LLM provider (zero-cost inference)\nOLLAMA_SERVER_URL=http://localhost:11434\nOLLAMA_SERVER_MODEL=your_model_name\n\n# Optional: Additional search capabilities\nDUCKDUCKGO_ENABLED=true\nGOOGLE_API_KEY=your_google_key\nGOOGLE_CX_KEY=your_google_cx\nTAVILY_API_KEY=your_tavily_key\nTRAVERSAAL_API_KEY=your_traversaal_key\nPERPLEXITY_API_KEY=your_perplexity_key\nPERPLEXITY_MODEL=sonar-pro\nPERPLEXITY_CONTEXT_SIZE=medium\n\n# Searxng meta search engine (aggregates results from multiple sources)\nSEARXNG_URL=http://your-searxng-instance:8080\nSEARXNG_CATEGORIES=general\nSEARXNG_LANGUAGE=\nSEARXNG_SAFESEARCH=0\nSEARXNG_TIME_RANGE=\n\n## Graphiti knowledge graph settings\nGRAPHITI_ENABLED=true\nGRAPHITI_TIMEOUT=30\nGRAPHITI_URL=http://graphiti:8000\nGRAPHITI_MODEL_NAME=gpt-5-mini\n\n# Neo4j settings (used by Graphiti stack)\nNEO4J_USER=neo4j\nNEO4J_DATABASE=neo4j\nNEO4J_PASSWORD=devpassword\nNEO4J_URI=bolt://neo4j:7687\n\n# Assistant configuration\nASSISTANT_USE_AGENTS=false         # Default value for agent usage when creating new assistants\n</code></pre> \n<ol start=\"5\"> \n <li>Change all security related environment variables in <code>.env</code> file to improve security.</li> \n</ol> \n<details> \n Security related environment variables \n <h3>Main Security Settings</h3> \n <ul> \n  <li><code>COOKIE_SIGNING_SALT</code> - Salt for cookie signing, change to random value</li> \n  <li><code>PUBLIC_URL</code> - Public URL of your server (eg. <code>https://pentagi.example.com</code>)</li> \n  <li><code>SERVER_SSL_CRT</code> and <code>SERVER_SSL_KEY</code> - Custom paths to your existing SSL certificate and key for HTTPS (these paths should be used in the docker-compose.yml file to mount as volumes)</li> \n </ul> \n <h3>Scraper Access</h3> \n <ul> \n  <li><code>SCRAPER_PUBLIC_URL</code> - Public URL for scraper if you want to use different scraper server for public URLs</li> \n  <li><code>SCRAPER_PRIVATE_URL</code> - Private URL for scraper (local scraper server in docker-compose.yml file to access it to local URLs)</li> \n </ul> \n <h3>Access Credentials</h3> \n <ul> \n  <li><code>PENTAGI_POSTGRES_USER</code> and <code>PENTAGI_POSTGRES_PASSWORD</code> - PostgreSQL credentials</li> \n  <li><code>NEO4J_USER</code> and <code>NEO4J_PASSWORD</code> - Neo4j credentials (for Graphiti knowledge graph)</li> \n </ul> \n</details> \n<ol start=\"6\"> \n <li>Remove all inline comments from <code>.env</code> file if you want to use it in VSCode or other IDEs as a envFile option:</li> \n</ol> \n<pre><code class=\"language-bash\">perl -i -pe 's/\\s+#.*$//' .env\n</code></pre> \n<ol start=\"7\"> \n <li>Run the PentAGI stack:</li> \n</ol> \n<pre><code class=\"language-bash\">curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose.yml\ndocker compose up -d\n</code></pre> \n<p>Visit <a href=\"https://localhost:8443\">localhost:8443</a> to access PentAGI Web UI (default is <code>admin@pentagi.com</code> / <code>admin</code>)</p> \n<blockquote> \n <p>[!NOTE] If you caught an error about <code>pentagi-network</code> or <code>observability-network</code> or <code>langfuse-network</code> you need to run <code>docker-compose.yml</code> firstly to create these networks and after that run <code>docker-compose-langfuse.yml</code>, <code>docker-compose-graphiti.yml</code>, and <code>docker-compose-observability.yml</code> to use Langfuse, Graphiti, and Observability services.</p> \n <p>You have to set at least one Language Model provider (OpenAI, Anthropic, Gemini, AWS Bedrock, or Ollama) to use PentAGI. AWS Bedrock provides enterprise-grade access to multiple foundation models from leading AI companies, while Ollama provides zero-cost local inference if you have sufficient computational resources. Additional API keys for search engines are optional but recommended for better results.</p> \n <p><code>LLM_SERVER_*</code> environment variables are experimental feature and will be changed in the future. Right now you can use them to specify custom LLM server URL and one model for all agent types.</p> \n <p><code>PROXY_URL</code> is a global proxy URL for all LLM providers and external search systems. You can use it for isolation from external networks.</p> \n <p>The <code>docker-compose.yml</code> file runs the PentAGI service as root user because it needs access to docker.sock for container management. If you're using TCP/IP network connection to Docker instead of socket file, you can remove root privileges and use the default <code>pentagi</code> user for better security.</p> \n</blockquote> \n<h3>Assistant Configuration</h3> \n<p>PentAGI allows you to configure default behavior for assistants:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>ASSISTANT_USE_AGENTS</code></td> \n   <td><code>false</code></td> \n   <td>Controls the default value for agent usage when creating new assistants</td> \n  </tr> \n </tbody> \n</table> \n<p>The <code>ASSISTANT_USE_AGENTS</code> setting affects the initial state of the \"Use Agents\" toggle when creating a new assistant in the UI:</p> \n<ul> \n <li><code>false</code> (default): New assistants are created with agent delegation disabled by default</li> \n <li><code>true</code>: New assistants are created with agent delegation enabled by default</li> \n</ul> \n<p>Note that users can always override this setting by toggling the \"Use Agents\" button in the UI when creating or editing an assistant. This environment variable only controls the initial default state.</p> \n<h2>🔌 API Access</h2> \n<p>PentAGI provides comprehensive programmatic access through both REST and GraphQL APIs, allowing you to integrate penetration testing workflows into your automation pipelines, CI/CD processes, and custom applications.</p> \n<h3>Generating API Tokens</h3> \n<p>API tokens are managed through the PentAGI web interface:</p> \n<ol> \n <li>Navigate to <strong>Settings</strong> → <strong>API Tokens</strong> in the web UI</li> \n <li>Click <strong>Create Token</strong> to generate a new API token</li> \n <li>Configure token properties: \n  <ul> \n   <li><strong>Name</strong> (optional): A descriptive name for the token</li> \n   <li><strong>Expiration Date</strong>: When the token will expire (minimum 1 minute, maximum 3 years)</li> \n  </ul> </li> \n <li>Click <strong>Create</strong> and <strong>copy the token immediately</strong> - it will only be shown once for security reasons</li> \n <li>Use the token as a Bearer token in your API requests</li> \n</ol> \n<p>Each token is associated with your user account and inherits your role's permissions.</p> \n<h3>Using API Tokens</h3> \n<p>Include the API token in the <code>Authorization</code> header of your HTTP requests:</p> \n<pre><code class=\"language-bash\"># GraphQL API example\ncurl -X POST https://your-pentagi-instance:8443/api/v1/graphql \\\n  -H \"Authorization: Bearer YOUR_API_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"{ flows { id title status } }\"}'\n\n# REST API example\ncurl https://your-pentagi-instance:8443/api/v1/flows \\\n  -H \"Authorization: Bearer YOUR_API_TOKEN\"\n</code></pre> \n<h3>API Exploration and Testing</h3> \n<p>PentAGI provides interactive documentation for exploring and testing API endpoints:</p> \n<h4>GraphQL Playground</h4> \n<p>Access the GraphQL Playground at <code>https://your-pentagi-instance:8443/api/v1/graphql/playground</code></p> \n<ol> \n <li>Click the <strong>HTTP Headers</strong> tab at the bottom</li> \n <li>Add your authorization header: <pre><code class=\"language-json\">{\n  \"Authorization\": \"Bearer YOUR_API_TOKEN\"\n}\n</code></pre> </li> \n <li>Explore the schema, run queries, and test mutations interactively</li> \n</ol> \n<h4>Swagger UI</h4> \n<p>Access the REST API documentation at <code>https://your-pentagi-instance:8443/api/v1/swagger/index.html</code></p> \n<ol> \n <li>Click the <strong>Authorize</strong> button</li> \n <li>Enter your token in the format: <code>Bearer YOUR_API_TOKEN</code></li> \n <li>Click <strong>Authorize</strong> to apply</li> \n <li>Test endpoints directly from the Swagger UI</li> \n</ol> \n<h3>Generating API Clients</h3> \n<p>You can generate type-safe API clients for your preferred programming language using the schema files included with PentAGI:</p> \n<h4>GraphQL Clients</h4> \n<p>The GraphQL schema is available at:</p> \n<ul> \n <li><strong>Web UI</strong>: Navigate to Settings to download <code>schema.graphqls</code></li> \n <li><strong>Direct file</strong>: <code>backend/pkg/graph/schema.graphqls</code> in the repository</li> \n</ul> \n<p>Generate clients using tools like:</p> \n<ul> \n <li><strong>GraphQL Code Generator</strong> (JavaScript/TypeScript): <a href=\"https://the-guild.dev/graphql/codegen\">https://the-guild.dev/graphql/codegen</a></li> \n <li><strong>genqlient</strong> (Go): <a href=\"https://github.com/Khan/genqlient\">https://github.com/Khan/genqlient</a></li> \n <li><strong>Apollo iOS</strong> (Swift): <a href=\"https://www.apollographql.com/docs/ios\">https://www.apollographql.com/docs/ios</a></li> \n</ul> \n<h4>REST API Clients</h4> \n<p>The OpenAPI specification is available at:</p> \n<ul> \n <li><strong>Swagger JSON</strong>: <code>https://your-pentagi-instance:8443/api/v1/swagger/doc.json</code></li> \n <li><strong>Swagger YAML</strong>: Available in <code>backend/pkg/server/docs/swagger.yaml</code></li> \n</ul> \n<p>Generate clients using:</p> \n<ul> \n <li> <p><strong>OpenAPI Generator</strong>: <a href=\"https://openapi-generator.tech\">https://openapi-generator.tech</a></p> <pre><code class=\"language-bash\">openapi-generator-cli generate \\\n  -i https://your-pentagi-instance:8443/api/v1/swagger/doc.json \\\n  -g python \\\n  -o ./pentagi-client\n</code></pre> </li> \n <li> <p><strong>Swagger Codegen</strong>: <a href=\"https://github.com/swagger-api/swagger-codegen\">https://github.com/swagger-api/swagger-codegen</a></p> <pre><code class=\"language-bash\">swagger-codegen generate \\\n  -i https://your-pentagi-instance:8443/api/v1/swagger/doc.json \\\n  -l typescript-axios \\\n  -o ./pentagi-client\n</code></pre> </li> \n <li> <p><strong>swagger-typescript-api</strong> (TypeScript): <a href=\"https://github.com/acacode/swagger-typescript-api\">https://github.com/acacode/swagger-typescript-api</a></p> <pre><code class=\"language-bash\">npx swagger-typescript-api \\\n  -p https://your-pentagi-instance:8443/api/v1/swagger/doc.json \\\n  -o ./src/api \\\n  -n pentagi-api.ts\n</code></pre> </li> \n</ul> \n<h3>API Usage Examples</h3> \n<details> \n <b>Creating a New Flow (GraphQL)</b> \n <pre><code class=\"language-graphql\">mutation CreateFlow {\n  createFlow(\n    modelProvider: \"openai\"\n    input: \"Test the security of https://example.com\"\n  ) {\n    id\n    title\n    status\n    createdAt\n  }\n}\n</code></pre> \n</details> \n<details> \n <b>Listing Flows (REST API)</b> \n <pre><code class=\"language-bash\">curl https://your-pentagi-instance:8443/api/v1/flows \\\n  -H \"Authorization: Bearer YOUR_API_TOKEN\" \\\n  | jq '.flows[] | {id, title, status}'\n</code></pre> \n</details> \n<details> \n <b>Python Client Example</b> \n <pre><code class=\"language-python\">import requests\n\nclass PentAGIClient:\n    def __init__(self, base_url, api_token):\n        self.base_url = base_url\n        self.headers = {\n            \"Authorization\": f\"Bearer {api_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n    \n    def create_flow(self, provider, target):\n        query = \"\"\"\n        mutation CreateFlow($provider: String!, $input: String!) {\n          createFlow(modelProvider: $provider, input: $input) {\n            id\n            title\n            status\n          }\n        }\n        \"\"\"\n        response = requests.post(\n            f\"{self.base_url}/api/v1/graphql\",\n            json={\n                \"query\": query,\n                \"variables\": {\n                    \"provider\": provider,\n                    \"input\": target\n                }\n            },\n            headers=self.headers\n        )\n        return response.json()\n    \n    def get_flows(self):\n        response = requests.get(\n            f\"{self.base_url}/api/v1/flows\",\n            headers=self.headers\n        )\n        return response.json()\n\n# Usage\nclient = PentAGIClient(\n    \"https://your-pentagi-instance:8443\",\n    \"your_api_token_here\"\n)\n\n# Create a new flow\nflow = client.create_flow(\"openai\", \"Scan https://example.com for vulnerabilities\")\nprint(f\"Created flow: {flow}\")\n\n# List all flows\nflows = client.get_flows()\nprint(f\"Total flows: {len(flows['flows'])}\")\n</code></pre> \n</details> \n<details> \n <b>TypeScript Client Example</b> \n <pre><code class=\"language-typescript\">import axios, { AxiosInstance } from 'axios';\n\ninterface Flow {\n  id: string;\n  title: string;\n  status: string;\n  createdAt: string;\n}\n\nclass PentAGIClient {\n  private client: AxiosInstance;\n\n  constructor(baseURL: string, apiToken: string) {\n    this.client = axios.create({\n      baseURL: `${baseURL}/api/v1`,\n      headers: {\n        'Authorization': `Bearer ${apiToken}`,\n        'Content-Type': 'application/json',\n      },\n    });\n  }\n\n  async createFlow(provider: string, input: string): Promise&lt;Flow&gt; {\n    const query = `\n      mutation CreateFlow($provider: String!, $input: String!) {\n        createFlow(modelProvider: $provider, input: $input) {\n          id\n          title\n          status\n          createdAt\n        }\n      }\n    `;\n\n    const response = await this.client.post('/graphql', {\n      query,\n      variables: { provider, input },\n    });\n\n    return response.data.data.createFlow;\n  }\n\n  async getFlows(): Promise&lt;Flow[]&gt; {\n    const response = await this.client.get('/flows');\n    return response.data.flows;\n  }\n\n  async getFlow(flowId: string): Promise&lt;Flow&gt; {\n    const response = await this.client.get(`/flows/${flowId}`);\n    return response.data;\n  }\n}\n\n// Usage\nconst client = new PentAGIClient(\n  'https://your-pentagi-instance:8443',\n  'your_api_token_here'\n);\n\n// Create a new flow\nconst flow = await client.createFlow(\n  'openai',\n  'Perform penetration test on https://example.com'\n);\nconsole.log('Created flow:', flow);\n\n// List all flows\nconst flows = await client.getFlows();\nconsole.log(`Total flows: ${flows.length}`);\n</code></pre> \n</details> \n<h3>Security Best Practices</h3> \n<p>When working with API tokens:</p> \n<ul> \n <li><strong>Never commit tokens to version control</strong> - use environment variables or secrets management</li> \n <li><strong>Rotate tokens regularly</strong> - set appropriate expiration dates and create new tokens periodically</li> \n <li><strong>Use separate tokens for different applications</strong> - makes it easier to revoke access if needed</li> \n <li><strong>Monitor token usage</strong> - review API token activity in the Settings page</li> \n <li><strong>Revoke unused tokens</strong> - disable or delete tokens that are no longer needed</li> \n <li><strong>Use HTTPS only</strong> - never send API tokens over unencrypted connections</li> \n</ul> \n<h3>Token Management</h3> \n<ul> \n <li><strong>View tokens</strong>: See all your active tokens in Settings → API Tokens</li> \n <li><strong>Edit tokens</strong>: Update token names or revoke tokens</li> \n <li><strong>Delete tokens</strong>: Permanently remove tokens (this action cannot be undone)</li> \n <li><strong>Token ID</strong>: Each token has a unique ID that can be copied for reference</li> \n</ul> \n<p>The token list shows:</p> \n<ul> \n <li>Token name (if provided)</li> \n <li>Token ID (unique identifier)</li> \n <li>Status (active/revoked/expired)</li> \n <li>Creation date</li> \n <li>Expiration date</li> \n</ul> \n<h3>Custom LLM Provider Configuration</h3> \n<p>When using custom LLM providers with the <code>LLM_SERVER_*</code> variables, you can fine-tune the reasoning format used in requests:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>LLM_SERVER_URL</code></td> \n   <td></td> \n   <td>Base URL for the custom LLM API endpoint</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_KEY</code></td> \n   <td></td> \n   <td>API key for the custom LLM provider</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_MODEL</code></td> \n   <td></td> \n   <td>Default model to use (can be overridden in provider config)</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_CONFIG_PATH</code></td> \n   <td></td> \n   <td>Path to the YAML configuration file for agent-specific models</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_PROVIDER</code></td> \n   <td></td> \n   <td>Provider name prefix for model names (e.g., <code>openrouter</code>, <code>deepseek</code> for LiteLLM proxy)</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_LEGACY_REASONING</code></td> \n   <td><code>false</code></td> \n   <td>Controls reasoning format in API requests</td> \n  </tr> \n  <tr> \n   <td><code>LLM_SERVER_PRESERVE_REASONING</code></td> \n   <td><code>false</code></td> \n   <td>Preserve reasoning content in multi-turn conversations (required by some providers)</td> \n  </tr> \n </tbody> \n</table> \n<p>The <code>LLM_SERVER_PROVIDER</code> setting is particularly useful when using <strong>LiteLLM proxy</strong>, which adds a provider prefix to model names. For example, when connecting to Moonshot API through LiteLLM, models like <code>kimi-2.5</code> become <code>moonshot/kimi-2.5</code>. By setting <code>LLM_SERVER_PROVIDER=moonshot</code>, you can use the same provider configuration file for both direct API access and LiteLLM proxy access without modifications.</p> \n<p>The <code>LLM_SERVER_LEGACY_REASONING</code> setting affects how reasoning parameters are sent to the LLM:</p> \n<ul> \n <li><code>false</code> (default): Uses modern format where reasoning is sent as a structured object with <code>max_tokens</code> parameter</li> \n <li><code>true</code>: Uses legacy format with string-based <code>reasoning_effort</code> parameter</li> \n</ul> \n<p>This setting is important when working with different LLM providers as they may expect different reasoning formats in their API requests. If you encounter reasoning-related errors with custom providers, try changing this setting.</p> \n<p>The <code>LLM_SERVER_PRESERVE_REASONING</code> setting controls whether reasoning content is preserved in multi-turn conversations:</p> \n<ul> \n <li><code>false</code> (default): Reasoning content is not preserved in conversation history</li> \n <li><code>true</code>: Reasoning content is preserved and sent in subsequent API calls</li> \n</ul> \n<p>This setting is required by some LLM providers (e.g., Moonshot) that return errors like \"thinking is enabled but reasoning_content is missing in assistant tool call message\" when reasoning content is not included in multi-turn conversations. Enable this setting if your provider requires reasoning content to be preserved.</p> \n<h3>Local LLM Provider Configuration</h3> \n<p>PentAGI supports Ollama for local LLM inference, providing zero-cost operation and enhanced privacy:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>OLLAMA_SERVER_URL</code></td> \n   <td></td> \n   <td>URL of your Ollama server</td> \n  </tr> \n  <tr> \n   <td><code>OLLAMA_SERVER_MODEL</code></td> \n   <td><code>llama3.1:8b-instruct-q8_0</code></td> \n   <td>Default model for inference</td> \n  </tr> \n  <tr> \n   <td><code>OLLAMA_SERVER_CONFIG_PATH</code></td> \n   <td></td> \n   <td>Path to custom agent configuration file</td> \n  </tr> \n  <tr> \n   <td><code>OLLAMA_SERVER_PULL_MODELS_TIMEOUT</code></td> \n   <td><code>600</code></td> \n   <td>Timeout for model downloads (seconds)</td> \n  </tr> \n  <tr> \n   <td><code>OLLAMA_SERVER_PULL_MODELS_ENABLED</code></td> \n   <td><code>false</code></td> \n   <td>Auto-download models on startup</td> \n  </tr> \n  <tr> \n   <td><code>OLLAMA_SERVER_LOAD_MODELS_ENABLED</code></td> \n   <td><code>false</code></td> \n   <td>Query server for available models</td> \n  </tr> \n </tbody> \n</table> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Basic Ollama setup with default model\nOLLAMA_SERVER_URL=http://localhost:11434\nOLLAMA_SERVER_MODEL=llama3.1:8b-instruct-q8_0\n\n# Production setup with auto-pull and model discovery\nOLLAMA_SERVER_URL=http://ollama-server:11434\nOLLAMA_SERVER_PULL_MODELS_ENABLED=true\nOLLAMA_SERVER_PULL_MODELS_TIMEOUT=900\nOLLAMA_SERVER_LOAD_MODELS_ENABLED=true\n\n# Custom configuration with agent-specific models\nOLLAMA_SERVER_CONFIG_PATH=/path/to/ollama-config.yml\n\n# Default configuration file inside docker container\nOLLAMA_SERVER_CONFIG_PATH=/opt/pentagi/conf/ollama-llama318b.provider.yml\n</code></pre> \n<p><strong>Performance Considerations:</strong></p> \n<ul> \n <li><strong>Model Discovery</strong> (<code>OLLAMA_SERVER_LOAD_MODELS_ENABLED=true</code>): Adds 1-2s startup latency querying Ollama API</li> \n <li><strong>Auto-pull</strong> (<code>OLLAMA_SERVER_PULL_MODELS_ENABLED=true</code>): First startup may take several minutes downloading models</li> \n <li><strong>Pull timeout</strong> (<code>OLLAMA_SERVER_PULL_MODELS_TIMEOUT=900</code>): 15 minutes in seconds</li> \n <li><strong>Static Config</strong>: Disable both flags and specify models in config file for fastest startup</li> \n</ul> \n<h4>Creating Custom Ollama Models with Extended Context</h4> \n<p>PentAGI requires models with larger context windows than the default Ollama configurations. You need to create custom models with increased <code>num_ctx</code> parameter through Modelfiles. While typical agent workflows consume around 64K tokens, PentAGI uses 110K context size for safety margin and handling complex penetration testing scenarios.</p> \n<p><strong>Important</strong>: The <code>num_ctx</code> parameter can only be set during model creation via Modelfile - it cannot be changed after model creation or overridden at runtime.</p> \n<h5>Example: Qwen3 32B FP16 with Extended Context</h5> \n<p>Create a Modelfile named <code>Modelfile_qwen3_32b_fp16_tc</code>:</p> \n<pre><code class=\"language-dockerfile\">FROM qwen3:32b-fp16\nPARAMETER num_ctx 110000\nPARAMETER temperature 0.3\nPARAMETER top_p 0.8\nPARAMETER min_p 0.0\nPARAMETER top_k 20\nPARAMETER repeat_penalty 1.1\n</code></pre> \n<p>Build the custom model:</p> \n<pre><code class=\"language-bash\">ollama create qwen3:32b-fp16-tc -f Modelfile_qwen3_32b_fp16_tc\n</code></pre> \n<h5>Example: QwQ 32B FP16 with Extended Context</h5> \n<p>Create a Modelfile named <code>Modelfile_qwq_32b_fp16_tc</code>:</p> \n<pre><code class=\"language-dockerfile\">FROM qwq:32b-fp16\nPARAMETER num_ctx 110000\nPARAMETER temperature 0.2\nPARAMETER top_p 0.7\nPARAMETER min_p 0.0\nPARAMETER top_k 40\nPARAMETER repeat_penalty 1.2\n</code></pre> \n<p>Build the custom model:</p> \n<pre><code class=\"language-bash\">ollama create qwq:32b-fp16-tc -f Modelfile_qwq_32b_fp16_tc\n</code></pre> \n<blockquote> \n <p><strong>Note</strong>: The QwQ 32B FP16 model requires approximately <strong>71.3 GB VRAM</strong> for inference. Ensure your system has sufficient GPU memory before attempting to use this model.</p> \n</blockquote> \n<p>These custom models are referenced in the pre-built provider configuration files (<code>ollama-qwen332b-fp16-tc.provider.yml</code> and <code>ollama-qwq32b-fp16-tc.provider.yml</code>) that are included in the Docker image at <code>/opt/pentagi/conf/</code>.</p> \n<h3>OpenAI Provider Configuration</h3> \n<p>PentAGI supports OpenAI's advanced language models, including the latest reasoning-capable o-series models designed for complex analytical tasks:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>OPEN_AI_KEY</code></td> \n   <td></td> \n   <td>API key for OpenAI services</td> \n  </tr> \n  <tr> \n   <td><code>OPEN_AI_SERVER_URL</code></td> \n   <td><code>https://api.openai.com/v1</code></td> \n   <td>OpenAI API endpoint</td> \n  </tr> \n </tbody> \n</table> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Basic OpenAI setup\nOPEN_AI_KEY=your_openai_api_key\nOPEN_AI_SERVER_URL=https://api.openai.com/v1\n\n# Using with proxy for enhanced security\nOPEN_AI_KEY=your_openai_api_key\nPROXY_URL=http://your-proxy:8080\n</code></pre> \n<p>The OpenAI provider offers cutting-edge capabilities including:</p> \n<ul> \n <li><strong>Reasoning Models</strong>: Advanced o-series models (o1, o3, o4-mini) with step-by-step analytical thinking</li> \n <li><strong>Latest GPT-4.1 Series</strong>: Flagship models optimized for complex security research and exploit development</li> \n <li><strong>Cost-Effective Options</strong>: From nano models for high-volume scanning to powerful reasoning models for deep analysis</li> \n <li><strong>Versatile Performance</strong>: Fast, intelligent models perfect for multi-step security analysis and penetration testing</li> \n <li><strong>Proven Reliability</strong>: Industry-leading models with consistent performance across diverse security scenarios</li> \n</ul> \n<p>The system automatically selects appropriate OpenAI models based on task complexity, optimizing for both performance and cost-effectiveness.</p> \n<h3>Anthropic Provider Configuration</h3> \n<p>PentAGI integrates with Anthropic's Claude models, known for their exceptional safety, reasoning capabilities, and sophisticated understanding of complex security contexts:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>ANTHROPIC_API_KEY</code></td> \n   <td></td> \n   <td>API key for Anthropic services</td> \n  </tr> \n  <tr> \n   <td><code>ANTHROPIC_SERVER_URL</code></td> \n   <td><code>https://api.anthropic.com/v1</code></td> \n   <td>Anthropic API endpoint</td> \n  </tr> \n </tbody> \n</table> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Basic Anthropic setup\nANTHROPIC_API_KEY=your_anthropic_api_key\nANTHROPIC_SERVER_URL=https://api.anthropic.com/v1\n\n# Using with proxy for secure environments\nANTHROPIC_API_KEY=your_anthropic_api_key\nPROXY_URL=http://your-proxy:8080\n</code></pre> \n<p>The Anthropic provider delivers superior capabilities including:</p> \n<ul> \n <li><strong>Advanced Reasoning</strong>: Claude 4 series with exceptional reasoning for sophisticated penetration testing</li> \n <li><strong>Extended Thinking</strong>: Claude 3.7 with step-by-step thinking capabilities for methodical security research</li> \n <li><strong>High-Speed Performance</strong>: Claude 3.5 Haiku for blazing-fast vulnerability scans and real-time monitoring</li> \n <li><strong>Comprehensive Analysis</strong>: Claude Sonnet models for complex security analysis and threat hunting</li> \n <li><strong>Safety-First Design</strong>: Built-in safety mechanisms ensuring responsible security testing practices</li> \n</ul> \n<p>The system leverages Claude's advanced understanding of security contexts to provide thorough and responsible penetration testing guidance.</p> \n<h3>Google AI (Gemini) Provider Configuration</h3> \n<p>PentAGI supports Google's Gemini models through the Google AI API, offering state-of-the-art reasoning capabilities and multimodal features:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>GEMINI_API_KEY</code></td> \n   <td></td> \n   <td>API key for Google AI services</td> \n  </tr> \n  <tr> \n   <td><code>GEMINI_SERVER_URL</code></td> \n   <td><code>https://generativelanguage.googleapis.com</code></td> \n   <td>Google AI API endpoint</td> \n  </tr> \n </tbody> \n</table> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Basic Gemini setup\nGEMINI_API_KEY=your_gemini_api_key\nGEMINI_SERVER_URL=https://generativelanguage.googleapis.com\n\n# Using with proxy\nGEMINI_API_KEY=your_gemini_api_key\nPROXY_URL=http://your-proxy:8080\n</code></pre> \n<p>The Gemini provider offers advanced features including:</p> \n<ul> \n <li><strong>Thinking Capabilities</strong>: Advanced reasoning models (Gemini 2.5 series) with step-by-step analysis</li> \n <li><strong>Multimodal Support</strong>: Text and image processing for comprehensive security assessments</li> \n <li><strong>Large Context Windows</strong>: Up to 2M tokens for analyzing extensive codebases and documentation</li> \n <li><strong>Cost-Effective Options</strong>: From high-performance pro models to economical flash variants</li> \n <li><strong>Security-Focused Models</strong>: Specialized configurations optimized for penetration testing workflows</li> \n</ul> \n<p>The system automatically selects appropriate Gemini models based on agent requirements, balancing performance, capabilities, and cost-effectiveness.</p> \n<h3>AWS Bedrock Provider Configuration</h3> \n<p>PentAGI integrates with Amazon Bedrock, offering access to a wide range of foundation models from leading AI companies including Anthropic, AI21, Cohere, Meta, and Amazon's own models:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>BEDROCK_REGION</code></td> \n   <td><code>us-east-1</code></td> \n   <td>AWS region for Bedrock service</td> \n  </tr> \n  <tr> \n   <td><code>BEDROCK_ACCESS_KEY_ID</code></td> \n   <td></td> \n   <td>AWS access key ID for authentication</td> \n  </tr> \n  <tr> \n   <td><code>BEDROCK_SECRET_ACCESS_KEY</code></td> \n   <td></td> \n   <td>AWS secret access key for authentication</td> \n  </tr> \n  <tr> \n   <td><code>BEDROCK_SESSION_TOKEN</code></td> \n   <td></td> \n   <td>AWS session token as alternative way for authentication</td> \n  </tr> \n  <tr> \n   <td><code>BEDROCK_SERVER_URL</code></td> \n   <td></td> \n   <td>Optional custom Bedrock endpoint URL</td> \n  </tr> \n </tbody> \n</table> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Basic AWS Bedrock setup with credentials\nBEDROCK_REGION=us-east-1\nBEDROCK_ACCESS_KEY_ID=your_aws_access_key\nBEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key\n\n# Using with proxy for enhanced security\nBEDROCK_REGION=us-east-1\nBEDROCK_ACCESS_KEY_ID=your_aws_access_key\nBEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key\nPROXY_URL=http://your-proxy:8080\n\n# Using custom endpoint (for VPC endpoints or testing)\nBEDROCK_REGION=us-east-1\nBEDROCK_ACCESS_KEY_ID=your_aws_access_key\nBEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key\nBEDROCK_SERVER_URL=https://bedrock-runtime.us-east-1.amazonaws.com\n</code></pre> \n<blockquote> \n <p>[!IMPORTANT] <strong>AWS Bedrock Rate Limits Warning</strong></p> \n <p>The default PentAGI configuration for AWS Bedrock uses two primary models:</p> \n <ul> \n  <li><code>us.anthropic.claude-sonnet-4-20250514-v1:0</code> (for most agents) - <strong>2 requests per minute</strong> for new AWS accounts</li> \n  <li><code>us.anthropic.claude-3-5-haiku-20241022-v1:0</code> (for simple tasks) - <strong>20 requests per minute</strong> for new AWS accounts</li> \n </ul> \n <p>These default rate limits are <strong>extremely restrictive</strong> for comfortable penetration testing scenarios and will significantly impact your workflow. We <strong>strongly recommend</strong>:</p> \n <ol> \n  <li><strong>Request quota increases</strong> for your AWS Bedrock models through the AWS Service Quotas console</li> \n  <li><strong>Use provisioned throughput models</strong> with hourly billing for higher throughput requirements</li> \n  <li><strong>Switch to alternative models</strong> with higher default quotas (e.g., Amazon Nova series, Meta Llama models)</li> \n  <li><strong>Consider using a different LLM provider</strong> (OpenAI, Anthropic, Gemini) if you need immediate high-throughput access</li> \n </ol> \n <p>Without adequate rate limits, you may experience frequent delays, timeouts, and degraded testing performance.</p> \n</blockquote> \n<p>The AWS Bedrock provider delivers comprehensive capabilities including:</p> \n<ul> \n <li><strong>Multi-Provider Access</strong>: Access to models from Anthropic (Claude), AI21 (Jamba), Cohere (Command), Meta (Llama), Amazon (Nova, Titan), and DeepSeek (R1) through a single interface</li> \n <li><strong>Advanced Reasoning</strong>: Support for Claude 4 and other reasoning-capable models with step-by-step thinking</li> \n <li><strong>Multimodal Models</strong>: Amazon Nova series supporting text, image, and video processing for comprehensive security analysis</li> \n <li><strong>Enterprise Security</strong>: AWS-native security controls, VPC integration, and compliance certifications</li> \n <li><strong>Cost Optimization</strong>: Wide range of model sizes and capabilities for cost-effective penetration testing</li> \n <li><strong>Regional Availability</strong>: Deploy models in your preferred AWS region for data residency and performance</li> \n <li><strong>High Performance</strong>: Low-latency inference through AWS's global infrastructure</li> \n</ul> \n<p>The system automatically selects appropriate Bedrock models based on task complexity and requirements, leveraging the full spectrum of available foundation models for optimal security testing results.</p> \n<blockquote> \n <p>[!WARNING] <strong>Converse API Requirements</strong></p> \n <p>PentAGI uses the <strong>Amazon Bedrock Converse API</strong> for model interactions, which requires models to support the following features:</p> \n <ul> \n  <li>✅ <strong>Converse</strong> - Basic conversation API support</li> \n  <li>✅ <strong>ConverseStream</strong> - Streaming response support</li> \n  <li>✅ <strong>Tool use</strong> - Function calling capabilities for penetration testing tools</li> \n  <li>✅ <strong>Streaming tool use</strong> - Real-time tool execution feedback</li> \n </ul> \n <p><strong>Before selecting models</strong>, verify their feature support at: <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html\">Supported models and model features</a></p> \n <p>⚠️ <strong>Important</strong>: Some models like AI21 Jurassic-2 and Cohere Command (Text) have <strong>limited chat support</strong> and may not work properly with PentAGI's multi-turn conversation workflows.</p> \n</blockquote> \n<blockquote> \n <p><strong>Note</strong>: AWS credentials can also be provided through IAM roles, environment variables, or AWS credential files following standard AWS SDK authentication patterns. Ensure your AWS account has appropriate permissions for Amazon Bedrock service access.</p> \n</blockquote> \n<p>For advanced configuration options and detailed setup instructions, please visit our <a href=\"https://docs.pentagi.com\">documentation</a>.</p> \n<h2>🔧 Advanced Setup</h2> \n<h3>Langfuse Integration</h3> \n<p>Langfuse provides advanced capabilities for monitoring and analyzing AI agent operations.</p> \n<ol> \n <li>Configure Langfuse environment variables in existing <code>.env</code> file.</li> \n</ol> \n<details> \n Langfuse valuable environment variables \n <h3>Database Credentials</h3> \n <ul> \n  <li><code>LANGFUSE_POSTGRES_USER</code> and <code>LANGFUSE_POSTGRES_PASSWORD</code> - Langfuse PostgreSQL credentials</li> \n  <li><code>LANGFUSE_CLICKHOUSE_USER</code> and <code>LANGFUSE_CLICKHOUSE_PASSWORD</code> - ClickHouse credentials</li> \n  <li><code>LANGFUSE_REDIS_AUTH</code> - Redis password</li> \n </ul> \n <h3>Encryption and Security Keys</h3> \n <ul> \n  <li><code>LANGFUSE_SALT</code> - Salt for hashing in Langfuse Web UI</li> \n  <li><code>LANGFUSE_ENCRYPTION_KEY</code> - Encryption key (32 bytes in hex)</li> \n  <li><code>LANGFUSE_NEXTAUTH_SECRET</code> - Secret key for NextAuth</li> \n </ul> \n <h3>Admin Credentials</h3> \n <ul> \n  <li><code>LANGFUSE_INIT_USER_EMAIL</code> - Admin email</li> \n  <li><code>LANGFUSE_INIT_USER_PASSWORD</code> - Admin password</li> \n  <li><code>LANGFUSE_INIT_USER_NAME</code> - Admin username</li> \n </ul> \n <h3>API Keys and Tokens</h3> \n <ul> \n  <li><code>LANGFUSE_INIT_PROJECT_PUBLIC_KEY</code> - Project public key (used from PentAGI side too)</li> \n  <li><code>LANGFUSE_INIT_PROJECT_SECRET_KEY</code> - Project secret key (used from PentAGI side too)</li> \n </ul> \n <h3>S3 Storage</h3> \n <ul> \n  <li><code>LANGFUSE_S3_ACCESS_KEY_ID</code> - S3 access key ID</li> \n  <li><code>LANGFUSE_S3_SECRET_ACCESS_KEY</code> - S3 secret access key</li> \n </ul> \n</details> \n<ol start=\"2\"> \n <li>Enable integration with Langfuse for PentAGI service in <code>.env</code> file.</li> \n</ol> \n<pre><code class=\"language-bash\">LANGFUSE_BASE_URL=http://langfuse-web:3000\nLANGFUSE_PROJECT_ID= # default: value from ${LANGFUSE_INIT_PROJECT_ID}\nLANGFUSE_PUBLIC_KEY= # default: value from ${LANGFUSE_INIT_PROJECT_PUBLIC_KEY}\nLANGFUSE_SECRET_KEY= # default: value from ${LANGFUSE_INIT_PROJECT_SECRET_KEY}\n</code></pre> \n<ol start=\"3\"> \n <li>Run the Langfuse stack:</li> \n</ol> \n<pre><code class=\"language-bash\">curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose-langfuse.yml\ndocker compose -f docker-compose.yml -f docker-compose-langfuse.yml up -d\n</code></pre> \n<p>Visit <a href=\"http://localhost:4000\">localhost:4000</a> to access Langfuse Web UI with credentials from <code>.env</code> file:</p> \n<ul> \n <li><code>LANGFUSE_INIT_USER_EMAIL</code> - Admin email</li> \n <li><code>LANGFUSE_INIT_USER_PASSWORD</code> - Admin password</li> \n</ul> \n<h3>Monitoring and Observability</h3> \n<p>For detailed system operation tracking, integration with monitoring tools is available.</p> \n<ol> \n <li>Enable integration with OpenTelemetry and all observability services for PentAGI in <code>.env</code> file.</li> \n</ol> \n<pre><code class=\"language-bash\">OTEL_HOST=otelcol:8148\n</code></pre> \n<ol start=\"2\"> \n <li>Run the observability stack:</li> \n</ol> \n<pre><code class=\"language-bash\">curl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose-observability.yml\ndocker compose -f docker-compose.yml -f docker-compose-observability.yml up -d\n</code></pre> \n<p>Visit <a href=\"http://localhost:3000\">localhost:3000</a> to access Grafana Web UI.</p> \n<blockquote> \n <p>[!NOTE] If you want to use Observability stack with Langfuse, you need to enable integration in <code>.env</code> file to set <code>LANGFUSE_OTEL_EXPORTER_OTLP_ENDPOINT</code> to <code>http://otelcol:4318</code>.</p> \n <p>To run all available stacks together (Langfuse, Graphiti, and Observability):</p> \n <pre><code class=\"language-bash\">docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-graphiti.yml -f docker-compose-observability.yml up -d\n</code></pre> \n <p>You can also register aliases for these commands in your shell to run it faster:</p> \n <pre><code class=\"language-bash\">alias pentagi=\"docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-graphiti.yml -f docker-compose-observability.yml\"\nalias pentagi-up=\"docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-graphiti.yml -f docker-compose-observability.yml up -d\"\nalias pentagi-down=\"docker compose -f docker-compose.yml -f docker-compose-langfuse.yml -f docker-compose-graphiti.yml -f docker-compose-observability.yml down\"\n</code></pre> \n</blockquote> \n<h3>Knowledge Graph Integration (Graphiti)</h3> \n<p>PentAGI integrates with <a href=\"https://github.com/vxcontrol/pentagi-graphiti\">Graphiti</a>, a temporal knowledge graph system powered by Neo4j, to provide advanced semantic understanding and relationship tracking for AI agent operations. The vxcontrol fork provides custom entity and edge types that are specific to pentesting purposes.</p> \n<h4>What is Graphiti?</h4> \n<p>Graphiti automatically extracts and stores structured knowledge from agent interactions, building a graph of entities, relationships, and temporal context. This enables:</p> \n<ul> \n <li><strong>Semantic Memory</strong>: Store and recall relationships between tools, targets, vulnerabilities, and techniques</li> \n <li><strong>Contextual Understanding</strong>: Track how different pentesting actions relate to each other over time</li> \n <li><strong>Knowledge Reuse</strong>: Learn from past penetration tests and apply insights to new assessments</li> \n <li><strong>Advanced Querying</strong>: Search for complex patterns like \"What tools were effective against similar targets?\"</li> \n</ul> \n<h4>Enabling Graphiti</h4> \n<p>The Graphiti knowledge graph is <strong>optional</strong> and disabled by default. To enable it:</p> \n<ol> \n <li>Configure Graphiti environment variables in <code>.env</code> file:</li> \n</ol> \n<pre><code class=\"language-bash\">## Graphiti knowledge graph settings\nGRAPHITI_ENABLED=true\nGRAPHITI_TIMEOUT=30\nGRAPHITI_URL=http://graphiti:8000\nGRAPHITI_MODEL_NAME=gpt-5-mini\n\n# Neo4j settings (used by Graphiti stack)\nNEO4J_USER=neo4j\nNEO4J_DATABASE=neo4j\nNEO4J_PASSWORD=devpassword\nNEO4J_URI=bolt://neo4j:7687\n\n# OpenAI API key (required by Graphiti for entity extraction)\nOPEN_AI_KEY=your_openai_api_key\n</code></pre> \n<ol start=\"2\"> \n <li>Run the Graphiti stack along with the main PentAGI services:</li> \n</ol> \n<pre><code class=\"language-bash\"># Download the Graphiti compose file if needed\ncurl -O https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose-graphiti.yml\n\n# Start PentAGI with Graphiti\ndocker compose -f docker-compose.yml -f docker-compose-graphiti.yml up -d\n</code></pre> \n<ol start=\"3\"> \n <li>Verify Graphiti is running:</li> \n</ol> \n<pre><code class=\"language-bash\"># Check service health\ndocker compose -f docker-compose.yml -f docker-compose-graphiti.yml ps graphiti neo4j\n\n# View Graphiti logs\ndocker compose -f docker-compose.yml -f docker-compose-graphiti.yml logs -f graphiti\n\n# Access Neo4j Browser (optional)\n# Visit http://localhost:7474 and login with NEO4J_USER/NEO4J_PASSWORD\n\n# Access Graphiti API (optional, for debugging)\n# Visit http://localhost:8000/docs for Swagger API documentation\n</code></pre> \n<blockquote> \n <p>[!NOTE] The Graphiti service is defined in <code>docker-compose-graphiti.yml</code> as a separate stack. You must run both compose files together to enable the knowledge graph functionality. The pre-built Docker image <code>vxcontrol/graphiti:latest</code> is used by default.</p> \n</blockquote> \n<h4>What Gets Stored</h4> \n<p>When enabled, PentAGI automatically captures:</p> \n<ul> \n <li><strong>Agent Responses</strong>: All agent reasoning, analysis, and decisions</li> \n <li><strong>Tool Executions</strong>: Commands executed, tools used, and their results</li> \n <li><strong>Context Information</strong>: Flow, task, and subtask hierarchy</li> \n</ul> \n<h3>GitHub and Google OAuth Integration</h3> \n<p>OAuth integration with GitHub and Google allows users to authenticate using their existing accounts on these platforms. This provides several benefits:</p> \n<ul> \n <li>Simplified login process without need to create separate credentials</li> \n <li>Enhanced security through trusted identity providers</li> \n <li>Access to user profile information from GitHub/Google accounts</li> \n <li>Seamless integration with existing development workflows</li> \n</ul> \n<p>For using GitHub OAuth you need to create a new OAuth application in your GitHub account and set the <code>GITHUB_CLIENT_ID</code> and <code>GITHUB_CLIENT_SECRET</code> in <code>.env</code> file.</p> \n<p>For using Google OAuth you need to create a new OAuth application in your Google account and set the <code>GOOGLE_CLIENT_ID</code> and <code>GOOGLE_CLIENT_SECRET</code> in <code>.env</code> file.</p> \n<h3>Docker Image Configuration</h3> \n<p>PentAGI allows you to configure Docker image selection for executing various tasks. The system automatically chooses the most appropriate image based on the task type, but you can constrain this selection by specifying your preferred images:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>DOCKER_DEFAULT_IMAGE</code></td> \n   <td><code>debian:latest</code></td> \n   <td>Default Docker image for general tasks and ambiguous cases</td> \n  </tr> \n  <tr> \n   <td><code>DOCKER_DEFAULT_IMAGE_FOR_PENTEST</code></td> \n   <td><code>vxcontrol/kali-linux</code></td> \n   <td>Default Docker image for security/penetration testing tasks</td> \n  </tr> \n </tbody> \n</table> \n<p>When these environment variables are set, AI agents will be limited to the image choices you specify. This is particularly useful for:</p> \n<ul> \n <li><strong>Security Enforcement</strong>: Restricting usage to only verified and trusted images</li> \n <li><strong>Environment Standardization</strong>: Using corporate or customized images across all operations</li> \n <li><strong>Performance Optimization</strong>: Utilizing pre-built images with necessary tools already installed</li> \n</ul> \n<p>Configuration examples:</p> \n<pre><code class=\"language-bash\"># Using a custom image for general tasks\nDOCKER_DEFAULT_IMAGE=mycompany/custom-debian:latest\n\n# Using a specialized image for penetration testing\nDOCKER_DEFAULT_IMAGE_FOR_PENTEST=mycompany/pentest-tools:v2.0\n</code></pre> \n<blockquote> \n <p>[!NOTE] If a user explicitly specifies a particular Docker image in their task, the system will try to use that exact image, ignoring these settings. These variables only affect the system's automatic image selection process.</p> \n</blockquote> \n<h2>💻 Development</h2> \n<h3>Development Requirements</h3> \n<ul> \n <li>golang</li> \n <li>nodejs</li> \n <li>docker</li> \n <li>postgres</li> \n <li>commitlint</li> \n</ul> \n<h3>Environment Setup</h3> \n<h4>Backend Setup</h4> \n<p>Run once <code>cd backend &amp;&amp; go mod download</code> to install needed packages.</p> \n<p>For generating swagger files have to run</p> \n<pre><code class=\"language-bash\">swag init -g ../../pkg/server/router.go -o pkg/server/docs/ --parseDependency --parseInternal --parseDepth 2 -d cmd/pentagi\n</code></pre> \n<p>before installing <code>swag</code> package via</p> \n<pre><code class=\"language-bash\">go install github.com/swaggo/swag/cmd/swag@v1.8.7\n</code></pre> \n<p>For generating graphql resolver files have to run</p> \n<pre><code class=\"language-bash\">go run github.com/99designs/gqlgen --config ./gqlgen/gqlgen.yml\n</code></pre> \n<p>after that you can see the generated files in <code>pkg/graph</code> folder.</p> \n<p>For generating ORM methods (database package) from sqlc configuration</p> \n<pre><code class=\"language-bash\">docker run --rm -v $(pwd):/src -w /src --network pentagi-network -e DATABASE_URL=\"{URL}\" sqlc/sqlc generate -f sqlc/sqlc.yml\n</code></pre> \n<p>For generating Langfuse SDK from OpenAPI specification</p> \n<pre><code class=\"language-bash\">fern generate --local\n</code></pre> \n<p>and to install fern-cli</p> \n<pre><code class=\"language-bash\">npm install -g fern-api\n</code></pre> \n<h4>Testing</h4> \n<p>For running tests <code>cd backend &amp;&amp; go test -v ./...</code></p> \n<h4>Frontend Setup</h4> \n<p>Run once <code>cd frontend &amp;&amp; npm install</code> to install needed packages.</p> \n<p>For generating graphql files have to run <code>npm run graphql:generate</code> which using <code>graphql-codegen.ts</code> file.</p> \n<p>Be sure that you have <code>graphql-codegen</code> installed globally:</p> \n<pre><code class=\"language-bash\">npm install -g graphql-codegen\n</code></pre> \n<p>After that you can run:</p> \n<ul> \n <li><code>npm run prettier</code> to check if your code is formatted correctly</li> \n <li><code>npm run prettier:fix</code> to fix it</li> \n <li><code>npm run lint</code> to check if your code is linted correctly</li> \n <li><code>npm run lint:fix</code> to fix it</li> \n</ul> \n<p>For generating SSL certificates you need to run <code>npm run ssl:generate</code> which using <code>generate-ssl.ts</code> file or it will be generated automatically when you run <code>npm run dev</code>.</p> \n<h4>Backend Configuration</h4> \n<p>Edit the configuration for <code>backend</code> in <code>.vscode/launch.json</code> file:</p> \n<ul> \n <li><code>DATABASE_URL</code> - PostgreSQL database URL (eg. <code>postgres://postgres:postgres@localhost:5432/pentagidb?sslmode=disable</code>)</li> \n <li><code>DOCKER_HOST</code> - Docker SDK API (eg. for macOS <code>DOCKER_HOST=unix:///Users/&lt;my-user&gt;/Library/Containers/com.docker.docker/Data/docker.raw.sock</code>) <a href=\"https://stackoverflow.com/a/62757128/5922857\">more info</a></li> \n</ul> \n<p>Optional:</p> \n<ul> \n <li><code>SERVER_PORT</code> - Port to run the server (default: <code>8443</code>)</li> \n <li><code>SERVER_USE_SSL</code> - Enable SSL for the server (default: <code>false</code>)</li> \n</ul> \n<h4>Frontend Configuration</h4> \n<p>Edit the configuration for <code>frontend</code> in <code>.vscode/launch.json</code> file:</p> \n<ul> \n <li><code>VITE_API_URL</code> - Backend API URL. <em>Omit</em> the URL scheme (e.g., <code>localhost:8080</code> <em>NOT</em> <code>http://localhost:8080</code>)</li> \n <li><code>VITE_USE_HTTPS</code> - Enable SSL for the server (default: <code>false</code>)</li> \n <li><code>VITE_PORT</code> - Port to run the server (default: <code>8000</code>)</li> \n <li><code>VITE_HOST</code> - Host to run the server (default: <code>0.0.0.0</code>)</li> \n</ul> \n<h3>Running the Application</h3> \n<h4>Backend</h4> \n<p>Run the command(s) in <code>backend</code> folder:</p> \n<ul> \n <li>Use <code>.env</code> file to set environment variables like a <code>source .env</code></li> \n <li>Run <code>go run cmd/pentagi/main.go</code> to start the server</li> \n</ul> \n<blockquote> \n <p>[!NOTE] The first run can take a while as dependencies and docker images need to be downloaded to setup the backend environment.</p> \n</blockquote> \n<h4>Frontend</h4> \n<p>Run the command(s) in <code>frontend</code> folder:</p> \n<ul> \n <li>Run <code>npm install</code> to install the dependencies</li> \n <li>Run <code>npm run dev</code> to run the web app</li> \n <li>Run <code>npm run build</code> to build the web app</li> \n</ul> \n<p>Open your browser and visit the web app URL.</p> \n<h2>🧪 Testing LLM Agents</h2> \n<p>PentAGI includes a powerful utility called <code>ctester</code> for testing and validating LLM agent capabilities. This tool helps ensure your LLM provider configurations work correctly with different agent types, allowing you to optimize model selection for each specific agent role.</p> \n<p>The utility features parallel testing of multiple agents, detailed reporting, and flexible configuration options.</p> \n<h3>Key Features</h3> \n<ul> \n <li><strong>Parallel Testing</strong>: Tests multiple agents simultaneously for faster results</li> \n <li><strong>Comprehensive Test Suite</strong>: Evaluates basic completion, JSON responses, function calling, and penetration testing knowledge</li> \n <li><strong>Detailed Reporting</strong>: Generates markdown reports with success rates and performance metrics</li> \n <li><strong>Flexible Configuration</strong>: Test specific agents or test groups as needed</li> \n <li><strong>Specialized Test Groups</strong>: Includes domain-specific tests for cybersecurity and penetration testing scenarios</li> \n</ul> \n<h3>Usage Scenarios</h3> \n<h4>For Developers (with local Go environment)</h4> \n<p>If you've cloned the repository and have Go installed:</p> \n<pre><code class=\"language-bash\"># Default configuration with .env file\ncd backend\ngo run cmd/ctester/*.go -verbose\n\n# Custom provider configuration\ngo run cmd/ctester/*.go -config ../examples/configs/openrouter.provider.yml -verbose\n\n# Generate a report file\ngo run cmd/ctester/*.go -config ../examples/configs/deepinfra.provider.yml -report ../test-report.md\n\n# Test specific agent types only\ngo run cmd/ctester/*.go -agents simple,simple_json,primary_agent -verbose\n\n# Test specific test groups only\ngo run cmd/ctester/*.go -groups basic,advanced -verbose\n</code></pre> \n<h4>For Users (using Docker image)</h4> \n<p>If you prefer to use the pre-built Docker image without setting up a development environment:</p> \n<pre><code class=\"language-bash\"># Using Docker to test with default environment\ndocker run --rm -v $(pwd)/.env:/opt/pentagi/.env vxcontrol/pentagi /opt/pentagi/bin/ctester -verbose\n\n# Test with your custom provider configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  -v $(pwd)/my-config.yml:/opt/pentagi/config.yml \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/config.yml -agents simple,primary_agent,coder -verbose\n\n# Generate a detailed report\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  -v $(pwd):/opt/pentagi/output \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -report /opt/pentagi/output/report.md\n</code></pre> \n<h4>Using Pre-configured Providers</h4> \n<p>The Docker image comes with built-in support for major providers (OpenAI, Anthropic, Gemini, Ollama) and pre-configured provider files for additional services (OpenRouter, DeepInfra, DeepSeek, Moonshot):</p> \n<pre><code class=\"language-bash\"># Test with OpenRouter configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/openrouter.provider.yml\n\n# Test with DeepInfra configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/deepinfra.provider.yml\n\n# Test with DeepSeek configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/deepseek.provider.yml\n\n# Test with Moonshot configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/moonshot.provider.yml\n\n# Test with OpenAI configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -type openai\n\n# Test with Anthropic configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -type anthropic\n\n# Test with Gemini configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -type gemini\n\n# Test with AWS Bedrock configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -type bedrock\n\n# Test with Custom OpenAI configuration\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/custom-openai.provider.yml\n\n# Test with Ollama configuration (local inference)\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-llama318b.provider.yml\n\n# Test with Ollama Qwen3 32B configuration (requires custom model creation)\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-qwen332b-fp16-tc.provider.yml\n\n# Test with Ollama QwQ 32B configuration (requires custom model creation and 71.3GB VRAM)\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/ollama-qwq32b-fp16-tc.provider.yml\n</code></pre> \n<p>To use these configurations, your <code>.env</code> file only needs to contain:</p> \n<pre><code>LLM_SERVER_URL=https://openrouter.ai/api/v1      # or https://api.deepinfra.com/v1/openai or https://api.deepseek.com or https://api.openai.com/v1 or https://api.moonshot.ai/v1\nLLM_SERVER_KEY=your_api_key\nLLM_SERVER_MODEL=                                # Leave empty, as models are specified in the config\nLLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/openrouter.provider.yml  # or deepinfra.provider.yml or deepseek.provider.yml or custom-openai.provider.yml or moonshot.provider.yml\nLLM_SERVER_PROVIDER=                             # Provider name for LiteLLM proxy (e.g., openrouter, deepseek, moonshot)\nLLM_SERVER_LEGACY_REASONING=false                # Controls reasoning format, for OpenAI must be true (default: false)\nLLM_SERVER_PRESERVE_REASONING=false              # Preserve reasoning content in multi-turn conversations (required by Moonshot, default: false)\n\n# For OpenAI (official API)\nOPEN_AI_KEY=your_openai_api_key                  # Your OpenAI API key\nOPEN_AI_SERVER_URL=https://api.openai.com/v1     # OpenAI API endpoint\n\n# For Anthropic (Claude models)\nANTHROPIC_API_KEY=your_anthropic_api_key         # Your Anthropic API key\nANTHROPIC_SERVER_URL=https://api.anthropic.com/v1  # Anthropic API endpoint\n\n# For Gemini (Google AI)\nGEMINI_API_KEY=your_gemini_api_key               # Your Google AI API key\nGEMINI_SERVER_URL=https://generativelanguage.googleapis.com  # Google AI API endpoint\n\n# For AWS Bedrock (enterprise foundation models)\nBEDROCK_REGION=us-east-1                         # AWS region for Bedrock service\nBEDROCK_ACCESS_KEY_ID=your_aws_access_key        # AWS access key ID\nBEDROCK_SECRET_ACCESS_KEY=your_aws_secret_key    # AWS secret access key\nBEDROCK_SESSION_TOKEN=your_aws_session_token     # AWS session token (alternative auth method)\nBEDROCK_SERVER_URL=                              # Optional custom Bedrock endpoint\n\n# For Ollama (local inference)\nOLLAMA_SERVER_URL=http://localhost:11434\nOLLAMA_SERVER_MODEL=llama3.1:8b-instruct-q8_0\nOLLAMA_SERVER_CONFIG_PATH=/opt/pentagi/conf/ollama-llama318b.provider.yml\nOLLAMA_SERVER_PULL_MODELS_ENABLED=false\nOLLAMA_SERVER_LOAD_MODELS_ENABLED=false\n</code></pre> \n<h4>Using OpenAI with Unverified Organizations</h4> \n<p>For OpenAI accounts with unverified organizations that don't have access to the latest reasoning models (o1, o3, o4-mini), you need to use a custom configuration.</p> \n<p>To use OpenAI with unverified organization accounts, configure your <code>.env</code> file as follows:</p> \n<pre><code class=\"language-bash\">LLM_SERVER_URL=https://api.openai.com/v1\nLLM_SERVER_KEY=your_openai_api_key\nLLM_SERVER_MODEL=                                # Leave empty, models are specified in config\nLLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/custom-openai.provider.yml\nLLM_SERVER_LEGACY_REASONING=true                 # Required for OpenAI reasoning format\n</code></pre> \n<p>This configuration uses the pre-built <code>custom-openai.provider.yml</code> file that maps all agent types to models available for unverified organizations, using <code>o3-mini</code> instead of models like <code>o1</code>, <code>o3</code>, and <code>o4-mini</code>.</p> \n<p>You can test this configuration using:</p> \n<pre><code class=\"language-bash\"># Test with custom OpenAI configuration for unverified accounts\ndocker run --rm \\\n  -v $(pwd)/.env:/opt/pentagi/.env \\\n  vxcontrol/pentagi /opt/pentagi/bin/ctester -config /opt/pentagi/conf/custom-openai.provider.yml\n</code></pre> \n<blockquote> \n <p>[!NOTE] The <code>LLM_SERVER_LEGACY_REASONING=true</code> setting is crucial for OpenAI compatibility as it ensures reasoning parameters are sent in the format expected by OpenAI's API.</p> \n</blockquote> \n<h4>Using LiteLLM Proxy</h4> \n<p>When using LiteLLM proxy to access various LLM providers, model names are prefixed with the provider name (e.g., <code>moonshot/kimi-2.5</code> instead of <code>kimi-2.5</code>). To use the same provider configuration files with both direct API access and LiteLLM proxy, set the <code>LLM_SERVER_PROVIDER</code> variable:</p> \n<pre><code class=\"language-bash\"># Direct access to Moonshot API\nLLM_SERVER_URL=https://api.moonshot.ai/v1\nLLM_SERVER_KEY=your_moonshot_api_key\nLLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/moonshot.provider.yml\nLLM_SERVER_PROVIDER=                             # Empty for direct access\n\n# Access via LiteLLM proxy\nLLM_SERVER_URL=http://litellm-proxy:4000\nLLM_SERVER_KEY=your_litellm_api_key\nLLM_SERVER_CONFIG_PATH=/opt/pentagi/conf/moonshot.provider.yml\nLLM_SERVER_PROVIDER=moonshot                     # Provider prefix for LiteLLM\n</code></pre> \n<p>With <code>LLM_SERVER_PROVIDER=moonshot</code>, the system automatically prefixes all model names from the configuration file with <code>moonshot/</code>, making them compatible with LiteLLM's model naming convention.</p> \n<p><strong>Supported provider names for LiteLLM:</strong></p> \n<ul> \n <li><code>openai</code> - for OpenAI models via LiteLLM</li> \n <li><code>anthropic</code> - for Anthropic/Claude models via LiteLLM</li> \n <li><code>gemini</code> - for Google Gemini models via LiteLLM</li> \n <li><code>openrouter</code> - for OpenRouter aggregator</li> \n <li><code>deepseek</code> - for DeepSeek models</li> \n <li><code>deepinfra</code> - for DeepInfra hosting</li> \n <li><code>moonshot</code> - for Moonshot AI (Kimi)</li> \n <li>Any other provider name configured in your LiteLLM instance</li> \n</ul> \n<p>This approach allows you to:</p> \n<ul> \n <li>Use the same configuration files for both direct and proxied access</li> \n <li>Switch between providers without modifying configuration files</li> \n <li>Easily test different routing strategies with LiteLLM</li> \n</ul> \n<h4>Running Tests in a Production Environment</h4> \n<p>If you already have a running PentAGI container and want to test the current configuration:</p> \n<pre><code class=\"language-bash\"># Run ctester in an existing container using current environment variables\ndocker exec -it pentagi /opt/pentagi/bin/ctester -verbose\n\n# Test specific agent types with deterministic ordering\ndocker exec -it pentagi /opt/pentagi/bin/ctester -agents simple,primary_agent,pentester -groups basic,knowledge -verbose\n\n# Generate a report file inside the container\ndocker exec -it pentagi /opt/pentagi/bin/ctester -report /opt/pentagi/data/agent-test-report.md\n\n# Access the report from the host\ndocker cp pentagi:/opt/pentagi/data/agent-test-report.md ./\n</code></pre> \n<h3>Command-line Options</h3> \n<p>The utility accepts several options:</p> \n<ul> \n <li><code>-env &lt;path&gt;</code> - Path to environment file (default: <code>.env</code>)</li> \n <li><code>-type &lt;provider&gt;</code> - Provider type: <code>custom</code>, <code>openai</code>, <code>anthropic</code>, <code>ollama</code>, <code>bedrock</code>, <code>gemini</code> (default: <code>custom</code>)</li> \n <li><code>-config &lt;path&gt;</code> - Path to custom provider config (default: from <code>LLM_SERVER_CONFIG_PATH</code> env variable)</li> \n <li><code>-tests &lt;path&gt;</code> - Path to custom tests YAML file (optional)</li> \n <li><code>-report &lt;path&gt;</code> - Path to write the report file (optional)</li> \n <li><code>-agents &lt;list&gt;</code> - Comma-separated list of agent types to test (default: <code>all</code>)</li> \n <li><code>-groups &lt;list&gt;</code> - Comma-separated list of test groups to run (default: <code>all</code>)</li> \n <li><code>-verbose</code> - Enable verbose output with detailed test results for each agent</li> \n</ul> \n<h3>Available Agent Types</h3> \n<p>Agents are tested in the following deterministic order:</p> \n<ol> \n <li><strong>simple</strong> - Basic completion tasks</li> \n <li><strong>simple_json</strong> - JSON-structured responses</li> \n <li><strong>primary_agent</strong> - Main reasoning agent</li> \n <li><strong>assistant</strong> - Interactive assistant mode</li> \n <li><strong>generator</strong> - Content generation</li> \n <li><strong>refiner</strong> - Content refinement and improvement</li> \n <li><strong>adviser</strong> - Expert advice and consultation</li> \n <li><strong>reflector</strong> - Self-reflection and analysis</li> \n <li><strong>searcher</strong> - Information gathering and search</li> \n <li><strong>enricher</strong> - Data enrichment and expansion</li> \n <li><strong>coder</strong> - Code generation and analysis</li> \n <li><strong>installer</strong> - Installation and setup tasks</li> \n <li><strong>pentester</strong> - Penetration testing and security assessment</li> \n</ol> \n<h3>Available Test Groups</h3> \n<ul> \n <li><strong>basic</strong> - Fundamental completion and prompt response tests</li> \n <li><strong>advanced</strong> - Complex reasoning and function calling tests</li> \n <li><strong>json</strong> - JSON format validation and structure tests (specifically designed for <code>simple_json</code> agent)</li> \n <li><strong>knowledge</strong> - Domain-specific cybersecurity and penetration testing knowledge tests</li> \n</ul> \n<blockquote> \n <p><strong>Note</strong>: The <code>json</code> test group is specifically designed for the <code>simple_json</code> agent type, while all other agents are tested with <code>basic</code>, <code>advanced</code>, and <code>knowledge</code> groups. This specialization ensures optimal testing coverage for each agent's intended purpose.</p> \n</blockquote> \n<h3>Example Provider Configuration</h3> \n<p>Provider configuration defines which models to use for different agent types:</p> \n<pre><code class=\"language-yaml\">simple:\n  model: \"provider/model-name\"\n  temperature: 0.7\n  top_p: 0.95\n  n: 1\n  max_tokens: 4000\n\nsimple_json:\n  model: \"provider/model-name\"\n  temperature: 0.7\n  top_p: 1.0\n  n: 1\n  max_tokens: 4000\n  json: true\n\n# ... other agent types ...\n</code></pre> \n<h3>Optimization Workflow</h3> \n<ol> \n <li><strong>Create a baseline</strong>: Run tests with default configuration to establish benchmark performance</li> \n <li><strong>Analyze agent-specific performance</strong>: Review the deterministic agent ordering to identify underperforming agents</li> \n <li><strong>Test specialized configurations</strong>: Experiment with different models for each agent type using provider-specific configs</li> \n <li><strong>Focus on domain knowledge</strong>: Pay special attention to knowledge group tests for cybersecurity expertise</li> \n <li><strong>Validate function calling</strong>: Ensure tool-based tests pass consistently for critical agent types</li> \n <li><strong>Compare results</strong>: Look for the best success rate and performance across all test groups</li> \n <li><strong>Deploy optimal configuration</strong>: Use in production with your optimized setup</li> \n</ol> \n<p>This tool helps ensure your AI agents are using the most effective models for their specific tasks, improving reliability while optimizing costs.</p> \n<h2>🧮 Embedding Configuration and Testing</h2> \n<p>PentAGI uses vector embeddings for semantic search, knowledge storage, and memory management. The system supports multiple embedding providers that can be configured according to your needs and preferences.</p> \n<h3>Supported Embedding Providers</h3> \n<p>PentAGI supports the following embedding providers:</p> \n<ul> \n <li><strong>OpenAI</strong> (default): Uses OpenAI's text embedding models</li> \n <li><strong>Ollama</strong>: Local embedding model through Ollama</li> \n <li><strong>Mistral</strong>: Mistral AI's embedding models</li> \n <li><strong>Jina</strong>: Jina AI's embedding service</li> \n <li><strong>HuggingFace</strong>: Models from HuggingFace</li> \n <li><strong>GoogleAI</strong>: Google's embedding models</li> \n <li><strong>VoyageAI</strong>: VoyageAI's embedding models</li> \n</ul> \n<details> \n <b>Embedding Provider Configuration</b> (click to expand) \n <h3>Environment Variables</h3> \n <p>To configure the embedding provider, set the following environment variables in your <code>.env</code> file:</p> \n <pre><code class=\"language-bash\"># Primary embedding configuration\nEMBEDDING_PROVIDER=openai       # Provider type (openai, ollama, mistral, jina, huggingface, googleai, voyageai)\nEMBEDDING_MODEL=text-embedding-3-small  # Model name to use\nEMBEDDING_URL=                  # Optional custom API endpoint\nEMBEDDING_KEY=                  # API key for the provider (if required)\nEMBEDDING_BATCH_SIZE=100        # Number of documents to process in a batch\nEMBEDDING_STRIP_NEW_LINES=true  # Whether to remove new lines from text before embedding\n\n# Advanced settings\nPROXY_URL=                      # Optional proxy for all API calls\n\n# SSL/TLS Certificate Configuration (for external communication with LLM backends and tool servers)\nEXTERNAL_SSL_CA_PATH=           # Path to custom CA certificate file (PEM format) inside the container\n                                # Must point to /opt/pentagi/ssl/ directory (e.g., /opt/pentagi/ssl/ca-bundle.pem)\nEXTERNAL_SSL_INSECURE=false     # Skip certificate verification (use only for testing)\n</code></pre> \n <details> \n  <b>How to Add Custom CA Certificates</b> (click to expand) \n  <p>If you see this error: <code>tls: failed to verify certificate: x509: certificate signed by unknown authority</code></p> \n  <p><strong>Step 1:</strong> Get your CA certificate bundle in PEM format (can contain multiple certificates)</p> \n  <p><strong>Step 2:</strong> Place the file in the SSL directory on your host machine:</p> \n  <pre><code class=\"language-bash\"># Default location (if PENTAGI_SSL_DIR is not set)\ncp ca-bundle.pem ./pentagi-ssl/\n\n# Or custom location (if using PENTAGI_SSL_DIR in docker-compose.yml)\ncp ca-bundle.pem /path/to/your/ssl/dir/\n</code></pre> \n  <p><strong>Step 3:</strong> Set the path in <code>.env</code> file (path must be inside the container):</p> \n  <pre><code class=\"language-bash\"># The volume pentagi-ssl is mounted to /opt/pentagi/ssl inside the container\nEXTERNAL_SSL_CA_PATH=/opt/pentagi/ssl/ca-bundle.pem\nEXTERNAL_SSL_INSECURE=false\n</code></pre> \n  <p><strong>Step 4:</strong> Restart PentAGI:</p> \n  <pre><code class=\"language-bash\">docker compose restart pentagi\n</code></pre> \n  <p><strong>Notes:</strong></p> \n  <ul> \n   <li>The <code>pentagi-ssl</code> volume is mounted to <code>/opt/pentagi/ssl</code> inside the container</li> \n   <li>You can change host directory using <code>PENTAGI_SSL_DIR</code> variable in docker-compose.yml</li> \n   <li>File supports multiple certificates and intermediate CAs in one PEM file</li> \n   <li>Use <code>EXTERNAL_SSL_INSECURE=true</code> only for testing (not recommended for production)</li> \n  </ul> \n </details> \n <h3>Provider-Specific Limitations</h3> \n <p>Each provider has specific limitations and supported features:</p> \n <ul> \n  <li><strong>OpenAI</strong>: Supports all configuration options</li> \n  <li><strong>Ollama</strong>: Does not support <code>EMBEDDING_KEY</code> as it uses local models</li> \n  <li><strong>Mistral</strong>: Does not support <code>EMBEDDING_MODEL</code> or custom HTTP client</li> \n  <li><strong>Jina</strong>: Does not support custom HTTP client</li> \n  <li><strong>HuggingFace</strong>: Requires <code>EMBEDDING_KEY</code> and supports all other options</li> \n  <li><strong>GoogleAI</strong>: Does not support <code>EMBEDDING_URL</code>, requires <code>EMBEDDING_KEY</code></li> \n  <li><strong>VoyageAI</strong>: Supports all configuration options</li> \n </ul> \n <p>If <code>EMBEDDING_URL</code> and <code>EMBEDDING_KEY</code> are not specified, the system will attempt to use the corresponding LLM provider settings (e.g., <code>OPEN_AI_KEY</code> when <code>EMBEDDING_PROVIDER=openai</code>).</p> \n <h3>Why Consistent Embedding Providers Matter</h3> \n <p>It's crucial to use the same embedding provider consistently because:</p> \n <ol> \n  <li><strong>Vector Compatibility</strong>: Different providers produce vectors with different dimensions and mathematical properties</li> \n  <li><strong>Semantic Consistency</strong>: Changing providers can break semantic similarity between previously embedded documents</li> \n  <li><strong>Memory Corruption</strong>: Mixed embeddings can lead to poor search results and broken knowledge base functionality</li> \n </ol> \n <p>If you change your embedding provider, you should flush and reindex your entire knowledge base (see <code>etester</code> utility below).</p> \n</details> \n<h3>Embedding Tester Utility (etester)</h3> \n<p>PentAGI includes a specialized <code>etester</code> utility for testing, managing, and debugging embedding functionality. This tool is essential for diagnosing and resolving issues related to vector embeddings and knowledge storage.</p> \n<details> \n <b>Etester Commands</b> (click to expand) \n <pre><code class=\"language-bash\"># Test embedding provider and database connection\ncd backend\ngo run cmd/etester/main.go test -verbose\n\n# Show statistics about the embedding database\ngo run cmd/etester/main.go info\n\n# Delete all documents from the embedding database (use with caution!)\ngo run cmd/etester/main.go flush\n\n# Recalculate embeddings for all documents (after changing provider)\ngo run cmd/etester/main.go reindex\n\n# Search for documents in the embedding database\ngo run cmd/etester/main.go search -query \"How to install PostgreSQL\" -limit 5\n</code></pre> \n <h3>Using Docker</h3> \n <p>If you're running PentAGI in Docker, you can use etester from within the container:</p> \n <pre><code class=\"language-bash\"># Test embedding provider\ndocker exec -it pentagi /opt/pentagi/bin/etester test\n\n# Show detailed database information\ndocker exec -it pentagi /opt/pentagi/bin/etester info -verbose\n</code></pre> \n <h3>Advanced Search Options</h3> \n <p>The <code>search</code> command supports various filters to narrow down results:</p> \n <pre><code class=\"language-bash\"># Filter by document type\ndocker exec -it pentagi /opt/pentagi/bin/etester search -query \"Security vulnerability\" -doc_type guide -threshold 0.8\n\n# Filter by flow ID\ndocker exec -it pentagi /opt/pentagi/bin/etester search -query \"Code examples\" -doc_type code -flow_id 42\n\n# All available search options\ndocker exec -it pentagi /opt/pentagi/bin/etester search -help\n</code></pre> \n <p>Available search parameters:</p> \n <ul> \n  <li><code>-query STRING</code>: Search query text (required)</li> \n  <li><code>-doc_type STRING</code>: Filter by document type (answer, memory, guide, code)</li> \n  <li><code>-flow_id NUMBER</code>: Filter by flow ID (positive number)</li> \n  <li><code>-answer_type STRING</code>: Filter by answer type (guide, vulnerability, code, tool, other)</li> \n  <li><code>-guide_type STRING</code>: Filter by guide type (install, configure, use, pentest, development, other)</li> \n  <li><code>-limit NUMBER</code>: Maximum number of results (default: 3)</li> \n  <li><code>-threshold NUMBER</code>: Similarity threshold (0.0-1.0, default: 0.7)</li> \n </ul> \n <h3>Common Troubleshooting Scenarios</h3> \n <ol> \n  <li><strong>After changing embedding provider</strong>: Always run <code>flush</code> or <code>reindex</code> to ensure consistency</li> \n  <li><strong>Poor search results</strong>: Try adjusting the similarity threshold or check if embeddings are correctly generated</li> \n  <li><strong>Database connection issues</strong>: Verify PostgreSQL is running with pgvector extension installed</li> \n  <li><strong>Missing API keys</strong>: Check environment variables for your chosen embedding provider</li> \n </ol> \n</details> \n<h2>🔍 Function Testing with ftester</h2> \n<p>PentAGI includes a versatile utility called <code>ftester</code> for debugging, testing, and developing specific functions and AI agent behaviors. While <code>ctester</code> focuses on testing LLM model capabilities, <code>ftester</code> allows you to directly invoke individual system functions and AI agent components with precise control over execution context.</p> \n<h3>Key Features</h3> \n<ul> \n <li><strong>Direct Function Access</strong>: Test individual functions without running the entire system</li> \n <li><strong>Mock Mode</strong>: Test functions without a live PentAGI deployment using built-in mocks</li> \n <li><strong>Interactive Input</strong>: Fill function arguments interactively for exploratory testing</li> \n <li><strong>Detailed Output</strong>: Color-coded terminal output with formatted responses and errors</li> \n <li><strong>Context-Aware Testing</strong>: Debug AI agents within the context of specific flows, tasks, and subtasks</li> \n <li><strong>Observability Integration</strong>: All function calls are logged to Langfuse and Observability stack</li> \n</ul> \n<h3>Usage Modes</h3> \n<h4>Command Line Arguments</h4> \n<p>Run ftester with specific function and arguments directly from the command line:</p> \n<pre><code class=\"language-bash\"># Basic usage with mock mode\ncd backend\ngo run cmd/ftester/main.go [function_name] -[arg1] [value1] -[arg2] [value2]\n\n# Example: Test terminal command in mock mode\ngo run cmd/ftester/main.go terminal -command \"ls -la\" -message \"List files\"\n\n# Using a real flow context\ngo run cmd/ftester/main.go -flow 123 terminal -command \"whoami\" -message \"Check user\"\n\n# Testing AI agent in specific task/subtask context\ngo run cmd/ftester/main.go -flow 123 -task 456 -subtask 789 pentester -message \"Find vulnerabilities\"\n</code></pre> \n<h4>Interactive Mode</h4> \n<p>Run ftester without arguments for a guided interactive experience:</p> \n<pre><code class=\"language-bash\"># Start interactive mode\ngo run cmd/ftester/main.go [function_name]\n\n# For example, to interactively fill browser tool arguments\ngo run cmd/ftester/main.go browser\n</code></pre> \n<details> \n <b>Available Functions</b> (click to expand) \n <h3>Environment Functions</h3> \n <ul> \n  <li><strong>terminal</strong>: Execute commands in a container and return the output</li> \n  <li><strong>file</strong>: Perform file operations (read, write, list) in a container</li> \n </ul> \n <h3>Search Functions</h3> \n <ul> \n  <li><strong>browser</strong>: Access websites and capture screenshots</li> \n  <li><strong>google</strong>: Search the web using Google Custom Search</li> \n  <li><strong>duckduckgo</strong>: Search the web using DuckDuckGo</li> \n  <li><strong>tavily</strong>: Search using Tavily AI search engine</li> \n  <li><strong>traversaal</strong>: Search using Traversaal AI search engine</li> \n  <li><strong>perplexity</strong>: Search using Perplexity AI</li> \n  <li><strong>searxng</strong>: Search using Searxng meta search engine (aggregates results from multiple engines)</li> \n </ul> \n <h3>Vector Database Functions</h3> \n <ul> \n  <li><strong>search_in_memory</strong>: Search for information in vector database</li> \n  <li><strong>search_guide</strong>: Find guidance documents in vector database</li> \n  <li><strong>search_answer</strong>: Find answers to questions in vector database</li> \n  <li><strong>search_code</strong>: Find code examples in vector database</li> \n </ul> \n <h3>AI Agent Functions</h3> \n <ul> \n  <li><strong>advice</strong>: Get expert advice from an AI agent</li> \n  <li><strong>coder</strong>: Request code generation or modification</li> \n  <li><strong>maintenance</strong>: Run system maintenance tasks</li> \n  <li><strong>memorist</strong>: Store and organize information in vector database</li> \n  <li><strong>pentester</strong>: Perform security tests and vulnerability analysis</li> \n  <li><strong>search</strong>: Complex search across multiple sources</li> \n </ul> \n <h3>Utility Functions</h3> \n <ul> \n  <li><strong>describe</strong>: Show information about flows, tasks, and subtasks</li> \n </ul> \n</details> \n<details> \n <b>Debugging Flow Context</b> (click to expand) \n <p>The <code>describe</code> function provides detailed information about tasks and subtasks within a flow. This is particularly useful for diagnosing issues when PentAGI encounters problems or gets stuck.</p> \n <pre><code class=\"language-bash\"># List all flows in the system\ngo run cmd/ftester/main.go describe\n\n# Show all tasks and subtasks for a specific flow\ngo run cmd/ftester/main.go -flow 123 describe\n\n# Show detailed information for a specific task\ngo run cmd/ftester/main.go -flow 123 -task 456 describe\n\n# Show detailed information for a specific subtask\ngo run cmd/ftester/main.go -flow 123 -task 456 -subtask 789 describe\n\n# Show verbose output with full descriptions and results\ngo run cmd/ftester/main.go -flow 123 describe -verbose\n</code></pre> \n <p>This function allows you to identify the exact point where a flow might be stuck and resume processing by directly invoking the appropriate agent function.</p> \n</details> \n<details> \n <b>Function Help and Discovery</b> (click to expand) \n <p>Each function has a help mode that shows available parameters:</p> \n <pre><code class=\"language-bash\"># Get help for a specific function\ngo run cmd/ftester/main.go [function_name] -help\n\n# Examples:\ngo run cmd/ftester/main.go terminal -help\ngo run cmd/ftester/main.go browser -help\ngo run cmd/ftester/main.go describe -help\n</code></pre> \n <p>You can also run ftester without arguments to see a list of all available functions:</p> \n <pre><code class=\"language-bash\">go run cmd/ftester/main.go\n</code></pre> \n</details> \n<details> \n <b>Output Format</b> (click to expand) \n <p>The <code>ftester</code> utility uses color-coded output to make interpretation easier:</p> \n <ul> \n  <li><strong>Blue headers</strong>: Section titles and key names</li> \n  <li><strong>Cyan [INFO]</strong>: General information messages</li> \n  <li><strong>Green [SUCCESS]</strong>: Successful operations</li> \n  <li><strong>Red [ERROR]</strong>: Error messages</li> \n  <li><strong>Yellow [WARNING]</strong>: Warning messages</li> \n  <li><strong>Yellow [MOCK]</strong>: Indicates mock mode operation</li> \n  <li><strong>Magenta values</strong>: Function arguments and results</li> \n </ul> \n <p>JSON and Markdown responses are automatically formatted for readability.</p> \n</details> \n<details> \n <b>Advanced Usage Scenarios</b> (click to expand) \n <h3>Debugging Stuck AI Flows</h3> \n <p>When PentAGI gets stuck in a flow:</p> \n <ol> \n  <li>Pause the flow through the UI</li> \n  <li>Use <code>describe</code> to identify the current task and subtask</li> \n  <li>Directly invoke the agent function with the same task/subtask IDs</li> \n  <li>Examine the detailed output to identify the issue</li> \n  <li>Resume the flow or manually intervene as needed</li> \n </ol> \n <h3>Testing Environment Variables</h3> \n <p>Verify that API keys and external services are configured correctly:</p> \n <pre><code class=\"language-bash\"># Test Google search API configuration\ngo run cmd/ftester/main.go google -query \"pentesting tools\"\n\n# Test browser access to external websites\ngo run cmd/ftester/main.go browser -url \"https://example.com\"\n</code></pre> \n <h3>Developing New AI Agent Behaviors</h3> \n <p>When developing new prompt templates or agent behaviors:</p> \n <ol> \n  <li>Create a test flow in the UI</li> \n  <li>Use ftester to directly invoke the agent with different prompts</li> \n  <li>Observe responses and adjust prompts accordingly</li> \n  <li>Check Langfuse for detailed traces of all function calls</li> \n </ol> \n <h3>Verifying Docker Container Setup</h3> \n <p>Ensure containers are properly configured:</p> \n <pre><code class=\"language-bash\">go run cmd/ftester/main.go -flow 123 terminal -command \"env | grep -i proxy\" -message \"Check proxy settings\"\n</code></pre> \n</details> \n<details> \n <b>Docker Container Usage</b> (click to expand) \n <p>If you have PentAGI running in Docker, you can use ftester from within the container:</p> \n <pre><code class=\"language-bash\"># Run ftester inside the running PentAGI container\ndocker exec -it pentagi /opt/pentagi/bin/ftester [arguments]\n\n# Examples:\ndocker exec -it pentagi /opt/pentagi/bin/ftester -flow 123 describe\ndocker exec -it pentagi /opt/pentagi/bin/ftester -flow 123 terminal -command \"ps aux\" -message \"List processes\"\n</code></pre> \n <p>This is particularly useful for production deployments where you don't have a local development environment.</p> \n</details> \n<details> \n <b>Integration with Observability Tools</b> (click to expand) \n <p>All function calls made through ftester are logged to:</p> \n <ol> \n  <li><strong>Langfuse</strong>: Captures the entire AI agent interaction chain, including prompts, responses, and function calls</li> \n  <li><strong>OpenTelemetry</strong>: Records metrics, traces, and logs for system performance analysis</li> \n  <li><strong>Terminal Output</strong>: Provides immediate feedback on function execution</li> \n </ol> \n <p>To access detailed logs:</p> \n <ul> \n  <li>Check Langfuse UI for AI agent traces (typically at <code>http://localhost:4000</code>)</li> \n  <li>Use Grafana dashboards for system metrics (typically at <code>http://localhost:3000</code>)</li> \n  <li>Examine terminal output for immediate function results and errors</li> \n </ul> \n</details> \n<h3>Command-line Options</h3> \n<p>The main utility accepts several options:</p> \n<ul> \n <li><code>-env &lt;path&gt;</code> - Path to environment file (optional, default: <code>.env</code>)</li> \n <li><code>-provider &lt;type&gt;</code> - Provider type to use (default: <code>custom</code>, options: <code>openai</code>, <code>anthropic</code>, <code>ollama</code>, <code>bedrock</code>, <code>gemini</code>, <code>custom</code>)</li> \n <li><code>-flow &lt;id&gt;</code> - Flow ID for testing (0 means using mocks, default: <code>0</code>)</li> \n <li><code>-task &lt;id&gt;</code> - Task ID for agent context (optional)</li> \n <li><code>-subtask &lt;id&gt;</code> - Subtask ID for agent context (optional)</li> \n</ul> \n<p>Function-specific arguments are passed after the function name using <code>-name value</code> format.</p> \n<h2>🏗️ Building</h2> \n<h3>Building Docker Image</h3> \n<pre><code class=\"language-bash\">docker build -t local/pentagi:latest .\n</code></pre> \n<blockquote> \n <p>[!NOTE] You can use <code>docker buildx</code> to build the image for different platforms like a <code>docker buildx build --platform linux/amd64 -t local/pentagi:latest .</code></p> \n <p>You need to change image name in docker-compose.yml file to <code>local/pentagi:latest</code> and run <code>docker compose up -d</code> to start the server or use <code>build</code> key option in <a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/docker-compose.yml\">docker-compose.yml</a> file.</p> \n</blockquote> \n<h2>👏 Credits</h2> \n<p>This project is made possible thanks to the following research and developments:</p> \n<ul> \n <li><a href=\"https://lilianweng.github.io/posts/2023-06-23-agent\">Emerging Architectures for LLM Applications</a></li> \n <li><a href=\"https://arxiv.org/abs/2403.08299\">A Survey of Autonomous LLM Agents</a></li> \n</ul> \n<h2>📄 License</h2> \n<h3>PentAGI Core License</h3> \n<p><strong>PentAGI Core</strong>: Licensed under <a href=\"https://raw.githubusercontent.com/vxcontrol/pentagi/master/LICENSE\">MIT License</a><br /> Copyright (c) 2025 PentAGI Development Team</p> \n<h3>VXControl Cloud SDK Integration</h3> \n<p><strong>VXControl Cloud SDK Integration</strong>: This repository integrates <a href=\"https://github.com/vxcontrol/cloud\">VXControl Cloud SDK</a> under a <strong>special licensing exception</strong> that applies <strong>ONLY</strong> to the official PentAGI project.</p> \n<h4>✅ Official PentAGI Project</h4> \n<ul> \n <li>This official repository: <code>https://github.com/vxcontrol/pentagi</code></li> \n <li>Official releases distributed by VXControl LLC</li> \n <li>Code used under direct authorization from VXControl LLC</li> \n</ul> \n<h4>⚠️ Important for Forks and Third-Party Use</h4> \n<p>If you fork this project or create derivative works, the VXControl SDK components are subject to <strong>AGPL-3.0</strong> license terms. You must either:</p> \n<ol> \n <li><strong>Remove VXControl SDK integration</strong></li> \n <li><strong>Open source your entire application</strong> (comply with AGPL-3.0 copyleft terms)</li> \n <li><strong>Obtain a commercial license</strong> from VXControl LLC</li> \n</ol> \n<h4>Commercial Licensing</h4> \n<p>For commercial use of VXControl Cloud SDK in proprietary applications, contact:</p> \n<ul> \n <li><strong>Email</strong>: <a href=\"mailto:info@vxcontrol.com\">info@vxcontrol.com</a></li> \n <li><strong>Subject</strong>: \"VXControl Cloud SDK Commercial License\"</li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:09.823064Z",
        "tags": [
          {
            "name": "transformation",
            "score": 16
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 17
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 50,
        "timeliness_score": 1,
        "final_score": 25.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://alexalejandre.com/programming/steve-klabnik-interview/",
        "title": "Lobsters Interview with steveklabnik",
        "summary": "<p>The following interview covers Rust and compilers, source control and monorepos, community engagement and vibe coding.</p>\n<p><a href=\"https://lobste.rs/~steveklabnik\" rel=\"ugc\">@steveklabnik</a> and I had the pleasure of speaking a few times over a few months. He wrote the Rust Book, a lovely <a href=\"https://steveklabnik.github.io/jujutsu-tutorial/\" rel=\"ugc\">Jujutsu tutorial</a>, worked at Oxide and gave many <a href=\"https://www.youtube.com/watch?v=79PSagCD_AY\" rel=\"ugc\">interesting talks</a>.  I thank <a href=\"https://lobste.rs/~smlckz\" rel=\"ugc\">@smlckz</a> and <a href=\"https://lobste.rs/~hoistbypetard\" rel=\"ugc\">@hoistbypetard</a> for their assistance proofreading.</p>\n<hr />\n<p><strong>How did you discover programming?</strong></p>\n<p>I grew up on a beef farm. My dad, his dad and his dad were all butchers. My uncle was a programmer in the 70s and 80s and brought a computer over to show what he did. I was 7 when I saw it and knew I wouldn't go outside anymore. Sorry dad. My little sister became the farm boy, she's a veterinarian now.</p>\n<p>I learned BASIC, then C, C++, Java. I don't remember not being able to program. I grew up reading slash dot (had a 5 digit id) and absorbed the culture around open source and free software. So I just ended up contributing to open source and joining a startup after college. People know me for Rust now, but I was involved in Ruby for years before that. Back then, in Rubyland, there was a guy named <a href=\"https://en.wikipedia.org/wiki/Why_the_lucky_stiff\" rel=\"ugc\">Why the Lucky Stiff</a>, a deliberately constructed identity doing important work. When he disappeared, I wanted to keep it going. He disappeared because people revealed his private persona to the world, which he wanted to keep separate. I made the choice there.</p>\n<p><strong>Many quite dislike their work and only want to talk about personal projects, but as a public personality does your professional and personal lives and interests totally merge together?</strong></p>\n<p>It's definitely a bit weird. I've been dating someone for about a year now and had to explain this <em>my being an online person</em> thing which clarified a lot of stuff.</p>\n<p>What matters most to me is impact, I'm trying to improve the world, make things better. For me, the best way is being a relatively public person; a public persona helps push things forward. I have a joke about a secret gamer identity; my Discord is my gamer name first which I change to Steve Klabnik in technical/programming Discords. That's most to keep from leaking my literal name into video game spaces, but if I had to maintain a public Steve and a private Steve, that'd be a little harder. So I got used to being a public person. It's easier to get things done when your goal's also your job, so I don't try to maximize personal income but find things I want to do. These days I don't have time to do a second job after my first job, whereas I used to have the time to work 80 hours around the clock. Hitting 40, I've been thinking about getting older...</p>\n<p>On the other hand, if I'm checking Lobsters, HN, Bluesky at night... Since I've often been in developer relations, like PR, if there were a crisis in the Rust community at Friday night... I'm always a bit on.</p>\n<p><strong>How did you avoid a you-shaped hole when you left Ruby or Oxide? How do you help keep something going without you?</strong></p>\n<p>I had the habit of picking up and maintaining other existing projects no one was working on. If someone else wanted to take over, great! But there wasn't so much of a crisis to leave things as I left them before. Some of those projects already had replacements like <a href=\"https://github.com/resque/resque\" rel=\"ugc\">Resque</a> and <a href=\"https://github.com/sidekiq/sidekiq\" rel=\"ugc\">Sidekiq</a> too. I also felt increasingly weird maintaining Why's stuff after he deliberately destroyed it. Worse, his projects were deeply tied into Ruby internals and deprecating APIs, making it difficult and time-consuming to maintain. This maintenance burden also informed his departure, which I came to learn first hand.</p>\n<p>I started going to Ruby conferences where people asked me to talk about things I cared about. But well, I cared about Rust and talked about it, connecting those communities together. So there was no clean break. Unless you commit info suicide on your persona like Why, which I couldn't do. I still like the Ruby community but did deliberately decide to focus my attention away; I haven't written Ruby in a long time.</p>\n<p>For Oxide, I said I was quitting and asked to discuss a transition plan. I started pair programming every day to onboard someone to the project I was working on by myself. It took about 6 weeks to hand everything over.</p>\n<p><strong>Matklad has an <a href=\"https://matklad.github.io/2024/03/22/basic-things.html\" rel=\"ugc\">article</a> about what open source projects need. You also have a few <a href=\"https://steveklabnik.com/writing/how-to-be-an-open-source-gardener/\" rel=\"ugc\">along these lines</a>. What advice do you have for a newer community which wants to build these things up and stay maintained long term?</strong></p>\n<p>A big thing I did in Rust and want <a href=\"https://github.com/jj-vcs/jj\" rel=\"ugc\">JJ</a> to follow is open source is an act of creation. You want something to exist, so you build it. That need for creation's often born out of unhappiness with how things exist today. I used to teach programming as a job and tell people if the program existed bug-free, you wouldn't be programming. It's the act of moving things from a state you don't like to one you do. When writing code, you're creating features which don't exist or fixing problems which do. It's easy and tempting for projects to fixate on the criticism they create by existing, but this is unhealthy. As an example, Rails was focused on Java sucking, but when you fixate on someone else sucking, you're not focused on improving your own stuff and rot. And what happens if you win? You lack a positive narrative to keep growing and eat yourself alive if you can't find another enemy. Well, it turns out JavaScript's not actually that bad and Rails missed the boat on JavaScript-heavy applications. Rails didn't fail into irrelevance, but did lose cultural dominance.</p>\n<p>So the Rust world focused on not saying Rust is great because C++ is terrible. There is criticism, but the project can't be about that. It's bad on a personal and a strategic level. Hating on others makes you a bad person. Instead, you have to focus on excited people building and creating. In the jj community, we should be \"git is fine, we just like jj better\" not \"git sucks, jj is good\". This is important and healthier for a community long term.</p>\n<p>I haven't been involved in Rust for about 3 years, but before there was a clear perspective that we were building a community, which meant we needed to bring people into the community. There's a funnel from all the people who hear the name \"Rust\", then who click on Rustlings, then who make a contribution...</p>\n<p><strong>How do you manage projects and communities in open source?</strong></p>\n<p>With open source, you can't compel people to do certain things. Well, programmers are prima donnas in a few ways, so even as employees you can't force them to do anything or they'll push back. So you need the soft skills to sell the vision and convince people to help. Building consensus is always a nice thing. People will follow good examples, but also bad ones. If leadership encourages a brash, off-the-cuff communication style, they will attract and retain similar people. If leadership is more measured, they'll accumulate a community of measured people.</p>\n<p>If I find words or styles of communication which resonates, I'll see community members replicate those same arguments. There's a classic book \"High Output Management\" by the Intel guy from the 90s, whose whole thing was that a CEO's job is purely cultural transmission to others because that's the only way you can affect change at scale. A CEO can't just stand on the assembly line and do everyone else's job better at the same time, after all. When managing, you reproduce the culture you want to see and it either works or it doesn't! It's a second order way of working, not doing it yourself but creating the environment where the work is done.</p>\n<p>Especially the higher you go, e.g. what distro is integrating what systems is all intraproject management and intracommunity coordination, 100% soft skills, because you're not even in the project you're managing. As an example, Ubuntu is currently integrating the Rust based <a href=\"https://github.com/uutils/coreutils\" rel=\"ugc\">uutil</a>, but can't force them to do anything. Ubuntu's communication must be like \"hey, we want this in order to make that happen, are you interested in it?\" Then the uutil people hopefully say \"yes, we will take your advice and do this, because this is a shared goal.\"</p>\n<p><strong>How do you approach course design, textbook writing?</strong></p>\n<p>The <a href=\"https://doc.rust-lang.org/book/foreword.html\" rel=\"ugc\">Rust Book</a> was me making a 50 pg. tutorial called Rust for Rubyists in 2013, which I then rewrote into 175ish pages. Later I got Carol in as my coauthor and we wrote what's now on the site. The <a href=\"https://steveklabnik.github.io/jujutsu-tutorial/introduction/introduction.html\" rel=\"ugc\">jj tutorial</a> is 100% me besides the Gerrit chapter.</p>\n<p>For all of these, I write down what I'm learning in the order I learn because writing helps me understand. There's no better way to know what a new person needs than by being new yourself. The problem's that not everyone is you, so you have to go beyond. The trick with the Rust Book's that it has extra constraints from being official e.g. not using many external packages lest it bias the ecosystem. Normally writing Rust involves many third party libraries, which you don't do in the course at all. I also felt the need to include all language features because it was going to be the primary way for people to learn.</p>\n<p>For the final version, I wrote down a ton of concepts I knew and went through the reference writing down more features to cover. I wrote them on note cards and started arranging them into a concept map. You need to know x before you learn y. The difficulty's all the dependencies especially early on. Guy Steele showed how to <a href=\"https://www.youtube.com/watch?v=lw6TaiXzHAE\" rel=\"ugc\">grow a language</a>. To learn Rust, you have to build the smallest possible \"kernel\" to bootstrap your understanding on, growing the language one piece at a time. This meant putting ownership and borrowing as soon as reasonable, because it was the newest thing really impacting people. After functions, variables, loops and borrowing, readers have a base to understand the rest.</p>\n<p>In the 2nd version of the jj tutorial, I'm focusing more heavily on workflows. People want to know what they can actually do with something more than what it is. Especially experienced programmers are willing to hand-wave things although they claim to want the details. They just want to get things done, at first.</p>\n<p>Those are the two major design philosophies for a book-length tutorial, start building from small parts or just run with it, explaining as you go. With jj, most people just want to get things done; there aren't many version control fanatics.</p>\n<p><strong>How do you yourself learn?</strong></p>\n<p>I read existing documentation then try to do stuff, mess around. When learning a programming language, I try to implement a text adventure game going back to the first thing I ever did on a computer at my grandma's house playing the <a href=\"https://rickadams.org/adventure/advent/\" rel=\"ugc\">Collosal Cave Adventure</a>. I've always loved text adventures. You get a little bit of I/O, data management, loops and stuff, enough to get a feel for writing something real. The one I wrote in Rust just had nine rooms, but that's enough to really get going. But you can't write a game in jj. I just had to use it, run into problems and ask for help.</p>\n<p><strong>How do you think about languages, APIs and design?</strong></p>\n<p>Simon Peyton Jones' \"avoid success at any cost\" motto for Haskell is really interesting, with multiple interpretations. The most important thing is build the thing you want to build. You have deliberately decide your priorities and what you care about. Oxide's really big on values. Figure out what's most important then put them in an order. Rust cares about safety, performance, correctness in that order. On a different axis, Rust always wanted to be used by many people, so choices leading to broad industry adoption were important to us.</p>\n<p>I have an article about the <a href=\"https://steveklabnik.com/writing/the-language-strangeness-budget/\" rel=\"ugc\">language strangeness budget</a> where you can only be weird about so many things before no one uses your thing anymore. You have to be deliberate and careful about where you innovate. Now, this advice only matters if aiming for broad adoption, but the key is making that deliberate choice. If you just want something fun for yourself, great! But you're making the compromise of it only being for yourself. Designing is inherently about making tough choices. Be aware and deliberate. Design requires taste and taste requires broad exposure and experience. If you don't realize there's a choice because you don't have enough context to know what your options are, you will do things accidentally, not deliberately.</p>\n<p><strong>If you could reinvent/change any aspect of Rust, what would you do alternatively?</strong></p>\n<p>A lot happened because we wanted to ship a useful thing with only so much time in the day, so some things were less deliberate than others. There's an alternate version of Rust with significantly faster compiler times, because while we cared about compile times when designing we always prioritized other values more. We never asked ourselves how this feature or implementation impacted compiler analysis time and there are several spots where something slightly different would have much faster compiler times, which people do care about. But had we spent time on that, we would have neglected other things and not been any more successful. I think whatever language eventually succeeds Rust will be much faster to compile and borrow checking will never be the big time sink when compiling.</p>\n<p><strong><a href=\"https://github.com/steveklabnik/rue\" rel=\"ugc\">Rue</a>'s readme says it's mostly a way of working on different compiler optimizations. Which of those have been most interesting?</strong></p>\n<p>Honestly, Rue's only public because GitHub charges for actions when your repo is private and I'm addicted to CI. Now, I love compilers and organized my college classes to get to compilers first but never worked on the Rust compiler, that just wasn't the best way to utilize my skills. So I wanted to mess around with compilers.</p>\n<p>Conceptually, I understood single static assignment with block params vs. fine nodes from reading papers, but never actually seriously looked at implementation code. Partly, I just want some code I can look at and mess around with without responsibilities. There's a big difference between intellectually understanding something and actually writing code for it. I knew about React's architecture for like years before I wrote a line of React - my understanding only grew when I actually coded and experimented with it.</p>\n<p>I've only been working on it for a few months, but I have a small effectively useless language (without strings). My goal is building out a full production compiler pipeline for this tiny, useless language because most people make languages useful then try to refactor the compiler; I'm doing the opposite. What if I grew the compiler wide and the language very short? While I don't have strings, I have 7 different layers of IR and will probably reach full incremental compilation before adding strings. That's just what I care about building.</p>\n<p>It took Rust like 2 years to implement <a href=\"https://rustc-dev-guide.rust-lang.org/mir/index.html\" rel=\"ugc\">MIR</a> because there was a whole production programming language, but it took me a few hours because no one uses it and there are no features. Implementing compiler internals is easier without surface features! I do have some language design features, but I'll only work on that when the compiler's ready. I only want to add features required to improve the compiler.</p>\n<hr />\n<p><strong>Hey, a few months have passed since we last spoke!</strong></p>\n<p>It's interesting how some of my thoughts have changed! I recently spent more time with Rue and came to appreciate Zig more, for example.</p>\n<p>A lot of Rust's complexity comes from wanting to be as low level and fast as C. In Rue, what if we don't make decisions based on those values? I assume Rue will have a runtime etc. Higher than Rust but lower than Go. It builds on some of Swift and Hylo's mutable value semantics. If you don't have references as a language construct, you can get rid of lifetimes! If you don't put references in structs nor return references, you don't need lifetimes and the borrow checker goes away! You lose a little efficiency, but oh well.</p>\n<p>Rust has affine types, but I think linear types are also neat. Linear types and borrowing's also weird...</p>\n<p>There's an issue of expressed and acted values too. The Rust team cares about compiler performance, has people working on it etc. We did care about this, but no enough to require RFCs to analyze compiler impacts and reject things for compiler overhead. I don't mean to criticize - I was there and involved too. (I still think the compiler will get faster, and maybe it'd be better from scratch but some features put a ceiling on it.)</p>\n<p>With Rue, how close can I get to Rust while caring about compiler performance? Recently, I've come to appreciate Zig a lot more for its decisions. Concretely, macros can introduce new items, so you have to expand all macros before type checking a Rust program. At least one of the Rust analyzer devs said they'd remove the ability of macros introducing items. Heavily relying on <a href=\"https://en.wikipedia.org/wiki/Monomorphization\" rel=\"ugc\">monomorphization</a> impacts compile time significantly, because you generate a lot of similar code then expect LLVM to filter it out. In Rust, conditional compilation is based on attribution. Zig made me uncomfortable in the past; dead code elimination finds things that aren't used and eliminates them, making the binary smaller. But you can also view that as a failure; any code generated but thrown away means you did work producing it before dumping it. Rust programs often generate a lot of code which it eventually dumps later. Zig just doesn't compile or process things if you know it won't occur! This had made me uncomfortable if e.g. had errors in some other branch e.g. compiling for Linux while the Windows config is fundamentally broken.</p>\n<p><strong>How did you approach building a system of values and getting buy-in for people?</strong></p>\n<p>I am kind of old school. A lot of it flows top-down; you can't have an outsider show up and impose values on a community. They have to come from some legitimate source in the community itself. Expressing values requires action too. People will notice if you say one thing and do another. On some level, <em>what leadership does</em> creates the actual values. It's tricky in general, because even rational adults find it hard to always act in accordance with their values.</p>\n<p><strong>How'd you decide which your values would be then?</strong></p>\n<p>I joked that my parents' biggest mistake was telling me to do what I thought was right, which caused a lot of friction when we disagreed! I have changed a lot as a person over the course of my life. I'd like to think that things happened which I took under consideration and made changes after. It often happens in software development communities that you find yourself among people you don't want to be like. You have to ask whether you're the kind of person you want to be, and make changes to align yourself. Earlier in my career, I loved talking shit on languages, tools and communities I thought were bad - but then I realized who I was becoming and made serious changes.</p>\n<p><strong>How do you approach programming? What's unusual about your methods?</strong></p>\n<p>My weirdest thing is not customizing my software. I don't set color schemes. I don't have a dot-files repo. A long time ago, teaching programming as a job, I helped people with their setups and wanted to understand the default user experience; I didn't want to recommend a program I only liked because I had 45 extensions... I didn't want to get out of touch. I don't use an ad-blocker.</p>\n<p>A hater once wrote that my Rust code seemed simpler and more straight forward, which I thought was a very nice thing for a hater to say! I tend not to write macros at all. I also avoid fancy advanced type system tricks. Although Rust has the reputation of a complicated, big language, you don't have to use it that way. I'm actually pretty tolerant of boilerplate these days.</p>\n<p>Handing off a project at Oxide, I mentioned some packages would reduce duplicates and boilerplate, but seeing the struct fields copied from one struct to another is more straightforward than some macro automatically doing it besides this one exception where....</p>\n<p><strong>I can't get over no ad-block.</strong></p>\n<p>A lot of pages have terrible intrusive ads, which guide my behavior to stay away from them.</p>\n<p>My relationship with privacy has also changed. I used to think tracking me was offensive and upsetting, but now I live such a public life with hundreds of hours of talks on youtube, where ads are the least of my worries.</p>\n<p><strong>Oxide rewrites basically everything. How'd you make sure you were actually writing better fitting replacements?</strong></p>\n<p>In other organizations, there's constantly a low-key conflict between programmers and management about what we spend time on. People often slip refactoring in before shipping the ticket, because they'll never get permission to refactor after closing the ticket.</p>\n<p>Oxide looks at what exits, what it needs and figures out whether they should build it or use something. Culturally, a lot of programmers read <a href=\"https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\" rel=\"ugc\">Joel Spolsky</a> 25 years ago. Oxide is like if that article had never been written and people would rewrite when useful.</p>\n<p>It comes down to what's fit for purpose. Software's often an 80% fit. Do you just live with that other 20%? Perhaps some people can live with a bigger misfit than others. This does slow down when we ship, but quality emerges from really working on this ourselves. That's an intangible but important benefit. We had more willingness to experiment and try than other places, which paid off.</p>\n<p>Oxide's leadership really cares about knowing your tools well. So if a tool doesn't yet exist, it's fine to make that tool for future productivity benefits. We wrote our own debugger for our own embedded real time operating system, which paid off when we had to debug firmware issues. Brian et al. had seen this approach work out in the past, so the whole organization buys in too. Oxide's the only company to rewrite AMD's CPU firmware. They didn't believe us until it happened.</p>\n<p><strong>How deeply did you dive into less popular programming paradigms?</strong></p>\n<p>I used to joke that I didn't do LSD in college but did Haskell instead; not sure which is more harmful! I used to experiment a lot. Earlier in my career, I cared a lot about programming for its own sake and now I care more about what I can do with programs. High level languages seem to have an inherent low end of where they can go. (I know this isn't directly true, you can write an OS in Lisp.) I care less about \"everything is a...\" type languages. \"Everything is an object\" is like a Beatles cover band, it's not a novel thing because we already explored that space but the interesting developments aren't there. The vitalization of lower level languages is some cyclical effect after spending a lot of energy on higher level languages.</p>\n<p>I do find <a href=\"https://www.unison-lang.org/\" rel=\"ugc\">Unison</a> cool. There's definitely room for alternative paradigms, but I want to see them prove themselves before investing a lot of time in it. Time's precious. I think I experienced enough with most of that stuff. There are some unexplored avenues like effect systems though.</p>\n<p><strong>How do you manage and prioritize your time?</strong></p>\n<p>It's hard and changed a lot for me this past year. I'm now in a serious relationship with someone who has kids, adding constraints I didn't previously have. A year ago, I could do whatever whenever, but now I care about people and have obligations to them.</p>\n<p>But when I feel I want to do the thing, I just do the thing as hard as possible. For example, I started working on Rue in August, got busy in September and set it down until the end of December when I spent a few frantic weeks on it. Claude and I shipped 100 commits on Christmas day! I wait for inspiration to spark then push on it as hard as I can.</p>\n<p>I have time blocks, spend time with work, spend time with my girlfriend, spend time on me, and within those I just do whatever I feel.</p>\n<p><strong>How do you structure commits?</strong></p>\n<p>I'm a big believer in CI and use it on PRs, even on personal projects. I don't push to main myself, either. Well, I use trunk. I care more about whether CI passes than perfectly crafting the exact commit I want. Committing to use PRs for everything, looking over the diff for 10k lines sucks on GitHub. So I tend towards very small changes. Ideally under 1000-line diffs. I once had a client where the CEO would disappear for a few months, then appear and commit something to master, so the rest of the company would frantically try to rebase all their work on top of everything. The original principles of CI matter a lot. I prefer high velocity of a small number of commits, rather than big perfect ones. Sometimes this means shipping duplication to master, then cleaning it up in a later PR, because keeping things factored while adding a new feature might suck. I trust my tests, keep my cycles quick and keep things small. Sometimes that even means feature flags; I'll ship broken features behind flags which won't get shown in production, and remove the flag when the feature's done, rather than work on a branch for a long time and eventually ship it in the end. At least, these processes work better for me.</p>\n<p>I'd rather have more small things than fewer larger things.</p>\n<p><strong>What about version control inspired you enough to leave Oxide?</strong></p>\n<p>I always loved git. I was early on it. I really hated how <a href=\"https://en.wikipedia.org/wiki/Concurrent_Versions_System\" rel=\"ugc\">CVS</a> worked (i.e. the above story.) Distributed version control just seemed straight up better to me. Code matters, but this is the software we entrust all our work output to. If git deleted all our repos tomorrow, it'd be a problem but not so bad because distributed, because backups, while your CVS repo going down would ruin you.</p>\n<p>You're the sum of all the people you spend time with. That's true of tools, too. We spend hours and hours with version control, if that tool can get better, it'll help a lot of people. I got involved with Rails, because I realized I could help every single webapp at once. I got involved with Ruby to help an even bigger set of people. I got involved with Rust, because making the OS better helps everyone! Moving down the stack gives you higher leverage to help more people and DVCS is quite low; there are few things you can do to make JavaScript, C and Rust developer's lives better at the same time.</p>\n<p>I like doing high leverage things. Working on version control is interesting to me because it can help a lot of people. I also really just like jj.</p>\n<p>But another thing: I never worked at a FAANG, but they've all converged on some things different from the rest of our industry, like monorepos. At some scale, they just move to monorepos for rational reasons (which aren't important right now.) This implies a lot of other things: path dependence and unexpected technology choices and unique systems. They have their own version control systems, often based on Mercurial for interesting historical reasons.</p>\n<p>In the past, rich people had access to things other people didn't. But today, there's no better Coca-Cola than Coca-Cola. Elon and me drink the same cola! Software's largely like this too. But FAANG companies have these entire stacks not available to the rest of us. If I wanted to use a monorepo and use Piper, that's just not an option; it's internal to Google, tied to their individual infrastructure... So I think there's some sort of Prometheus play around stealing the fire from the gods.</p>\n<p>I've been toying with my own personal monorepo for all projects. You know what sucks? Setting up integrations, IDEs etc. every time I start a new project! I'm very monorepo brained. I'm interested in tools like jj which show that world to the rest of us.</p>\n<p><strong>What are the benefits of a monorepo?</strong></p>\n<p>If I want CI to pass, my commits are limited. If it takes an hour for my CI to run, I get 24 commits a day and that's it. To scale up, you need to start to think about whether literally every test should run on every commit: No. How do you determine which tests to run? How do I share dependencies across projects? How do I integrate build systems with all the projects? There are a lot of big topics. But then it's quick to start a new project. It removes coordination costs. At Oxide, every team can use any tools they want. So some teams run on Gerrit, others on GitHub etc. which is cool but moving teams means relearning a new stack. On the flip side, a monorepo's homogeneity means you don't have to learn something new to work on another part of the code base. But now the monorepo's huge. Making everyone download the whole repo kind of sucks. Trade offs. At scale, different trade offs make more sense. These tools also assume scale. Cargo doesn't scale up to a Google sized monorepo. Buck, Blaze or Bazel are built for monorepos, annoying to use on small scales. I feel like there's a smoother transition somewhere with more powerful tools.</p>\n<p><strong>How did you become \"AI-pilled?\"</strong></p>\n<p>A year ago, I would have said these tools were BS and didn't matter. I try to be an informed hater though and realized I hadn't tried them in a while. I never liked autocomplete, so the first generation of \"spicy autocomplete\" did nothing for me. But agents are a fundamentally different way of working. Claude and ChatGPT also started writing ok Rust code.</p>\n<p>I had a rough 2024. In 2025, I did a lot of soul searching and considered the implications of these new tools, what my actual opinions about software development were etc. And I don't know man, I barely wrote any code last year. I don't know if I'm going to write any code this year personally, by hand, like at all. I started programming at 7. This might be the first year I don't code since then. It's <a href=\"https://ratfactor.com/tech-nope2\" rel=\"ugc\">uncomfortable and strange</a>.</p>\n<p>I hate the whole \"if you don't learn this stuff, you'll fall behind\" rhetoric from AI people. When Rails came out, everyone loved and flocked to it. But you know what? Not everyone actually did, only a small vocal minority. The people who didn't learn Rails weren't left behind. They didn't lose their career for not jumping on the hottest trend. It's reasonable and rational to not care. But I enjoy them. They are tools which require skill. People are willing to acknowledge that vim is useful, even if they use Emacs. I see AI tooling like vim. You have to approach it like a scientist or an engineer. You can't just say \"build me a Google clone\". Using them in an engineering-science-y way to produce good results takes different kinds of skills than directly writing code yourself. I used to care a lot about being one with the code; some of my best memories are spending a weekend solving a bug in college. But these days that just means I spent my whole weekend being frustrated and didn't get anything done!</p>\n<p>I've been meaning to write about <a href=\"https://steveklabnik.com/writing/getting-started-with-claude-for-software-development/\" rel=\"ugc\">how to approach this</a>, but it takes so much heat from people online... Some of my friends are vehement anti-AI people which has made our friendship awkward, which sucks, because I like my friends. I also talk about this less on e.g. Lobsters than I normally would. I just do it in private channels to avoid the shit. But I should be more open about it, it can help people.</p>\n<p><strong>People have been complaining about AI-driven PR spam.</strong></p>\n<p>My work in open source predisposed me to be ok with AI here. There have always been crap PRs by people who don't know what they're doing. That's the normal state of things for open source! You just get a bunch of junk from people you don't know. Some might be great, don't get me wrong. You need to have processes in place to make sure a PR is good before merging and that's true no matter who authors the code.</p>\n<p><strong>How do you use it?</strong></p>\n<p>I'll briefly go into how these tools work. I'll assume you're using Claude here. You send a request to the model. What's in the request? The tool author's system prompt, the prompt you typed in, then a bag of context (e.g. the conversation history). You can tweak all these parameters. Sometimes the correct approach is throwing the system prompt away and writing your own (using an API). People were obsessed with prompt engineering for a while - thinking prompts were the primary lever. But the context window is the biggest percentage of input. So recently people have been talking about context engineering. When the context window fills up, LLM performance goes down. You can make worse prompts if you do a better job context engineering.</p>\n<p>We used to argue about horizontal vs. vertical slicing for apps, DB, framework, application, view layers vs. feature folders. From a context perspective, a folder per feature is easier for an agent or a person to figure out what's needed (assuming you separated your feature out). How do you ensure the context window only has what's relevant to the goal?</p>\n<p>In Rue, I have these architecture decision records (ADR) describing a design and its rationale. I'll tell Claude to read ADR 1 and 5 and then mention I want to modify the type system. It's like tickets, you want a ticket with a minimum reproduction. I don't think these are new things, rather we've been collectively paying these practices lip service, and those who actually follow them will do better with these tools. A well-structured codebase means both a human and an agent will have a better time; it's just easier to notice an agent flailing around than realize a developer taking 3 weeks to ship a fix is the same symptom.</p>\n<p>LLMs are like an average user, which is a nice feedback mechanism too. In the first iteration of Rue, Claude was trying to dump the assembly for a program it was debugging. It kept passing <code>-S</code> which wasn't implemented instead of <code>--emit-asm-</code> which I thought was nicer. But it turns out <code>-S</code> is a standard flag across compilers, assuming it exists is a good assumption. So I implemented that as an LLM to stop it from flailing around. There's value in watching what an LLM assumes. It will give reasonable attempts or answers, because it's seen everything. If you can make something easy enough for Claude to understand, it might be a good model.</p>\n<p><a href=\"https://lobste.rs/s/w1bsle/lobsters_interview_with_steveklabnik\">Comments</a></p>",
        "source": "lobste.rs",
        "published": "Fri, 20 Feb 2026 13:18:35 -0600",
        "fetched_at": "2026-02-22T23:21:13.783536Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 4,
        "final_score": 18.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/SynkraAI/aios-core",
        "title": "SynkraAI/aios-core",
        "summary": "<p>Synkra AIOS: AI-Orchestrated System for Full Stack Development - Core Framework v4.0</p><hr /><h1>Synkra AIOS: Framework Universal de Agentes IA 🚀</h1> \n<blockquote> \n <p>🌍 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/README.en.md\">English</a> | <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/README.md\">Português</a></strong></p> \n</blockquote> \n<p><a href=\"https://www.npmjs.com/package/aios-core\"><img alt=\"Versão NPM\" src=\"https://img.shields.io/npm/v/aios-core.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\"><img alt=\"Licença: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true\" /></a> <a href=\"https://nodejs.org/\"><img alt=\"Versão Node.js\" src=\"https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true\" /></a> <a href=\"https://github.com/SynkraAI/aios-core/actions/workflows/ci.yml\"><img alt=\"CI\" src=\"https://github.com/SynkraAI/aios-core/actions/workflows/ci.yml/badge.svg?sanitize=true\" /></a> <a href=\"https://codecov.io/gh/SynkraAI/aios-core\"><img alt=\"codecov\" src=\"https://codecov.io/gh/SynkraAI/aios-core/branch/main/graph/badge.svg?sanitize=true\" /></a> <a href=\"https://synkra.ai\"><img alt=\"Documentação\" src=\"https://img.shields.io/badge/docs-dispon%C3%ADvel-orange.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\"><img alt=\"Open Source\" src=\"https://img.shields.io/badge/Open%20Source-Yes-success.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\"><img alt=\"Contributions Welcome\" src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CODE_OF_CONDUCT.md\"><img alt=\"Code of Conduct\" src=\"https://img.shields.io/badge/code%20of%20conduct-Contributor%20Covenant-blue.svg?sanitize=true\" /></a></p> \n<p>Framework de Desenvolvimento Auto-Modificável Alimentado por IA. Fundado em Desenvolvimento Ágil Dirigido por Agentes, oferecendo capacidades revolucionárias para desenvolvimento dirigido por IA e muito mais. Transforme qualquer domínio com expertise especializada de IA: desenvolvimento de software, entretenimento, escrita criativa, estratégia de negócios, bem-estar pessoal e muito mais.</p> \n<h2>Comece Aqui (10 Min)</h2> \n<p>Se é sua primeira vez no AIOS, siga este caminho linear:</p> \n<ol> \n <li>Instale em um projeto novo ou existente:</li> \n</ol> \n<pre><code class=\"language-bash\"># novo projeto\nnpx aios-core init meu-projeto\n\n# projeto existente\ncd seu-projeto\nnpx aios-core install\n</code></pre> \n<ol start=\"2\"> \n <li>Escolha sua IDE/CLI e o caminho de ativação:</li> \n</ol> \n<ul> \n <li>Claude Code: <code>/agent-name</code></li> \n <li>Gemini CLI: <code>/aios-menu</code> → <code>/aios-&lt;agent&gt;</code></li> \n <li>Codex CLI: <code>/skills</code> → <code>aios-&lt;agent-id&gt;</code></li> \n <li>Cursor/Copilot/AntiGravity: siga os limites e workarounds em <code>docs/ide-integration.md</code></li> \n</ul> \n<ol start=\"3\"> \n <li>Ative 1 agente e confirme o greeting.</li> \n <li>Rode 1 comando inicial (<code>*help</code> ou equivalente) para validar first-value.</li> \n</ol> \n<p>Definição de first-value (binária): ativação de agente + greeting válido + comando inicial com output útil em &lt;= 10 minutos.</p> \n<h2>Compatibilidade de Hooks por IDE (Realidade AIOS 4.2)</h2> \n<p>Muitos recursos avançados do AIOS dependem de eventos de ciclo de vida (hooks). A tabela abaixo mostra a paridade real entre IDEs/plataformas:</p> \n<table> \n <thead> \n  <tr> \n   <th>IDE/CLI</th> \n   <th>Paridade de Hooks vs Claude</th> \n   <th>Impacto Prático</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Claude Code</td> \n   <td>Completa (referência)</td> \n   <td>Automação máxima de contexto, guardrails e auditoria</td> \n  </tr> \n  <tr> \n   <td>Gemini CLI</td> \n   <td>Alta (eventos nativos)</td> \n   <td>Cobertura forte de automações pre/post tool e sessão</td> \n  </tr> \n  <tr> \n   <td>Codex CLI</td> \n   <td>Parcial/limitada</td> \n   <td>Parte das automações depende de <code>AGENTS.md</code>, <code>/skills</code>, MCP e fluxo operacional</td> \n  </tr> \n  <tr> \n   <td>Cursor</td> \n   <td>Sem lifecycle hooks equivalentes</td> \n   <td>Menor automação de pre/post tool; foco em regras, MCP e fluxo do agente</td> \n  </tr> \n  <tr> \n   <td>GitHub Copilot</td> \n   <td>Sem lifecycle hooks equivalentes</td> \n   <td>Menor automação de sessão/tooling; foco em instruções de repositório + MCP no VS Code</td> \n  </tr> \n  <tr> \n   <td>AntiGravity</td> \n   <td>Workflow-based (não hook-based)</td> \n   <td>Integração por workflows, não por eventos de hook equivalentes ao Claude</td> \n  </tr> \n </tbody> \n</table> \n<p>Impactos e mitigação detalhados: <code>docs/ide-integration.md</code>.</p> \n<h2>Acknowledgments &amp; Attribution</h2> \n<p>Synkra AIOS was originally derived from the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">BMad Method</a>, created by <a href=\"https://github.com/bmadcode\">Brian Madison</a> (BMad Code, LLC). We gratefully acknowledge the BMad Method for providing the foundation from which this project began.</p> \n<p><strong>Important:</strong> This project is <strong>NOT affiliated with, endorsed by, or sanctioned by</strong> the BMad Method or BMad Code, LLC. Contributors appearing in the git history from the original BMad Method repository do not imply active participation in or endorsement of Synkra AIOS.</p> \n<p>Since its origin, AIOS has evolved significantly with its own architecture, terminology, and features (v4.x+), and does not depend on BMad for current operation. The BMad Method remains an excellent framework in its own right — please visit the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">official BMad Method repository</a> to learn more.</p> \n<p>BMad, BMad Method, and BMad Core are trademarks of BMad Code, LLC. See <a href=\"https://github.com/bmad-code-org/BMAD-METHOD/raw/main/TRADEMARK.md\">TRADEMARK.md</a> for usage guidelines.</p> \n<h2>Visão Geral</h2> \n<h3>Premissa Arquitetural: CLI First</h3> \n<p>O Synkra AIOS segue uma hierarquia clara de prioridades:</p> \n<pre><code>CLI First → Observability Second → UI Third\n</code></pre> \n<table> \n <thead> \n  <tr> \n   <th>Camada</th> \n   <th>Prioridade</th> \n   <th>Foco</th> \n   <th>Exemplos</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>CLI</strong></td> \n   <td>Máxima</td> \n   <td>Onde a inteligência vive. Toda execução, decisões e automação acontecem aqui.</td> \n   <td>Agentes (<code>@dev</code>, <code>@qa</code>), workflows, comandos</td> \n  </tr> \n  <tr> \n   <td><strong>Observability</strong></td> \n   <td>Secundária</td> \n   <td>Observar e monitorar o que acontece no CLI em tempo real.</td> \n   <td>Dashboard SSE, logs, métricas, timeline</td> \n  </tr> \n  <tr> \n   <td><strong>UI</strong></td> \n   <td>Terciária</td> \n   <td>Gestão pontual e visualizações quando necessário.</td> \n   <td>Kanban, settings, story management</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Princípios derivados:</strong></p> \n<ul> \n <li>A CLI é a fonte da verdade - dashboards apenas observam</li> \n <li>Funcionalidades novas devem funcionar 100% via CLI antes de ter UI</li> \n <li>A UI nunca deve ser requisito para operação do sistema</li> \n <li>Observabilidade serve para entender o que o CLI está fazendo, não para controlá-lo</li> \n</ul> \n<hr /> \n<p><strong>As Duas Inovações Chave do Synkra AIOS:</strong></p> \n<p><strong>1. Planejamento Agêntico:</strong> Agentes dedicados (analyst, pm, architect) colaboram com você para criar documentos de PRD e Arquitetura detalhados e consistentes. Através de engenharia avançada de prompts e refinamento com human-in-the-loop, estes agentes de planejamento produzem especificações abrangentes que vão muito além da geração genérica de tarefas de IA.</p> \n<p><strong>2. Desenvolvimento Contextualizado por Engenharia:</strong> O agente sm (Scrum Master) então transforma estes planos detalhados em histórias de desenvolvimento hiperdetalhadas que contêm tudo que o agente dev precisa - contexto completo, detalhes de implementação e orientação arquitetural incorporada diretamente nos arquivos de histórias.</p> \n<p>Esta abordagem de duas fases elimina tanto a <strong>inconsistência de planejamento</strong> quanto a <strong>perda de contexto</strong> - os maiores problemas no desenvolvimento assistido por IA. Seu agente dev abre um arquivo de história com compreensão completa do que construir, como construir e por quê.</p> \n<p><strong>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Veja o fluxo de trabalho completo no Guia do Usuário</a></strong> - Fase de planejamento, ciclo de desenvolvimento e todos os papéis dos agentes</p> \n<h2>Pré-requisitos</h2> \n<ul> \n <li>Node.js &gt;=18.0.0 (v20+ recomendado)</li> \n <li>npm &gt;=9.0.0</li> \n <li>GitHub CLI (opcional, necessário para colaboração em equipe)</li> \n</ul> \n<blockquote> \n <p><strong>Problemas de instalação?</strong> Consulte o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/installation-troubleshooting.md\">Guia de Troubleshooting</a></p> \n</blockquote> \n<p><strong>Guias específicos por plataforma:</strong></p> \n<ul> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/macos.md\">Guia de Instalação para macOS</a></li> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/windows.md\">Guia de Instalação para Windows</a></li> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/linux.md\">Guia de Instalação para Linux</a></li> \n</ul> \n<p><strong>Documentação multilíngue disponível:</strong> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/installation/\">Português</a> | <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/es/installation/\">Español</a></p> \n<h2>Navegação Rápida</h2> \n<h3>Entendendo o Fluxo de Trabalho AIOS</h3> \n<p><strong>Antes de mergulhar, revise estes diagramas críticos de fluxo de trabalho que explicam como o AIOS funciona:</strong></p> \n<ol> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md#the-planning-workflow-web-ui\">Fluxo de Planejamento (Interface Web)</a></strong> - Como criar documentos de PRD e Arquitetura</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md#the-core-development-cycle-ide\">Ciclo Principal de Desenvolvimento (IDE)</a></strong> - Como os agentes sm, dev e qa colaboram através de arquivos de histórias</li> \n</ol> \n<blockquote> \n <p>⚠️ <strong>Estes diagramas explicam 90% da confusão sobre o fluxo Synkra AIOS Agentic Agile</strong> - Entender a criação de PRD+Arquitetura e o fluxo de trabalho sm/dev/qa e como os agentes passam notas através de arquivos de histórias é essencial - e também explica por que isto NÃO é taskmaster ou apenas um simples executor de tarefas!</p> \n</blockquote> \n<h3>O que você gostaria de fazer?</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#in%C3%ADcio-r%C3%A1pido\">Instalar e Construir software com Equipe Ágil Full Stack de IA</a></strong> → Instruções de Início Rápido</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Aprender como usar o AIOS</a></strong> → Guia completo do usuário e passo a passo</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#agentes-dispon%C3%ADveis\">Ver agentes IA disponíveis</a></strong> → Papéis especializados para sua equipe</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#-al%C3%A9m-do-desenvolvimento-de-software---squads\">Explorar usos não técnicos</a></strong> → Escrita criativa, negócios, bem-estar, educação</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#criando-seu-pr%C3%B3prio-squad\">Criar meus próprios agentes IA</a></strong> → Construir agentes para seu domínio</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-overview.md\">Navegar Squads prontos</a></strong> → Veja como criar e usar equipes de agentes IA</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ARCHITECTURE-INDEX.md\">Entender a arquitetura</a></strong> → Mergulho técnico profundo</li> \n <li><strong><a href=\"https://github.com/SynkraAI/aios-core/issues\">Reportar problemas</a></strong> → Bug reports e feature requests</li> \n</ul> \n<h2>Importante: Mantenha Sua Instalação AIOS Atualizada</h2> \n<p><strong>Mantenha-se atualizado sem esforço!</strong> Para atualizar sua instalação AIOS existente:</p> \n<pre><code class=\"language-bash\">npx aios-core@latest install\n</code></pre> \n<p>Isto vai:</p> \n<ul> \n <li>✅ Detectar automaticamente sua instalação existente</li> \n <li>✅ Atualizar apenas os arquivos que mudaram</li> \n <li>✅ Criar arquivos de backup <code>.bak</code> para quaisquer modificações customizadas</li> \n <li>✅ Preservar suas configurações específicas do projeto</li> \n</ul> \n<p>Isto facilita beneficiar-se das últimas melhorias, correções de bugs e novos agentes sem perder suas customizações!</p> \n<h2>Início Rápido</h2> \n<h3>🚀 Instalação via NPX (Recomendado)</h3> \n<p><strong>Instale o Synkra AIOS com um único comando:</strong></p> \n<pre><code class=\"language-bash\"># Criar um novo projeto com assistente interativo moderno\nnpx aios-core init meu-projeto\n\n# Ou instalar em projeto existente\ncd seu-projeto\nnpx aios-core install\n\n# Ou usar uma versão específica\nnpx aios-core@latest init meu-projeto\n</code></pre> \n<h3>✨ Assistente de Instalação Moderno</h3> \n<p>O Synkra AIOS agora inclui uma experiência de instalação interativa de última geração, inspirada em ferramentas modernas como Vite e Next.js:</p> \n<p><strong>Recursos do Instalador Interativo:</strong></p> \n<ul> \n <li>🎨 <strong>Interface Moderna</strong>: Prompts coloridos e visuais com @clack/prompts</li> \n <li>✅ <strong>Validação em Tempo Real</strong>: Feedback instantâneo sobre entradas inválidas</li> \n <li>🔄 <strong>Indicadores de Progresso</strong>: Spinners para operações longas (cópia de arquivos, instalação de deps)</li> \n <li>📦 <strong>Seleção Multi-Componente</strong>: Escolha quais componentes instalar com interface intuitiva</li> \n <li>⚙️ <strong>Escolha de Gerenciador de Pacotes</strong>: Selecione entre npm, yarn ou pnpm</li> \n <li>⌨️ <strong>Suporte a Cancelamento</strong>: Ctrl+C ou ESC para sair graciosamente a qualquer momento</li> \n <li>📊 <strong>Resumo de Instalação</strong>: Visualize todas as configurações antes de prosseguir</li> \n <li>⏱️ <strong>Rastreamento de Duração</strong>: Veja quanto tempo levou a instalação</li> \n</ul> \n<p><strong>O instalador oferece:</strong></p> \n<ul> \n <li>✅ Download da versão mais recente do NPM</li> \n <li>✅ Assistente de instalação interativo moderno</li> \n <li>✅ Configuração automática do IDE (Codex CLI, Cursor ou Claude Code)</li> \n <li>✅ Configuração de todos os agentes e fluxos de trabalho AIOS</li> \n <li>✅ Criação dos arquivos de configuração necessários</li> \n <li>✅ Inicialização do sistema de meta-agentes</li> \n <li>✅ Verificações de saúde do sistema</li> \n <li>✅ <strong>Suporte Cross-Platform</strong>: Testado em Windows, macOS e Linux</li> \n</ul> \n<blockquote> \n <p><strong>É isso!</strong> Sem clonar, sem configuração manual - apenas um comando e você está pronto para começar com uma experiência de instalação moderna e profissional.</p> \n</blockquote> \n<p><strong>Pré-requisitos</strong>: <a href=\"https://nodejs.org\">Node.js</a> v18+ necessário (v20+ recomendado) | <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/installation-troubleshooting.md\">Troubleshooting</a></p> \n<h3>Atualizando uma Instalação Existente</h3> \n<p>Se você já tem o AIOS instalado:</p> \n<pre><code class=\"language-bash\">npx aios-core@latest install\n# O instalador detectará sua instalação existente e a atualizará\n</code></pre> \n<h3>Configure Seu IDE para Desenvolvimento AIOS</h3> \n<p>O Synkra AIOS inclui regras pré-configuradas para IDE para melhorar sua experiência de desenvolvimento:</p> \n<h4>Para Cursor:</h4> \n<ol> \n <li>Abra as configurações do Cursor</li> \n <li>Navegue até <strong>User Rules</strong></li> \n <li>Copie o conteúdo de <code>.cursor/global-rules.md</code></li> \n <li>Cole na seção de regras e salve</li> \n</ol> \n<h4>Para Claude Code:</h4> \n<ul> \n <li>✅ Já configurado! O arquivo <code>.claude/CLAUDE.md</code> é carregado automaticamente</li> \n <li>Sync dedicado de agentes: <code>npm run sync:ide:claude</code></li> \n <li>Validacao dedicada: <code>npm run validate:claude-sync &amp;&amp; npm run validate:claude-integration</code></li> \n</ul> \n<h4>Para Codex CLI:</h4> \n<ul> \n <li>✅ Integração de primeira classe no AIOS 4.2 (pipeline de ativação e greeting compartilhado)</li> \n <li>✅ Já configurado! O arquivo <code>AGENTS.md</code> na raiz é carregado automaticamente</li> \n <li>Opcional: sincronize agentes auxiliares com <code>npm run sync:ide:codex</code></li> \n <li>Recomendado neste repositório: gerar e versionar skills locais com <code>npm run sync:skills:codex</code></li> \n <li>Use <code>npm run sync:skills:codex:global</code> apenas fora deste projeto (para evitar duplicidade no <code>/skills</code>)</li> \n <li>Validacao dedicada: <code>npm run validate:codex-sync &amp;&amp; npm run validate:codex-integration</code></li> \n <li>Guardrails de skills/paths: <code>npm run validate:codex-skills &amp;&amp; npm run validate:paths</code></li> \n</ul> \n<h4>Para Gemini CLI:</h4> \n<ul> \n <li>✅ Regras e agentes sincronizaveis com <code>npm run sync:ide:gemini</code></li> \n <li>Arquivos gerados em <code>.gemini/rules.md</code>, <code>.gemini/rules/AIOS/agents/</code> e <code>.gemini/commands/*.toml</code></li> \n <li>✅ Hooks e settings locais no fluxo de instalacao (<code>.gemini/hooks/</code> + <code>.gemini/settings.json</code>)</li> \n <li>✅ Ativacao rapida por slash commands (<code>/aios-menu</code>, <code>/aios-dev</code>, <code>/aios-architect</code>, etc.)</li> \n <li>Validacao dedicada: <code>npm run validate:gemini-sync &amp;&amp; npm run validate:gemini-integration</code></li> \n <li>Paridade multi-IDE em um comando: <code>npm run validate:parity</code></li> \n</ul> \n<p>Estas regras fornecem:</p> \n<ul> \n <li>🤖 Reconhecimento e integração de comandos de agentes</li> \n <li>📋 Fluxo de trabalho de desenvolvimento dirigido por histórias</li> \n <li>✅ Rastreamento automático de checkboxes</li> \n <li>🧪 Padrões de teste e validação</li> \n <li>📝 Padrões de código específicos do AIOS</li> \n</ul> \n<h3>Início Mais Rápido com Interface Web (2 minutos)</h3> \n<ol> \n <li><strong>Instale o AIOS</strong>: Execute <code>npx aios-core init meu-projeto</code></li> \n <li><strong>Configure seu IDE</strong>: Siga as instruções de configuração para Codex CLI, Cursor ou Claude Code</li> \n <li><strong>Comece a Planejar</strong>: Ative um agente como <code>@analyst</code> para começar a criar seu briefing</li> \n <li><strong>Use comandos AIOS</strong>: Digite <code>*help</code> para ver comandos disponíveis</li> \n <li><strong>Siga o fluxo</strong>: Veja o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Guia do usuário</a> para mais detalhes</li> \n</ol> \n<h3>Referência de Comandos CLI</h3> \n<p>O Synkra AIOS oferece uma CLI moderna e cross-platform com comandos intuitivos:</p> \n<pre><code class=\"language-bash\"># Gerenciamento de Projeto (com assistente interativo)\nnpx aios-core init &lt;nome-projeto&gt; [opções]\n  --force              Forçar criação em diretório não vazio\n  --skip-install       Pular instalação de dependências npm\n  --template &lt;nome&gt;    Usar template específico (default, minimal, enterprise)\n\n# Instalação e Configuração (com prompts modernos)\nnpx aios-core install [opções]\n  --force              Sobrescrever configuração existente\n  --quiet              Saída mínima durante instalação\n  --dry-run            Simular instalação sem modificar arquivos\n\n# Comandos do Sistema\nnpx aios-core --version   Exibir versão instalada\nnpx aios-core --help      Exibir ajuda detalhada\nnpx aios-core info        Exibir informações do sistema\nnpx aios-core doctor      Executar diagnósticos do sistema\nnpx aios-core doctor --fix Corrigir problemas detectados automaticamente\n\n# Manutenção\nnpx aios-core update      Atualizar para versão mais recente\nnpx aios-core uninstall   Remover Synkra AIOS\n</code></pre> \n<p><strong>Recursos da CLI:</strong></p> \n<ul> \n <li>✅ <strong>Help System Abrangente</strong>: <code>--help</code> em qualquer comando mostra documentação detalhada</li> \n <li>✅ <strong>Validação de Entrada</strong>: Feedback imediato sobre parâmetros inválidos</li> \n <li>✅ <strong>Mensagens Coloridas</strong>: Erros em vermelho, sucessos em verde, avisos em amarelo</li> \n <li>✅ <strong>Cross-Platform</strong>: Funciona perfeitamente em Windows, macOS e Linux</li> \n <li>✅ <strong>Suporte a Dry-Run</strong>: Teste instalações sem modificar arquivos</li> \n</ul> \n<h3>💡 Exemplos de Uso</h3> \n<h4>Instalação Interativa Completa</h4> \n<pre><code class=\"language-bash\">$ npx aios-core install\n\n🚀 Synkra AIOS Installation\n\n◆ What is your project name?\n│  my-awesome-project\n│\n◇ Which directory should we use?\n│  ./my-awesome-project\n│\n◆ Choose components to install:\n│  ● Core Framework (Required)\n│  ● Agent System (Required)\n│  ● Squads (optional)\n│  ○ Example Projects (optional)\n│\n◇ Select package manager:\n│  ● npm\n│  ○ yarn\n│  ○ pnpm\n│\n◆ Initialize Git repository?\n│  Yes\n│\n◆ Install dependencies?\n│  Yes\n│\n▸ Creating project directory...\n▸ Copying framework files...\n▸ Initializing Git repository...\n▸ Installing dependencies (this may take a minute)...\n▸ Configuring environment...\n▸ Running post-installation setup...\n\n✔ Installation completed successfully! (34.2s)\n\nNext steps:\n  cd my-awesome-project\n  aios-core doctor     # Verify installation\n  aios-core --help     # See available commands\n</code></pre> \n<h4>Instalação Silenciosa (CI/CD)</h4> \n<pre><code class=\"language-bash\"># Instalação automatizada sem prompts\n$ npx aios-core install --quiet --force\n✔ Synkra AIOS installed successfully\n</code></pre> \n<h4>Simulação de Instalação (Dry-Run)</h4> \n<pre><code class=\"language-bash\"># Testar instalação sem modificar arquivos\n$ npx aios-core install --dry-run\n\n[DRY RUN] Would create: ./my-project/\n[DRY RUN] Would copy: .aios-core/ (45 files)\n[DRY RUN] Would initialize: Git repository\n[DRY RUN] Would install: npm dependencies\n✔ Dry run completed - no files were modified\n</code></pre> \n<h4>Diagnóstico do Sistema</h4> \n<pre><code class=\"language-bash\">$ npx aios-core doctor\n\n🏥 AIOS System Diagnostics\n\n✔ Node.js version: v20.10.0 (meets requirement: &gt;=18.0.0)\n✔ npm version: 10.2.3\n✔ Git installed: version 2.43.0\n✔ GitHub CLI: gh 2.40.1\n✔ Synkra AIOS: v4.2.11\n\nConfiguration:\n✔ .aios-core/ directory exists\n✔ Agent files: 11 found\n✔ Workflow files: 8 found\n✔ Templates: 15 found\n\nDependencies:\n✔ @clack/prompts: ^0.7.0\n✔ commander: ^12.0.0\n✔ execa: ^9.0.0\n✔ fs-extra: ^11.0.0\n✔ picocolors: ^1.0.0\n\n✅ All checks passed! Your installation is healthy.\n</code></pre> \n<h4>Obter Ajuda</h4> \n<pre><code class=\"language-bash\">$ npx aios-core --help\n\nUsage: aios-core [options] [command]\n\nSynkra AIOS: AI-Orchestrated System for Full Stack Development\n\nOptions:\n  -V, --version                output the version number\n  -h, --help                   display help for command\n\nCommands:\n  init &lt;project-name&gt;          Create new AIOS project with interactive wizard\n  install [options]            Install AIOS in current directory\n  info                         Display system information\n  doctor [options]             Run system diagnostics and health checks\n  help [command]               display help for command\n\nRun 'aios-core &lt;command&gt; --help' for detailed information about each command.\n</code></pre> \n<h3>Alternativa: Clonar e Construir</h3> \n<p>Para contribuidores ou usuários avançados que queiram modificar o código fonte:</p> \n<pre><code class=\"language-bash\"># Clonar o repositório\ngit clone https://github.com/SynkraAI/aios-core.git\ncd aios-core\n\n# Instalar dependências\nnpm install\n\n# Executar o instalador\nnpm run install:aios\n</code></pre> \n<h3>Configuração Rápida para Equipe</h3> \n<p>Para membros da equipe ingressando no projeto:</p> \n<pre><code class=\"language-bash\"># Instalar AIOS no projeto\nnpx aios-core@latest install\n\n# Isto vai:\n# 1. Detectar instalação existente (se houver)\n# 2. Instalar/atualizar framework AIOS\n# 3. Configurar agentes e workflows\n</code></pre> \n<h2>🌟 Além do Desenvolvimento de Software - Squads</h2> \n<p>O framework de linguagem natural do AIOS funciona em QUALQUER domínio. Os Squads fornecem agentes IA especializados para escrita criativa, estratégia de negócios, saúde e bem-estar, educação e muito mais. Além disso, os Squads podem expandir o núcleo do Synkra AIOS com funcionalidade específica que não é genérica para todos os casos. <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Veja o Guia de Squads</a> e aprenda a criar os seus próprios!</p> \n<h2>Agentes Disponíveis</h2> \n<p>O Synkra AIOS vem com 11 agentes especializados:</p> \n<h3>Agentes Meta</h3> \n<ul> \n <li><strong>aios-master</strong> - Agente mestre de orquestração (inclui capacidades de desenvolvimento de framework)</li> \n <li><strong>aios-orchestrator</strong> - Orquestrador de fluxo de trabalho e coordenação de equipe</li> \n</ul> \n<h3>Agentes de Planejamento (Interface Web)</h3> \n<ul> \n <li><strong>analyst</strong> - Especialista em análise de negócios e criação de PRD</li> \n <li><strong>pm</strong> (Product Manager) - Gerente de produto e priorização</li> \n <li><strong>architect</strong> - Arquiteto de sistema e design técnico</li> \n <li><strong>ux-expert</strong> - Design de experiência do usuário e usabilidade</li> \n</ul> \n<h3>Agentes de Desenvolvimento (IDE)</h3> \n<ul> \n <li><strong>sm</strong> (Scrum Master) - Gerenciamento de sprint e criação de histórias</li> \n <li><strong>dev</strong> - Desenvolvedor e implementação</li> \n <li><strong>qa</strong> - Garantia de qualidade e testes</li> \n <li><strong>po</strong> (Product Owner) - Gerenciamento de backlog e histórias</li> \n</ul> \n<h2>Documentação e Recursos</h2> \n<h3>Guias Essenciais</h3> \n<ul> \n <li>📖 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Guia do Usuário</a></strong> - Passo a passo completo desde a concepção até a conclusão do projeto</li> \n <li>🏗️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/AIOS-VISUAL-OVERVIEW.md\">Arquitetura Principal</a></strong> - Mergulho técnico profundo e design do sistema</li> \n <li>🚀 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a></strong> - Estenda o AIOS para qualquer domínio além do desenvolvimento de software</li> \n</ul> \n<h3>Documentação Adicional</h3> \n<ul> \n <li>🤖 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a></strong> - Crie e publique equipes de agentes IA</li> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/getting-started.md\">Primeiros Passos</a></strong> - Tutorial passo a passo para iniciantes</li> \n <li>🔧 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/troubleshooting.md\">Solução de Problemas</a></strong> - Soluções para problemas comuns</li> \n <li>🎯 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/GUIDING-PRINCIPLES.md\">Princípios Orientadores</a></strong> - Filosofia e melhores práticas do AIOS</li> \n <li>🏛️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/AIOS-VISUAL-OVERVIEW.md\">Visão Geral da Arquitetura</a></strong> - Visão detalhada da arquitetura do sistema</li> \n <li>⚙️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/performance-tuning-guide.md\">Guia de Ajuste de Performance</a></strong> - Otimize seu fluxo de trabalho AIOS</li> \n <li>🔒 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/security-best-practices.md\">Melhores Práticas de Segurança</a></strong> - Segurança e proteção de dados</li> \n <li>🔄 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/migration-guide.md\">Guia de Migração</a></strong> - Migração de versões anteriores</li> \n <li>📦 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/versioning-and-releases.md\">Versionamento e Releases</a></strong> - Política de versões</li> \n</ul> \n<h2>🤖 AIOS Autonomous Development Engine (ADE)</h2> \n<p>O Synkra AIOS introduz o <strong>Autonomous Development Engine (ADE)</strong> - um sistema completo para desenvolvimento autônomo que transforma requisitos em código funcional.</p> \n<h3>🎯 O Que é o ADE?</h3> \n<p>O ADE é um conjunto de <strong>7 Epics</strong> que habilitam execução autônoma de desenvolvimento:</p> \n<table> \n <thead> \n  <tr> \n   <th>Epic</th> \n   <th>Nome</th> \n   <th>Descrição</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>1</strong></td> \n   <td>Worktree Manager</td> \n   <td>Isolamento de branches via Git worktrees</td> \n  </tr> \n  <tr> \n   <td><strong>2</strong></td> \n   <td>Migration V2→V3</td> \n   <td>Migração para formato autoClaude V3</td> \n  </tr> \n  <tr> \n   <td><strong>3</strong></td> \n   <td>Spec Pipeline</td> \n   <td>Transforma requisitos em specs executáveis</td> \n  </tr> \n  <tr> \n   <td><strong>4</strong></td> \n   <td>Execution Engine</td> \n   <td>Executa specs com 13 steps + self-critique</td> \n  </tr> \n  <tr> \n   <td><strong>5</strong></td> \n   <td>Recovery System</td> \n   <td>Recuperação automática de falhas</td> \n  </tr> \n  <tr> \n   <td><strong>6</strong></td> \n   <td>QA Evolution</td> \n   <td>Review estruturado em 10 fases</td> \n  </tr> \n  <tr> \n   <td><strong>7</strong></td> \n   <td>Memory Layer</td> \n   <td>Memória persistente de padrões e insights</td> \n  </tr> \n </tbody> \n</table> \n<h3>🔄 Fluxo Principal</h3> \n<pre><code>User Request → Spec Pipeline → Execution Engine → QA Review → Working Code\n                                      ↓\n                              Recovery System\n                                      ↓\n                               Memory Layer\n</code></pre> \n<h3>⚡ Quick Start ADE</h3> \n<pre><code class=\"language-bash\"># 1. Criar spec a partir de requisito\n@pm *gather-requirements\n@architect *assess-complexity\n@analyst *research-deps\n@pm *write-spec\n@qa *critique-spec\n\n# 2. Executar spec aprovada\n@architect *create-plan\n@architect *create-context\n@dev *execute-subtask 1.1\n\n# 3. QA Review\n@qa *review-build STORY-42\n</code></pre> \n<h3>📖 Documentação ADE</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/ade-guide.md\">Guia Completo do ADE</a></strong> - Tutorial passo a passo</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-AGENT-CHANGES.md\">Alterações nos Agentes</a></strong> - Comandos e capabilities por agente</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC1-HANDOFF.md\">Epic 1 - Worktree Manager</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC2-HANDOFF.md\">Epic 2 - Migration V2→V3</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC3-HANDOFF.md\">Epic 3 - Spec Pipeline</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC4-HANDOFF.md\">Epic 4 - Execution Engine</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC5-HANDOFF.md\">Epic 5 - Recovery System</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC6-HANDOFF.md\">Epic 6 - QA Evolution</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC7-HANDOFF.md\">Epic 7 - Memory Layer</a></strong></li> \n</ul> \n<h3>🆕 Novos Comandos por Agente</h3> \n<p><strong>@devops:</strong></p> \n<ul> \n <li><code>*create-worktree</code>, <code>*list-worktrees</code>, <code>*merge-worktree</code>, <code>*cleanup-worktrees</code></li> \n <li><code>*inventory-assets</code>, <code>*analyze-paths</code>, <code>*migrate-agent</code>, <code>*migrate-batch</code></li> \n</ul> \n<p><strong>@pm:</strong></p> \n<ul> \n <li><code>*gather-requirements</code>, <code>*write-spec</code></li> \n</ul> \n<p><strong>@architect:</strong></p> \n<ul> \n <li><code>*assess-complexity</code>, <code>*create-plan</code>, <code>*create-context</code>, <code>*map-codebase</code></li> \n</ul> \n<p><strong>@analyst:</strong></p> \n<ul> \n <li><code>*research-deps</code>, <code>*extract-patterns</code></li> \n</ul> \n<p><strong>@qa:</strong></p> \n<ul> \n <li><code>*critique-spec</code>, <code>*review-build</code>, <code>*request-fix</code>, <code>*verify-fix</code></li> \n</ul> \n<p><strong>@dev:</strong></p> \n<ul> \n <li><code>*execute-subtask</code>, <code>*track-attempt</code>, <code>*rollback</code>, <code>*capture-insights</code>, <code>*list-gotchas</code>, <code>*apply-qa-fix</code></li> \n</ul> \n<h2>Criando Seu Próprio Squad</h2> \n<p>Squads permitem estender o AIOS para qualquer domínio. Estrutura básica:</p> \n<pre><code>squads/seu-squad/\n├── config.yaml           # Configuração do squad\n├── agents/              # Agentes especializados\n├── tasks/               # Fluxos de trabalho de tarefas\n├── templates/           # Templates de documentos\n├── checklists/          # Checklists de validação\n├── data/                # Base de conhecimento\n├── README.md            # Documentação do squad\n└── user-guide.md        # Guia do usuário\n</code></pre> \n<p>Veja o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a> para instruções detalhadas.</p> \n<h2>Squads Disponíveis</h2> \n<p>Squads são equipes modulares de agentes IA. Veja a <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-overview.md\">Visão Geral de Squads</a> para mais informações.</p> \n<h3>Squads Externos</h3> \n<ul> \n <li><strong><a href=\"https://github.com/SynkraAI/aios-hybrid-ops-pedro-valerio\">hybrid-ops</a></strong> - Operações híbridas humano-agente (repositório separado)</li> \n</ul> \n<h2>AIOS Pro</h2> \n<p>O <strong>AIOS Pro</strong> (<code>@aios-fullstack/pro</code>) é o módulo premium do Synkra AIOS, oferecendo funcionalidades avançadas para equipes e projetos de maior escala.</p> \n<blockquote> \n <p><strong>Disponibilidade restrita:</strong> O AIOS Pro está disponível exclusivamente para membros do <strong>AIOS Cohort Advanced</strong>. <a href=\"https://synkra.ai\">Saiba mais sobre o programa</a>.</p> \n</blockquote> \n<h3>Instalação</h3> \n<pre><code class=\"language-bash\">npm install @aios-fullstack/pro\n</code></pre> \n<h3>Features Premium</h3> \n<ul> \n <li><strong>Squads Avançados</strong> - Squads especializados com capacidades expandidas</li> \n <li><strong>Memory Layer</strong> - Memória persistente de padrões e insights entre sessões</li> \n <li><strong>Métricas &amp; Analytics</strong> - Dashboard de produtividade e métricas de desenvolvimento</li> \n <li><strong>Integrações Enterprise</strong> - Conectores para Jira, Linear, Notion e mais</li> \n <li><strong>Configuração em Camadas</strong> - Sistema de configuração L1-L4 com herança</li> \n <li><strong>Licenciamento</strong> - Gerenciamento de licença via <code>aios pro activate --key &lt;KEY&gt;</code></li> \n</ul> \n<p>Para mais informações, execute <code>npx aios-core pro --help</code> após a instalação.</p> \n<h2>Suporte</h2> \n<ul> \n <li>🐛 <a href=\"https://github.com/SynkraAI/aios-core/issues\">Rastreador de Issues</a> - Bug reports e feature requests</li> \n <li>💡 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/FEATURE_PROCESS.md\">Processo de Features</a> - Como propor novas funcionalidades</li> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">Como Contribuir</a></li> \n <li>🗺️ <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/roadmap.md\">Roadmap</a> - Veja o que estamos construindo</li> \n <li>🤖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a> - Crie equipes de agentes IA</li> \n</ul> \n<h2>Git Workflow e Validação</h2> \n<p>O Synkra AIOS implementa um sistema de validação de múltiplas camadas para garantir qualidade do código e consistência:</p> \n<h3>🛡️ Defense in Depth - 3 Camadas de Validação</h3> \n<p><strong>Camada 1: Pre-commit (Local - Rápida)</strong></p> \n<ul> \n <li>✅ ESLint - Qualidade de código</li> \n <li>✅ TypeScript - Verificação de tipos</li> \n <li>⚡ Performance: &lt;5s</li> \n <li>💾 Cache habilitado</li> \n</ul> \n<p><strong>Camada 2: Pre-push (Local - Validação de Stories)</strong></p> \n<ul> \n <li>✅ Validação de checkboxes de histórias</li> \n <li>✅ Consistência de status</li> \n <li>✅ Seções obrigatórias</li> \n</ul> \n<p><strong>Camada 3: CI/CD (Cloud - Obrigatório para merge)</strong></p> \n<ul> \n <li>✅ Todos os testes</li> \n <li>✅ Cobertura de testes (80% mínimo)</li> \n <li>✅ Validações completas</li> \n <li>✅ GitHub Actions</li> \n</ul> \n<h3>📖 Documentação Detalhada</h3> \n<ul> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/git-workflow-guide.md\">Guia Completo de Git Workflow</a></strong> - Guia detalhado do fluxo de trabalho</li> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">CONTRIBUTING.md</a></strong> - Guia de contribuição</li> \n</ul> \n<h3>Comandos Disponíveis</h3> \n<pre><code class=\"language-bash\"># Validações locais\nnpm run lint           # ESLint\nnpm run typecheck      # TypeScript\nnpm test              # Testes\nnpm run test:coverage # Testes com cobertura\n\n# Validador AIOS\nnode .aios-core/utils/aios-validator.js pre-commit   # Validação pre-commit\nnode .aios-core/utils/aios-validator.js pre-push     # Validação pre-push\nnode .aios-core/utils/aios-validator.js stories      # Validar todas stories\n</code></pre> \n<h3>Branch Protection</h3> \n<p>Configure proteção da branch master com:</p> \n<pre><code class=\"language-bash\">node scripts/setup-branch-protection.js\n</code></pre> \n<p>Requer:</p> \n<ul> \n <li>GitHub CLI (gh) instalado e autenticado</li> \n <li>Acesso de admin ao repositório</li> \n</ul> \n<h2>Contribuindo</h2> \n<p><strong>Estamos empolgados com contribuições e acolhemos suas ideias, melhorias e Squads!</strong> 🎉</p> \n<p>Para contribuir:</p> \n<ol> \n <li>Fork o repositório</li> \n <li>Crie uma branch para sua feature (<code>git checkout -b feature/MinhaNovaFeature</code>)</li> \n <li>Commit suas mudanças (<code>git commit -m 'feat: Adicionar nova feature'</code>)</li> \n <li>Push para a branch (<code>git push origin feature/MinhaNovaFeature</code>)</li> \n <li>Abra um Pull Request</li> \n</ol> \n<p>Veja também:</p> \n<ul> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/how-to-contribute-with-pull-requests.md\">Como Contribuir com Pull Requests</a></li> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/git-workflow-guide.md\">Guia de Git Workflow</a></li> \n</ul> \n<h2>📄 Legal</h2> \n<table> \n <thead> \n  <tr> \n   <th>Documento</th> \n   <th>English</th> \n   <th>Português</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Licença</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\">MIT License</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Modelo de Licença</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/license-clarification.md\">Core vs Pro</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Privacidade</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/privacy.md\">Privacy Policy</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Termos de Uso</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/terms.md\">Terms of Use</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Código de Conduta</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CODE_OF_CONDUCT.md\">Code of Conduct</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/code-of-conduct.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Contribuição</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">Contributing</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/contributing.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Segurança</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/security.md\">Security</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/security.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Comunidade</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/community.md\">Community</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/community.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Roadmap</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/roadmap.md\">Roadmap</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/roadmap.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Changelog</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CHANGELOG.md\">Version History</a></td> \n   <td>-</td> \n  </tr> \n </tbody> \n</table> \n<h2>Reconhecimentos</h2> \n<p>This project was originally derived from the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">BMad Method</a> by <a href=\"https://github.com/bmadcode\">Brian Madison</a>. We thank Brian and all BMad Method contributors for the original work that made this project possible.</p> \n<p><strong>Note:</strong> Some contributors shown in the GitHub contributors graph are inherited from the original BMad Method git history and do not represent active participation in or endorsement of Synkra AIOS.</p> \n<p><a href=\"https://github.com/SynkraAI/aios-core/graphs/contributors\"><img alt=\"Contributors\" src=\"https://contrib.rocks/image?repo=SynkraAI/aios-core\" /></a></p> \n<p><sub>Construído com ❤️ para a comunidade de desenvolvimento assistido por IA</sub></p> \n<hr /> \n<p><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#synkra-aios-framework-universal-de-agentes-ia-\">⬆ Voltar ao topo</a></strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:11.022692Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 5
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 8.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/amy_vereda_ai/how-many-direct-reports-should-an-engineering-manager-have-39la",
        "title": "How Many Direct Reports Should an Engineering Manager Have?",
        "summary": "<p><em>The research says 5-9. Reality is messier.</em></p>\n\n\n\n\n<p>Every engineering manager eventually asks this question: <strong>how many people should I actually manage?</strong></p>\n\n<p>The answer matters more than most people think. Too few reports and you're a glorified tech lead. Too many and you're a meeting machine who can't give anyone meaningful attention.</p>\n\n<h2>\n  \n  \n  What the Research Says\n</h2>\n\n<p>The most-cited number comes from management research going back decades: <strong>7 ± 2 direct reports</strong> is the sweet spot.</p>\n\n<p>Here's why that range exists:</p>\n\n<ul>\n<li>\n<strong>Below 5 reports</strong>: You're probably not fully utilized as a manager. Companies will either add IC work to your plate (making you a player-coach, which has its own problems) or question whether the role needs to exist.</li>\n<li>\n<strong>5-7 reports</strong>: The goldilocks zone. Enough people to justify a full-time management role, few enough that you can have meaningful weekly 1:1s, give real feedback, and actually know what each person is working on.</li>\n<li>\n<strong>8-9 reports</strong>: Manageable if your team is senior and autonomous. You'll need to be disciplined about where you spend your time.</li>\n<li>\n<strong>10+ reports</strong>: You're in survival mode. 1:1s become biweekly or superficial. You miss signals — burnout, disengagement, blockers that fester.</li>\n</ul>\n\n<h2>\n  \n  \n  The Variables Nobody Talks About\n</h2>\n\n<p>That 7±2 number assumes a lot. In practice, your capacity depends on:</p>\n\n<h3>\n  \n  \n  Team seniority\n</h3>\n\n<p>A team of senior engineers who are self-directed and experienced needs less management overhead than a team with multiple junior developers who need mentoring, code review guidance, and career coaching.</p>\n\n<h3>\n  \n  \n  How much IC work you're doing\n</h3>\n\n<p>If you're still writing code 40% of the time (common at startups), you effectively have half the management capacity. A player-coach managing 7 people is really managing 7 people with 3 people's worth of attention.</p>\n\n<h3>\n  \n  \n  Organizational complexity\n</h3>\n\n<p>Cross-team dependencies, stakeholder management, hiring — these all eat into your people-management bandwidth. If you're spending 30% of your week in cross-functional meetings, your effective span of control shrinks.</p>\n\n<h3>\n  \n  \n  Whether your team has an EM or tech lead split\n</h3>\n\n<p>Some orgs split people management (EM) from technical leadership (tech lead or staff engineer). If you have a strong tech lead handling architecture decisions and technical mentoring, you can manage more people.</p>\n\n<h2>\n  \n  \n  What Actually Happens at Scale\n</h2>\n\n<p>Here's what I've observed at companies of different sizes:</p>\n\n<ul>\n<li>\n<strong>Startups (&lt; 50 eng)</strong>: Managers often have 4-6 reports but are also player-coaches. Effective span is more like 3-4.</li>\n<li>\n<strong>Growth stage (50-200 eng)</strong>: This is where span problems hit hardest. Rapid hiring means managers suddenly go from 5 to 10+ reports. This is the #1 cause of manager burnout I've seen.</li>\n<li>\n<strong>Enterprise (200+ eng)</strong>: Usually better about maintaining 5-8 report ratios, but org complexity adds hidden overhead.</li>\n</ul>\n\n<h2>\n  \n  \n  The Real Question: Can You Give Each Person What They Need?\n</h2>\n\n<p>Instead of obsessing over a number, ask yourself:</p>\n\n<ol>\n<li>\n<strong>Can I have a meaningful 1:1 with each report every week?</strong> Not a status update — a real conversation about their work, growth, and blockers.</li>\n<li>\n<strong>Would I notice if someone was burning out?</strong> If you don't have enough signal from your team to catch this early, you have too many reports.</li>\n<li>\n<strong>Can I write a thoughtful performance review for each person?</strong> If you're copy-pasting generic feedback, you're spread too thin.</li>\n<li>\n<strong>Do I know what each person wants to do next in their career?</strong> Not their job title aspiration — their actual growth areas and interests.</li>\n</ol>\n\n<p>If you answered \"no\" to any of these, you either have too many reports or you need better systems to stay informed.</p>\n\n<h2>\n  \n  \n  Building Systems That Scale\n</h2>\n\n<p>The managers I've seen handle larger teams well all have one thing in common: <strong>they build systems instead of relying on memory and heroics.</strong></p>\n\n<p>A few that help:</p>\n\n<ul>\n<li>\n<strong>Async standups</strong> instead of daily meetings. You get signal without burning calendar time. Tools like <a href=\"https://www.vereda.ai/free-slack-standup-bot\" rel=\"noopener noreferrer\">Vereda</a> run these in Slack and use AI to surface patterns — blockers that keep recurring, people who seem stuck, workload imbalances.</li>\n<li>\n<strong>Structured 1:1 docs</strong> that carry forward context week to week. If you're starting every 1:1 with \"so what's going on?\" you're wasting the first 10 minutes rebuilding context.</li>\n<li>\n<strong>Lightweight team health metrics</strong>. Not surveillance — just enough signal to know where to focus your attention. Are standups getting shorter (possible disengagement)? Is one person always blocked on the same dependency?</li>\n</ul>\n\n<h2>\n  \n  \n  The Bottom Line\n</h2>\n\n<p><strong>5-7 is the sweet spot for most engineering managers.</strong> Go above 9 and you're making tradeoffs you probably shouldn't. Go below 4 and make sure you're adding enough value to justify a dedicated management role.</p>\n\n<p>But the number is less important than the quality of attention you give each person. A great manager with 8 reports and good systems will outperform a mediocre manager with 5.</p>\n\n\n\n\n<p><em>I'm building <a href=\"https://www.vereda.ai\" rel=\"noopener noreferrer\">Vereda</a> — a free Slack standup bot with AI analytics for engineering teams. It helps managers stay informed without adding meetings, especially as teams grow. If managing a growing team is something you're dealing with, <a href=\"https://www.vereda.ai\" rel=\"noopener noreferrer\">check it out</a>.</em></p>",
        "source": "dev.to",
        "published": "Sun, 22 Feb 2026 23:09:01 +0000",
        "fetched_at": "2026-02-22T23:21:15.307329Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 2,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/nedcodes/everything-i-learned-about-cursorrules-after-mass-testing-them-for-2-months-31km",
        "title": "Everything I've learned so far about .cursorrules after mass testing them",
        "summary": "<p>I've been running experiments on Cursor's rule system for a while now. I started because my rules weren't working and I couldn't figure out why, and I ended up going way deeper than I planned.</p>\n\n<p>So if you're still using a <code>.cursorrules</code> file in your project root, it works, but it's the old way. Cursor moved to <code>.cursor/rules/*.mdc</code> files a while back. The .mdc format lets you scope rules to specific file types, set metadata in frontmatter, and organize rules into separate files instead of one giant blob. I tested both. If you have a <code>.cursorrules</code> AND <code>.mdc</code> files, the .mdc files win. The old file still loads in a clean directory with nothing else, but once you have the new format, that's what Cursor uses.</p>\n\n<p>Migrating takes maybe 10 minutes. I split my monolithic <code>.cursorrules</code> into separate <code>.mdc</code> files by concern. One for TypeScript conventions, one for testing patterns, whatever.</p>\n\n<h2>\n  \n  \n  alwaysApply: true or nothing\n</h2>\n\n<p>This one cost me WAY too much time...</p>\n\n<p>Every <code>.mdc</code> file has YAML frontmatter at the top. There's a field called <code>alwaysApply</code> and if you don't set it to <code>true</code>, your rule just doesn't fire. I tested this 13 times because I was convinced something else was wrong. Nope. Without the flag? It got ignored. Every time. With it? It worked every time.</p>\n\n<p>Your frontmatter needs to look like this:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight yaml\"><code><span class=\"nn\">---</span>\n<span class=\"na\">description</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">TypeScript</span><span class=\"nv\"> </span><span class=\"s\">conventions</span><span class=\"nv\"> </span><span class=\"s\">for</span><span class=\"nv\"> </span><span class=\"s\">this</span><span class=\"nv\"> </span><span class=\"s\">project\"</span>\n<span class=\"na\">globs</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">**/*.ts\"</span>\n<span class=\"na\">alwaysApply</span><span class=\"pi\">:</span> <span class=\"kc\">true</span>\n<span class=\"nn\">---</span>\n</code></pre>\n\n</div>\n\n\n\n<p>Without that last line, Cursor acts like the rule doesn't exist.</p>\n\n<h2>\n  \n  \n  Be specific or get ignored\n</h2>\n\n<p>I tested vague rules vs specific ones at different lengths. Length doesn't matter AT ALL.</p>\n\n<p>\"Write clean, maintainable code.\" Longer version? Nah. Shorter version? Nah. Doesn't matter how many paragraphs you write elaborating on it. Your 'clean and maintainable' means the most generic of the generic.</p>\n\n<p>\"Use early returns instead of nested if blocks.\" That one it followed consistently, even as a single line.</p>\n\n<p>Cursor isn't reading between the lines. It's not going to interpret \"clean code\" (or anything else) the way you mean it. You have to spell out exactly what you want unless what you want is...a universal standard, I guess.</p>\n\n<h2>\n  \n  \n  Conflicting rules will stall the agent\n</h2>\n\n<p>I had two rules in separate <code>.mdc</code> files. One said \"always add explicit type annotations.\" The other said \"infer types when obvious.\" I didn't think this would be a big deal, I thought it could pick out the difference in context and use the right one when appropriate.</p>\n\n<p>Cursor couldn't resolve the contradiction. The agent just sat there. It didn't error, it didn't pick one, it didn't try to merge them. Just... nothing. I thought it was a performance issue before I even thought to check if my rules were fighting each other. We just expect this stuff to work and in reality its brain can break as easily as ours when we're frustrated.</p>\n\n<h2>\n  \n  \n  \"Clean up this code\" will delete your comments\n</h2>\n\n<p>This one STILL bothers me. I ran \"clean up this code\" on 17 different files. Every single comment got stripped. It didn't matter if the comment explained a browser workaround, a compliance requirement, a deprecation timeline. Cursor treated them all as noise.</p>\n\n<p>Zero files kept their comments.</p>\n\n<p>I added a rule that says \"preserve all existing comments unless they contain TODO, FIXME, or are clearly outdated\" and ran it again. Even then it only kept maybe half of them. Cursor seems to have a strong bias toward \"clean = fewer comments\" and you have to actively fight it.</p>\n\n<p>I wrote a whole post about this one because I can see a lot of people not catching it in diffs.</p>\n\n<h2>\n  \n  \n  Your frontmatter is probably broken\n</h2>\n\n<p>This is what finally pushed me to build something. Malformed YAML in your <code>.mdc</code> frontmatter fails completely silently. Missing colon, bad indentation, unclosed quote. No error, no warning. The rule just doesn't exist as far as Cursor is concerned.</p>\n\n<p>I had rules that looked fine but weren't doing anything, and the reason was a missing colon in the frontmatter. It wasn't a logic problem or a wording problem. It was a typo.</p>\n\n<p>So I built <a href=\"https://github.com/nedcodes-ok/cursor-lint\" rel=\"noopener noreferrer\">cursor-lint</a> to catch this stuff. I just run it as a pre-commit hook now so I don't waste another afternoon wondering why a rule isn't firing. It checks frontmatter, validates required fields, flags conflicts between rules.</p>\n\n<h2>\n  \n  \n  Rules vs skills\n</h2>\n\n<p>Cursor added \"agent skills\" (<code>.cursor/skills/*.md</code>) recently. I tested both on the same tasks and they both work.</p>\n\n<p>The difference: rules with <code>alwaysApply: true</code> load on EVERY task, even unrelated ones. You have a TypeScript formatting rule and you ask Cursor to write a Python script? That TS rule still loads and can confuse things. Skills only load when the task is relevant.</p>\n\n<p>Oh and one weird thing. <code>.claude/skills/</code> files from Claude Code don't get discovered by Cursor's agent at all. Skills have to be in <code>.cursor/skills/</code>.</p>\n\n<h2>\n  \n  \n  Model choice doesn't matter for rule compliance\n</h2>\n\n<p>I expected at least one model to be worse at following instructions but nope. I tested the same rules across Sonnet 4.5, Gemini 3 Flash, and GPT-5.1 Codex Mini. All three followed the rules at the same rate. Compliance is about rule quality, not model selection.</p>\n\n<h2>\n  \n  \n  Negative vs positive framing doesn't matter either\n</h2>\n\n<p>\"Do NOT use nested ternaries\" vs \"Use if/else blocks instead of nested ternaries.\" I ran 30 tests on this. No difference. 30/30 compliance both ways.</p>\n\n<p>Write rules however feels natural to you. The framing doesn't matter, that's something that mattered for AIs a few years ago but not now.</p>\n\n<h2>\n  \n  \n  What I use now\n</h2>\n\n<p>I have about 8 <code>.mdc</code> files in most projects. TypeScript conventions, comment preservation, testing patterns, a few framework-specific ones. Each file is short and specific. I run cursor-lint as a pre-commit hook and in CI through the <a href=\"https://github.com/nedcodes-ok/cursor-lint-action\" rel=\"noopener noreferrer\">GitHub Action</a>.</p>\n\n<p>The whole setup takes maybe 15 minutes for a new project and it saves me from the stuff I spent weeks debugging when I didn't know any of this.</p>\n\n<p>If you want experiment results when I run them, I have a <a href=\"https://buttondown.com/nedcodes\" rel=\"noopener noreferrer\">newsletter</a> that goes out when I have findings. I don't have a schedule, but I try to keep it educational and non salesy.</p>",
        "source": "dev.to",
        "published": "Sun, 22 Feb 2026 22:34:02 +0000",
        "fetched_at": "2026-02-22T23:21:15.307388Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 21,
        "timeliness_score": 2,
        "final_score": 7.7,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/summarize",
        "title": "steipete/summarize",
        "summary": "<p>Point at any URL/YouTube/Podcast or file. Get the gist. CLI and Chrome Extension.</p><hr /><h1>Summarize 📝 — Chrome Side Panel + CLI</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=Summarize%F0%9F%93%9D&amp;subheader=Chrome+Side+Panel+%2B+CLI&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast summaries from URLs, files, and media. Works in the terminal, a Chrome Side Panel and Firefox Sidebar.</p> \n<p><strong>0.11.0 preview (unreleased):</strong> this README reflects the upcoming release.</p> \n<h2>0.11.0 preview highlights (most interesting first)</h2> \n<ul> \n <li>Chrome Side Panel <strong>chat</strong> (streaming agent + history) inside the sidebar.</li> \n <li><strong>YouTube slides</strong>: screenshots + OCR + transcript cards, timestamped seek, OCR/Transcript toggle.</li> \n <li>Media-aware summaries: auto‑detect video/audio vs page content.</li> \n <li>Streaming Markdown + metrics + cache‑aware status.</li> \n <li>CLI supports URLs, files, podcasts, YouTube, audio/video, PDFs.</li> \n</ul> \n<h2>Feature overview</h2> \n<ul> \n <li>URLs, files, and media: web pages, PDFs, images, audio/video, YouTube, podcasts, RSS.</li> \n <li>Slide extraction for video sources (YouTube/direct media) with OCR + timestamped cards.</li> \n <li>Transcript-first media flow: published transcripts when available, Whisper fallback when not.</li> \n <li>Streaming output with Markdown rendering, metrics, and cache-aware status.</li> \n <li>Local, paid, and free models: OpenAI‑compatible local endpoints, paid providers, plus an OpenRouter free preset.</li> \n <li>Output modes: Markdown/text, JSON diagnostics, extract-only, metrics, timing, and cost estimates.</li> \n <li>Smart default: if content is shorter than the requested length, we return it as-is (use <code>--force-summary</code> to override).</li> \n</ul> \n<h2>Get the extension (recommended)</h2> \n<p><img alt=\"Summarize extension screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-extension.png\" /></p> \n<p>One‑click summarizer for the current tab. Chrome Side Panel + Firefox Sidebar + local daemon for streaming Markdown.</p> \n<p><strong>Chrome Web Store:</strong> <a href=\"https://chromewebstore.google.com/detail/summarize/cejgnmmhbbpdmjnfppjdfkocebngehfg\">Summarize Side Panel</a></p> \n<p>YouTube slide screenshots (from the browser):</p> \n<p><img alt=\"Summarize YouTube slide screenshots\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/youtube-slides.png\" /></p> \n<h3>Beginner quickstart (extension)</h3> \n<ol> \n <li>Install the CLI (choose one): \n  <ul> \n   <li><strong>npm</strong> (cross‑platform): <code>npm i -g @steipete/summarize</code></li> \n   <li><strong>Homebrew</strong> (macOS arm64): <code>brew install steipete/tap/summarize</code></li> \n  </ul> </li> \n <li>Install the extension (Chrome Web Store link above) and open the Side Panel.</li> \n <li>The panel shows a token + install command. Run it in Terminal: \n  <ul> \n   <li><code>summarize daemon install --token &lt;TOKEN&gt;</code></li> \n  </ul> </li> \n</ol> \n<p>Why a daemon/service?</p> \n<ul> \n <li>The extension can’t run heavy extraction inside the browser. It talks to a local background service on <code>127.0.0.1</code> for fast streaming and media tools (yt‑dlp, ffmpeg, OCR, transcription).</li> \n <li>The service autostarts (launchd/systemd/Scheduled Task) so the Side Panel is always ready.</li> \n</ul> \n<p>If you only want the <strong>CLI</strong>, you can skip the daemon install entirely.</p> \n<p>Notes:</p> \n<ul> \n <li>Summarization only runs when the Side Panel is open.</li> \n <li>Auto mode summarizes on navigation (incl. SPAs); otherwise use the button.</li> \n <li>Daemon is localhost-only and requires a shared token.</li> \n <li>Autostart: macOS (launchd), Linux (systemd user), Windows (Scheduled Task).</li> \n <li>Tip: configure <code>free</code> via <code>summarize refresh-free</code> (needs <code>OPENROUTER_API_KEY</code>). Add <code>--set-default</code> to set model=<code>free</code>.</li> \n</ul> \n<p>More:</p> \n<ul> \n <li>Step-by-step install: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/README.md\">apps/chrome-extension/README.md</a></li> \n <li>Architecture + troubleshooting: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/chrome-extension.md\">docs/chrome-extension.md</a></li> \n <li>Firefox compatibility notes: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/docs/firefox.md\">apps/chrome-extension/docs/firefox.md</a></li> \n</ul> \n<h3>Slides (extension)</h3> \n<ul> \n <li>Select <strong>Video + Slides</strong> in the Summarize picker.</li> \n <li>Slides render at the top; expand to full‑width cards with timestamps.</li> \n <li>Click a slide to seek the video; toggle <strong>Transcript/OCR</strong> when OCR is significant.</li> \n <li>Requirements: <code>yt-dlp</code> + <code>ffmpeg</code> for extraction; <code>tesseract</code> for OCR. Missing tools show an in‑panel notice.</li> \n</ul> \n<h3>Advanced (unpacked / dev)</h3> \n<ol> \n <li>Build + load the extension (unpacked): \n  <ul> \n   <li>Chrome: <code>pnpm -C apps/chrome-extension build</code> \n    <ul> \n     <li><code>chrome://extensions</code> → Developer mode → Load unpacked</li> \n     <li>Pick: <code>apps/chrome-extension/.output/chrome-mv3</code></li> \n    </ul> </li> \n   <li>Firefox: <code>pnpm -C apps/chrome-extension build:firefox</code> \n    <ul> \n     <li><code>about:debugging#/runtime/this-firefox</code> → Load Temporary Add-on</li> \n     <li>Pick: <code>apps/chrome-extension/.output/firefox-mv3/manifest.json</code></li> \n    </ul> </li> \n  </ul> </li> \n <li>Open Side Panel/Sidebar → copy token.</li> \n <li>Install daemon in dev mode: \n  <ul> \n   <li><code>pnpm summarize daemon install --token &lt;TOKEN&gt; --dev</code></li> \n  </ul> </li> \n</ol> \n<h2>CLI</h2> \n<p><img alt=\"Summarize CLI screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-cli.png\" /></p> \n<h3>Install</h3> \n<p>Requires Node 22+.</p> \n<ul> \n <li>npx (no install):</li> \n</ul> \n<pre><code class=\"language-bash\">npx -y @steipete/summarize \"https://example.com\"\n</code></pre> \n<ul> \n <li>npm (global):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i -g @steipete/summarize\n</code></pre> \n<ul> \n <li>npm (library / minimal deps):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i @steipete/summarize-core\n</code></pre> \n<pre><code class=\"language-ts\">import { createLinkPreviewClient } from \"@steipete/summarize-core/content\";\n</code></pre> \n<ul> \n <li>Homebrew (custom tap):</li> \n</ul> \n<pre><code class=\"language-bash\">brew install steipete/tap/summarize\n</code></pre> \n<p>Apple Silicon only (arm64).</p> \n<h3>CLI vs extension</h3> \n<ul> \n <li><strong>CLI only:</strong> just install via npm/Homebrew and run <code>summarize ...</code> (no daemon needed).</li> \n <li><strong>Chrome/Firefox extension:</strong> install the CLI <strong>and</strong> run <code>summarize daemon install --token &lt;TOKEN&gt;</code> so the Side Panel can stream results and use local tools.</li> \n</ul> \n<h3>Quickstart</h3> \n<pre><code class=\"language-bash\">summarize \"https://example.com\"\n</code></pre> \n<h3>Inputs</h3> \n<p>URLs or local paths:</p> \n<pre><code class=\"language-bash\">summarize \"/path/to/file.pdf\" --model google/gemini-3-flash-preview\nsummarize \"https://example.com/report.pdf\" --model google/gemini-3-flash-preview\nsummarize \"/path/to/audio.mp3\"\nsummarize \"/path/to/video.mp4\"\n</code></pre> \n<p>Stdin (pipe content using <code>-</code>):</p> \n<pre><code class=\"language-bash\">echo \"content\" | summarize -\npbpaste | summarize -\n# binary stdin also works (PDF/image/audio/video bytes)\ncat /path/to/file.pdf | summarize -\n</code></pre> \n<p><strong>Notes:</strong></p> \n<ul> \n <li>Stdin has a 50MB size limit</li> \n <li>The <code>-</code> argument tells summarize to read from standard input</li> \n <li>Text stdin is treated as UTF-8 text (whitespace-only input is rejected as empty)</li> \n <li>Binary stdin is preserved as raw bytes and file type is auto-detected when possible</li> \n <li>Useful for piping clipboard content or command output</li> \n</ul> \n<p>YouTube (supports <code>youtube.com</code> and <code>youtu.be</code>):</p> \n<pre><code class=\"language-bash\">summarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto\n</code></pre> \n<p>Podcast RSS (transcribes latest enclosure):</p> \n<pre><code class=\"language-bash\">summarize \"https://feeds.npr.org/500005/podcast.xml\"\n</code></pre> \n<p>Apple Podcasts episode page:</p> \n<pre><code class=\"language-bash\">summarize \"https://podcasts.apple.com/us/podcast/2424-jelly-roll/id360084272?i=1000740717432\"\n</code></pre> \n<p>Spotify episode page (best-effort; may fail for exclusives):</p> \n<pre><code class=\"language-bash\">summarize \"https://open.spotify.com/episode/5auotqWAXhhKyb9ymCuBJY\"\n</code></pre> \n<h3>Output length</h3> \n<p><code>--length</code> controls how much output we ask for (guideline), not a hard cap.</p> \n<pre><code class=\"language-bash\">summarize \"https://example.com\" --length long\nsummarize \"https://example.com\" --length 20k\n</code></pre> \n<ul> \n <li>Presets: <code>short|medium|long|xl|xxl</code></li> \n <li>Character targets: <code>1500</code>, <code>20k</code>, <code>20000</code></li> \n <li>Optional hard cap: <code>--max-output-tokens &lt;count&gt;</code> (e.g. <code>2000</code>, <code>2k</code>) \n  <ul> \n   <li>Provider/model APIs still enforce their own maximum output limits.</li> \n   <li>If omitted, no max token parameter is sent (provider default).</li> \n   <li>Prefer <code>--length</code> unless you need a hard cap.</li> \n  </ul> </li> \n <li>Short content: when extracted content is shorter than the requested length, the CLI returns the content as-is. \n  <ul> \n   <li>Override with <code>--force-summary</code> to always run the LLM.</li> \n  </ul> </li> \n <li>Minimums: <code>--length</code> numeric values must be &gt;= 50 chars; <code>--max-output-tokens</code> must be &gt;= 16.</li> \n <li>Preset targets (source of truth: <code>packages/core/src/prompts/summary-lengths.ts</code>): \n  <ul> \n   <li>short: target ~900 chars (range 600-1,200)</li> \n   <li>medium: target ~1,800 chars (range 1,200-2,500)</li> \n   <li>long: target ~4,200 chars (range 2,500-6,000)</li> \n   <li>xl: target ~9,000 chars (range 6,000-14,000)</li> \n   <li>xxl: target ~17,000 chars (range 14,000-22,000)</li> \n  </ul> </li> \n</ul> \n<h3>What file types work?</h3> \n<p>Best effort and provider-dependent. These usually work well:</p> \n<ul> \n <li><code>text/*</code> and common structured text (<code>.txt</code>, <code>.md</code>, <code>.json</code>, <code>.yaml</code>, <code>.xml</code>, ...) \n  <ul> \n   <li>Text-like files are inlined into the prompt for better provider compatibility.</li> \n  </ul> </li> \n <li>PDFs: <code>application/pdf</code> (provider support varies; Google is the most reliable here)</li> \n <li>Images: <code>image/jpeg</code>, <code>image/png</code>, <code>image/webp</code>, <code>image/gif</code></li> \n <li>Audio/Video: <code>audio/*</code>, <code>video/*</code> (local audio/video files MP3/WAV/M4A/OGG/FLAC/MP4/MOV/WEBM automatically transcribed, when supported by the model)</li> \n</ul> \n<p>Notes:</p> \n<ul> \n <li>If a provider rejects a media type, the CLI fails fast with a friendly message.</li> \n <li>xAI models do not support attaching generic files (like PDFs) via the AI SDK; use Google/OpenAI/Anthropic for those.</li> \n</ul> \n<h3>Model ids</h3> \n<p>Use gateway-style ids: <code>&lt;provider&gt;/&lt;model&gt;</code>.</p> \n<p>Examples:</p> \n<ul> \n <li><code>openai/gpt-5-mini</code></li> \n <li><code>anthropic/claude-sonnet-4-5</code></li> \n <li><code>xai/grok-4-fast-non-reasoning</code></li> \n <li><code>google/gemini-3-flash-preview</code></li> \n <li><code>zai/glm-4.7</code></li> \n <li><code>openrouter/openai/gpt-5-mini</code> (force OpenRouter)</li> \n</ul> \n<p>Note: some models/providers do not support streaming or certain file media types. When that happens, the CLI prints a friendly error (or auto-disables streaming for that model when supported by the provider).</p> \n<h3>Limits</h3> \n<ul> \n <li>Text inputs over 10 MB are rejected before tokenization.</li> \n <li>Text prompts are preflighted against the model input limit (LiteLLM catalog), using a GPT tokenizer.</li> \n</ul> \n<h3>Common flags</h3> \n<pre><code class=\"language-bash\">summarize &lt;input&gt; [flags]\n</code></pre> \n<p>Use <code>summarize --help</code> or <code>summarize help</code> for the full help text.</p> \n<ul> \n <li><code>--model &lt;provider/model&gt;</code>: which model to use (defaults to <code>auto</code>)</li> \n <li><code>--model auto</code>: automatic model selection + fallback (default)</li> \n <li><code>--model &lt;name&gt;</code>: use a config-defined model (see Configuration)</li> \n <li><code>--timeout &lt;duration&gt;</code>: <code>30s</code>, <code>2m</code>, <code>5000ms</code> (default <code>2m</code>)</li> \n <li><code>--retries &lt;count&gt;</code>: LLM retry attempts on timeout (default <code>1</code>)</li> \n <li><code>--length short|medium|long|xl|xxl|s|m|l|&lt;chars&gt;</code></li> \n <li><code>--language, --lang &lt;language&gt;</code>: output language (<code>auto</code> = match source)</li> \n <li><code>--max-output-tokens &lt;count&gt;</code>: hard cap for LLM output tokens</li> \n <li><code>--cli [provider]</code>: use a CLI provider (<code>--model cli/&lt;provider&gt;</code>). Supports <code>claude</code>, <code>gemini</code>, <code>codex</code>, <code>agent</code>. If omitted, uses auto selection with CLI enabled.</li> \n <li><code>--stream auto|on|off</code>: stream LLM output (<code>auto</code> = TTY only; disabled in <code>--json</code> mode)</li> \n <li><code>--plain</code>: keep raw output (no ANSI/OSC Markdown rendering)</li> \n <li><code>--no-color</code>: disable ANSI colors</li> \n <li><code>--theme &lt;name&gt;</code>: CLI theme (<code>aurora</code>, <code>ember</code>, <code>moss</code>, <code>mono</code>)</li> \n <li><code>--format md|text</code>: website/file content format (default <code>text</code>)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code>: HTML -&gt; Markdown mode (default <code>readability</code>)</li> \n <li><code>--preprocess off|auto|always</code>: controls <code>uvx markitdown</code> usage (default <code>auto</code>) \n  <ul> \n   <li>Install <code>uvx</code>: <code>brew install uv</code> (or <a href=\"https://astral.sh/uv/\">https://astral.sh/uv/</a>)</li> \n  </ul> </li> \n <li><code>--extract</code>: print extracted content and exit (URLs only; stdin <code>-</code> is not supported) \n  <ul> \n   <li>Deprecated alias: <code>--extract-only</code></li> \n  </ul> </li> \n <li><code>--slides</code>: extract slides for YouTube/direct video URLs and render them inline in the summary narrative (auto-renders inline in supported terminals)</li> \n <li><code>--slides-ocr</code>: run OCR on extracted slides (requires <code>tesseract</code>)</li> \n <li><code>--slides-dir &lt;dir&gt;</code>: base output dir for slide images (default <code>./slides</code>)</li> \n <li><code>--slides-scene-threshold &lt;value&gt;</code>: scene detection threshold (0.1-1.0)</li> \n <li><code>--slides-max &lt;count&gt;</code>: maximum slides to extract (default <code>6</code>)</li> \n <li><code>--slides-min-duration &lt;seconds&gt;</code>: minimum seconds between slides</li> \n <li><code>--json</code>: machine-readable output with diagnostics, prompt, <code>metrics</code>, and optional summary</li> \n <li><code>--verbose</code>: debug/diagnostics on stderr</li> \n <li><code>--metrics off|on|detailed</code>: metrics output (default <code>on</code>)</li> \n</ul> \n<h3>Coding CLIs (Codex, Claude, Gemini, Agent)</h3> \n<p>Summarize can use common coding CLIs as local model backends:</p> \n<ul> \n <li><code>codex</code> -&gt; <code>--cli codex</code> / <code>--model cli/codex/&lt;model&gt;</code></li> \n <li><code>claude</code> -&gt; <code>--cli claude</code> / <code>--model cli/claude/&lt;model&gt;</code></li> \n <li><code>gemini</code> -&gt; <code>--cli gemini</code> / <code>--model cli/gemini/&lt;model&gt;</code></li> \n <li><code>agent</code> (Cursor Agent CLI) -&gt; <code>--cli agent</code> / <code>--model cli/agent/&lt;model&gt;</code></li> \n</ul> \n<p>Requirements:</p> \n<ul> \n <li>Binary installed and on <code>PATH</code> (or set <code>CODEX_PATH</code>, <code>CLAUDE_PATH</code>, <code>GEMINI_PATH</code>, <code>AGENT_PATH</code>)</li> \n <li>Provider authenticated (<code>codex login</code>, <code>claude auth</code>, <code>gemini</code> login flow, <code>agent login</code> or <code>CURSOR_API_KEY</code>)</li> \n</ul> \n<p>Quick smoke test:</p> \n<pre><code class=\"language-bash\">printf \"Summarize CLI smoke input.\\nOne short paragraph. Reply can be brief.\\n\" &gt;/tmp/summarize-cli-smoke.txt\n\nsummarize --cli codex --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli claude --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli gemini --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli agent --plain --timeout 2m /tmp/summarize-cli-smoke.txt\n</code></pre> \n<p>Set explicit CLI allowlist/order:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"codex\", \"claude\", \"gemini\", \"agent\"] }\n}\n</code></pre> \n<p>Configure implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": {\n    \"autoFallback\": {\n      \"enabled\": true,\n      \"onlyWhenNoApiKeys\": true,\n      \"order\": [\"claude\", \"gemini\", \"codex\", \"agent\"]\n    }\n  }\n}\n</code></pre> \n<p>More details: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\"><code>docs/cli.md</code></a></p> \n<h3>Auto model ordering</h3> \n<p><code>--model auto</code> builds candidate attempts from built-in rules (or your <code>model.rules</code> overrides). CLI attempts are prepended when:</p> \n<ul> \n <li><code>cli.enabled</code> is set (explicit allowlist/order), or</li> \n <li>implicit auto selection is active and <code>cli.autoFallback</code> is enabled.</li> \n</ul> \n<p>Default fallback behavior: only when no API keys are configured, order <code>claude, gemini, codex, agent</code>, and remember/prioritize last successful provider (<code>~/.summarize/cli-state.json</code>).</p> \n<p>Set explicit CLI attempts:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"gemini\"] }\n}\n</code></pre> \n<p>Disable implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"autoFallback\": { \"enabled\": false } }\n}\n</code></pre> \n<p>Note: explicit <code>--model auto</code> does not trigger implicit auto CLI fallback unless <code>cli.enabled</code> is set.</p> \n<h3>Website extraction (Firecrawl + Markdown)</h3> \n<p>Non-YouTube URLs go through a fetch -&gt; extract pipeline. When direct fetch/extraction is blocked or too thin, <code>--firecrawl auto</code> can fall back to Firecrawl (if configured).</p> \n<ul> \n <li><code>--firecrawl off|auto|always</code> (default <code>auto</code>)</li> \n <li><code>--extract --format md|text</code> (default <code>text</code>; if <code>--format</code> is omitted, <code>--extract</code> defaults to <code>md</code> for non-YouTube URLs)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code> (default <code>readability</code>) \n  <ul> \n   <li><code>auto</code>: use an LLM converter when configured; may fall back to <code>uvx markitdown</code></li> \n   <li><code>llm</code>: force LLM conversion (requires a configured model key)</li> \n   <li><code>off</code>: disable LLM conversion (still may return Firecrawl Markdown when configured)</li> \n  </ul> </li> \n <li>Plain-text mode: use <code>--format text</code>.</li> \n</ul> \n<h3>YouTube transcripts</h3> \n<p><code>--youtube auto</code> tries best-effort web transcript endpoints first. When captions are not available, it falls back to:</p> \n<ol> \n <li>Apify (if <code>APIFY_API_TOKEN</code> is set): uses a scraping actor (<code>faVsWy9VTSNVIhWpR</code>)</li> \n <li>yt-dlp + Whisper (if <code>yt-dlp</code> is available): downloads audio, then transcribes with local <code>whisper.cpp</code> when installed (preferred), otherwise falls back to OpenAI (<code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>)</li> \n</ol> \n<p>Environment variables for yt-dlp mode:</p> \n<ul> \n <li><code>YT_DLP_PATH</code> - optional path to yt-dlp binary (otherwise <code>yt-dlp</code> is resolved via <code>PATH</code>)</li> \n <li><code>SUMMARIZE_WHISPER_CPP_MODEL_PATH</code> - optional override for the local <code>whisper.cpp</code> model file</li> \n <li><code>SUMMARIZE_WHISPER_CPP_BINARY</code> - optional override for the local binary (default: <code>whisper-cli</code>)</li> \n <li><code>SUMMARIZE_DISABLE_LOCAL_WHISPER_CPP=1</code> - disable local whisper.cpp (force remote)</li> \n <li><code>OPENAI_API_KEY</code> - OpenAI Whisper transcription</li> \n <li><code>OPENAI_WHISPER_BASE_URL</code> - optional OpenAI-compatible Whisper endpoint override</li> \n <li><code>FAL_KEY</code> - FAL AI Whisper fallback</li> \n</ul> \n<p>Apify costs money but tends to be more reliable when captions exist.</p> \n<h3>Slide extraction (YouTube + direct video URLs)</h3> \n<p>Extract slide screenshots (scene detection via <code>ffmpeg</code>) and optional OCR:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --slides\nsummarize \"https://www.youtube.com/watch?v=...\" --slides --slides-ocr\n</code></pre> \n<p>Outputs are written under <code>./slides/&lt;sourceId&gt;/</code> (or <code>--slides-dir</code>). OCR results are included in JSON output (<code>--json</code>) and stored in <code>slides.json</code> inside the slide directory. When scene detection is too sparse, the extractor also samples at a fixed interval to improve coverage. When using <code>--slides</code>, supported terminals (kitty/iTerm/Konsole) render inline thumbnails automatically inside the summary narrative (the model inserts <code>[slide:N]</code> markers). Timestamp links are clickable when the terminal supports OSC-8 (YouTube/Vimeo/Loom/Dropbox). If inline images are unsupported, Summarize prints a note with the on-disk slide directory.</p> \n<p>Use <code>--slides --extract</code> to print the full timed transcript and insert slide images inline at matching timestamps.</p> \n<p>Format the extracted transcript as Markdown (headings + paragraphs) via an LLM:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --extract --format md --markdown-mode llm\n</code></pre> \n<h3>Media transcription (Whisper)</h3> \n<p>Local audio/video files are transcribed first, then summarized. <code>--video-mode transcript</code> forces direct media URLs (and embedded media) through Whisper first. Prefers local <code>whisper.cpp</code> when available; otherwise requires <code>OPENAI_API_KEY</code> or <code>FAL_KEY</code>.</p> \n<h3>Local ONNX transcription (Parakeet/Canary)</h3> \n<p>Summarize can use NVIDIA Parakeet/Canary ONNX models via a local CLI you provide. Auto selection (default) prefers ONNX when configured.</p> \n<ul> \n <li>Setup helper: <code>summarize transcriber setup</code></li> \n <li>Install <code>sherpa-onnx</code> from upstream binaries/build (Homebrew may not have a formula)</li> \n <li>Auto selection: set <code>SUMMARIZE_ONNX_PARAKEET_CMD</code> or <code>SUMMARIZE_ONNX_CANARY_CMD</code> (no flag needed)</li> \n <li>Force a model: <code>--transcriber parakeet|canary|whisper|auto</code></li> \n <li>Docs: <code>docs/nvidia-onnx-transcription.md</code></li> \n</ul> \n<h3>Verified podcast services (2025-12-25)</h3> \n<p>Run: <code>summarize &lt;url&gt;</code></p> \n<ul> \n <li>Apple Podcasts</li> \n <li>Spotify</li> \n <li>Amazon Music / Audible podcast pages</li> \n <li>Podbean</li> \n <li>Podchaser</li> \n <li>RSS feeds (Podcasting 2.0 transcripts when available)</li> \n <li>Embedded YouTube podcast pages (e.g. JREPodcast)</li> \n</ul> \n<p>Transcription: prefers local <code>whisper.cpp</code> when installed; otherwise uses OpenAI Whisper or FAL when keys are set.</p> \n<h3>Translation paths</h3> \n<p><code>--language/--lang</code> controls the output language of the summary (and other LLM-generated text). Default is <code>auto</code>.</p> \n<p>When the input is audio/video, the CLI needs a transcript first. The transcript comes from one of these paths:</p> \n<ol> \n <li>Existing transcript (preferred) \n  <ul> \n   <li>YouTube: uses <code>youtubei</code> / <code>captionTracks</code> when available.</li> \n   <li>Podcasts: uses Podcasting 2.0 RSS <code>&lt;podcast:transcript&gt;</code> (JSON/VTT) when the feed publishes it.</li> \n  </ul> </li> \n <li>Whisper transcription (fallback) \n  <ul> \n   <li>YouTube: falls back to yt-dlp (audio download) + Whisper transcription when configured; Apify is a last resort.</li> \n   <li>Prefers local <code>whisper.cpp</code> when installed + model available.</li> \n   <li>Otherwise uses cloud Whisper (OpenAI <code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>).</li> \n  </ul> </li> \n</ol> \n<p>For direct media URLs, use <code>--video-mode transcript</code> to force transcribe -&gt; summarize:</p> \n<pre><code class=\"language-bash\">summarize https://example.com/file.mp4 --video-mode transcript --lang en\n</code></pre> \n<h3>Configuration</h3> \n<p>Single config location:</p> \n<ul> \n <li><code>~/.summarize/config.json</code></li> \n</ul> \n<p>Supported keys today:</p> \n<pre><code class=\"language-json\">{\n  \"model\": { \"id\": \"openai/gpt-5-mini\" },\n  \"env\": { \"OPENAI_API_KEY\": \"sk-...\" },\n  \"ui\": { \"theme\": \"ember\" }\n}\n</code></pre> \n<p>Shorthand (equivalent):</p> \n<pre><code class=\"language-json\">{\n  \"model\": \"openai/gpt-5-mini\"\n}\n</code></pre> \n<p>Also supported:</p> \n<ul> \n <li><code>model: { \"mode\": \"auto\" }</code> (automatic model selection + fallback; see <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a>)</li> \n <li><code>model.rules</code> (customize candidates / ordering)</li> \n <li><code>models</code> (define presets selectable via <code>--model &lt;preset&gt;</code>)</li> \n <li><code>env</code> (generic env var defaults; process env still wins)</li> \n <li><code>apiKeys</code> (legacy shortcut, mapped to env names; prefer <code>env</code> for new configs)</li> \n <li><code>cache.media</code> (media download cache: TTL 7 days, 2048 MB cap by default; <code>--no-media-cache</code> disables)</li> \n <li><code>media.videoMode: \"auto\"|\"transcript\"|\"understand\"</code></li> \n <li><code>slides.enabled</code> / <code>slides.max</code> / <code>slides.ocr</code> / <code>slides.dir</code> (defaults for <code>--slides</code>)</li> \n <li><code>ui.theme: \"aurora\"|\"ember\"|\"moss\"|\"mono\"</code></li> \n <li><code>openai.useChatCompletions: true</code> (force OpenAI-compatible chat completions)</li> \n</ul> \n<p>Note: the config is parsed leniently (JSON5), but comments are not allowed. Unknown keys are ignored.</p> \n<p>Media cache defaults:</p> \n<pre><code class=\"language-json\">{\n  \"cache\": {\n    \"media\": { \"enabled\": true, \"ttlDays\": 7, \"maxMb\": 2048, \"verify\": \"size\" }\n  }\n}\n</code></pre> \n<p>Note: <code>--no-cache</code> bypasses summary caching only (LLM output). Extract/transcript caches still apply. Use <code>--no-media-cache</code> to skip media files.</p> \n<p>Precedence:</p> \n<ol> \n <li><code>--model</code></li> \n <li><code>SUMMARIZE_MODEL</code></li> \n <li><code>~/.summarize/config.json</code></li> \n <li>default (<code>auto</code>)</li> \n</ol> \n<p>Theme precedence:</p> \n<ol> \n <li><code>--theme</code></li> \n <li><code>SUMMARIZE_THEME</code></li> \n <li><code>~/.summarize/config.json</code> (<code>ui.theme</code>)</li> \n <li>default (<code>aurora</code>)</li> \n</ol> \n<p>Environment variable precedence:</p> \n<ol> \n <li>process env</li> \n <li><code>~/.summarize/config.json</code> (<code>env</code>)</li> \n <li><code>~/.summarize/config.json</code> (<code>apiKeys</code>, legacy)</li> \n</ol> \n<h3>Environment variables</h3> \n<p>Set the key matching your chosen <code>--model</code>:</p> \n<ul> \n <li> <p>Optional fallback defaults can be stored in config:</p> \n  <ul> \n   <li><code>~/.summarize/config.json</code> -&gt; <code>\"env\": { \"OPENAI_API_KEY\": \"sk-...\" }</code></li> \n   <li>process env always takes precedence</li> \n   <li>legacy <code>\"apiKeys\"</code> still works (mapped to env names)</li> \n  </ul> </li> \n <li> <p><code>OPENAI_API_KEY</code> (for <code>openai/...</code>)</p> </li> \n <li> <p><code>NVIDIA_API_KEY</code> (for <code>nvidia/...</code>)</p> </li> \n <li> <p><code>ANTHROPIC_API_KEY</code> (for <code>anthropic/...</code>)</p> </li> \n <li> <p><code>XAI_API_KEY</code> (for <code>xai/...</code>)</p> </li> \n <li> <p><code>Z_AI_API_KEY</code> (for <code>zai/...</code>; supports <code>ZAI_API_KEY</code> alias)</p> </li> \n <li> <p><code>GEMINI_API_KEY</code> (for <code>google/...</code>)</p> \n  <ul> \n   <li>also accepts <code>GOOGLE_GENERATIVE_AI_API_KEY</code> and <code>GOOGLE_API_KEY</code> as aliases</li> \n  </ul> </li> \n</ul> \n<p>OpenAI-compatible chat completions toggle:</p> \n<ul> \n <li><code>OPENAI_USE_CHAT_COMPLETIONS=1</code> (or set <code>openai.useChatCompletions</code> in config)</li> \n</ul> \n<p>UI theme:</p> \n<ul> \n <li><code>SUMMARIZE_THEME=aurora|ember|moss|mono</code></li> \n <li><code>SUMMARIZE_TRUECOLOR=1</code> (force 24-bit ANSI)</li> \n <li><code>SUMMARIZE_NO_TRUECOLOR=1</code> (disable 24-bit ANSI)</li> \n</ul> \n<p>OpenRouter (OpenAI-compatible):</p> \n<ul> \n <li>Set <code>OPENROUTER_API_KEY=...</code></li> \n <li>Prefer forcing OpenRouter per model id: <code>--model openrouter/&lt;author&gt;/&lt;slug&gt;</code></li> \n <li>Built-in preset: <code>--model free</code> (uses a default set of OpenRouter <code>:free</code> models)</li> \n</ul> \n<h3><code>summarize refresh-free</code></h3> \n<p>Quick start: make free the default (keep <code>auto</code> available)</p> \n<pre><code class=\"language-bash\">summarize refresh-free --set-default\nsummarize \"https://example.com\"\nsummarize \"https://example.com\" --model auto\n</code></pre> \n<p>Regenerates the <code>free</code> preset (<code>models.free</code> in <code>~/.summarize/config.json</code>) by:</p> \n<ul> \n <li>Fetching OpenRouter <code>/models</code>, filtering <code>:free</code></li> \n <li>Skipping models that look very small (&lt;27B by default) based on the model id/name</li> \n <li>Testing which ones return non-empty text (concurrency 4, timeout 10s)</li> \n <li>Picking a mix of smart-ish (bigger <code>context_length</code> / output cap) and fast models</li> \n <li>Refining timings and writing the sorted list back</li> \n</ul> \n<p>If <code>--model free</code> stops working, run:</p> \n<pre><code class=\"language-bash\">summarize refresh-free\n</code></pre> \n<p>Flags:</p> \n<ul> \n <li><code>--runs 2</code> (default): extra timing runs per selected model (total runs = 1 + runs)</li> \n <li><code>--smart 3</code> (default): how many smart-first picks (rest filled by fastest)</li> \n <li><code>--min-params 27b</code> (default): ignore models with inferred size smaller than N billion parameters</li> \n <li><code>--max-age-days 180</code> (default): ignore models older than N days (set 0 to disable)</li> \n <li><code>--set-default</code>: also sets <code>\"model\": \"free\"</code> in <code>~/.summarize/config.json</code></li> \n</ul> \n<p>Example:</p> \n<pre><code class=\"language-bash\">OPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/meta-llama/llama-3.1-8b-instruct:free\nOPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/minimax/minimax-m2.5\n</code></pre> \n<p>If your OpenRouter account enforces an allowed-provider list, make sure at least one provider is allowed for the selected model. When routing fails, <code>summarize</code> prints the exact providers to allow.</p> \n<p>Legacy: <code>OPENAI_BASE_URL=https://openrouter.ai/api/v1</code> (and either <code>OPENAI_API_KEY</code> or <code>OPENROUTER_API_KEY</code>) also works.</p> \n<p>NVIDIA API Catalog (OpenAI-compatible; free credits):</p> \n<ul> \n <li>Set <code>NVIDIA_API_KEY=...</code></li> \n <li>Optional: <code>NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1</code></li> \n <li>Credits: API Catalog trial starts with 1000 free API credits on signup (up to 5000 total via “Request More” in the API Catalog profile)</li> \n <li>Pick a model id from <code>/v1/models</code> (examples: fast <code>stepfun-ai/step-3.5-flash</code>, strong but slower <code>z-ai/glm5</code>)</li> \n</ul> \n<pre><code class=\"language-bash\">export NVIDIA_API_KEY=\"nvapi-...\"\nsummarize \"https://example.com\" --model nvidia/stepfun-ai/step-3.5-flash\n</code></pre> \n<p>Z.AI (OpenAI-compatible):</p> \n<ul> \n <li><code>Z_AI_API_KEY=...</code> (or <code>ZAI_API_KEY=...</code>)</li> \n <li>Optional base URL override: <code>Z_AI_BASE_URL=...</code></li> \n</ul> \n<p>Optional services:</p> \n<ul> \n <li><code>FIRECRAWL_API_KEY</code> (website extraction fallback)</li> \n <li><code>YT_DLP_PATH</code> (path to yt-dlp binary for audio extraction)</li> \n <li><code>FAL_KEY</code> (FAL AI API key for audio transcription via Whisper)</li> \n <li><code>APIFY_API_TOKEN</code> (YouTube transcript fallback)</li> \n</ul> \n<h3>Model limits</h3> \n<p>The CLI uses the LiteLLM model catalog for model limits (like max output tokens):</p> \n<ul> \n <li>Downloaded from: <code>https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json</code></li> \n <li>Cached at: <code>~/.summarize/cache/</code></li> \n</ul> \n<h3>Library usage (optional)</h3> \n<p>Recommended (minimal deps):</p> \n<ul> \n <li><code>@steipete/summarize-core/content</code></li> \n <li><code>@steipete/summarize-core/prompts</code></li> \n</ul> \n<p>Compatibility (pulls in CLI deps):</p> \n<ul> \n <li><code>@steipete/summarize/content</code></li> \n <li><code>@steipete/summarize/prompts</code></li> \n</ul> \n<h3>Development</h3> \n<pre><code class=\"language-bash\">pnpm install\npnpm check\n</code></pre> \n<h2>More</h2> \n<ul> \n <li>Docs index: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/README.md\">docs/README.md</a></li> \n <li>CLI providers and config: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\">docs/cli.md</a></li> \n <li>Auto model rules: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a></li> \n <li>Website extraction: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/website.md\">docs/website.md</a></li> \n <li>YouTube handling: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/youtube.md\">docs/youtube.md</a></li> \n <li>Media pipeline: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/media.md\">docs/media.md</a></li> \n <li>Config schema and precedence: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/config.md\">docs/config.md</a></li> \n</ul> \n<h2>Troubleshooting</h2> \n<ul> \n <li>\"Receiving end does not exist\": Chrome did not inject the content script yet. \n  <ul> \n   <li>Extension details -&gt; Site access -&gt; On all sites (or allow this domain)</li> \n   <li>Reload the tab once.</li> \n  </ul> </li> \n <li>\"Failed to fetch\" / daemon unreachable: \n  <ul> \n   <li><code>summarize daemon status</code></li> \n   <li>Logs: <code>~/.summarize/logs/daemon.err.log</code></li> \n  </ul> </li> \n</ul> \n<p>License: MIT</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:11.022675Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 19,
        "timeliness_score": 1,
        "final_score": 6.4,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/RichardAtCT/claude-code-telegram",
        "title": "RichardAtCT/claude-code-telegram",
        "summary": "<p>A powerful Telegram bot that provides remote access to Claude Code, enabling developers to interact with their projects from anywhere with full AI assistance and session persistence.</p><hr /><h1>Claude Code Telegram Bot</h1> \n<p><a href=\"https://opensource.org/licenses/MIT\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true\" /></a> <a href=\"https://www.python.org/downloads/\"><img alt=\"Python 3.11+\" src=\"https://img.shields.io/badge/python-3.11+-blue.svg?sanitize=true\" /></a></p> \n<p>A Telegram bot that gives you remote access to <a href=\"https://claude.ai/code\">Claude Code</a>. Chat naturally with Claude about your projects from anywhere -- no terminal commands needed.</p> \n<h2>What is this?</h2> \n<p>This bot connects Telegram to Claude Code, providing a conversational AI interface for your codebase:</p> \n<ul> \n <li><strong>Chat naturally</strong> -- ask Claude to analyze, edit, or explain your code in plain language</li> \n <li><strong>Maintain context</strong> across conversations with automatic session persistence per project</li> \n <li><strong>Code on the go</strong> from any device with Telegram</li> \n <li><strong>Receive proactive notifications</strong> from webhooks, scheduled jobs, and CI/CD events</li> \n <li><strong>Stay secure</strong> with built-in authentication, directory sandboxing, and audit logging</li> \n</ul> \n<h2>Quick Start</h2> \n<h3>Demo</h3> \n<pre><code>You: Can you help me add error handling to src/api.py?\n\nBot: I'll analyze src/api.py and add error handling...\n     [Claude reads your code, suggests improvements, and can apply changes directly]\n\nYou: Looks good. Now run the tests to make sure nothing broke.\n\nBot: Running pytest...\n     All 47 tests passed. The error handling changes are working correctly.\n</code></pre> \n<h3>1. Prerequisites</h3> \n<ul> \n <li><strong>Python 3.11+</strong> -- <a href=\"https://www.python.org/downloads/\">Download here</a></li> \n <li><strong>Claude Code CLI</strong> -- <a href=\"https://claude.ai/code\">Install from here</a></li> \n <li><strong>Telegram Bot Token</strong> -- Get one from <a href=\"https://t.me/botfather\">@BotFather</a></li> \n</ul> \n<h3>2. Install</h3> \n<p>Choose your preferred method:</p> \n<h4>Option A: Install from a release tag (Recommended)</h4> \n<pre><code class=\"language-bash\"># Using uv (recommended — installs in an isolated environment)\nuv tool install git+https://github.com/RichardAtCT/claude-code-telegram@v1.3.0\n\n# Or using pip\npip install git+https://github.com/RichardAtCT/claude-code-telegram@v1.3.0\n\n# Track the latest stable release\npip install git+https://github.com/RichardAtCT/claude-code-telegram@latest\n</code></pre> \n<h4>Option B: From source (for development)</h4> \n<pre><code class=\"language-bash\">git clone https://github.com/RichardAtCT/claude-code-telegram.git\ncd claude-code-telegram\nmake dev  # requires Poetry\n</code></pre> \n<blockquote> \n <p><strong>Note:</strong> Always install from a tagged release (not <code>main</code>) for stability. See <a href=\"https://github.com/RichardAtCT/claude-code-telegram/releases\">Releases</a> for available versions.</p> \n</blockquote> \n<h3>3. Configure</h3> \n<pre><code class=\"language-bash\">cp .env.example .env\n# Edit .env with your settings:\n</code></pre> \n<p><strong>Minimum required:</strong></p> \n<pre><code class=\"language-bash\">TELEGRAM_BOT_TOKEN=1234567890:ABC-DEF1234ghIkl-zyx57W2v1u123ew11\nTELEGRAM_BOT_USERNAME=my_claude_bot\nAPPROVED_DIRECTORY=/Users/yourname/projects\nALLOWED_USERS=123456789  # Your Telegram user ID\n</code></pre> \n<h3>4. Run</h3> \n<pre><code class=\"language-bash\">make run          # Production\nmake run-debug    # With debug logging\n</code></pre> \n<p>Message your bot on Telegram to get started.</p> \n<blockquote> \n <p><strong>Detailed setup:</strong> See <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/docs/setup.md\">docs/setup.md</a> for Claude authentication options and troubleshooting.</p> \n</blockquote> \n<h2>Modes</h2> \n<p>The bot supports two interaction modes:</p> \n<h3>Agentic Mode (Default)</h3> \n<p>The default conversational mode. Just talk to Claude naturally -- no special commands required.</p> \n<p><strong>Commands:</strong> <code>/start</code>, <code>/new</code>, <code>/status</code>, <code>/verbose</code>, <code>/repo</code> If <code>ENABLE_PROJECT_THREADS=true</code>: <code>/sync_threads</code></p> \n<pre><code>You: What files are in this project?\nBot: Working... (3s)\n     📖 Read\n     📂 LS\n     💬 Let me describe the project structure\nBot: [Claude describes the project structure]\n\nYou: Add a retry decorator to the HTTP client\nBot: Working... (8s)\n     📖 Read: http_client.py\n     💬 I'll add a retry decorator with exponential backoff\n     ✏️ Edit: http_client.py\n     💻 Bash: poetry run pytest tests/ -v\nBot: [Claude shows the changes and test results]\n\nYou: /verbose 0\nBot: Verbosity set to 0 (quiet)\n</code></pre> \n<p>Use <code>/verbose 0|1|2</code> to control how much background activity is shown:</p> \n<table> \n <thead> \n  <tr> \n   <th>Level</th> \n   <th>Shows</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>0</strong> (quiet)</td> \n   <td>Final response only (typing indicator stays active)</td> \n  </tr> \n  <tr> \n   <td><strong>1</strong> (normal, default)</td> \n   <td>Tool names + reasoning snippets in real-time</td> \n  </tr> \n  <tr> \n   <td><strong>2</strong> (detailed)</td> \n   <td>Tool names with inputs + longer reasoning text</td> \n  </tr> \n </tbody> \n</table> \n<h4>GitHub Workflow</h4> \n<p>Claude Code already knows how to use <code>gh</code> CLI and <code>git</code>. Authenticate on your server with <code>gh auth login</code>, then work with repos conversationally:</p> \n<pre><code>You: List my repos related to monitoring\nBot: [Claude runs gh repo list, shows results]\n\nYou: Clone the uptime one\nBot: [Claude runs gh repo clone, clones into workspace]\n\nYou: /repo\nBot: 📦 uptime-monitor/  ◀\n     📁 other-project/\n\nYou: Show me the open issues\nBot: [Claude runs gh issue list]\n\nYou: Create a fix branch and push it\nBot: [Claude creates branch, commits, pushes]\n</code></pre> \n<p>Use <code>/repo</code> to list cloned repos in your workspace, or <code>/repo &lt;name&gt;</code> to switch directories (sessions auto-resume).</p> \n<h3>Classic Mode</h3> \n<p>Set <code>AGENTIC_MODE=false</code> to enable the full 13-command terminal-like interface with directory navigation, inline keyboards, quick actions, git integration, and session export.</p> \n<p><strong>Commands:</strong> <code>/start</code>, <code>/help</code>, <code>/new</code>, <code>/continue</code>, <code>/end</code>, <code>/status</code>, <code>/cd</code>, <code>/ls</code>, <code>/pwd</code>, <code>/projects</code>, <code>/export</code>, <code>/actions</code>, <code>/git</code><br /> If <code>ENABLE_PROJECT_THREADS=true</code>: <code>/sync_threads</code></p> \n<pre><code>You: /cd my-web-app\nBot: Directory changed to my-web-app/\n\nYou: /ls\nBot: src/  tests/  package.json  README.md\n\nYou: /actions\nBot: [Run Tests] [Install Deps] [Format Code] [Run Linter]\n</code></pre> \n<h2>Event-Driven Automation</h2> \n<p>Beyond direct chat, the bot can respond to external triggers:</p> \n<ul> \n <li><strong>Webhooks</strong> -- Receive GitHub events (push, PR, issues) and route them through Claude for automated summaries or code review</li> \n <li><strong>Scheduler</strong> -- Run recurring Claude tasks on a cron schedule (e.g., daily code health checks)</li> \n <li><strong>Notifications</strong> -- Deliver agent responses to configured Telegram chats</li> \n</ul> \n<p>Enable with <code>ENABLE_API_SERVER=true</code> and <code>ENABLE_SCHEDULER=true</code>. See <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/docs/setup.md\">docs/setup.md</a> for configuration.</p> \n<h2>Features</h2> \n<h3>Working Features</h3> \n<ul> \n <li> <p>Conversational agentic mode (default) with natural language interaction</p> </li> \n <li> <p>Classic terminal-like mode with 13 commands and inline keyboards</p> </li> \n <li> <p>Full Claude Code integration with SDK (primary) and CLI (fallback)</p> </li> \n <li> <p>Automatic session persistence per user/project directory</p> </li> \n <li> <p>Multi-layer authentication (whitelist + optional token-based)</p> </li> \n <li> <p>Rate limiting with token bucket algorithm</p> </li> \n <li> <p>Directory sandboxing with path traversal prevention</p> </li> \n <li> <p>File upload handling with archive extraction</p> </li> \n <li> <p>Image/screenshot upload with analysis</p> </li> \n <li> <p>Git integration with safe repository operations</p> </li> \n <li> <p>Quick actions system with context-aware buttons</p> </li> \n <li> <p>Session export in Markdown, HTML, and JSON formats</p> </li> \n <li> <p>SQLite persistence with migrations</p> </li> \n <li> <p>Usage and cost tracking</p> </li> \n <li> <p>Audit logging and security event tracking</p> </li> \n <li> <p>Event bus for decoupled message routing</p> </li> \n <li> <p>Webhook API server (GitHub HMAC-SHA256, generic Bearer token auth)</p> </li> \n <li> <p>Job scheduler with cron expressions and persistent storage</p> </li> \n <li> <p>Notification service with per-chat rate limiting</p> </li> \n <li> <p>Tunable verbose output showing Claude's tool usage and reasoning in real-time</p> </li> \n <li> <p>Persistent typing indicator so users always know the bot is working</p> </li> \n <li> <p>16 configurable tools with allowlist/disallowlist control (see <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/docs/tools.md\">docs/tools.md</a>)</p> </li> \n</ul> \n<h3>Planned Enhancements</h3> \n<ul> \n <li>Plugin system for third-party extensions</li> \n</ul> \n<h2>Configuration</h2> \n<h3>Required</h3> \n<pre><code class=\"language-bash\">TELEGRAM_BOT_TOKEN=...           # From @BotFather\nTELEGRAM_BOT_USERNAME=...        # Your bot's username\nAPPROVED_DIRECTORY=...           # Base directory for project access\nALLOWED_USERS=123456789          # Comma-separated Telegram user IDs\n</code></pre> \n<h3>Common Options</h3> \n<pre><code class=\"language-bash\"># Claude\nANTHROPIC_API_KEY=sk-ant-...     # API key (optional if using CLI auth)\nCLAUDE_MAX_COST_PER_USER=10.0    # Spending limit per user (USD)\nCLAUDE_TIMEOUT_SECONDS=300       # Operation timeout\n\n# Mode\nAGENTIC_MODE=true                # Agentic (default) or classic mode\nVERBOSE_LEVEL=1                  # 0=quiet, 1=normal (default), 2=detailed\n\n# Rate Limiting\nRATE_LIMIT_REQUESTS=10           # Requests per window\nRATE_LIMIT_WINDOW=60             # Window in seconds\n\n# Features (classic mode)\nENABLE_GIT_INTEGRATION=true\nENABLE_FILE_UPLOADS=true\nENABLE_QUICK_ACTIONS=true\n</code></pre> \n<h3>Agentic Platform</h3> \n<pre><code class=\"language-bash\"># Webhook API Server\nENABLE_API_SERVER=false          # Enable FastAPI webhook server\nAPI_SERVER_PORT=8080             # Server port\n\n# Webhook Authentication\nGITHUB_WEBHOOK_SECRET=...        # GitHub HMAC-SHA256 secret\nWEBHOOK_API_SECRET=...           # Bearer token for generic providers\n\n# Scheduler\nENABLE_SCHEDULER=false           # Enable cron job scheduler\n\n# Notifications\nNOTIFICATION_CHAT_IDS=123,456    # Default chat IDs for proactive notifications\n</code></pre> \n<h3>Project Threads Mode</h3> \n<pre><code class=\"language-bash\"># Enable strict topic routing by project\nENABLE_PROJECT_THREADS=true\n\n# Mode: private (default) or group\nPROJECT_THREADS_MODE=private\n\n# YAML registry file (see config/projects.example.yaml)\nPROJECTS_CONFIG_PATH=config/projects.yaml\n\n# Required only when PROJECT_THREADS_MODE=group\nPROJECT_THREADS_CHAT_ID=-1001234567890\n\n# Minimum delay (seconds) between Telegram API calls during topic sync\n# Set 0 to disable pacing\nPROJECT_THREADS_SYNC_ACTION_INTERVAL_SECONDS=1.1\n</code></pre> \n<p>In strict mode, only <code>/start</code> and <code>/sync_threads</code> work outside mapped project topics. In private mode, <code>/start</code> auto-syncs project topics for your private bot chat. To use topics with your bot, enable them in BotFather: <code>Bot Settings -&gt; Threaded mode</code>.</p> \n<blockquote> \n <p><strong>Full reference:</strong> See <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/docs/configuration.md\">docs/configuration.md</a> and <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/.env.example\"><code>.env.example</code></a>.</p> \n</blockquote> \n<h3>Finding Your Telegram User ID</h3> \n<p>Message <a href=\"https://t.me/userinfobot\">@userinfobot</a> on Telegram -- it will reply with your user ID number.</p> \n<h2>Troubleshooting</h2> \n<p><strong>Bot doesn't respond:</strong></p> \n<ul> \n <li>Check your <code>TELEGRAM_BOT_TOKEN</code> is correct</li> \n <li>Verify your user ID is in <code>ALLOWED_USERS</code></li> \n <li>Ensure Claude Code CLI is installed and accessible</li> \n <li>Check bot logs with <code>make run-debug</code></li> \n</ul> \n<p><strong>Claude integration not working:</strong></p> \n<ul> \n <li>SDK mode (default): Check <code>claude auth status</code> or verify <code>ANTHROPIC_API_KEY</code></li> \n <li>CLI mode: Verify <code>claude --version</code> and <code>claude auth status</code></li> \n <li>Check <code>CLAUDE_ALLOWED_TOOLS</code> includes necessary tools (see <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/docs/tools.md\">docs/tools.md</a> for the full reference)</li> \n</ul> \n<p><strong>High usage costs:</strong></p> \n<ul> \n <li>Adjust <code>CLAUDE_MAX_COST_PER_USER</code> to set spending limits</li> \n <li>Monitor usage with <code>/status</code></li> \n <li>Use shorter, more focused requests</li> \n</ul> \n<h2>Security</h2> \n<p>This bot implements defense-in-depth security:</p> \n<ul> \n <li><strong>Access Control</strong> -- Whitelist-based user authentication</li> \n <li><strong>Directory Isolation</strong> -- Sandboxing to approved directories</li> \n <li><strong>Rate Limiting</strong> -- Request and cost-based limits</li> \n <li><strong>Input Validation</strong> -- Injection and path traversal protection</li> \n <li><strong>Webhook Authentication</strong> -- GitHub HMAC-SHA256 and Bearer token verification</li> \n <li><strong>Audit Logging</strong> -- Complete tracking of all user actions</li> \n</ul> \n<p>See <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/SECURITY.md\">SECURITY.md</a> for details.</p> \n<h2>Development</h2> \n<pre><code class=\"language-bash\">make dev           # Install all dependencies\nmake test          # Run tests with coverage\nmake lint          # Black + isort + flake8 + mypy\nmake format        # Auto-format code\nmake run-debug     # Run with debug logging\n</code></pre> \n<h3>Version Management</h3> \n<p>The version is defined once in <code>pyproject.toml</code> and read at runtime via <code>importlib.metadata</code>. To cut a release:</p> \n<pre><code class=\"language-bash\">make bump-patch    # 1.2.0 -&gt; 1.2.1 (bug fixes)\nmake bump-minor    # 1.2.0 -&gt; 1.3.0 (new features)\nmake bump-major    # 1.2.0 -&gt; 2.0.0 (breaking changes)\n</code></pre> \n<p>Each command commits, tags, and pushes automatically, triggering CI tests and a GitHub Release with auto-generated notes.</p> \n<h3>Contributing</h3> \n<ol> \n <li>Fork the repository</li> \n <li>Create a feature branch: <code>git checkout -b feature/amazing-feature</code></li> \n <li>Make changes with tests: <code>make test &amp;&amp; make lint</code></li> \n <li>Submit a Pull Request</li> \n</ol> \n<p><strong>Code standards:</strong> Python 3.11+, Black formatting (88 chars), type hints required, pytest with &gt;85% coverage.</p> \n<h2>License</h2> \n<p>MIT License -- see <a href=\"https://raw.githubusercontent.com/RichardAtCT/claude-code-telegram/main/LICENSE\">LICENSE</a>.</p> \n<h2>Acknowledgments</h2> \n<ul> \n <li><a href=\"https://claude.ai\">Claude</a> by Anthropic</li> \n <li><a href=\"https://github.com/python-telegram-bot/python-telegram-bot\">python-telegram-bot</a></li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:09.823069Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 1,
        "final_score": 5.8,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/gogcli",
        "title": "steipete/gogcli",
        "summary": "<p>Google Suite CLI: Gmail, GCal, GDrive, GContacts.</p><hr /><h1>🧭 gogcli — Google in your terminal.</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=gogcli%F0%9F%A7%AD&amp;subheader=Google+in+your+terminal&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast, script-friendly CLI for Gmail, Calendar, Chat, Classroom, Drive, Docs, Slides, Sheets, Forms, Apps Script, Contacts, Tasks, People, Groups (Workspace), and Keep (Workspace-only). JSON-first output, multiple accounts, and least-privilege auth built in.</p> \n<h2>Features</h2> \n<ul> \n <li><strong>Gmail</strong> - search threads and messages, send emails, view attachments, manage labels/drafts/filters/delegation/vacation settings, history, and watch (Pub/Sub push)</li> \n <li><strong>Email tracking</strong> - track opens for <code>gog gmail send --track</code> with a small Cloudflare Worker backend</li> \n <li><strong>Calendar</strong> - list/create/update events, detect conflicts, manage invitations, check free/busy status, team calendars, propose new times, focus/OOO/working-location events, recurrence + reminders</li> \n <li><strong>Classroom</strong> - manage courses, roster, coursework/materials, submissions, announcements, topics, invitations, guardians, profiles</li> \n <li><strong>Chat</strong> - list/find/create spaces, list messages/threads (filter by thread/unread), send messages and DMs (Workspace-only)</li> \n <li><strong>Drive</strong> - list/search/upload/download files, manage permissions/comments, organize folders, list shared drives</li> \n <li><strong>Contacts</strong> - search/create/update contacts, access Workspace directory/other contacts</li> \n <li><strong>Tasks</strong> - manage tasklists and tasks: get/create/add/update/done/undo/delete/clear, repeat schedules</li> \n <li><strong>Sheets</strong> - read/write/update spreadsheets, insert rows/cols, format cells, read notes, create new sheets (and export via Drive)</li> \n <li><strong>Forms</strong> - create/get forms and inspect responses</li> \n <li><strong>Apps Script</strong> - create/get projects, inspect content, and run functions</li> \n <li><strong>Docs/Slides</strong> - export to PDF/DOCX/PPTX via Drive (plus create/copy, docs-to-text)</li> \n <li><strong>People</strong> - access profile information</li> \n <li><strong>Keep (Workspace only)</strong> - list/get/search notes and download attachments (service account + domain-wide delegation)</li> \n <li><strong>Groups</strong> - list groups you belong to, view group members (Google Workspace)</li> \n <li><strong>Local time</strong> - quick local/UTC time display for scripts and agents</li> \n <li><strong>Multiple accounts</strong> - manage multiple Google accounts simultaneously (with aliases)</li> \n <li><strong>Command allowlist</strong> - restrict top-level commands for sandboxed/agent runs</li> \n <li><strong>Secure credential storage</strong> using OS keyring or encrypted on-disk keyring (configurable)</li> \n <li><strong>Auto-refreshing tokens</strong> - authenticate once, use indefinitely</li> \n <li><strong>Least-privilege auth</strong> - <code>--readonly</code> and <code>--drive-scope</code> to request fewer scopes</li> \n <li><strong>Workspace service accounts</strong> - domain-wide delegation auth (preferred when configured)</li> \n <li><strong>Parseable output</strong> - JSON mode for scripting and automation (Calendar adds day-of-week fields)</li> \n</ul> \n<h2>Installation</h2> \n<h3>Homebrew</h3> \n<pre><code class=\"language-bash\">brew install steipete/tap/gogcli\n</code></pre> \n<h3>Arch User Repository</h3> \n<pre><code class=\"language-bash\">yay -S gogcli\n</code></pre> \n<h3>Build from Source</h3> \n<pre><code class=\"language-bash\">git clone https://github.com/steipete/gogcli.git\ncd gogcli\nmake\n</code></pre> \n<p>Run:</p> \n<pre><code class=\"language-bash\">./bin/gog --help\n</code></pre> \n<p>Help:</p> \n<ul> \n <li><code>gog --help</code> shows top-level command groups.</li> \n <li>Drill down with <code>gog &lt;group&gt; --help</code> (and deeper subcommands).</li> \n <li>For the full expanded command list: <code>GOG_HELP=full gog --help</code>.</li> \n <li>Make shortcut: <code>make gog -- --help</code> (or <code>make gog -- gmail --help</code>).</li> \n <li><code>make gog-help</code> shows CLI help (note: <code>make gog --help</code> is Make’s own help; use <code>--</code>).</li> \n <li>Version: <code>gog --version</code> or <code>gog version</code>.</li> \n</ul> \n<h2>Quick Start</h2> \n<h3>1. Get OAuth2 Credentials</h3> \n<p>Before adding an account, create OAuth2 credentials from Google Cloud Console:</p> \n<ol> \n <li>Open the Google Cloud Console credentials page: <a href=\"https://console.cloud.google.com/apis/credentials\">https://console.cloud.google.com/apis/credentials</a></li> \n <li>Create a project: <a href=\"https://console.cloud.google.com/projectcreate\">https://console.cloud.google.com/projectcreate</a></li> \n <li>Enable the APIs you need: \n  <ul> \n   <li>Gmail API: <a href=\"https://console.cloud.google.com/apis/api/gmail.googleapis.com\">https://console.cloud.google.com/apis/api/gmail.googleapis.com</a></li> \n   <li>Google Calendar API: <a href=\"https://console.cloud.google.com/apis/api/calendar-json.googleapis.com\">https://console.cloud.google.com/apis/api/calendar-json.googleapis.com</a></li> \n   <li>Google Chat API: <a href=\"https://console.cloud.google.com/apis/api/chat.googleapis.com\">https://console.cloud.google.com/apis/api/chat.googleapis.com</a></li> \n   <li>Google Drive API: <a href=\"https://console.cloud.google.com/apis/api/drive.googleapis.com\">https://console.cloud.google.com/apis/api/drive.googleapis.com</a></li> \n   <li>Google Classroom API: <a href=\"https://console.cloud.google.com/apis/api/classroom.googleapis.com\">https://console.cloud.google.com/apis/api/classroom.googleapis.com</a></li> \n   <li>People API (Contacts): <a href=\"https://console.cloud.google.com/apis/api/people.googleapis.com\">https://console.cloud.google.com/apis/api/people.googleapis.com</a></li> \n   <li>Google Tasks API: <a href=\"https://console.cloud.google.com/apis/api/tasks.googleapis.com\">https://console.cloud.google.com/apis/api/tasks.googleapis.com</a></li> \n   <li>Google Sheets API: <a href=\"https://console.cloud.google.com/apis/api/sheets.googleapis.com\">https://console.cloud.google.com/apis/api/sheets.googleapis.com</a></li> \n   <li>Google Forms API: <a href=\"https://console.cloud.google.com/apis/api/forms.googleapis.com\">https://console.cloud.google.com/apis/api/forms.googleapis.com</a></li> \n   <li>Apps Script API: <a href=\"https://console.cloud.google.com/apis/api/script.googleapis.com\">https://console.cloud.google.com/apis/api/script.googleapis.com</a></li> \n   <li>Cloud Identity API (Groups): <a href=\"https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com\">https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com</a></li> \n  </ul> </li> \n <li>Configure OAuth consent screen: <a href=\"https://console.cloud.google.com/auth/branding\">https://console.cloud.google.com/auth/branding</a></li> \n <li>If your app is in \"Testing\", add test users: <a href=\"https://console.cloud.google.com/auth/audience\">https://console.cloud.google.com/auth/audience</a></li> \n <li>Create OAuth client: \n  <ul> \n   <li>Go to <a href=\"https://console.cloud.google.com/auth/clients\">https://console.cloud.google.com/auth/clients</a></li> \n   <li>Click \"Create Client\"</li> \n   <li>Application type: \"Desktop app\"</li> \n   <li>Download the JSON file (usually named <code>client_secret_....apps.googleusercontent.com.json</code>)</li> \n  </ul> </li> \n</ol> \n<h3>2. Store Credentials</h3> \n<pre><code class=\"language-bash\">gog auth credentials ~/Downloads/client_secret_....json\n</code></pre> \n<p>For multiple OAuth clients/projects:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work-client.json\ngog auth credentials list\n</code></pre> \n<h3>3. Authorize Your Account</h3> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com\n</code></pre> \n<p>This will open a browser window for OAuth authorization. The refresh token is stored securely in your system keychain.</p> \n<p>Headless / remote server flows (no browser on the server):</p> \n<p>Manual interactive flow (recommended):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services user --manual\n</code></pre> \n<ul> \n <li>The CLI prints an auth URL. Open it in a local browser.</li> \n <li>After approval, copy the full loopback redirect URL from the browser address bar.</li> \n <li>Paste that URL back into the terminal when prompted.</li> \n</ul> \n<p>Split remote flow (<code>--remote</code>, useful for two-step/scripted handoff):</p> \n<pre><code class=\"language-bash\"># Step 1: print auth URL (open it locally in a browser)\ngog auth add you@gmail.com --services user --remote --step 1\n\n# Step 2: paste the full redirect URL from your browser address bar\ngog auth add you@gmail.com --services user --remote --step 2 --auth-url 'http://127.0.0.1:&lt;port&gt;/oauth2/callback?code=...&amp;state=...'\n</code></pre> \n<ul> \n <li>The <code>state</code> is cached on disk for a short time (about 10 minutes). If it expires, rerun step 1.</li> \n <li>Remote step 2 requires a redirect URL that includes <code>state</code> (state check mandatory).</li> \n</ul> \n<h3>4. Test Authentication</h3> \n<pre><code class=\"language-bash\">export GOG_ACCOUNT=you@gmail.com\ngog gmail labels list\n</code></pre> \n<h2>Authentication &amp; Secrets</h2> \n<h3>Accounts and tokens</h3> \n<p><code>gog</code> stores your OAuth refresh tokens in a “keyring” backend. Default is <code>auto</code> (best available backend for your OS/environment).</p> \n<p>Before you can run <code>gog auth add</code>, you must store OAuth client credentials once via <code>gog auth credentials &lt;credentials.json&gt;</code> (download a Desktop app OAuth client JSON from the Cloud Console). For multiple clients, use <code>gog --client &lt;name&gt; auth credentials ...</code>; tokens are isolated per client.</p> \n<p>List accounts:</p> \n<pre><code class=\"language-bash\">gog auth list\n</code></pre> \n<p>Verify tokens are usable (helps spot revoked/expired tokens):</p> \n<pre><code class=\"language-bash\">gog auth list --check\n</code></pre> \n<p>Accounts can be authorized either via OAuth refresh tokens or Workspace service accounts (domain-wide delegation). If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see <code>gog auth list</code>).</p> \n<p>Show current auth state/services for the active account:</p> \n<pre><code class=\"language-bash\">gog auth status\n</code></pre> \n<h3>Multiple OAuth clients</h3> \n<p>Use <code>--client</code> (or <code>GOG_CLIENT</code>) to select a named OAuth client:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work.json\ngog --client work auth add you@company.com\n</code></pre> \n<p>Optional domain mapping for auto-selection:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work.json --domain example.com\n</code></pre> \n<p>How it works:</p> \n<ul> \n <li>Default client is <code>default</code> (stored in <code>credentials.json</code>).</li> \n <li>Named clients are stored as <code>credentials-&lt;client&gt;.json</code>.</li> \n <li>Tokens are isolated per client (<code>token:&lt;client&gt;:&lt;email&gt;</code>); defaults are per client too.</li> \n</ul> \n<p>Client selection order (when <code>--client</code> is not set):</p> \n<ol> \n <li><code>--client</code> / <code>GOG_CLIENT</code></li> \n <li><code>account_clients</code> config (email -&gt; client)</li> \n <li><code>client_domains</code> config (domain -&gt; client)</li> \n <li>Credentials file named after the email domain (<code>credentials-example.com.json</code>)</li> \n <li><code>default</code></li> \n</ol> \n<p>Config example (JSON5):</p> \n<pre><code class=\"language-json5\">{\n  account_clients: { \"you@company.com\": \"work\" },\n  client_domains: { \"example.com\": \"work\" },\n}\n</code></pre> \n<p>List stored credentials:</p> \n<pre><code class=\"language-bash\">gog auth credentials list\n</code></pre> \n<p>See <code>docs/auth-clients.md</code> for the full client selection and mapping rules.</p> \n<h3>Keyring backend: Keychain vs encrypted file</h3> \n<p>Backends:</p> \n<ul> \n <li><code>auto</code> (default): picks the best backend for the platform.</li> \n <li><code>keychain</code>: macOS Keychain (recommended on macOS; avoids password management).</li> \n <li><code>file</code>: encrypted on-disk keyring (requires a password).</li> \n</ul> \n<p>Set backend via command (writes <code>keyring_backend</code> into <code>config.json</code>):</p> \n<pre><code class=\"language-bash\">gog auth keyring file\ngog auth keyring keychain\ngog auth keyring auto\n</code></pre> \n<p>Show current backend + source (env/config/default) and config path:</p> \n<pre><code class=\"language-bash\">gog auth keyring\n</code></pre> \n<p>Non-interactive runs (CI/ssh): file backend requires <code>GOG_KEYRING_PASSWORD</code>.</p> \n<pre><code class=\"language-bash\">export GOG_KEYRING_PASSWORD='...'\ngog --no-input auth status\n</code></pre> \n<p>Force backend via env (overrides config):</p> \n<pre><code class=\"language-bash\">export GOG_KEYRING_BACKEND=file\n</code></pre> \n<p>Precedence: <code>GOG_KEYRING_BACKEND</code> env var overrides <code>config.json</code>.</p> \n<h2>Configuration</h2> \n<h3>Account Selection</h3> \n<p>Specify the account using either a flag or environment variable:</p> \n<pre><code class=\"language-bash\"># Via flag\ngog gmail search 'newer_than:7d' --account you@gmail.com\n\n# Via alias\ngog auth alias set work work@company.com\ngog gmail search 'newer_than:7d' --account work\n\n# Via environment\nexport GOG_ACCOUNT=you@gmail.com\ngog gmail search 'newer_than:7d'\n\n# Auto-select (default account or the single stored token)\ngog gmail labels list --account auto\n</code></pre> \n<p>List configured accounts:</p> \n<pre><code class=\"language-bash\">gog auth list\n</code></pre> \n<h3>Output</h3> \n<ul> \n <li>Default: human-friendly tables on stdout.</li> \n <li><code>--plain</code>: stable TSV on stdout (tabs preserved; best for piping to tools that expect <code>\\t</code>).</li> \n <li><code>--json</code>: JSON on stdout (best for scripting).</li> \n <li>Human-facing hints/progress go to stderr.</li> \n <li>Colors are enabled only in rich TTY output and are disabled automatically for <code>--json</code> and <code>--plain</code>.</li> \n</ul> \n<h3>Service Scopes</h3> \n<p>By default, <code>gog auth add</code> requests access to the <strong>user</strong> services (see <code>gog auth services</code> for the current list and scopes).</p> \n<p>To request fewer scopes:</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive,calendar\n</code></pre> \n<p>To request read-only scopes (write operations will fail with 403 insufficient scopes):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive,calendar --readonly\n</code></pre> \n<p>To control Drive’s scope (default: <code>full</code>):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive --drive-scope full\ngog auth add you@gmail.com --services drive --drive-scope readonly\ngog auth add you@gmail.com --services drive --drive-scope file\n</code></pre> \n<p>Notes:</p> \n<ul> \n <li><code>--drive-scope readonly</code> is enough for listing/downloading/exporting via Drive (write operations will 403).</li> \n <li><code>--drive-scope file</code> is write-capable (limited to files created/opened by this app) and can’t be combined with <code>--readonly</code>.</li> \n</ul> \n<p>If you need to add services later and Google doesn't return a refresh token, re-run with <code>--force-consent</code>:</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services user --force-consent\n# Or add just Sheets\ngog auth add you@gmail.com --services sheets --force-consent\n</code></pre> \n<p><code>--services all</code> is accepted as an alias for <code>user</code> for backwards compatibility.</p> \n<p>Docs commands are implemented via the Drive API, and <code>docs</code> requests both Drive and Docs API scopes.</p> \n<p>Service scope matrix (auto-generated; run <code>go run scripts/gen-auth-services-md.go</code>):</p> \n<!-- auth-services:start --> \n<table> \n <thead> \n  <tr> \n   <th>Service</th> \n   <th>User</th> \n   <th>APIs</th> \n   <th>Scopes</th> \n   <th>Notes</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>gmail</td> \n   <td>yes</td> \n   <td>Gmail API</td> \n   <td><code>https://www.googleapis.com/auth/gmail.modify</code><br /><code>https://www.googleapis.com/auth/gmail.settings.basic</code><br /><code>https://www.googleapis.com/auth/gmail.settings.sharing</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>calendar</td> \n   <td>yes</td> \n   <td>Calendar API</td> \n   <td><code>https://www.googleapis.com/auth/calendar</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>chat</td> \n   <td>yes</td> \n   <td>Chat API</td> \n   <td><code>https://www.googleapis.com/auth/chat.spaces</code><br /><code>https://www.googleapis.com/auth/chat.messages</code><br /><code>https://www.googleapis.com/auth/chat.memberships</code><br /><code>https://www.googleapis.com/auth/chat.users.readstate.readonly</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>classroom</td> \n   <td>yes</td> \n   <td>Classroom API</td> \n   <td><code>https://www.googleapis.com/auth/classroom.courses</code><br /><code>https://www.googleapis.com/auth/classroom.rosters</code><br /><code>https://www.googleapis.com/auth/classroom.coursework.students</code><br /><code>https://www.googleapis.com/auth/classroom.coursework.me</code><br /><code>https://www.googleapis.com/auth/classroom.courseworkmaterials</code><br /><code>https://www.googleapis.com/auth/classroom.announcements</code><br /><code>https://www.googleapis.com/auth/classroom.topics</code><br /><code>https://www.googleapis.com/auth/classroom.guardianlinks.students</code><br /><code>https://www.googleapis.com/auth/classroom.profile.emails</code><br /><code>https://www.googleapis.com/auth/classroom.profile.photos</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>drive</td> \n   <td>yes</td> \n   <td>Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>docs</td> \n   <td>yes</td> \n   <td>Docs API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/documents</code></td> \n   <td>Export/copy/create via Drive</td> \n  </tr> \n  <tr> \n   <td>slides</td> \n   <td>yes</td> \n   <td>Slides API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/presentations</code></td> \n   <td>Create/edit presentations</td> \n  </tr> \n  <tr> \n   <td>contacts</td> \n   <td>yes</td> \n   <td>People API</td> \n   <td><code>https://www.googleapis.com/auth/contacts</code><br /><code>https://www.googleapis.com/auth/contacts.other.readonly</code><br /><code>https://www.googleapis.com/auth/directory.readonly</code></td> \n   <td>Contacts + other contacts + directory</td> \n  </tr> \n  <tr> \n   <td>tasks</td> \n   <td>yes</td> \n   <td>Tasks API</td> \n   <td><code>https://www.googleapis.com/auth/tasks</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>sheets</td> \n   <td>yes</td> \n   <td>Sheets API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/spreadsheets</code></td> \n   <td>Export via Drive</td> \n  </tr> \n  <tr> \n   <td>people</td> \n   <td>yes</td> \n   <td>People API</td> \n   <td><code>profile</code></td> \n   <td>OIDC profile scope</td> \n  </tr> \n  <tr> \n   <td>forms</td> \n   <td>yes</td> \n   <td>Forms API</td> \n   <td><code>https://www.googleapis.com/auth/forms.body</code><br /><code>https://www.googleapis.com/auth/forms.responses.readonly</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>appscript</td> \n   <td>yes</td> \n   <td>Apps Script API</td> \n   <td><code>https://www.googleapis.com/auth/script.projects</code><br /><code>https://www.googleapis.com/auth/script.deployments</code><br /><code>https://www.googleapis.com/auth/script.processes</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>groups</td> \n   <td>no</td> \n   <td>Cloud Identity API</td> \n   <td><code>https://www.googleapis.com/auth/cloud-identity.groups.readonly</code></td> \n   <td>Workspace only</td> \n  </tr> \n  <tr> \n   <td>keep</td> \n   <td>no</td> \n   <td>Keep API</td> \n   <td><code>https://www.googleapis.com/auth/keep.readonly</code></td> \n   <td>Workspace only; service account (domain-wide delegation)</td> \n  </tr> \n </tbody> \n</table> \n<!-- auth-services:end --> \n<h3>Service Accounts (Workspace only)</h3> \n<p>A service account is a non-human Google identity that belongs to a Google Cloud project. In Google Workspace, a service account can impersonate a user via <strong>domain-wide delegation</strong> (admin-controlled) and access APIs like Gmail/Calendar/Drive as that user.</p> \n<p>In <code>gog</code>, service accounts are an <strong>optional auth method</strong> that can be configured per account email. If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see <code>gog auth list</code>).</p> \n<h4>1) Create a Service Account (Google Cloud)</h4> \n<ol> \n <li>Create (or pick) a Google Cloud project.</li> \n <li>Enable the APIs you’ll use (e.g. Gmail, Calendar, Drive, Sheets, Docs, People, Tasks, Cloud Identity).</li> \n <li>Go to <strong>IAM &amp; Admin → Service Accounts</strong> and create a service account.</li> \n <li>In the service account details, enable <strong>Domain-wide delegation</strong>.</li> \n <li>Create a key (<strong>Keys → Add key → Create new key → JSON</strong>) and download the JSON key file.</li> \n</ol> \n<h4>2) Allowlist scopes (Google Workspace Admin Console)</h4> \n<p>Domain-wide delegation is enforced by Workspace admin settings.</p> \n<ol> \n <li>Open <strong>Admin console → Security → API controls → Domain-wide delegation</strong>.</li> \n <li>Add a new API client: \n  <ul> \n   <li>Client ID: use the service account’s “Client ID” from Google Cloud.</li> \n   <li>OAuth scopes: comma-separated list of scopes you want to allow (copy from <code>gog auth services</code> and/or your <code>gog auth add --services ...</code> usage).</li> \n  </ul> </li> \n</ol> \n<p>If a scope is missing from the allowlist, service-account token minting can fail (or API calls will 403 with insufficient permissions).</p> \n<h4>3) Configure <code>gog</code> to use the service account</h4> \n<p>Store the key for the user you want to impersonate:</p> \n<pre><code class=\"language-bash\">gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json\n</code></pre> \n<p>Verify <code>gog</code> is preferring the service account for that account:</p> \n<pre><code class=\"language-bash\">gog --account you@yourdomain.com auth status\ngog auth list\n</code></pre> \n<h3>Google Keep (Workspace only)</h3> \n<p>Keep requires Workspace + domain-wide delegation. You can configure it via the generic service-account command above (recommended), or the legacy Keep helper:</p> \n<pre><code class=\"language-bash\">gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json\ngog keep list --account you@yourdomain.com\ngog keep get &lt;noteId&gt; --account you@yourdomain.com\n</code></pre> \n<h3>Environment Variables</h3> \n<ul> \n <li><code>GOG_ACCOUNT</code> - Default account email or alias to use (avoids repeating <code>--account</code>; otherwise uses keyring default or a single stored token)</li> \n <li><code>GOG_CLIENT</code> - OAuth client name (selects stored credentials + token bucket)</li> \n <li><code>GOG_JSON</code> - Default JSON output</li> \n <li><code>GOG_PLAIN</code> - Default plain output</li> \n <li><code>GOG_COLOR</code> - Color mode: <code>auto</code> (default), <code>always</code>, or <code>never</code></li> \n <li><code>GOG_TIMEZONE</code> - Default output timezone for Calendar/Gmail (IANA name, <code>UTC</code>, or <code>local</code>)</li> \n <li><code>GOG_ENABLE_COMMANDS</code> - Comma-separated allowlist of top-level commands (e.g., <code>calendar,tasks</code>)</li> \n</ul> \n<h3>Config File (JSON5)</h3> \n<p>Find the actual config path in <code>gog --help</code> or <code>gog auth keyring</code>.</p> \n<p>Typical paths:</p> \n<ul> \n <li>macOS: <code>~/Library/Application Support/gogcli/config.json</code></li> \n <li>Linux: <code>~/.config/gogcli/config.json</code> (or <code>$XDG_CONFIG_HOME/gogcli/config.json</code>)</li> \n <li>Windows: <code>%AppData%\\\\gogcli\\\\config.json</code></li> \n</ul> \n<p>Example (JSON5 supports comments and trailing commas):</p> \n<pre><code class=\"language-json5\">{\n  // Avoid macOS Keychain prompts\n  keyring_backend: \"file\",\n  // Default output timezone for Calendar/Gmail (IANA, UTC, or local)\n  default_timezone: \"UTC\",\n  // Optional account aliases\n  account_aliases: {\n    work: \"work@company.com\",\n    personal: \"me@gmail.com\",\n  },\n  // Optional per-account OAuth client selection\n  account_clients: {\n    \"work@company.com\": \"work\",\n  },\n  // Optional domain -&gt; client mapping\n  client_domains: {\n    \"example.com\": \"work\",\n  },\n}\n</code></pre> \n<h3>Config Commands</h3> \n<pre><code class=\"language-bash\">gog config path\ngog config list\ngog config keys\ngog config get default_timezone\ngog config set default_timezone UTC\ngog config unset default_timezone\n</code></pre> \n<h3>Account Aliases</h3> \n<pre><code class=\"language-bash\">gog auth alias set work work@company.com\ngog auth alias list\ngog auth alias unset work\n</code></pre> \n<p>Aliases work anywhere you pass <code>--account</code> or <code>GOG_ACCOUNT</code> (reserved: <code>auto</code>, <code>default</code>).</p> \n<h3>Command Allowlist (Sandboxing)</h3> \n<pre><code class=\"language-bash\"># Only allow calendar + tasks commands for an agent\ngog --enable-commands calendar,tasks calendar events --today\n\n# Same via env\nexport GOG_ENABLE_COMMANDS=calendar,tasks\ngog tasks list &lt;tasklistId&gt;\n</code></pre> \n<h2>Security</h2> \n<h3>Credential Storage</h3> \n<p>OAuth credentials are stored securely in your system's keychain:</p> \n<ul> \n <li><strong>macOS</strong>: Keychain Access</li> \n <li><strong>Linux</strong>: Secret Service (GNOME Keyring, KWallet)</li> \n <li><strong>Windows</strong>: Credential Manager</li> \n</ul> \n<p>The CLI uses <a href=\"https://github.com/99designs/keyring\">github.com/99designs/keyring</a> for secure storage.</p> \n<p>If no OS keychain backend is available (e.g., Linux/WSL/container), keyring can fall back to an encrypted on-disk store and may prompt for a password; for non-interactive runs set <code>GOG_KEYRING_PASSWORD</code>.</p> \n<h3>Keychain Prompts (macOS)</h3> \n<p>macOS Keychain may prompt more than you’d expect when the “app identity” keeps changing (different binary path, <code>go run</code> temp builds, rebuilding to new <code>./bin/gog</code>, multiple copies). Keychain treats those as different apps, so it asks again.</p> \n<p>Options:</p> \n<ul> \n <li><strong>Default (recommended):</strong> keep using Keychain (secure) and run a stable <code>gog</code> binary path to reduce repeat prompts.</li> \n <li><strong>Force Keychain:</strong> <code>GOG_KEYRING_BACKEND=keychain</code> (disables any file-backend fallback).</li> \n <li><strong>Avoid Keychain prompts entirely:</strong> <code>GOG_KEYRING_BACKEND=file</code> (stores encrypted entries on disk under your config dir). \n  <ul> \n   <li>To avoid password prompts too (CI/non-interactive): set <code>GOG_KEYRING_PASSWORD=...</code> (tradeoff: secret in env).</li> \n  </ul> </li> \n</ul> \n<h3>Best Practices</h3> \n<ul> \n <li><strong>Never commit OAuth client credentials</strong> to version control</li> \n <li>Store client credentials outside your project directory</li> \n <li>Use different OAuth clients for development and production</li> \n <li>Re-authorize with <code>--force-consent</code> if you suspect token compromise</li> \n <li>Remove unused accounts with <code>gog auth remove &lt;email&gt;</code></li> \n</ul> \n<h3>OAuth Client IDs in Open Source</h3> \n<p>Some open source Google CLIs ship a pre-configured OAuth client ID/secret copied from other desktop apps to avoid OAuth consent verification, testing-user limits, or quota issues. This makes the consent screen/security emails show the other app’s name and can stop working at any time.</p> \n<p><code>gogcli</code> does not do this. Supported auth:</p> \n<ul> \n <li>Your own OAuth Desktop client JSON via <code>gog auth credentials ...</code> + <code>gog auth add ...</code></li> \n <li>Google Workspace service accounts with domain-wide delegation (Workspace only)</li> \n</ul> \n<h2>Commands</h2> \n<p>Flag aliases:</p> \n<ul> \n <li><code>--out</code> also accepts <code>--output</code>.</li> \n <li><code>--out-dir</code> also accepts <code>--output-dir</code> (Gmail thread attachment downloads).</li> \n</ul> \n<h3>Authentication</h3> \n<pre><code class=\"language-bash\">gog auth credentials &lt;path&gt;           # Store OAuth client credentials\ngog auth credentials list             # List stored OAuth client credentials\ngog --client work auth credentials &lt;path&gt;  # Store named OAuth client credentials\ngog auth add &lt;email&gt;                  # Authorize and store refresh token\ngog auth service-account set &lt;email&gt; --key &lt;path&gt;  # Configure service account impersonation (Workspace only)\ngog auth service-account status &lt;email&gt;            # Show service account status\ngog auth service-account unset &lt;email&gt;             # Remove service account\ngog auth keep &lt;email&gt; --key &lt;path&gt;                 # Legacy alias (Keep)\ngog auth keyring [backend]            # Show/set keyring backend (auto|keychain|file)\ngog auth status                       # Show current auth state/services\ngog auth services                     # List available services and OAuth scopes\ngog auth list                         # List stored accounts\ngog auth list --check                 # Validate stored refresh tokens\ngog auth remove &lt;email&gt;               # Remove a stored refresh token\ngog auth manage                       # Open accounts manager in browser\ngog auth tokens                       # Manage stored refresh tokens\n</code></pre> \n<h3>Keep (Workspace only)</h3> \n<pre><code class=\"language-bash\">gog keep list --account you@yourdomain.com\ngog keep get &lt;noteId&gt; --account you@yourdomain.com\ngog keep search &lt;query&gt; --account you@yourdomain.com\ngog keep attachment &lt;attachmentName&gt; --account you@yourdomain.com --out ./attachment.bin\n</code></pre> \n<h3>Gmail</h3> \n<pre><code class=\"language-bash\"># Search and read\ngog gmail search 'newer_than:7d' --max 10\ngog gmail thread get &lt;threadId&gt;\ngog gmail thread get &lt;threadId&gt; --download              # Download attachments to current dir\ngog gmail thread get &lt;threadId&gt; --download --out-dir ./attachments\ngog gmail get &lt;messageId&gt;\ngog gmail get &lt;messageId&gt; --format metadata\ngog gmail attachment &lt;messageId&gt; &lt;attachmentId&gt;\ngog gmail attachment &lt;messageId&gt; &lt;attachmentId&gt; --out ./attachment.bin\ngog gmail url &lt;threadId&gt;              # Print Gmail web URL\ngog gmail thread modify &lt;threadId&gt; --add STARRED --remove INBOX\n\n# Send and compose\ngog gmail send --to a@b.com --subject \"Hi\" --body \"Plain fallback\"\ngog gmail send --to a@b.com --subject \"Hi\" --body-file ./message.txt\ngog gmail send --to a@b.com --subject \"Hi\" --body-file -   # Read body from stdin\ngog gmail send --to a@b.com --subject \"Hi\" --body \"Plain fallback\" --body-html \"&lt;p&gt;Hello&lt;/p&gt;\"\n# Reply + include quoted original message (auto-generates HTML quote unless you pass --body-html)\ngog gmail send --reply-to-message-id &lt;messageId&gt; --quote --to a@b.com --subject \"Re: Hi\" --body \"My reply\"\ngog gmail drafts list\ngog gmail drafts create --subject \"Draft\" --body \"Body\"\ngog gmail drafts create --to a@b.com --subject \"Draft\" --body \"Body\"\ngog gmail drafts update &lt;draftId&gt; --subject \"Draft\" --body \"Body\"\ngog gmail drafts update &lt;draftId&gt; --to a@b.com --subject \"Draft\" --body \"Body\"\ngog gmail drafts send &lt;draftId&gt;\n\n# Labels\ngog gmail labels list\ngog gmail labels get INBOX --json  # Includes message counts\ngog gmail labels create \"My Label\"\ngog gmail labels modify &lt;threadId&gt; --add STARRED --remove INBOX\ngog gmail labels delete &lt;labelIdOrName&gt;  # Deletes user label (guards system labels; confirm)\n\n# Batch operations\ngog gmail batch delete &lt;messageId&gt; &lt;messageId&gt;\ngog gmail batch modify &lt;messageId&gt; &lt;messageId&gt; --add STARRED --remove INBOX\n\n# Filters\ngog gmail filters list\ngog gmail filters create --from 'noreply@example.com' --add-label 'Notifications'\ngog gmail filters delete &lt;filterId&gt;\n\n# Settings\ngog gmail autoforward get\ngog gmail autoforward enable --email forward@example.com\ngog gmail autoforward disable\ngog gmail forwarding list\ngog gmail forwarding add --email forward@example.com\ngog gmail sendas list\ngog gmail sendas create --email alias@example.com\ngog gmail vacation get\ngog gmail vacation enable --subject \"Out of office\" --message \"...\"\ngog gmail vacation disable\n\n# Delegation (G Suite/Workspace)\ngog gmail delegates list\ngog gmail delegates add --email delegate@example.com\ngog gmail delegates remove --email delegate@example.com\n\n# Watch (Pub/Sub push)\ngog gmail watch start --topic projects/&lt;p&gt;/topics/&lt;t&gt; --label INBOX\ngog gmail watch serve --bind 127.0.0.1 --token &lt;shared&gt; --hook-url http://127.0.0.1:18789/hooks/agent\ngog gmail watch serve --bind 0.0.0.0 --verify-oidc --oidc-email &lt;svc@...&gt; --hook-url &lt;url&gt;\ngog gmail watch serve --bind 127.0.0.1 --token &lt;shared&gt; --exclude-labels SPAM,TRASH --hook-url http://127.0.0.1:18789/hooks/agent\ngog gmail history --since &lt;historyId&gt;\n</code></pre> \n<p>Gmail watch (Pub/Sub push):</p> \n<ul> \n <li>Create Pub/Sub topic + push subscription (OIDC preferred; shared token ok for dev).</li> \n <li>Full flow + payload details: <code>docs/watch.md</code>.</li> \n <li><code>watch serve --exclude-labels</code> defaults to <code>SPAM,TRASH</code>; IDs are case-sensitive.</li> \n</ul> \n<h3>Email Tracking</h3> \n<p>Track when recipients open your emails:</p> \n<pre><code class=\"language-bash\"># Set up local tracking config (per-account; generates keys; follow printed deploy steps)\ngog gmail track setup --worker-url https://gog-email-tracker.&lt;acct&gt;.workers.dev\n\n# Send with tracking\ngog gmail send --to recipient@example.com --subject \"Hello\" --body-html \"&lt;p&gt;Hi!&lt;/p&gt;\" --track\n\n# Check opens\ngog gmail track opens &lt;tracking_id&gt;\ngog gmail track opens --to recipient@example.com\n\n# View status\ngog gmail track status\n</code></pre> \n<p>Docs: <code>docs/email-tracking.md</code> (setup/deploy) + <code>docs/email-tracking-worker.md</code> (internals).</p> \n<p><strong>Notes:</strong> <code>--track</code> requires exactly 1 recipient (no cc/bcc) and an HTML body (<code>--body-html</code> or <code>--quote</code>). Use <code>--track-split</code> to send per-recipient messages with individual tracking ids. The tracking worker stores IP/user-agent + coarse geo by default.</p> \n<h3>Calendar</h3> \n<pre><code class=\"language-bash\"># Calendars\ngog calendar calendars\ngog calendar acl &lt;calendarId&gt;         # List access control rules\ngog calendar colors                   # List available event/calendar colors\ngog calendar time --timezone America/New_York\ngog calendar users                    # List workspace users (use email as calendar ID)\n\n# Events (with timezone-aware time flags)\ngog calendar events &lt;calendarId&gt; --today                    # Today's events\ngog calendar events &lt;calendarId&gt; --tomorrow                 # Tomorrow's events\ngog calendar events &lt;calendarId&gt; --week                     # This week (Mon-Sun by default; use --week-start)\ngog calendar events &lt;calendarId&gt; --days 3                   # Next 3 days\ngog calendar events &lt;calendarId&gt; --from today --to friday   # Relative dates\ngog calendar events &lt;calendarId&gt; --from today --to friday --weekday   # Include weekday columns\ngog calendar events &lt;calendarId&gt; --from 2025-01-01T00:00:00Z --to 2025-01-08T00:00:00Z\ngog calendar events --all             # Fetch events from all calendars\ngog calendar events --calendars 1,3   # Fetch events from calendar indices (see gog calendar calendars)\ngog calendar events --cal Work --cal Personal  # Fetch events from calendars by name/ID\ngog calendar event &lt;calendarId&gt; &lt;eventId&gt;\ngog calendar get &lt;calendarId&gt; &lt;eventId&gt;                     # Alias for event\ngog calendar search \"meeting\" --today\ngog calendar search \"meeting\" --tomorrow\ngog calendar search \"meeting\" --days 365\ngog calendar search \"meeting\" --from 2025-01-01T00:00:00Z --to 2025-01-31T00:00:00Z --max 50\n\n# Search defaults to 30 days ago through 90 days ahead unless you set --from/--to/--today/--week/--days.\n# Tip: set GOG_CALENDAR_WEEKDAY=1 to default --weekday for calendar events output.\n\n# JSON event output includes timezone and localized times (useful for agents).\ngog calendar get &lt;calendarId&gt; &lt;eventId&gt; --json\n# {\n#   \"event\": {\n#     \"id\": \"...\",\n#     \"summary\": \"...\",\n#     \"startDayOfWeek\": \"Friday\",\n#     \"endDayOfWeek\": \"Friday\",\n#     \"timezone\": \"America/Los_Angeles\",\n#     \"eventTimezone\": \"America/New_York\",\n#     \"startLocal\": \"2026-01-23T20:45:00-08:00\",\n#     \"endLocal\": \"2026-01-23T22:45:00-08:00\",\n#     \"start\": { \"dateTime\": \"2026-01-23T23:45:00-05:00\" },\n#     \"end\": { \"dateTime\": \"2026-01-24T01:45:00-05:00\" }\n#   }\n# }\n\n# Team calendars (requires Cloud Identity API for Google Workspace)\ngog calendar team &lt;group-email&gt; --today           # Show team's events for today\ngog calendar team &lt;group-email&gt; --week            # Show team's events for the week (use --week-start)\ngog calendar team &lt;group-email&gt; --freebusy        # Show only busy/free blocks (faster)\ngog calendar team &lt;group-email&gt; --query \"standup\" # Filter by event title\n\n# Create and update\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Meeting\" \\\n  --from 2025-01-15T10:00:00Z \\\n  --to 2025-01-15T11:00:00Z\n\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Team Sync\" \\\n  --from 2025-01-15T14:00:00Z \\\n  --to 2025-01-15T15:00:00Z \\\n  --attendees \"alice@example.com,bob@example.com\" \\\n  --location \"Zoom\"\n\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --summary \"Updated Meeting\" \\\n  --from 2025-01-15T11:00:00Z \\\n  --to 2025-01-15T12:00:00Z\n\n# Send notifications when creating/updating\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Team Sync\" \\\n  --from 2025-01-15T14:00:00Z \\\n  --to 2025-01-15T15:00:00Z \\\n  --send-updates all\n\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --send-updates externalOnly\n\n# Default: no attendee notifications unless you pass --send-updates.\ngog calendar delete &lt;calendarId&gt; &lt;eventId&gt; \\\n  --send-updates all --force\n\n# Recurrence + reminders\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Payment\" \\\n  --from 2025-02-11T09:00:00-03:00 \\\n  --to 2025-02-11T09:15:00-03:00 \\\n  --rrule \"RRULE:FREQ=MONTHLY;BYMONTHDAY=11\" \\\n  --reminder \"email:3d\" \\\n  --reminder \"popup:30m\"\n\n# Special event types via --event-type (focus-time/out-of-office/working-location)\ngog calendar create primary \\\n  --event-type focus-time \\\n  --from 2025-01-15T13:00:00Z \\\n  --to 2025-01-15T14:00:00Z\n\ngog calendar create primary \\\n  --event-type out-of-office \\\n  --from 2025-01-20 \\\n  --to 2025-01-21 \\\n  --all-day\n\ngog calendar create primary \\\n  --event-type working-location \\\n  --working-location-type office \\\n  --working-office-label \"HQ\" \\\n  --from 2025-01-22 \\\n  --to 2025-01-23\n\n# Dedicated shortcuts (same event types, more opinionated defaults)\ngog calendar focus-time --from 2025-01-15T13:00:00Z --to 2025-01-15T14:00:00Z\ngog calendar out-of-office --from 2025-01-20 --to 2025-01-21 --all-day\ngog calendar working-location --type office --office-label \"HQ\" --from 2025-01-22 --to 2025-01-23\n# Add attendees without replacing existing attendees/RSVP state\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --add-attendee \"alice@example.com,bob@example.com\"\n\ngog calendar delete &lt;calendarId&gt; &lt;eventId&gt;\n\n# Invitations\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status accepted\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status declined\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status tentative\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status declined --send-updates externalOnly\n\n# Propose a new time (browser-only flow; API limitation)\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt;\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt; --open\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt; --decline --comment \"Can we do 5pm?\"\n\n# Availability\ngog calendar freebusy --calendars \"primary,work@example.com\" \\\n  --from 2025-01-15T00:00:00Z \\\n  --to 2025-01-16T00:00:00Z\n\ngog calendar conflicts --calendars \"primary,work@example.com\" \\\n  --today                             # Today's conflicts\n</code></pre> \n<h3>Time</h3> \n<pre><code class=\"language-bash\">gog time now\ngog time now --timezone UTC\n</code></pre> \n<h3>Drive</h3> \n<pre><code class=\"language-bash\"># List and search\ngog drive ls --max 20\ngog drive ls --parent &lt;folderId&gt; --max 20\ngog drive ls --no-all-drives            # Only list from \"My Drive\"\ngog drive search \"invoice\" --max 20\ngog drive search \"invoice\" --no-all-drives\ngog drive search \"mimeType = 'application/pdf'\" --raw-query\ngog drive get &lt;fileId&gt;                # Get file metadata\ngog drive url &lt;fileId&gt;                # Print Drive web URL\ngog drive copy &lt;fileId&gt; \"Copy Name\"\n\n# Upload and download\ngog drive upload ./path/to/file --parent &lt;folderId&gt;\ngog drive upload ./path/to/file --replace &lt;fileId&gt;  # Replace file content in-place (preserves shared link)\ngog drive upload ./report.docx --convert\ngog drive upload ./chart.png --convert-to sheet\ngog drive upload ./report.docx --convert --name report.docx\ngog drive download &lt;fileId&gt; --out ./downloaded.bin\ngog drive download &lt;fileId&gt; --format pdf --out ./exported.pdf     # Google Workspace files only\ngog drive download &lt;fileId&gt; --format docx --out ./doc.docx\ngog drive download &lt;fileId&gt; --format pptx --out ./slides.pptx\n\n# Organize\ngog drive mkdir \"New Folder\"\ngog drive mkdir \"New Folder\" --parent &lt;parentFolderId&gt;\ngog drive rename &lt;fileId&gt; \"New Name\"\ngog drive move &lt;fileId&gt; --parent &lt;destinationFolderId&gt;\ngog drive delete &lt;fileId&gt;             # Move to trash\ngog drive delete &lt;fileId&gt; --permanent # Permanently delete\n\n# Permissions\ngog drive permissions &lt;fileId&gt;\ngog drive share &lt;fileId&gt; --to user --email user@example.com --role reader\ngog drive share &lt;fileId&gt; --to user --email user@example.com --role writer\ngog drive share &lt;fileId&gt; --to domain --domain example.com --role reader\ngog drive unshare &lt;fileId&gt; --permission-id &lt;permissionId&gt;\n\n# Shared drives (Team Drives)\ngog drive drives --max 100\n</code></pre> \n<h3>Docs / Slides / Sheets</h3> \n<pre><code class=\"language-bash\"># Docs\ngog docs info &lt;docId&gt;\ngog docs cat &lt;docId&gt; --max-bytes 10000\ngog docs create \"My Doc\"\ngog docs create \"My Doc\" --file ./doc.md            # Import markdown\ngog docs copy &lt;docId&gt; \"My Doc Copy\"\ngog docs export &lt;docId&gt; --format pdf --out ./doc.pdf\ngog docs list-tabs &lt;docId&gt;\ngog docs cat &lt;docId&gt; --tab \"Notes\"\ngog docs cat &lt;docId&gt; --all-tabs\ngog docs update &lt;docId&gt; --format markdown --content-file ./doc.md\ngog docs write &lt;docId&gt; --replace --markdown --file ./doc.md\ngog docs find-replace &lt;docId&gt; \"old\" \"new\"\n\n# Slides\ngog slides info &lt;presentationId&gt;\ngog slides create \"My Deck\"\ngog slides create-from-markdown \"My Deck\" --content-file ./slides.md\ngog slides copy &lt;presentationId&gt; \"My Deck Copy\"\ngog slides export &lt;presentationId&gt; --format pdf --out ./deck.pdf\ngog slides list-slides &lt;presentationId&gt;\ngog slides add-slide &lt;presentationId&gt; ./slide.png --notes \"Speaker notes\"\ngog slides update-notes &lt;presentationId&gt; &lt;slideId&gt; --notes \"Updated notes\"\ngog slides replace-slide &lt;presentationId&gt; &lt;slideId&gt; ./new-slide.png --notes \"New notes\"\n\n# Sheets\ngog sheets copy &lt;spreadsheetId&gt; \"My Sheet Copy\"\ngog sheets export &lt;spreadsheetId&gt; --format pdf --out ./sheet.pdf\ngog sheets format &lt;spreadsheetId&gt; 'Sheet1!A1:B2' --format-json '{\"textFormat\":{\"bold\":true}}' --format-fields 'userEnteredFormat.textFormat.bold'\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" rows 2 --count 3\ngog sheets notes &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n</code></pre> \n<h3>Contacts</h3> \n<pre><code class=\"language-bash\"># Personal contacts\ngog contacts list --max 50\ngog contacts search \"Ada\" --max 50\ngog contacts get people/&lt;resourceName&gt;\ngog contacts get user@example.com     # Get by email\n\n# Other contacts (people you've interacted with)\ngog contacts other list --max 50\ngog contacts other search \"John\" --max 50\n\n# Create and update\ngog contacts create \\\n  --given \"John\" \\\n  --family \"Doe\" \\\n  --email \"john@example.com\" \\\n  --phone \"+1234567890\"\n\ngog contacts update people/&lt;resourceName&gt; \\\n  --given \"Jane\" \\\n  --email \"jane@example.com\" \\\n  --birthday \"1990-05-12\" \\\n  --notes \"Met at WWDC\"\n\n# Update via JSON (see docs/contacts-json-update.md)\ngog contacts get people/&lt;resourceName&gt; --json | \\\n  jq '(.contact.urls //= []) | (.contact.urls += [{\"value\":\"obsidian://open?vault=notes&amp;file=People/John%20Doe\",\"type\":\"profile\"}])' | \\\n  gog contacts update people/&lt;resourceName&gt; --from-file -\n\ngog contacts delete people/&lt;resourceName&gt;\n\n# Workspace directory (requires Google Workspace)\ngog contacts directory list --max 50\ngog contacts directory search \"Jane\" --max 50\n</code></pre> \n<h3>Tasks</h3> \n<pre><code class=\"language-bash\"># Task lists\ngog tasks lists --max 50\ngog tasks lists create &lt;title&gt;\n\n# Tasks in a list\ngog tasks list &lt;tasklistId&gt; --max 50\ngog tasks get &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks add &lt;tasklistId&gt; --title \"Task title\"\ngog tasks add &lt;tasklistId&gt; --title \"Weekly sync\" --due 2025-02-01 --repeat weekly --repeat-count 4\ngog tasks add &lt;tasklistId&gt; --title \"Daily standup\" --due 2025-02-01 --repeat daily --repeat-until 2025-02-05\ngog tasks update &lt;tasklistId&gt; &lt;taskId&gt; --title \"New title\"\ngog tasks done &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks undo &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks delete &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks clear &lt;tasklistId&gt;\n\n# Note: Google Tasks treats due dates as date-only; time components may be ignored.\n# See docs/dates.md for all supported date/time input formats across commands.\n</code></pre> \n<h3>Sheets</h3> \n<pre><code class=\"language-bash\"># Read\ngog sheets metadata &lt;spreadsheetId&gt;\ngog sheets get &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Export (via Drive)\ngog sheets export &lt;spreadsheetId&gt; --format pdf --out ./sheet.pdf\ngog sheets export &lt;spreadsheetId&gt; --format xlsx --out ./sheet.xlsx\n\n# Write\ngog sheets update &lt;spreadsheetId&gt; 'A1' 'val1|val2,val3|val4'\ngog sheets update &lt;spreadsheetId&gt; 'A1' --values-json '[[\"a\",\"b\"],[\"c\",\"d\"]]'\ngog sheets update &lt;spreadsheetId&gt; 'Sheet1!A1:C1' 'new|row|data' --copy-validation-from 'Sheet1!A2:C2'\ngog sheets append &lt;spreadsheetId&gt; 'Sheet1!A:C' 'new|row|data'\ngog sheets append &lt;spreadsheetId&gt; 'Sheet1!A:C' 'new|row|data' --copy-validation-from 'Sheet1!A2:C2'\ngog sheets clear &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Format\ngog sheets format &lt;spreadsheetId&gt; 'Sheet1!A1:B2' --format-json '{\"textFormat\":{\"bold\":true}}' --format-fields 'userEnteredFormat.textFormat.bold'\n\n# Insert rows/cols\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" rows 2 --count 3\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" cols 3 --after\n\n# Notes\ngog sheets notes &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Create\ngog sheets create \"My New Spreadsheet\" --sheets \"Sheet1,Sheet2\"\n</code></pre> \n<h3>Forms</h3> \n<pre><code class=\"language-bash\"># Forms\ngog forms get &lt;formId&gt;\ngog forms create --title \"Weekly Check-in\" --description \"Friday async update\"\n\n# Responses\ngog forms responses list &lt;formId&gt; --max 20\ngog forms responses get &lt;formId&gt; &lt;responseId&gt;\n</code></pre> \n<h3>Apps Script</h3> \n<pre><code class=\"language-bash\"># Projects\ngog appscript get &lt;scriptId&gt;\ngog appscript content &lt;scriptId&gt;\ngog appscript create --title \"Automation Helpers\"\ngog appscript create --title \"Bound Script\" --parent-id &lt;driveFileId&gt;\n\n# Execute functions\ngog appscript run &lt;scriptId&gt; myFunction --params '[\"arg1\", 123, true]'\ngog appscript run &lt;scriptId&gt; myFunction --dev-mode\n</code></pre> \n<h3>People</h3> \n<pre><code class=\"language-bash\"># Profile\ngog people me\ngog people get people/&lt;userId&gt;\n\n# Search the Workspace directory\ngog people search \"Ada Lovelace\" --max 5\n\n# Relations (defaults to people/me)\ngog people relations\ngog people relations people/&lt;userId&gt; --type manager\n</code></pre> \n<h3>Chat</h3> \n<pre><code class=\"language-bash\"># Spaces\ngog chat spaces list\ngog chat spaces find \"Engineering\"\ngog chat spaces create \"Engineering\" --member alice@company.com --member bob@company.com\n\n# Messages\ngog chat messages list spaces/&lt;spaceId&gt; --max 5\ngog chat messages list spaces/&lt;spaceId&gt; --thread &lt;threadId&gt;\ngog chat messages list spaces/&lt;spaceId&gt; --unread\ngog chat messages send spaces/&lt;spaceId&gt; --text \"Build complete!\" --thread spaces/&lt;spaceId&gt;/threads/&lt;threadId&gt;\n\n# Threads\ngog chat threads list spaces/&lt;spaceId&gt;\n\n# Direct messages\ngog chat dm space user@company.com\ngog chat dm send user@company.com --text \"ping\"\n</code></pre> \n<p>Note: Chat commands require a Google Workspace account (consumer @gmail.com accounts are not supported).</p> \n<h3>Groups (Google Workspace)</h3> \n<pre><code class=\"language-bash\"># List groups you belong to\ngog groups list\n\n# List members of a group\ngog groups members engineering@company.com\n</code></pre> \n<p>Note: Groups commands require the Cloud Identity API and the <code>cloud-identity.groups.readonly</code> scope. If you get a permissions error, re-authenticate:</p> \n<pre><code class=\"language-bash\">gog auth add your@email.com --services groups --force-consent\n</code></pre> \n<h3>Classroom (Google Workspace for Education)</h3> \n<pre><code class=\"language-bash\"># Courses\ngog classroom courses list\ngog classroom courses list --role teacher\ngog classroom courses get &lt;courseId&gt;\ngog classroom courses create --name \"Math 101\"\ngog classroom courses update &lt;courseId&gt; --name \"Math 102\"\ngog classroom courses archive &lt;courseId&gt;\ngog classroom courses unarchive &lt;courseId&gt;\ngog classroom courses url &lt;courseId&gt;\n\n# Roster\ngog classroom roster &lt;courseId&gt;\ngog classroom roster &lt;courseId&gt; --students\ngog classroom students add &lt;courseId&gt; &lt;userId&gt;\ngog classroom teachers add &lt;courseId&gt; &lt;userId&gt;\n\n# Coursework\ngog classroom coursework list &lt;courseId&gt;\ngog classroom coursework get &lt;courseId&gt; &lt;courseworkId&gt;\ngog classroom coursework create &lt;courseId&gt; --title \"Homework 1\" --type ASSIGNMENT --state PUBLISHED\ngog classroom coursework update &lt;courseId&gt; &lt;courseworkId&gt; --title \"Updated\"\ngog classroom coursework assignees &lt;courseId&gt; &lt;courseworkId&gt; --mode INDIVIDUAL_STUDENTS --add-student &lt;studentId&gt;\n\n# Materials\ngog classroom materials list &lt;courseId&gt;\ngog classroom materials create &lt;courseId&gt; --title \"Syllabus\" --state PUBLISHED\n\n# Submissions\ngog classroom submissions list &lt;courseId&gt; &lt;courseworkId&gt;\ngog classroom submissions get &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions grade &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt; --grade 85\ngog classroom submissions return &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions turn-in &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions reclaim &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\n\n# Announcements\ngog classroom announcements list &lt;courseId&gt;\ngog classroom announcements create &lt;courseId&gt; --text \"Welcome!\"\ngog classroom announcements update &lt;courseId&gt; &lt;announcementId&gt; --text \"Updated\"\ngog classroom announcements assignees &lt;courseId&gt; &lt;announcementId&gt; --mode INDIVIDUAL_STUDENTS --add-student &lt;studentId&gt;\n\n# Topics\ngog classroom topics list &lt;courseId&gt;\ngog classroom topics create &lt;courseId&gt; --name \"Unit 1\"\ngog classroom topics update &lt;courseId&gt; &lt;topicId&gt; --name \"Unit 2\"\n\n# Invitations\ngog classroom invitations list\ngog classroom invitations create &lt;courseId&gt; &lt;userId&gt; --role student\ngog classroom invitations accept &lt;invitationId&gt;\n\n# Guardians\ngog classroom guardians list &lt;studentId&gt;\ngog classroom guardians get &lt;studentId&gt; &lt;guardianId&gt;\ngog classroom guardians delete &lt;studentId&gt; &lt;guardianId&gt;\n\n# Guardian invitations\ngog classroom guardian-invitations list &lt;studentId&gt;\ngog classroom guardian-invitations create &lt;studentId&gt; --email parent@example.com\n\n# Profiles\ngog classroom profile get\ngog classroom profile get &lt;userId&gt;\n</code></pre> \n<p>Note: Classroom commands require a Google Workspace for Education account. Personal Google accounts have limited Classroom functionality.</p> \n<h3>Docs</h3> \n<pre><code class=\"language-bash\"># Export (via Drive)\ngog docs export &lt;docId&gt; --format pdf --out ./doc.pdf\ngog docs export &lt;docId&gt; --format docx --out ./doc.docx\ngog docs export &lt;docId&gt; --format txt --out ./doc.txt\n</code></pre> \n<h3>Slides</h3> \n<pre><code class=\"language-bash\"># Export (via Drive)\ngog slides export &lt;presentationId&gt; --format pptx --out ./deck.pptx\ngog slides export &lt;presentationId&gt; --format pdf --out ./deck.pdf\n</code></pre> \n<h2>Output Formats</h2> \n<h3>Text</h3> \n<p>Human-readable output with colors (default):</p> \n<pre><code class=\"language-bash\">$ gog gmail search 'newer_than:7d' --max 3\nTHREAD_ID           SUBJECT                           FROM                  DATE\n18f1a2b3c4d5e6f7    Meeting notes                     alice@example.com     2025-01-10\n17e1d2c3b4a5f6e7    Invoice #12345                    billing@vendor.com    2025-01-09\n16d1c2b3a4e5f6d7    Project update                    bob@example.com       2025-01-08\n</code></pre> \n<p>Message-level search (one row per email; add <code>--include-body</code> to fetch/decode bodies):</p> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 3\nID                  THREAD             SUBJECT                           FROM                  DATE\n18f1a2b3c4d5e6f7    9e8d7c6b5a4f3e2d    Meeting notes                     alice@example.com     2025-01-10\n17e1d2c3b4a5f6e7    9e8d7c6b5a4f3e2d    Invoice #12345                    billing@vendor.com    2025-01-09\n16d1c2b3a4e5f6d7    7f6e5d4c3b2a1908    Project update                    bob@example.com       2025-01-08\n</code></pre> \n<h3>JSON</h3> \n<p>Machine-readable output for scripting and automation:</p> \n<pre><code class=\"language-bash\">$ gog gmail search 'newer_than:7d' --max 3 --json\n{\n  \"threads\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"snippet\": \"Meeting notes from today...\",\n      \"messages\": [...]\n    },\n    ...\n  ]\n}\n</code></pre> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 3 --json\n{\n  \"messages\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"threadId\": \"9e8d7c6b5a4f3e2d\",\n      \"subject\": \"Meeting notes\",\n      \"from\": \"alice@example.com\",\n      \"date\": \"2025-01-10\"\n    },\n    ...\n  ]\n}\n</code></pre> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 1 --include-body --json\n{\n  \"messages\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"threadId\": \"9e8d7c6b5a4f3e2d\",\n      \"subject\": \"Meeting notes\",\n      \"from\": \"alice@example.com\",\n      \"date\": \"2025-01-10\",\n      \"body\": \"Hi team — meeting notes...\"\n    }\n  ]\n}\n</code></pre> \n<p>Data goes to stdout, errors and progress to stderr for clean piping:</p> \n<pre><code class=\"language-bash\">gog --json drive ls --max 5 | jq '.files[] | select(.mimeType==\"application/pdf\")'\n</code></pre> \n<p>Useful pattern:</p> \n<ul> \n <li><code>gog --json ... | jq .</code></li> \n</ul> \n<p>Calendar JSON convenience fields:</p> \n<ul> \n <li><code>startDayOfWeek</code> / <code>endDayOfWeek</code> on event payloads (derived from start/end).</li> \n</ul> \n<h2>Examples</h2> \n<h3>Search recent emails and download attachments</h3> \n<pre><code class=\"language-bash\"># Search for emails from the last week\ngog gmail search 'newer_than:7d has:attachment' --max 10\n\n# Get thread details and download attachments\ngog gmail thread get &lt;threadId&gt; --download\n</code></pre> \n<h3>Modify labels on a thread</h3> \n<pre><code class=\"language-bash\"># Archive and star a thread\ngog gmail thread modify &lt;threadId&gt; --remove INBOX --add STARRED\n</code></pre> \n<h3>Create a calendar event with attendees</h3> \n<pre><code class=\"language-bash\"># Find a free time slot\ngog calendar freebusy --calendars \"primary\" \\\n  --from 2025-01-15T00:00:00Z \\\n  --to 2025-01-16T00:00:00Z\n\n# Create the meeting\ngog calendar create primary \\\n  --summary \"Team Standup\" \\\n  --from 2025-01-15T10:00:00Z \\\n  --to 2025-01-15T10:30:00Z \\\n  --attendees \"alice@example.com,bob@example.com\"\n</code></pre> \n<h3>Find and download files from Drive</h3> \n<pre><code class=\"language-bash\"># Search for PDFs\ngog drive search \"invoice filetype:pdf\" --max 20 --json | \\\n  jq -r '.files[] | .id' | \\\n  while read fileId; do\n    gog drive download \"$fileId\"\n  done\n</code></pre> \n<h3>Manage multiple accounts</h3> \n<pre><code class=\"language-bash\"># Check personal Gmail\ngog gmail search 'is:unread' --account personal@gmail.com\n\n# Check work Gmail\ngog gmail search 'is:unread' --account work@company.com\n\n# Or set default\nexport GOG_ACCOUNT=work@company.com\ngog gmail search 'is:unread'\n</code></pre> \n<h3>Update a Google Sheet from a CSV</h3> \n<pre><code class=\"language-bash\"># Convert CSV to pipe-delimited format and update sheet\ncat data.csv | tr ',' '|' | \\\n  gog sheets update &lt;spreadsheetId&gt; 'Sheet1!A1'\n</code></pre> \n<h3>Export Sheets / Docs / Slides</h3> \n<pre><code class=\"language-bash\"># Sheets\ngog sheets export &lt;spreadsheetId&gt; --format pdf\n\n# Docs\ngog docs export &lt;docId&gt; --format docx\n\n# Slides\ngog slides export &lt;presentationId&gt; --format pptx\n</code></pre> \n<h3>Batch process Gmail threads</h3> \n<pre><code class=\"language-bash\"># Mark all emails from a sender as read\ngog --json gmail search 'from:noreply@example.com' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --remove UNREAD\n\n# Archive old emails\ngog --json gmail search 'older_than:1y' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --remove INBOX\n\n# Label important emails\ngog --json gmail search 'from:boss@example.com' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --add IMPORTANT\n</code></pre> \n<h2>Advanced Features</h2> \n<h3>Verbose Mode</h3> \n<p>Enable verbose logging for troubleshooting:</p> \n<pre><code class=\"language-bash\">gog --verbose gmail search 'newer_than:7d'\n# Shows API requests and responses\n</code></pre> \n<h2>Global Flags</h2> \n<p>All commands support these flags:</p> \n<ul> \n <li><code>--account &lt;email|alias|auto&gt;</code> - Account to use (overrides GOG_ACCOUNT)</li> \n <li><code>--enable-commands &lt;csv&gt;</code> - Allowlist top-level commands (e.g., <code>calendar,tasks</code>)</li> \n <li><code>--json</code> - Output JSON to stdout (best for scripting)</li> \n <li><code>--plain</code> - Output stable, parseable text to stdout (TSV; no colors)</li> \n <li><code>--color &lt;mode&gt;</code> - Color mode: <code>auto</code>, <code>always</code>, or <code>never</code> (default: auto)</li> \n <li><code>--force</code> - Skip confirmations for destructive commands</li> \n <li><code>--no-input</code> - Never prompt; fail instead (useful for CI)</li> \n <li><code>--verbose</code> - Enable verbose logging</li> \n <li><code>--help</code> - Show help for any command</li> \n</ul> \n<h2>Shell Completions</h2> \n<p>Generate shell completions for your preferred shell:</p> \n<h3>Bash</h3> \n<pre><code class=\"language-bash\"># macOS (with Homebrew)\ngog completion bash &gt; $(brew --prefix)/etc/bash_completion.d/gog\n\n# Linux\ngog completion bash &gt; /etc/bash_completion.d/gog\n\n# Or load directly in your current session\nsource &lt;(gog completion bash)\n</code></pre> \n<h3>Zsh</h3> \n<pre><code class=\"language-zsh\"># Generate completion file\ngog completion zsh &gt; \"${fpath[1]}/_gog\"\n\n# Or add to .zshrc for automatic loading\necho 'eval \"$(gog completion zsh)\"' &gt;&gt; ~/.zshrc\n\n# Enable completions if not already enabled\necho \"autoload -U compinit; compinit\" &gt;&gt; ~/.zshrc\n</code></pre> \n<h3>Fish</h3> \n<pre><code class=\"language-fish\">gog completion fish &gt; ~/.config/fish/completions/gog.fish\n</code></pre> \n<h3>PowerShell</h3> \n<pre><code class=\"language-powershell\"># Load for current session\ngog completion powershell | Out-String | Invoke-Expression\n\n# Or add to profile for all sessions\ngog completion powershell &gt;&gt; $PROFILE\n</code></pre> \n<p>After installing completions, start a new shell session for changes to take effect.</p> \n<h2>Development</h2> \n<p>After cloning, install tools:</p> \n<pre><code class=\"language-bash\">make tools\n</code></pre> \n<p>Pinned tools (installed into <code>.tools/</code>):</p> \n<ul> \n <li>Format: <code>make fmt</code> (goimports + gofumpt)</li> \n <li>Lint: <code>make lint</code> (golangci-lint)</li> \n <li>Test: <code>make test</code></li> \n</ul> \n<p>CI runs format checks, tests, and lint on push/PR.</p> \n<h3>Integration Tests (Live Google APIs)</h3> \n<p>Opt-in tests that hit real Google APIs using your stored <code>gog</code> credentials/tokens.</p> \n<pre><code class=\"language-bash\"># Optional: override which account to use\nexport GOG_IT_ACCOUNT=you@gmail.com\nexport GOG_CLIENT=work\ngo test -tags=integration ./...\n</code></pre> \n<p>Tip: if you want to avoid macOS Keychain prompts during these runs, set <code>GOG_KEYRING_BACKEND=file</code> and <code>GOG_KEYRING_PASSWORD=...</code> (uses encrypted on-disk keyring).</p> \n<h3>Live Test Script (CLI)</h3> \n<p>Fast end-to-end smoke checks against live APIs:</p> \n<pre><code class=\"language-bash\">scripts/live-test.sh --fast\nscripts/live-test.sh --account you@gmail.com --skip groups,keep,calendar-enterprise\nscripts/live-test.sh --client work --account you@company.com\n</code></pre> \n<p>Script toggles:</p> \n<ul> \n <li><code>--auth all,groups</code> to re-auth before running</li> \n <li><code>--client &lt;name&gt;</code> to select OAuth client credentials</li> \n <li><code>--strict</code> to fail on optional features (groups/keep/enterprise)</li> \n <li><code>--allow-nontest</code> to override the test-account guardrail</li> \n</ul> \n<p>Go test wrapper (opt-in):</p> \n<pre><code class=\"language-bash\">GOG_LIVE=1 go test -tags=integration ./internal/integration -run Live\n</code></pre> \n<p>Optional env:</p> \n<ul> \n <li><code>GOG_LIVE_FAST=1</code></li> \n <li><code>GOG_LIVE_SKIP=groups,keep</code></li> \n <li><code>GOG_LIVE_AUTH=all,groups</code></li> \n <li><code>GOG_LIVE_ALLOW_NONTEST=1</code></li> \n <li><code>GOG_LIVE_EMAIL_TEST=steipete+gogtest@gmail.com</code></li> \n <li><code>GOG_LIVE_GROUP_EMAIL=group@domain</code></li> \n <li><code>GOG_LIVE_CLASSROOM_COURSE=&lt;courseId&gt;</code></li> \n <li><code>GOG_LIVE_CLASSROOM_CREATE=1</code></li> \n <li><code>GOG_LIVE_CLASSROOM_ALLOW_STATE=1</code></li> \n <li><code>GOG_LIVE_TRACK=1</code></li> \n <li><code>GOG_LIVE_GMAIL_BATCH_DELETE=1</code></li> \n <li><code>GOG_LIVE_GMAIL_FILTERS=1</code></li> \n <li><code>GOG_LIVE_GMAIL_WATCH_TOPIC=projects/.../topics/...</code></li> \n <li><code>GOG_LIVE_CALENDAR_RESPOND=1</code></li> \n <li><code>GOG_LIVE_CALENDAR_RECURRENCE=1</code></li> \n <li><code>GOG_KEEP_SERVICE_ACCOUNT=/path/to/service-account.json</code></li> \n <li><code>GOG_KEEP_IMPERSONATE=user@workspace-domain</code></li> \n</ul> \n<h3>Make Shortcut</h3> \n<p>Build and run:</p> \n<pre><code class=\"language-bash\">make gog auth add you@gmail.com\n</code></pre> \n<p>For clean stdout when scripting:</p> \n<ul> \n <li>Use <code>--</code> when the first arg is a flag: <code>make gog -- --json gmail search \"from:me\" | jq .</code></li> \n</ul> \n<h2>License</h2> \n<p>MIT</p> \n<h2>Links</h2> \n<ul> \n <li><a href=\"https://github.com/steipete/gogcli\">GitHub Repository</a></li> \n <li><a href=\"https://developers.google.com/gmail/api\">Gmail API Documentation</a></li> \n <li><a href=\"https://developers.google.com/calendar\">Google Calendar API Documentation</a></li> \n <li><a href=\"https://developers.google.com/drive\">Google Drive API Documentation</a></li> \n <li><a href=\"https://developers.google.com/people\">Google People API Documentation</a></li> \n <li><a href=\"https://developers.google.com/tasks\">Google Tasks API Documentation</a></li> \n <li><a href=\"https://developers.google.com/sheets\">Google Sheets API Documentation</a></li> \n <li><a href=\"https://cloud.google.com/identity/docs/reference/rest\">Cloud Identity API Documentation</a></li> \n</ul> \n<h2>Credits</h2> \n<p>This project is inspired by Mario Zechner's original CLIs:</p> \n<ul> \n <li><a href=\"https://github.com/badlogic/gmcli\">gmcli</a></li> \n <li><a href=\"https://github.com/badlogic/gccli\">gccli</a></li> \n <li><a href=\"https://github.com/badlogic/gdcli\">gdcli</a></li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:11.022655Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 16,
        "timeliness_score": 1,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/dino_kukic/optimizing-documentation-for-search-518c",
        "title": "Optimizing documentation for search",
        "summary": "<p>Here’s an obvious statement. Well-optimized documentation for search is important. And, I’ll try to cover everything I think will make your documentation rank better and be helpful to developers right where they search for the answers.</p>\n\n<blockquote>\n<p>I am not too much into the weeds of different docs generators and some of them may be limited in how to handle all of these or they may be handling some of these natively, but the guide itself tries to provide a platform agnostic overview, kinda looking from the outside. That’s also how search engines look at your pages. </p>\n</blockquote>\n\n<h2>\n  \n  \n  Subdomain vs. subfolder\n</h2>\n\n<p>I’ll always prefer a subfolder (<code>/docs</code>) over a subdomain (<code>docs.</code>) approach, mainly because in practice I’ve seen quite a few examples where traffic went up for both main domain and subdomain pages after the merge. On top of that, it’s a live and forever debate in the SEO community which revolves around <em>“it doesn’t matter”</em> or <em>“subdomain is worse”</em>. Given that keeping everything in the subfolder doesn’t hurt in any case, it’s just a <em>“better safe than sorry”</em> type of situation. So, where technical means allow it, subfolder is the way to go. Here are the ways to achieve it:</p>\n\n<ul>\n<li>Either you have the same frontend tech-stack for everything, or</li>\n<li>You can set up a reverse proxy to serve docs content from another (sub)domain on /docs, but bear in mind that this will introduce some additional latency.</li>\n</ul>\n\n<h2>\n  \n  \n  Docs versioning\n</h2>\n\n<p>Here’s another obvious statement. Docs are a living thing. Given the fact that they follow product development, things can change frequently, items deleted, merged into another topic, separated into its own topic and more. And, more often than not, bigger changes will prompt the company to create another version of the docs and SEO-wise, this can cause a lot of breaking changes.</p>\n\n<h3>\n  \n  \n  URL structure\n</h3>\n\n<p>It matters a lot more than we’d like it to be. One decision you’ll have to make is whether to keep things in a separate folder such as <code>/docs/v2/</code> or use the parameters such as <code>/docs?version=2</code>. Whenever faced with this choice, always go with the former. The way query params are treated leaves things to interpretation and it might cause search engines to completely ignore them, especially if the content overlaps to a large extent. Paths are considered distinct URLs by default while that is not the case for query params.</p>\n\n<p>Another thing that might come up is <em>“why would we struggle with creating new pages in the existing project when we can just copy it and spin up another instance on <code>v2.docs.example.com</code>?”</em>. It is similar to what I wrote about the subdomain vs subfolder. Subdomains are often treated as their own entities and, if separated, they need to build their own authority from scratch. </p>\n\n<p>Now, once you've decided on paths, you still have a choice to make. Do you put the latest version at <code>/docs/feature</code> and versioned ones at <code>/docs/v2/feature</code>? Or do you version everything explicitly? One way to go is keeping your strongest URLs clean and short, which is better for link building and sharing. Old versions live under their version prefix, and if at some point you decide to completely deprecate the old version, you have a few options:</p>\n\n<ul>\n<li>A permanent (301 or 308) redirect to the latest version. </li>\n<li>Return 410 for a page that's genuinely removed and won't come back. Make sure you don’t have any external links (through Ahrefs or a similar tool) before that. If you do, just redirect it to something relevant.</li>\n<li>If you want to keep it for the users but not have it indexed by search engines, either add Noindex in meta robots or a canonical tag to the newest version in order to not compete with your current docs.</li>\n</ul>\n\n<p><a href=\"https://developers.google.com/search/docs/crawling-indexing/robots-meta-tag\" rel=\"noopener noreferrer\">You can find a guide on meta robots here.</a></p>\n\n<p>One thing to consider is, if you decide to keep one master URL which always keeps the latest version of the docs, you would want to make it clear on the page itself as otherwise it wouldn’t be clear from the URL itself.</p>\n\n<p>Canonical tags can be super helpful if a lot of the content overlaps. For example, you might have an authentication guide where things changed just slightly, but you still have to maintain two versions to keep the new docs coherent. </p>\n\n<p><a href=\"https://developers.google.com/search/docs/crawling-indexing/consolidate-duplicate-urls\" rel=\"noopener noreferrer\">You can find a guide on canonical tags here.</a></p>\n\n<h2>\n  \n  \n  Structured data\n</h2>\n\n<p>By structured data I mean <a href=\"http://schema.org/\" rel=\"noopener noreferrer\">schema.org</a> and other HTML-related structured data you can provide to the search engines so they can understand your content better.</p>\n\n<h3>\n  \n  \n  HTML structured data\n</h3>\n\n<p>Make sure your images have alt text and try to be specific. On one hand you are improving the accessibility of your docs, on the other you are giving search engines a little bit more context to work with. Ideally your filenames would also provide some more context. <a href=\"https://developers.google.com/search/docs/appearance/google-images#descriptive-alt-text%20descriptive-titles-captions-filenames\" rel=\"noopener noreferrer\">Here’s a guide on how to write descriptive alt text and more.</a></p>\n\n<p>While not a ranking signal, it would be great to also add OpenGraph. Developers will share links on Slack or a social media platform and you want to provide them with the best experience.</p>\n\n<h3>\n  \n  \n  Schema.org\n</h3>\n\n<p>I think the simplest way to implement schema is to use <a href=\"https://json-ld.org/\" rel=\"noopener noreferrer\">JSON-LD</a> as other ways make things a tad too complicated by having to exist within HTML. <br />\nStart with <a href=\"https://schema.org/BreadcrumbList\" rel=\"noopener noreferrer\">BreadcrumbList</a>. It's usually the lowest hanging fruit. Your docs already have a hierarchy, breadcrumbs make that hierarchy visible in the SERP, and they're crawlable navigation on top of that (more on that in internal linking part).</p>\n\n<p>For tutorial-style pages, <a href=\"https://schema.org/HowTo\" rel=\"noopener noreferrer\">HowTo</a> schema works well. When your docs walk someone through a process step by step. It's not going to work for reference docs, but for guides it fits naturally. <a href=\"https://schema.org/SoftwareSourceCode\" rel=\"noopener noreferrer\">SoftwareSourceCode</a> schema type can help Google understand what language you're writing in and what the code is actually doing. Not every search engine uses this yet, but it's a signal that costs us (almost) nothing to add.</p>\n\n<p>If you have video tutorials embedded in your docs, <a href=\"https://schema.org/VideoObject\" rel=\"noopener noreferrer\">VideoObject</a> schema makes them discoverable outside of your website. Same idea with <a href=\"https://schema.org/FAQPage\" rel=\"noopener noreferrer\">FAQ schema</a> for pages that have a questions-and-answers section. Google will sometimes surface these as rich results, and even when it doesn't, you're giving the engine more context about your content.</p>\n\n<h2>\n  \n  \n  Internal linking\n</h2>\n\n<p>The rules here are super simple, you want to link internally as much as possible. I’d argue it’s the most overlooked thing in SEO and, with a little work, the outcomes can be great. </p>\n\n<p>One rule of thumb though on the development side is you want to use/render <a> tags for all your links. Anything else, such as <code>&lt;button&gt;</code>, JavaScript interactions and similar are making it super hard for search engines to discover the URLs.</a></p>\n\n<p>And actually, I’ve got one more. Keep anchor text contextual as well. Instead of <em>“here”</em> and <em>“learn more”</em>, always try to link the part of the text that describes what’s on the URL you’re linking to.</p>\n\n<p>The first thing to look at is your side navigation. The structure of your nav directly impacts how internal URLs are discovered and how page authority flows through your docs. If your navigation is too deep or too fragmented, pages buried three or four levels down are going to get crawled less frequently and accumulate less authority. Try to keep things as flat as you can without making the nav unusable.</p>\n\n<p>Next and previous links in doc sequences are another easy win that most sites skip. If you have a multi-page guide, linking each page to the next and previous one creates a crawl path that lets search engines discover everything in order. Google itself no longer uses it, but Bing does and it’s still a general good practice. It also helps the reader move through the content without going back to the nav every time.</p>\n\n<p>One other simple way to add a bunch of pages to the docs is to use your changelog page to link to any docs page that is related to the release. Also helps the user get a more detailed understanding of the changes.</p>\n\n<p>Cross-linking between your blog and your docs is one of the most underused channels. And, it’s mostly a coordination problem when the person writing a blog perhaps isn’t fully familiar with the docs. However, it’s a natural flow, guiding the user from a more general guide more towards product content. </p>\n\n<p>::: tip<br />\nThe SEO in me is trying to take over the keyboard and not let me write this, but while linking from the blog to the docs is something I advocate for, I’d argue against doing it the opposite direction. For one, you want to keep people at the docs to get all their questions answered and not interrupt the flow. And two, this is particularly true for rather generic blog posts that can’t help a developer achieve a specific product-related task.<br />\n:::</p>\n\n<p>The oldest trick in the internal linking book is adding some related items somewhere on the page. Most blogs do this, I also do it on <a href=\"https://devtooljobs.com/\" rel=\"noopener noreferrer\">devtooljobs.com</a> and it really helps the discoverability of new URLs and helps keep things well connected.</p>\n\n<p>Stripe docs are often cited as a great example from multiple standpoints and for a good reason. Each guide is so well explained, connected and linked out and everyone should take an inspiration. </p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Feu-central-1.graphassets.com%2FApcTGuMv7TJamP0MPpsWwz%2Fcml3pv1fgc19z06uloi99rzd0\"><img alt=\"stripe documentation screenshot\" height=\"934\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Feu-central-1.graphassets.com%2FApcTGuMv7TJamP0MPpsWwz%2Fcml3pv1fgc19z06uloi99rzd0\" width=\"1915\" /></a></p>\n\n<h2>\n  \n  \n  Content / UX\n</h2>\n\n<p>Should the search functionality within your docs help with SEO or is it purely a client-side thing? The short answer is it should be client-side only. A search results page within your docs is almost never something you want indexed. It's thin content, it's dynamic, and it competes with your actual doc pages. Let your internal search do its job for users, but keep it out of Google's way. If you use query params for search, the way to achieve this is by adding a canonical url from the search results page to the home page or <code>/search</code> if you have something like that.</p>\n\n<p>Put some effort into writing the meta description for a page. While not a ranking signal it helps improve the click-through rate (at least for the times when search engines don’t just pick up something from the text).</p>\n\n<p>When it comes to code snippets, I’ve got three things to say. One, if you are using a syntax highlighting library, they can cause the page to load a bit slower so always load syntax highlighting only for the languages that you use instead of everything the library provides. Two, try to provide try to always add some more context around a code block such as titles or captions. And finally, click-to-copy has become a standard nowadays with code snippets. Users expect it in most cases so adding this option affects user signals (it’s also just normal). </p>\n\n<p>Another relatively established good practice is to add a table of contents on longer pages. Helps the user navigate and helps create site links in SERPs. In addition, you want links to subsections to be descriptive so pretty much slugified subheading and not some ID or something like that.</p>\n\n<p>If you're embedding something like CodeSandbox, the content inside that embed is not crawlable. Search engines can't see it. So if your interactive example is the main way someone is supposed to understand what's happening, you need the explanation to exist in crawlable text too. Treat it as something that helps enrich your page and not as a substitute.</p>\n\n<p>Troubleshooting section or error message documentation is a great way to rank for more long-tail keywords and also attract backlinks from other websites writing the guides (and this works well for LLMs, too). Essentially try to pick up what errors and similar developers might be searching related to your product and build out pages that answer their queries. Vercel does this very well with <a href=\"https://vercel.com/docs/errors\" rel=\"noopener noreferrer\">their errors section</a>. Each error is a different page that helps the user understand where the problem is.</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Feu-central-1.graphassets.com%2FApcTGuMv7TJamP0MPpsWwz%2Fcml31yb03p2by06uliysofy9k\"><img alt=\"Vercel error documentation example\" height=\"1384\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Feu-central-1.graphassets.com%2FApcTGuMv7TJamP0MPpsWwz%2Fcml31yb03p2by06uliysofy9k\" width=\"2844\" /></a></p>\n\n<p>In Google Search Console, you can get plenty of ideas on what may be missing from your docs. This deserves a separate guide, but in principle, you just need to check the queries a page ranks for and there might be some long-tail stuff that your docs don’t address yet.</p>\n\n<p>And finally, docs tend to contain architecture diagrams, screenshots and similar. Make sure these images are optimized so that they don’t affect the page load time.</p>\n\n<p>Treat this guide as <em>“this is something we strive for”</em>, but never go SEO-first. Almost none of these should ever go over what’s best for the user in your situation. And, situations can vary. </p>",
        "source": "dev.to",
        "published": "Sun, 22 Feb 2026 23:08:24 +0000",
        "fetched_at": "2026-02-22T23:21:15.307341Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 2,
        "final_score": 5.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/abhigyanpatwari/GitNexus",
        "title": "abhigyanpatwari/GitNexus",
        "summary": "<p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p><hr /><h1>GitNexus</h1> \n<p><strong>Building git for agent context.</strong></p> \n<p>Indexes any codebase into a knowledge graph — every dependency, call chain, cluster, and execution flow — then exposes it through smart tools so AI agents never miss code.</p> \n<p><a href=\"https://www.npmjs.com/package/gitnexus\"><img alt=\"npm version\" src=\"https://img.shields.io/npm/v/gitnexus.svg?sanitize=true\" /></a> <a href=\"https://polyformproject.org/licenses/noncommercial/1.0.0/\"><img alt=\"License: PolyForm Noncommercial\" src=\"https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg?sanitize=true\" /></a></p> \n<p><a href=\"https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72\">https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72</a></p> \n<blockquote> \n <p><em>Like DeepWiki, but deeper.</em> DeepWiki helps you <em>understand</em> code. GitNexus lets you <em>analyze</em> it — because a knowledge graph tracks every relationship, not just descriptions.</p> \n</blockquote> \n<p><strong>TL;DR:</strong> The <strong>Web UI</strong> is a quick way to chat with any repo. The <strong>CLI + MCP</strong> is how you make your AI agent actually reliable — it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.</p> \n<hr /> \n<h2>Two Ways to Use GitNexus</h2> \n<table> \n <thead> \n  <tr> \n   <th></th> \n   <th><strong>CLI + MCP</strong></th> \n   <th><strong>Web UI</strong></th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>What</strong></td> \n   <td>Index repos locally, connect AI agents via MCP</td> \n   <td>Visual graph explorer + AI chat in browser</td> \n  </tr> \n  <tr> \n   <td><strong>For</strong></td> \n   <td>Daily development with Cursor, Claude Code, Windsurf, OpenCode</td> \n   <td>Quick exploration, demos, one-off analysis</td> \n  </tr> \n  <tr> \n   <td><strong>Scale</strong></td> \n   <td>Full repos, any size</td> \n   <td>Limited by browser memory (~5k files)</td> \n  </tr> \n  <tr> \n   <td><strong>Install</strong></td> \n   <td><code>npm install -g gitnexus</code></td> \n   <td>No install —<a href=\"https://gitnexus.vercel.app\">gitnexus.vercel.app</a></td> \n  </tr> \n  <tr> \n   <td><strong>Storage</strong></td> \n   <td>KuzuDB native (fast, persistent)</td> \n   <td>KuzuDB WASM (in-memory, per session)</td> \n  </tr> \n  <tr> \n   <td><strong>Parsing</strong></td> \n   <td>Tree-sitter native bindings</td> \n   <td>Tree-sitter WASM</td> \n  </tr> \n  <tr> \n   <td><strong>Privacy</strong></td> \n   <td>Everything local, no network</td> \n   <td>Everything in-browser, no server</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>CLI + MCP (recommended)</h2> \n<p>The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.</p> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># Index your repo (run from repo root)\nnpx gitnexus analyze\n</code></pre> \n<p>That's it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates <code>AGENTS.md</code> / <code>CLAUDE.md</code> context files — all in one command.</p> \n<p>To configure MCP for your editor, run <code>npx gitnexus setup</code> once — or set it up manually below.</p> \n<h3>MCP Setup</h3> \n<p><code>gitnexus setup</code> auto-detects your editors and writes the correct global MCP config. You only need to run it once.</p> \n<h3>Editor Support</h3> \n<table> \n <thead> \n  <tr> \n   <th>Editor</th> \n   <th>MCP</th> \n   <th>Skills</th> \n   <th>Hooks (auto-augment)</th> \n   <th>Support</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Claude Code</strong></td> \n   <td>Yes</td> \n   <td>Yes</td> \n   <td>Yes (PreToolUse)</td> \n   <td><strong>Full</strong></td> \n  </tr> \n  <tr> \n   <td><strong>Cursor</strong></td> \n   <td>Yes</td> \n   <td>Yes</td> \n   <td>—</td> \n   <td>MCP + Skills</td> \n  </tr> \n  <tr> \n   <td><strong>Windsurf</strong></td> \n   <td>Yes</td> \n   <td>—</td> \n   <td>—</td> \n   <td>MCP</td> \n  </tr> \n  <tr> \n   <td><strong>OpenCode</strong></td> \n   <td>Yes</td> \n   <td>Yes</td> \n   <td>—</td> \n   <td>MCP + Skills</td> \n  </tr> \n </tbody> \n</table> \n<blockquote> \n <p><strong>Claude Code</strong> gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.</p> \n</blockquote> \n<p>If you prefer manual configuration:</p> \n<p><strong>Claude Code</strong> (full support — MCP + skills + hooks):</p> \n<pre><code class=\"language-bash\">claude mcp add gitnexus -- npx -y gitnexus@latest mcp\n</code></pre> \n<p><strong>Cursor</strong> (<code>~/.cursor/mcp.json</code> — global, works for all projects):</p> \n<pre><code class=\"language-json\">{\n  \"mcpServers\": {\n    \"gitnexus\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"gitnexus@latest\", \"mcp\"]\n    }\n  }\n}\n</code></pre> \n<p><strong>OpenCode</strong> (<code>~/.config/opencode/config.json</code>):</p> \n<pre><code class=\"language-json\">{\n  \"mcp\": {\n    \"gitnexus\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"gitnexus@latest\", \"mcp\"]\n    }\n  }\n}\n</code></pre> \n<h3>CLI Commands</h3> \n<pre><code class=\"language-bash\">gitnexus setup                    # Configure MCP for your editors (one-time)\ngitnexus analyze [path]           # Index a repository (or update stale index)\ngitnexus analyze --force          # Force full re-index\ngitnexus analyze --skip-embeddings  # Skip embedding generation (faster)\ngitnexus mcp                     # Start MCP server (stdio) — serves all indexed repos\ngitnexus serve                   # Start HTTP server for web UI connection\ngitnexus list                    # List all indexed repositories\ngitnexus status                  # Show index status for current repo\ngitnexus clean                   # Delete index for current repo\ngitnexus clean --all --force     # Delete all indexes\ngitnexus wiki [path]             # Generate repository wiki from knowledge graph\ngitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)\ngitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL\n</code></pre> \n<h3>What Your AI Agent Gets</h3> \n<p><strong>7 tools</strong> exposed via MCP:</p> \n<table> \n <thead> \n  <tr> \n   <th>Tool</th> \n   <th>What It Does</th> \n   <th><code>repo</code> Param</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>list_repos</code></td> \n   <td>Discover all indexed repositories</td> \n   <td>—</td> \n  </tr> \n  <tr> \n   <td><code>query</code></td> \n   <td>Process-grouped hybrid search (BM25 + semantic + RRF)</td> \n   <td>Optional</td> \n  </tr> \n  <tr> \n   <td><code>context</code></td> \n   <td>360-degree symbol view — categorized refs, process participation</td> \n   <td>Optional</td> \n  </tr> \n  <tr> \n   <td><code>impact</code></td> \n   <td>Blast radius analysis with depth grouping and confidence</td> \n   <td>Optional</td> \n  </tr> \n  <tr> \n   <td><code>detect_changes</code></td> \n   <td>Git-diff impact — maps changed lines to affected processes</td> \n   <td>Optional</td> \n  </tr> \n  <tr> \n   <td><code>rename</code></td> \n   <td>Multi-file coordinated rename with graph + text search</td> \n   <td>Optional</td> \n  </tr> \n  <tr> \n   <td><code>cypher</code></td> \n   <td>Raw Cypher graph queries</td> \n   <td>Optional</td> \n  </tr> \n </tbody> \n</table> \n<blockquote> \n <p>When only one repo is indexed, the <code>repo</code> parameter is optional. With multiple repos, specify which one: <code>query({query: \"auth\", repo: \"my-app\"})</code>.</p> \n</blockquote> \n<p><strong>Resources</strong> for instant context:</p> \n<table> \n <thead> \n  <tr> \n   <th>Resource</th> \n   <th>Purpose</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>gitnexus://repos</code></td> \n   <td>List all indexed repositories (read this first)</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/context</code></td> \n   <td>Codebase stats, staleness check, and available tools</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/clusters</code></td> \n   <td>All functional clusters with cohesion scores</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/cluster/{name}</code></td> \n   <td>Cluster members and details</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/processes</code></td> \n   <td>All execution flows</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/process/{name}</code></td> \n   <td>Full process trace with steps</td> \n  </tr> \n  <tr> \n   <td><code>gitnexus://repo/{name}/schema</code></td> \n   <td>Graph schema for Cypher queries</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>2 MCP prompts</strong> for guided workflows:</p> \n<table> \n <thead> \n  <tr> \n   <th>Prompt</th> \n   <th>What It Does</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>detect_impact</code></td> \n   <td>Pre-commit change analysis — scope, affected processes, risk level</td> \n  </tr> \n  <tr> \n   <td><code>generate_map</code></td> \n   <td>Architecture documentation from the knowledge graph with mermaid diagrams</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>4 agent skills</strong> installed to <code>.claude/skills/</code> automatically:</p> \n<ul> \n <li><strong>Exploring</strong> — Navigate unfamiliar code using the knowledge graph</li> \n <li><strong>Debugging</strong> — Trace bugs through call chains</li> \n <li><strong>Impact Analysis</strong> — Analyze blast radius before changes</li> \n <li><strong>Refactoring</strong> — Plan safe refactors using dependency mapping</li> \n</ul> \n<hr /> \n<h2>Multi-Repo MCP Architecture</h2> \n<p>GitNexus uses a <strong>global registry</strong> so one MCP server can serve multiple indexed repos. No per-project MCP config needed — set it up once and it works everywhere.</p> \n<pre><code class=\"language-mermaid\">flowchart TD\n    subgraph CLI [CLI Commands]\n        Setup[\"gitnexus setup\"]\n        Analyze[\"gitnexus analyze\"]\n        Clean[\"gitnexus clean\"]\n        List[\"gitnexus list\"]\n    end\n\n    subgraph Registry [\"~/.gitnexus/\"]\n        RegFile[\"registry.json\"]\n    end\n\n    subgraph Repos [Project Repos]\n        RepoA[\".gitnexus/ in repo A\"]\n        RepoB[\".gitnexus/ in repo B\"]\n    end\n\n    subgraph MCP [MCP Server]\n        Server[\"server.ts\"]\n        Backend[\"LocalBackend\"]\n        Pool[\"Connection Pool\"]\n        ConnA[\"KuzuDB conn A\"]\n        ConnB[\"KuzuDB conn B\"]\n    end\n\n    Setup --&gt;|\"writes global MCP config\"| CursorConfig[\"~/.cursor/mcp.json\"]\n    Analyze --&gt;|\"registers repo\"| RegFile\n    Analyze --&gt;|\"stores index\"| RepoA\n    Clean --&gt;|\"unregisters repo\"| RegFile\n    List --&gt;|\"reads\"| RegFile\n    Server --&gt;|\"reads registry\"| RegFile\n    Server --&gt; Backend\n    Backend --&gt; Pool\n    Pool --&gt;|\"lazy open\"| ConnA\n    Pool --&gt;|\"lazy open\"| ConnB\n    ConnA --&gt;|\"queries\"| RepoA\n    ConnB --&gt;|\"queries\"| RepoB\n</code></pre> \n<p><strong>How it works:</strong> Each <code>gitnexus analyze</code> stores the index in <code>.gitnexus/</code> inside the repo (portable, gitignored) and registers a pointer in <code>~/.gitnexus/registry.json</code>. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the <code>repo</code> parameter is optional on all tools — agents don't need to change anything.</p> \n<hr /> \n<h2>Web UI (browser-based)</h2> \n<p>A fully client-side graph explorer and AI chat. No server, no install — your code never leaves the browser.</p> \n<p><strong>Try it now:</strong> <a href=\"https://gitnexus.vercel.app\">gitnexus.vercel.app</a> — drag &amp; drop a ZIP and start exploring.</p> \n<img alt=\"gitnexus_img\" height=\"1343\" src=\"https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285\" width=\"2550\" /> \n<p>Or run locally:</p> \n<pre><code class=\"language-bash\">git clone https://github.com/abhigyanpatwari/gitnexus.git\ncd gitnexus/gitnexus-web\nnpm install\nnpm run dev\n</code></pre> \n<p>The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It's great for quick exploration but limited by browser memory for larger repos.</p> \n<hr /> \n<h2>The Problem GitNexus Solves</h2> \n<p>Tools like <strong>Cursor</strong>, <strong>Claude Code</strong>, <strong>Cline</strong>, <strong>Roo Code</strong>, and <strong>Windsurf</strong> are powerful — but they don't truly know your codebase structure.</p> \n<p><strong>What happens:</strong></p> \n<ol> \n <li>AI edits <code>UserService.validate()</code></li> \n <li>Doesn't know 47 functions depend on its return type</li> \n <li><strong>Breaking changes ship</strong></li> \n</ol> \n<h3>Traditional Graph RAG vs GitNexus</h3> \n<p>Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus <strong>precomputes structure at index time</strong> — clustering, tracing, scoring — so tools return complete context in one call:</p> \n<pre><code class=\"language-mermaid\">flowchart TB\n    subgraph Traditional[\"Traditional Graph RAG\"]\n        direction TB\n        U1[\"User: What depends on UserService?\"]\n        U1 --&gt; LLM1[\"LLM receives raw graph\"]\n        LLM1 --&gt; Q1[\"Query 1: Find callers\"]\n        Q1 --&gt; Q2[\"Query 2: What files?\"]\n        Q2 --&gt; Q3[\"Query 3: Filter tests?\"]\n        Q3 --&gt; Q4[\"Query 4: High-risk?\"]\n        Q4 --&gt; OUT1[\"Answer after 4+ queries\"]\n    end\n\n    subgraph GN[\"GitNexus Smart Tools\"]\n        direction TB\n        U2[\"User: What depends on UserService?\"]\n        U2 --&gt; TOOL[\"impact UserService upstream\"]\n        TOOL --&gt; PRECOMP[\"Pre-structured response:\n        8 callers, 3 clusters, all 90%+ confidence\"]\n        PRECOMP --&gt; OUT2[\"Complete answer, 1 query\"]\n    end\n</code></pre> \n<p><strong>Core innovation: Precomputed Relational Intelligence</strong></p> \n<ul> \n <li><strong>Reliability</strong> — LLM can't miss context, it's already in the tool response</li> \n <li><strong>Token efficiency</strong> — No 10-query chains to understand one function</li> \n <li><strong>Model democratization</strong> — Smaller LLMs work because tools do the heavy lifting</li> \n</ul> \n<hr /> \n<h2>How It Works</h2> \n<p>GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:</p> \n<ol> \n <li><strong>Structure</strong> — Walks the file tree and maps folder/file relationships</li> \n <li><strong>Parsing</strong> — Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs</li> \n <li><strong>Resolution</strong> — Resolves imports and function calls across files with language-aware logic</li> \n <li><strong>Clustering</strong> — Groups related symbols into functional communities</li> \n <li><strong>Processes</strong> — Traces execution flows from entry points through call chains</li> \n <li><strong>Search</strong> — Builds hybrid search indexes for fast retrieval</li> \n</ol> \n<h3>Supported Languages</h3> \n<p>TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust</p> \n<hr /> \n<h2>Tool Examples</h2> \n<h3>Impact Analysis</h3> \n<pre><code>impact({target: \"UserService\", direction: \"upstream\", minConfidence: 0.8})\n\nTARGET: Class UserService (src/services/user.ts)\n\nUPSTREAM (what depends on this):\n  Depth 1 (WILL BREAK):\n    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45\n    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78\n    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12\n  Depth 2 (LIKELY AFFECTED):\n    authRouter [IMPORTS] -&gt; src/routes/auth.ts\n</code></pre> \n<p>Options: <code>maxDepth</code>, <code>minConfidence</code>, <code>relationTypes</code> (<code>CALLS</code>, <code>IMPORTS</code>, <code>EXTENDS</code>, <code>IMPLEMENTS</code>), <code>includeTests</code></p> \n<h3>Process-Grouped Search</h3> \n<pre><code>query({query: \"authentication middleware\"})\n\nprocesses:\n  - summary: \"LoginFlow\"\n    priority: 0.042\n    symbol_count: 4\n    process_type: cross_community\n    step_count: 7\n\nprocess_symbols:\n  - name: validateUser\n    type: Function\n    filePath: src/auth/validate.ts\n    process_id: proc_login\n    step_index: 2\n\ndefinitions:\n  - name: AuthConfig\n    type: Interface\n    filePath: src/types/auth.ts\n</code></pre> \n<h3>Context (360-degree Symbol View)</h3> \n<pre><code>context({name: \"validateUser\"})\n\nsymbol:\n  uid: \"Function:validateUser\"\n  kind: Function\n  filePath: src/auth/validate.ts\n  startLine: 15\n\nincoming:\n  calls: [handleLogin, handleRegister, UserController]\n  imports: [authRouter]\n\noutgoing:\n  calls: [checkPassword, createSession]\n\nprocesses:\n  - name: LoginFlow (step 2/7)\n  - name: RegistrationFlow (step 3/5)\n</code></pre> \n<h3>Detect Changes (Pre-Commit)</h3> \n<pre><code>detect_changes({scope: \"all\"})\n\nsummary:\n  changed_count: 12\n  affected_count: 3\n  changed_files: 4\n  risk_level: medium\n\nchanged_symbols: [validateUser, AuthService, ...]\naffected_processes: [LoginFlow, RegistrationFlow, ...]\n</code></pre> \n<h3>Rename (Multi-File)</h3> \n<pre><code>rename({symbol_name: \"validateUser\", new_name: \"verifyUser\", dry_run: true})\n\nstatus: success\nfiles_affected: 5\ntotal_edits: 8\ngraph_edits: 6     (high confidence)\ntext_search_edits: 2  (review carefully)\nchanges: [...]\n</code></pre> \n<h3>Cypher Queries</h3> \n<pre><code class=\"language-cypher\">-- Find what calls auth functions with high confidence\nMATCH (c:Community {heuristicLabel: 'Authentication'})&lt;-[:CodeRelation {type: 'MEMBER_OF'}]-(fn)\nMATCH (caller)-[r:CodeRelation {type: 'CALLS'}]-&gt;(fn)\nWHERE r.confidence &gt; 0.8\nRETURN caller.name, fn.name, r.confidence\nORDER BY r.confidence DESC\n</code></pre> \n<hr /> \n<h2>Wiki Generation</h2> \n<p>Generate LLM-powered documentation from your knowledge graph:</p> \n<pre><code class=\"language-bash\"># Requires an LLM API key (OPENAI_API_KEY, etc.)\ngitnexus wiki\n\n# Use a custom model or provider\ngitnexus wiki --model gpt-4o\ngitnexus wiki --base-url https://api.anthropic.com/v1\n\n# Force full regeneration\ngitnexus wiki --force\n</code></pre> \n<p>The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page — all with cross-references to the knowledge graph.</p> \n<hr /> \n<h2>Tech Stack</h2> \n<table> \n <thead> \n  <tr> \n   <th>Layer</th> \n   <th>CLI</th> \n   <th>Web</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Runtime</strong></td> \n   <td>Node.js (native)</td> \n   <td>Browser (WASM)</td> \n  </tr> \n  <tr> \n   <td><strong>Parsing</strong></td> \n   <td>Tree-sitter native bindings</td> \n   <td>Tree-sitter WASM</td> \n  </tr> \n  <tr> \n   <td><strong>Database</strong></td> \n   <td>KuzuDB native</td> \n   <td>KuzuDB WASM</td> \n  </tr> \n  <tr> \n   <td><strong>Embeddings</strong></td> \n   <td>HuggingFace transformers.js (GPU/CPU)</td> \n   <td>transformers.js (WebGPU/WASM)</td> \n  </tr> \n  <tr> \n   <td><strong>Search</strong></td> \n   <td>BM25 + semantic + RRF</td> \n   <td>BM25 + semantic + RRF</td> \n  </tr> \n  <tr> \n   <td><strong>Agent Interface</strong></td> \n   <td>MCP (stdio)</td> \n   <td>LangChain ReAct agent</td> \n  </tr> \n  <tr> \n   <td><strong>Visualization</strong></td> \n   <td>—</td> \n   <td>Sigma.js + Graphology (WebGL)</td> \n  </tr> \n  <tr> \n   <td><strong>Frontend</strong></td> \n   <td>—</td> \n   <td>React 18, TypeScript, Vite, Tailwind v4</td> \n  </tr> \n  <tr> \n   <td><strong>Clustering</strong></td> \n   <td>Graphology</td> \n   <td>Graphology</td> \n  </tr> \n  <tr> \n   <td><strong>Concurrency</strong></td> \n   <td>Worker threads + async</td> \n   <td>Web Workers + Comlink</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>Roadmap</h2> \n<h3>Actively Building</h3> \n<ul> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> <strong>LLM Cluster Enrichment</strong> — Semantic cluster names via LLM API</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> <strong>AST Decorator Detection</strong> — Parse @Controller, @Get, etc.</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> <strong>Incremental Indexing</strong> — Only re-index changed files</li> \n</ul> \n<h3>Recently Completed</h3> \n<ul> \n <li><input checked=\"checked\" disabled=\"disabled\" type=\"checkbox\" /> Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis</li> \n <li><input checked=\"checked\" disabled=\"disabled\" type=\"checkbox\" /> Process-Grouped Search, 360-Degree Context, Claude Code Hooks</li> \n <li><input checked=\"checked\" disabled=\"disabled\" type=\"checkbox\" /> Multi-Repo MCP, Zero-Config Setup, 9 Language Support</li> \n <li><input checked=\"checked\" disabled=\"disabled\" type=\"checkbox\" /> Community Detection, Process Detection, Confidence Scoring</li> \n <li><input checked=\"checked\" disabled=\"disabled\" type=\"checkbox\" /> Hybrid Search, Vector Index</li> \n</ul> \n<hr /> \n<h2>Security &amp; Privacy</h2> \n<ul> \n <li><strong>CLI</strong>: Everything runs locally on your machine. No network calls. Index stored in <code>.gitnexus/</code> (gitignored). Global registry at <code>~/.gitnexus/</code> stores only paths and metadata.</li> \n <li><strong>Web</strong>: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.</li> \n <li>Open source — audit the code yourself.</li> \n</ul> \n<hr /> \n<h2>Acknowledgments</h2> \n<ul> \n <li><a href=\"https://tree-sitter.github.io/\">Tree-sitter</a> — AST parsing</li> \n <li><a href=\"https://kuzudb.com/\">KuzuDB</a> — Embedded graph database with vector support</li> \n <li><a href=\"https://www.sigmajs.org/\">Sigma.js</a> — WebGL graph rendering</li> \n <li><a href=\"https://huggingface.co/docs/transformers.js\">transformers.js</a> — Browser ML</li> \n <li><a href=\"https://graphology.github.io/\">Graphology</a> — Graph data structures</li> \n <li><a href=\"https://modelcontextprotocol.io/\">MCP</a> — Model Context Protocol</li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-22T23:21:09.823059Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 15,
        "timeliness_score": 1,
        "final_score": 5.2,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}