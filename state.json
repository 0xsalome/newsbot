{
  "meta": {
    "last_updated": "2026-02-20T23:26:17.970287Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://phys.org/news/2026-02-recycling-strategies-fungi-affect-forests.html",
        "posted_at": "2026-02-13",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260211073047.htm",
        "posted_at": "2026-02-13",
        "score": 4.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-ai-physics-complex-protein-biomedical.html",
        "posted_at": "2026-02-14",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223918.htm",
        "posted_at": "2026-02-14",
        "score": 5.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223857.htm",
        "posted_at": "2026-02-15",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215225541.htm",
        "posted_at": "2026-02-16",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-renewable-biological-catalyst-potential-wastewater.html",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "posted_at": "2026-02-17",
        "score": 5.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005717.htm",
        "posted_at": "2026-02-18",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "posted_at": "2026-02-19",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-machine-central-problem-quantum-chemistry.html",
        "posted_at": "2026-02-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260220010830.htm",
        "posted_at": "2026-02-20",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-impact-glass-evidence-cosmic-collision.html",
        "posted_at": "2026-02-20",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "posted_at": "2026-02-13",
        "score": 19.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.10625",
        "posted_at": "2026-02-13",
        "score": 17.0,
        "tags": [
          "transformation",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/",
        "posted_at": "2026-02-13",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/13/airbnb-says-a-third-of-its-customer-support-is-now-handled-by-ai-in-the-u-s-and-canada/",
        "posted_at": "2026-02-13",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-02-14",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2505.13557",
        "posted_at": "2026-02-14",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-14",
        "score": 4.8,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/",
        "posted_at": "2026-02-14",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/",
        "posted_at": "2026-02-15",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "posted_at": "2026-02-16",
        "score": 33.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2501.05454",
        "posted_at": "2026-02-16",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-02-17",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.14299",
        "posted_at": "2026-02-17",
        "score": 21.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
        "posted_at": "2026-02-17",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/17/india-bids-to-attract-over-200b-in-ai-infrastructure-investment-by-2028/",
        "posted_at": "2026-02-17",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-02-18",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2510.22391",
        "posted_at": "2026-02-18",
        "score": 18.6,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2510.25867",
        "posted_at": "2026-02-19",
        "score": 19.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-02-19",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/19/1133360/microsoft-has-a-new-plan-to-prove-whats-real-and-whats-ai-online/",
        "posted_at": "2026-02-19",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/19/web-summit-qatar-read-ai-lucidya-notetakers-customer-support/",
        "posted_at": "2026-02-19",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-02-20",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.16320",
        "posted_at": "2026-02-20",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-20",
        "score": 4.8,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/20/peak-xv-raises-1-3b-doubles-down-on-ai-as-global-vc-rivalry-in-india-heats-up/",
        "posted_at": "2026-02-20",
        "score": 4.6,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "posted_at": "2026-02-13",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/vivaldis-four-seasons-performed-on-original-baroque-instruments.html",
        "posted_at": "2026-02-13",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/cats-in-medieval-manuscripts-and-paintings.html",
        "posted_at": "2026-02-14",
        "score": 3.7,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/proof-points-grade-inflation-lower-pay/",
        "posted_at": "2026-02-14",
        "score": 3.0,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.2,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://erichlof.github.io/THREE.js-PathTracing-Renderer/",
        "posted_at": "2026-02-16",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-being-a-madman-for-8-minutes.html",
        "posted_at": "2026-02-16",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/nz-is-slowly-slipping-on-the-global-corruption-index-is-is-time-for-an-anti-corruption-agency-275781",
        "posted_at": "2026-02-17",
        "score": 3.8,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://fuji.halfof8.com/",
        "posted_at": "2026-02-17",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.historytoday.com/archive/first-global-empire",
        "posted_at": "2026-02-18",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/why-some-people-think-in-words.html",
        "posted_at": "2026-02-18",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "posted_at": "2026-02-19",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/the-ancient-egyptian-book-of-the-dead-a-guidebook-for-surviving-the-afterlife.html",
        "posted_at": "2026-02-19",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-02-20",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.bbc.com/news/live/c0l9r67drg7t",
        "posted_at": "2026-02-20",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://phys.org/news/2026-02-basic-listeria-bacteria-unique-cancer.html",
        "posted_at": "2026-02-13",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260212025554.htm",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-ai-physics-complex-protein-biomedical.html",
        "posted_at": "2026-02-14",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-14",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "posted_at": "2026-02-15",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-recycling-strategies-fungi-affect-forests.html",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "posted_at": "2026-02-16",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-honey-bees-precisely-previously-thought.html",
        "posted_at": "2026-02-17",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "posted_at": "2026-02-17",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-fungus-species-genes-threatens-coffee.html",
        "posted_at": "2026-02-18",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005714.htm",
        "posted_at": "2026-02-18",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "posted_at": "2026-02-19",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-unique-path-poxviruses.html",
        "posted_at": "2026-02-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260218044628.htm",
        "posted_at": "2026-02-20",
        "score": 6.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-20",
        "score": 5.2,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/places/nevada-national-security-site",
        "posted_at": "2026-02-13",
        "score": 10.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/the-cosmic-collision-that-formed-saturns-rings-1267668/",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-02-14",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/when-galileos-cosmic-convictions-landed-him-in-court-1267592/",
        "posted_at": "2026-02-14",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "posted_at": "2026-02-15",
        "score": 12.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/are-the-mysteries-of-quantum-mechanics-beginning-to-dissolve-20260213/",
        "posted_at": "2026-02-15",
        "score": 4.1,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-02-16",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/pulsar-found-near-the-center-of-the-milky-way-could-test-einsteins-theories-1267701/",
        "posted_at": "2026-02-16",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/2014/09/design-package-2014/",
        "posted_at": "2026-02-17",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "posted_at": "2026-02-18",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "posted_at": "2026-02-19",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/the-biophysical-world-inside-a-jam-packed-cell-20260218/",
        "posted_at": "2026-02-19",
        "score": 4.7,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "posted_at": "2026-02-20",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/hell-heron-new-dinosaur-species-with-a-head-mounted-sword-discovered-in-africa-1269018/",
        "posted_at": "2026-02-20",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-02-13",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/13/india-partners-with-alibaba-com-for-export-push-despite-past-china-tech-bans/",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/hong-kong/society/article/3343598/small-precious-breakthrough-paralysed-hong-kong-dancer-mo-li?utm_source=rss_feed",
        "posted_at": "2026-02-14",
        "score": 5.7,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-02-14",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/week-asia/health-environment/article/3343458/malaysia-says-no-e-waste-dumping-can-its-ban-stop-global-trade?utm_source=rss_feed",
        "posted_at": "2026-02-15",
        "score": 5.7,
        "tags": [
          "transformation",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-02-16",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
        "posted_at": "2026-02-17",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-02-17",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-02-18",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/kidde-ring-new-smoke-alarm-2026/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-02-19",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://arstechnica.com/science/2026/02/newly-hatched-chickens-form-the-same-sound-association-we-do/",
        "posted_at": "2026-02-19",
        "score": 3.4,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.scmp.com/economy/global-economy/article/3344156/china-defends-wtos-most-favoured-nation-principle-after-us-eu-challenge-rule?utm_source=rss_feed",
        "posted_at": "2026-02-20",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/meet-scotlands-whisky-sniffing-robot-dog/",
        "posted_at": "2026-02-20",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
        "posted_at": "2026-02-13",
        "score": 9.7,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/lawrencedcodes/staying-market-volatility-resilient-as-a-dev-in-the-ai-era-52gc",
        "posted_at": "2026-02-13",
        "score": 8.3,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/wordpress-vs-headless-cms-a-strategic-decision-framework-for-development-teams-evaluating-platform-35lh",
        "posted_at": "2026-02-14",
        "score": 13.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/disler/claude-code-hooks-mastery",
        "posted_at": "2026-02-14",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/videosdeti/add-nix-to-your-project-one-file-zero-setup-drama-4cl4",
        "posted_at": "2026-02-15",
        "score": 9.5,
        "tags": [
          "transformation",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/julcasans/redacta-elevating-video-content-with-github-copilot-cli-kc9",
        "posted_at": "2026-02-15",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/nautechsystems/nautilus_trader",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/moonshine-ai/moonshine",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/cli-driven-component-deployment-pushing-code-to-production-in-one-command-for-visual-page-builders-279o",
        "posted_at": "2026-02-17",
        "score": 10.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/ruvnet/wifi-densepose",
        "posted_at": "2026-02-17",
        "score": 8.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/edge-rendering-vs-server-side-rendering-performance-trade-offs-explained-lmg",
        "posted_at": "2026-02-18",
        "score": 10.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/thanasistraitsis/flutter-sticky-bottom-button-beyond-the-floatingactionbutton-2i7o",
        "posted_at": "2026-02-18",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/uenyioha/prompting-techniques-that-actually-work-lessons-from-automating-architecture-analysis-57al",
        "posted_at": "2026-02-19",
        "score": 16.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/resizer/i-built-a-privacy-first-image-resizer-that-runs-entirely-in-your-browser-5dnp",
        "posted_at": "2026-02-19",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/ukgksl/how-snooki-accidentally-invented-the-influencer-era-p19",
        "posted_at": "2026-02-20",
        "score": 13.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://alexalejandre.com/programming/steve-klabnik-interview/",
        "posted_at": "2026-02-20",
        "score": 12.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "title": "Scientists discover gene that could save bananas from deadly Panama disease",
        "summary": "A major breakthrough could help save the world’s bananas from a devastating disease. Scientists have discovered the exact genetic region in a wild banana that provides resistance to Fusarium wilt Subtropical Race 4 — a destructive strain that threatens Cavendish bananas worldwide. While this wild banana isn’t edible, the discovery gives breeders a powerful genetic roadmap to develop future bananas that are both delicious and naturally protected from this deadly pathogen.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 09:43:15 EST",
        "fetched_at": "2026-02-20T23:25:25.834664Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040818.htm",
        "title": "Scientists just mapped mysterious earthquakes deep inside Earth",
        "summary": "Scientists at Stanford have unveiled the first-ever global map of rare earthquakes that rumble deep within Earth’s mantle rather than its crust. Long debated and notoriously difficult to confirm, these elusive quakes turn out to cluster in regions like the Himalayas and near the Bering Strait. By developing a breakthrough method that distinguishes mantle quakes using subtle differences in seismic waves, researchers identified hundreds of these hidden tremors worldwide.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 20 Feb 2026 08:05:28 EST",
        "fetched_at": "2026-02-20T23:25:25.834630Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.2,
        "temp_score_trend": 5.8
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "title": "This new blood test could detect cancer before it shows up on scans",
        "summary": "A new light-based sensor can spot incredibly tiny amounts of cancer biomarkers in blood, raising the possibility of earlier and simpler cancer detection. The technology merges DNA nanotechnology, CRISPR, and quantum dots to generate a clear signal from just a few molecules. In lung cancer tests, it worked even in real patient serum samples. Researchers hope it could eventually power portable blood tests for cancer and other diseases.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 20:48:34 EST",
        "fetched_at": "2026-02-20T23:25:25.834801Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223918.htm",
        "title": "This breakthrough could finally unlock male birth control",
        "summary": "Scientists at Michigan State University have uncovered the molecular “switch” that powers sperm for their final, high-speed dash toward an egg. By tracking how sperm use glucose as fuel, the team discovered how dormant cells suddenly flip into overdrive, burning energy in a carefully controlled, multi-step process. A key enzyme, aldolase, helps convert sugar into the burst of power needed for fertilization, while other enzymes act like traffic controllers directing the flow of fuel.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 14 Feb 2026 10:47:27 EST",
        "fetched_at": "2026-02-20T23:25:25.834879Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005717.htm",
        "title": "Breakthrough CRISPR system could reverse antibiotic resistance crisis",
        "summary": "Antibiotic resistance is racing toward a global crisis, with “superbugs” projected to cause over 10 million deaths annually by 2050. Now, scientists at UC San Diego have unveiled a powerful new CRISPR-based tool that doesn’t just fight resistant bacteria—it can actively strip away their drug resistance. Inspired by gene drives used in insects, the technology spreads a genetic “fix” through bacterial populations, even inside stubborn biofilms that shield microbes from antibiotics.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 18 Feb 2026 03:08:21 EST",
        "fetched_at": "2026-02-20T23:25:25.834768Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215225541.htm",
        "title": "Scientists confirm one-dimensional electron behavior in phosphorus chains",
        "summary": "For the first time, researchers have shown that self-assembled phosphorus chains can host genuinely one-dimensional electron behavior. Using advanced imaging and spectroscopy techniques, they separated the signals from chains aligned in different directions to reveal their true nature. The findings suggest that squeezing the chains closer together could trigger a dramatic shift from semiconductor to metal. That means simply adjusting density could unlock entirely new electronic states.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 06:52:35 EST",
        "fetched_at": "2026-02-20T23:25:25.834838Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040745.htm",
        "title": "Scientists finally explain why chronic constipation treatments often fail",
        "summary": "A newly discovered bacterial duo may be the hidden cause of chronic constipation. The two microbes break down the colon’s protective mucus layer, leaving stool dry and hard — a problem traditional laxatives don’t fix. Parkinson’s patients, who often struggle with constipation years before tremors appear, have higher levels of these bacteria. Blocking the bacteria’s mucus-destroying enzyme prevented constipation in mice, hinting at a new treatment strategy.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 08:46:05 EST",
        "fetched_at": "2026-02-20T23:25:25.834668Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260218044628.htm",
        "title": "New map reveals where lethal scorpions are most likely to strike",
        "summary": "Scientists have developed a powerful new way to forecast where some of the world’s most dangerous scorpions are likely to be found. By combining fieldwork in Africa with advanced computer modeling, the team discovered that soil type is the strongest factor shaping where many lethal species live, while temperature patterns also play a key role.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 18 Feb 2026 23:36:03 EST",
        "fetched_at": "2026-02-20T23:25:25.834673Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044003.htm",
        "title": "Lab grown human spinal cord heals after injury in major breakthrough",
        "summary": "Researchers have built a realistic human mini spinal cord in the lab and used it to simulate traumatic injury. The model reproduced key damage seen in real spinal cord injuries, including inflammation and scar formation. After treatment with fast moving “dancing molecules,” nerve fibers began growing again and scar tissue shrank. The results suggest the therapy could eventually help repair spinal cord damage.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 07:41:25 EST",
        "fetched_at": "2026-02-20T23:25:25.834796Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://phys.org/news/2026-02-atom-power-sides.html",
        "title": "'All-in-one,' single-atom could power both sides of water splitting",
        "summary": "Green hydrogen production technology, which utilizes renewable energy to produce eco-friendly hydrogen without carbon emissions, is gaining attention as a core technology for addressing global warming. Green hydrogen is produced through electrolysis, a process that separates hydrogen and oxygen by applying electrical energy to water, requiring low-cost, high-efficiency, high-performance catalysts.",
        "source": "phys.org",
        "published": "Fri, 20 Feb 2026 13:13:10 EST",
        "fetched_at": "2026-02-20T23:25:27.076304Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
        "summary": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers — Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>",
        "source": "venturebeat.com",
        "published": "Thu, 22 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628633Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 13
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 41,
        "timeliness_score": 3,
        "final_score": 22.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
        "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> — Anthropic&#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors — tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> — an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety — that is, the task of securing Claude&#x27;s real-world actions — is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development — a major feature built in ten days, possibly by the company&#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 12 Jan 2026 11:30:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628663Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 40,
        "timeliness_score": 3,
        "final_score": 21.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "source": "venturebeat.com",
        "published": "Fri, 16 Jan 2026 14:01:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628653Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 39,
        "timeliness_score": 3,
        "final_score": 21.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "source": "venturebeat.com",
        "published": "Wed, 07 Jan 2026 20:00:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628668Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 3,
        "final_score": 17.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "source": "venturebeat.com",
        "published": "Mon, 19 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628646Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 3,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-02-20T23:25:13.628673Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2602.16745",
        "title": "PETS: A Principled Framework Towards Optimal Trajectory Allocation for Efficient Test-Time Self-Consistency",
        "summary": "arXiv:2602.16745v1 Announce Type: cross \nAbstract: Test-time scaling can improve model performance by aggregating stochastic reasoning trajectories. However, achieving sample-efficient test-time self-consistency under a limited budget remains an open challenge. We introduce PETS (Principled and Efficient Test-TimeSelf-Consistency), which initiates a principled study of trajectory allocation through an optimization framework. Central to our approach is the self-consistency rate, a new measure defined as agreement with the infinite-budget majority vote. This formulation makes sample-efficient test-time allocation theoretically grounded and amenable to rigorous analysis. We study both offline and online settings. In the offline regime, where all questions are known in advance, we connect trajectory allocation to crowdsourcing, a classic and well-developed area, by modeling reasoning traces as workers. This perspective allows us to leverage rich existing theory, yielding theoretical guarantees and an efficient majority-voting-based allocation algorithm. In the online streaming regime, where questions arrive sequentially and allocations must be made on the fly, we propose a novel method inspired by the offline framework. Our approach adapts budgets to question difficulty while preserving strong theoretical guarantees and computational efficiency. Experiments show that PETS consistently outperforms uniform allocation. On GPQA, PETS achieves perfect self-consistency in both settings while reducing the sampling budget by up to 75% (offline) and 55% (online) relative to uniform allocation. Code is available at https://github.com/ZDCSlab/PETS.",
        "source": "export.arxiv.org",
        "published": "Fri, 20 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-20T23:25:10.194914Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2602.14879",
        "title": "CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography",
        "summary": "arXiv:2602.14879v2 Announce Type: replace-cross \nAbstract: Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-its-kind benchmark dataset comprising two components: a Lesion Image and Metadata Set containing 20,335 lesions from 7,795 CT studies with bounding boxes, descriptions, and size information, and a multitask visual question answering benchmark with 2,850 QA pairs covering lesion localization, description, size estimation, and attribute categorization. Hard negative examples are included to reflect real-world diagnostic challenges. We evaluate multiple state-of-the-art multimodal models, including vision-language and medical CLIP variants, by comparing their performance to radiologist assessments, demonstrating the value of CT-Bench as a comprehensive benchmark for lesion analysis. Moreover, fine-tuning models on the Lesion Image and Metadata Set yields significant performance gains across both components, underscoring the clinical utility of CT-Bench.",
        "source": "export.arxiv.org",
        "published": "Fri, 20 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-20T23:25:10.196008Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2602.16844",
        "title": "Overseeing Agents Without Constant Oversight: Challenges and Opportunities",
        "summary": "arXiv:2602.16844v1 Announce Type: cross \nAbstract: To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utility of basic action traces for verification, explore three alternatives via design probes, and test a novel interface's impact on error finding in question-answering tasks. As expected, we find that current practices are cumbersome, limiting their efficacy. Conversely, our proposed design reduced the time participants spent finding errors. However, although participants reported higher levels of confidence in their decisions, their final accuracy was not meaningfully improved. To this end, our study surfaces challenges for human verification of agentic systems, including managing built-in assumptions, users' subjective and changing correctness criteria, and the shortcomings, yet importance, of communicating the agent's process.",
        "source": "export.arxiv.org",
        "published": "Fri, 20 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-20T23:25:10.194982Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 8
          }
        ],
        "structural_score": 17,
        "timeliness_score": 5,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 14.600000000000001,
        "temp_score_trend": 7.4
      },
      {
        "url": "https://arxiv.org/abs/2602.16898",
        "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
        "summary": "arXiv:2602.16898v1 Announce Type: cross \nAbstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step.Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.",
        "source": "export.arxiv.org",
        "published": "Fri, 20 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-20T23:25:10.195003Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 17,
        "timeliness_score": 5,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 14.600000000000001,
        "temp_score_trend": 7.4
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "title": "How one California school came together to pack 20,000 meals for the holidays",
        "summary": "At an Elk Grove high school in Sacramento County, students worked a night in the cafeteria to combat global food insecurity.",
        "source": "edsource.org",
        "published": "Mon, 08 Dec 2025 08:03:00 +0000",
        "fetched_at": "2026-02-20T23:25:42.103534Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "title": "Rethinking screen time in California classrooms",
        "summary": "Effective instruction requires a balance between traditional methods and digital engagement. Here's what school districts, families and the state must do.",
        "source": "edsource.org",
        "published": "Tue, 20 Jan 2026 02:58:44 +0000",
        "fetched_at": "2026-02-20T23:25:42.102917Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 3,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "title": "Universal prekindergarten has arrived; now we must sustain it",
        "summary": "County offices of education across the state are calling on the governor and the Legislature to support universal prekindergarten with sustained funding.",
        "source": "edsource.org",
        "published": "Tue, 06 Jan 2026 03:38:57 +0000",
        "fetched_at": "2026-02-20T23:25:42.103067Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "title": "The path to universal preschool in California: Avoiding past mistakes",
        "summary": "California is expanding its transitional kindergarten (TK) to a universal prekindergarten (UPK) system, and must learn from the mistakes of the 1971 federal effort to create a universal early care and education system, which was vetoed by President Nixon.",
        "source": "edsource.org",
        "published": "Tue, 23 Dec 2025 07:03:30 +0000",
        "fetched_at": "2026-02-20T23:25:42.103165Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "title": "California schools prepare to introduce universal reading screening",
        "summary": "A quick screening test will be administered to all students in kindergarten through second grade to detect possible reading difficulties, but it is not intended to be a final diagnosis.",
        "source": "edsource.org",
        "published": "Tue, 20 May 2025 07:05:00 +0000",
        "fetched_at": "2026-02-20T23:25:42.105136Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "title": "As we expand universal preschool access, let’s ensure teachers mirror their students’ ethnicity",
        "summary": "Author&#8217;s original hed: As Universal Preschool Access Expands to Reach More Families of Color, So Do Inequitable Practices Such as Racial Bias, Exclusionary Discipline and Lack of Cultural Representation, Leading to a Crisis for Black Boys As California progresses toward universal preschool access, the need increases for training, hiring and retaining early childhood male educators who are racially and ethnically representative of the children... <span class=\"read-more\"><a href=\"https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393\">read more</a></span>",
        "source": "edsource.org",
        "published": "Tue, 09 Jul 2024 15:53:36 +0000",
        "fetched_at": "2026-02-20T23:25:42.107752Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "title": "Survey: Californians are worried about student health, lukewarm toward a state school bond",
        "summary": "The annual Public Policy Institute of California survey on education issues found wide support for universal TK and teaching about slavery but divisions on transgender issues.",
        "source": "edsource.org",
        "published": "Thu, 11 Apr 2024 05:11:37 +0000",
        "fetched_at": "2026-02-20T23:25:42.108391Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2026/supporting-new-teachers-retention/750763",
        "title": "How districts can fix the teacher ‘support shortage’",
        "summary": "California's teacher workforce is recovering, but retention is still a challenge, and districts need to invest in comprehensive support systems to ensure teachers stay in the profession and thrive.",
        "source": "edsource.org",
        "published": "Mon, 09 Feb 2026 23:38:55 +0000",
        "fetched_at": "2026-02-20T23:25:42.102689Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "title": "Federal appeals court pauses ruling on student gender identity disclosure in California",
        "summary": "An appeals court panel wrote that it is “skeptical” of the lower court’s decision, which would challenge policies adopted by 598 of the state’s nearly 1,000 local school districts.",
        "source": "edsource.org",
        "published": "Thu, 08 Jan 2026 00:04:46 +0000",
        "fetched_at": "2026-02-20T23:25:42.103025Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2025/clovis-unified-preschool-program-gets-creative-with-state-arts-funding/743835",
        "title": "Clovis Unified preschool program gets creative with state arts funding",
        "summary": "Clovis Unified is using $150,000 of state arts funding to provide arts, music and theater education to preschool students through an interactive farm exhibit.",
        "source": "edsource.org",
        "published": "Mon, 03 Nov 2025 08:05:00 +0000",
        "fetched_at": "2026-02-20T23:25:42.103817Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      }
    ],
    "mycotech": [
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003638",
        "title": "Metabolic modeling reveals determinants of prebiotic and probiotic treatment efficacy across multiple human intervention trials",
        "summary": "<p>by Nick Quinn-Bohmann, Alex V. Carr, Sean M. Gibbons</p>\n\nPrebiotic, probiotic, and combined (synbiotic) interventions often show variable outcomes across individuals, driven by complex interactions between introduced biotics, the endogenous microbiota, and the host diet. Predicting individual-specific success or failure of probiotic and prebiotic therapies remains a major challenge. Here, we leverage microbial community-scale metabolic models (MCMMs) to predict probiotic engraftment and microbiota-mediated short-chain fatty acid (SCFA) production in response to probiotic and prebiotic interventions. Using data from two human clinical trial cohorts, testing a five-strain probiotic combined with the prebiotic inulin designed to improve metabolic health and an eight-strain probiotic designed to treat recurrent <i>Clostridioides difficile</i> infections, respectively, we show that MCMM-predicted engraftment largely agrees with measurements, achieving 75%–80% accuracy. Engraftment probabilities varied across taxa. MCMMs captured treatment-driven shifts in predicted SCFA production, and higher model-predicted growth rates of <i>Akkermansia muciniphila</i> were negatively associated with glucose area under the curve (AUC) in the first trial, providing clues about the mechanisms underlying treatment efficacy. Extending these models to a third human cohort undergoing a healthy diet and lifestyle intervention revealed substantial inter-individual variability in predicted responses to increasing dietary fiber, which were significantly associated with baseline-to-follow-up changes in cardiometabolic health markers. Finally, our simulation results suggested that personalized prebiotic selection may further enhance probiotic efficacy. Together, these findings demonstrate the potential of metabolic modeling to guide personalized microbiome-mediated interventions.",
        "source": "journals.plos.org",
        "published": "2026-02-19T14:00:00Z",
        "fetched_at": "2026-02-20T23:25:55.997086Z",
        "tags": [
          {
            "name": "transformation",
            "score": 8
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260219040749.htm",
        "title": "Scientists discover gene that could save bananas from deadly Panama disease",
        "summary": "A major breakthrough could help save the world’s bananas from a devastating disease. Scientists have discovered the exact genetic region in a wild banana that provides resistance to Fusarium wilt Subtropical Race 4 — a destructive strain that threatens Cavendish bananas worldwide. While this wild banana isn’t edible, the discovery gives breeders a powerful genetic roadmap to develop future bananas that are both delicious and naturally protected from this deadly pathogen.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 19 Feb 2026 09:43:15 EST",
        "fetched_at": "2026-02-20T23:25:54.870632Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "title": "A hidden Aloe vera compound takes aim at Alzheimer’s",
        "summary": "Scientists have uncovered promising clues that compounds found in Aloe vera could play a role in fighting Alzheimer’s disease. Using advanced computer modeling, researchers discovered that beta-sitosterol—a natural plant compound—strongly interacts with two key enzymes involved in memory loss and cognitive decline. The compound showed stability, strong binding, and favorable safety indicators, making it a standout candidate for future drug development.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 08 Feb 2026 07:57:41 EST",
        "fetched_at": "2026-02-20T23:25:54.870762Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003631",
        "title": "Recurrent mutations in the stress regulator Cap1 reveal a trade-off between azole resistance and oxidative stress response in <i>Candida albicans</i>",
        "summary": "<p>by Xin Zhou, Audrey Hilk, Norma V. Solis, Nancy Scott, Christopher Zajac, Scott G. Filler, Anna Selmecki</p>\n\nDrug resistance is a critical challenge in treating life-threatening fungal infections. Here, we uncover a mechanism of acquired azole resistance in <i>Candida albicans</i> through mutations in <i>CAP1</i>, encoding a conserved fungal transcription factor that mediates the oxidative stress response. We analyzed 300 clinical isolates and identified 25 distinct <i>CAP1</i> missense or nonsense mutations, with many occurring within the DNA-binding domain. We identified two nearly identical <i>CAP1</i> heterozygous nonsense mutations, one in an isolate obtained from a bloodstream infection and one in a population of cells undergoing adaptation to fluconazole <i>in vitro</i>. Both <i>CAP1</i> nonsense mutations resulted in loss of the C-terminal nuclear export signal, leading to nuclear retention of Cap1 and subsequent activation of genes associated with the oxidative stress response and drug transport. The <i>CAP1</i> C-terminal truncations conferred significant fitness advantages in the presence of fluconazole, both <i>in vitro</i> and in a murine model of candidiasis. Strikingly, we discovered a therapeutic vulnerability: azole concentrations above the minimal inhibitory concentration were fungicidal to mutants with the <i>CAP1</i> C-terminal truncation. The fungicidal effect was attributed to both elevated azole-induced reactive oxygen species and a compromised oxidative stress response in Cap1-truncated cells. Our results provide novel characterization of <i>de novo</i> <i>CAP1</i> point mutations emerging in both laboratory and clinical contexts, elucidate the mechanisms underlying Cap1-regulated stress responses, and reveal a potential therapeutic target for overcoming drug resistance in <i>C. albicans</i> infections.",
        "source": "journals.plos.org",
        "published": "2026-02-02T14:00:00Z",
        "fetched_at": "2026-02-20T23:25:55.997212Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 14,
        "timeliness_score": 1,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "title": "This weird deep-sea creature was named by thousands of people online",
        "summary": "A newly discovered deep-sea creature has become an unlikely Internet star. After appearing in a popular YouTube video, a rare chiton found nearly three miles beneath the ocean surface sparked a global naming effort, drawing more than 8,000 suggestions from people around the world. Scientists ultimately chose the name Ferreiraella populi, meaning “of the people,” honoring the public that helped bring it into the scientific record.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 07 Feb 2026 23:32:36 EST",
        "fetched_at": "2026-02-20T23:25:54.870753Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "title": "This tiny molecular trick makes spider silk almost unbreakable",
        "summary": "Scientists have cracked a key mystery behind spider silk’s legendary strength and flexibility. They discovered that tiny molecular interactions act like natural glue, holding silk proteins together as they transform from liquid into incredibly tough fibers. This same process helps create silk that’s stronger than steel by weight and tougher than Kevlar.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 01:22:10 EST",
        "fetched_at": "2026-02-20T23:25:54.870767Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "title": "The remarkable climate case for turning farm waste into building materials",
        "summary": "Wheat straw and rice husks already appear in niche construction products. A new study explores the global climate effects if they went mainstream.",
        "source": "www.anthropocenemagazine.org",
        "published": "Fri, 06 Feb 2026 13:00:00 +0000",
        "fetched_at": "2026-02-20T23:25:57.251210Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003577",
        "title": "Piriform seizures mediated by the piriform-entorhino-dentate circuit induce brain-wide functional reorganization in mice",
        "summary": "<p>by Yan Tao, Yuxin Zhao, Wenqi Zhong, Jiajia Zhang, Hongyan Zhu, Xutao Zhu, Zikun Wang, Na Wang, Liqin Yang, Fuqiang Xu, Ruiqi Wu</p>\n\nSystematic identification of global epileptic reorganization and critical seizure-controlling circuits is essential for comprehending epilepsy pathophysiology and for developing network-guided targeted therapies. The piriform cortex (PC) is a recognized epileptogenic region, but how its hyperactivity reshapes whole-brain dynamics and which specific circuits mediate seizures remains unclear. Through multimodal integration of optogenetics, fMRI, electrophysiology, Ca<sup>2+</sup> imaging, neural tracing, and circuit-specific manipulation, we mapped the whole-brain dynamics following optogenetic stimulation of PC and identified the fundamental circuit governing piriform seizures. We observed pronounced generalized seizures in mice via repeated optogenetic stimulation of PC <i>Vglut1</i>+ neurons. Optogenetic kindling of PC<sup>Vglut1</sup> induced widespread blood-oxygen-level-dependent (BOLD) signal hyperactivation and resting-state functional connectivity (rsFC) alterations, notably sustained hyperactivation in the lateral entorhinal cortex (Lent) and enhanced PC-Lent rsFC. Chronic elimination of Lent neurons receiving PC projections significantly decreased the Lent-dentate gyrus (DG) rsFC. Disruption of the PC-Lent or Lent-DG circuit effectively suppressed PC-stimulation-triggered seizures and brain-wide hyperactivation. Our findings demonstrate the dominant role of the PC<sup>Vglut1</sup>-Lent<sup>glut</sup>-DG circuit in mediating piriform seizures and driving their resulting brain-wide functional reorganization, offering new insights for targeted epilepsy treatments.",
        "source": "journals.plos.org",
        "published": "2026-02-12T14:00:00Z",
        "fetched_at": "2026-02-20T23:25:55.997145Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 1,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003667",
        "title": "Categorical identity signatures can reduce host error rates during brood parasitism",
        "summary": "<p>by Tanmay Dixit, Ming Liu, Jana M. Riederer, Jonah M. Walker, Cameron J. Blair, Jess Lund, Collins Moya, Claire N. Spottiswoode</p>\n\nBiological recognition is often modeled as involving discrimination of continuously-distributed (and continuously-perceived) traits according to decision thresholds. However, traits such as animal signals can be categorically distributed. Here, we test how such categorical distributions may influence fundamental trade-offs in signal recognition, using a brood parasite–host system involving identity recognition. The African cuckoo finch <i>Anomalospiza imberbis</i> parasitizes several host species, each of which has evolved inter-individual variation in egg appearance (“egg signatures”) that facilitates recognition and rejection of mimetic cuckoo finch eggs. We demonstrate that egg signature traits in one host species, the zitting cisticola <i>Cisticola juncidis</i>, are categorically distributed. Field experiments reveal that zitting cisticolas make fewer Type II errors (accepting parasitic eggs) <i>and</i> Type I errors (rejecting their own eggs) than hosts exhibiting continuous variation. This challenges the long-standing expectation from classification models, statistics, and signal detection theory that there must be a strict trade-off between these two error types. Individual-based simulations clarify mechanisms by which categorical variation can generate low error rates, especially when combined with “category-based rejection,” whereby hosts only reject eggs of different categories to their own. Our findings show that the categorical distribution and category-based perception of trait variation can shape error trade-offs and coevolutionary dynamics, which should inform studies on other mimicry or self/non-self recognition systems, including immune recognition. They also highlight the importance of quantifying trait distributions and how they are perceived, when understanding coevolution between deceivers and those they deceive.",
        "source": "journals.plos.org",
        "published": "2026-02-20T14:00:00Z",
        "fetched_at": "2026-02-20T23:25:55.997056Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 1,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.6,
        "temp_score_trend": 3.3999999999999995
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003639",
        "title": "Transcriptomic and chromatin accessibility profiling unveils new regulators of heat hormesis in <i>Caenorhabditis elegans</i>",
        "summary": "<p>by Hsin-Yun Chang, Sarah E. McMurry, Sicheng Ma, Charles L. Heinke, Christian A. Mansour, Sophia Marie T. Schwab, Charles G. Danko, Siu Sylvia Lee</p>\n\nHeat hormesis describes the beneficial adaptations resulting from transient exposure to mild heat stress, which enhances stress resilience and promotes healthy aging. While heat hormesis is widely observed, much remains to be learned about its molecular basis. This study bridges a critical knowledge gap through a comprehensive multiomic analysis, providing key insights into the transcriptomic and chromatin accessibility landscapes throughout a heat hormesis regimen in <i>Caenorhabditis elegans</i>. We uncover highly dynamic, dose-dependent molecular responses to heat stress and reveal that while most initial molecular changes induced by mild stress revert to baseline, key differences emerge in response to subsequent heat shock challenge that likely contribute to physiological benefits. We further demonstrate that heat hormesis extends life span specifically in wild-type animals, but not in germline-less mutants, likely due to transient disruption of germline activities during mild heat exposure, which appears sufficient to trigger pro-longevity mechanisms. This finding points to tissue-specific responses in mediating the physiological outcomes of heat hormesis. Importantly, we identify several highly conserved regulators of heat hormesis that likely orchestrate gene expression to enhance stress resilience. Among these regulators, some (MARS-1/MARS1, SNPC-4/SNAPc, FOS-1/c-Fos) are broadly required for heat-hormesis-induced benefits, whereas others (ELT-2/GATA4, DPY-27/SMC4) are uniquely important in specific genetic backgrounds. This study advances our understanding of stress resilience mechanisms, points to multiple new avenues for future investigations, and provides a molecular framework for promoting healthy aging through strategic mid-life stress management.",
        "source": "journals.plos.org",
        "published": "2026-02-20T14:00:00Z",
        "fetched_at": "2026-02-20T23:25:55.997068Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 1,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "title": "The Rebirth of Pennsylvania’s Infamous Burning Town",
        "summary": "<p>“There’s not much there anymore, it’s pretty much just a crossroads.”</p>\n<p>I read the posts online telling me not to bother, but I wanted to go anyway. Certainly I could feel something as we got close: the sense of desperation, of ruin and abandon. So I drove with a small group of friends deep into eastern Pennsylvania—coal country—through towns with names like Frackville, Pottsville, Ashland. Many downtowns had at least one house that had burned to ruin and been left abandoned. It was early June, but clouds covered the sky and we drove through a slight but persistent rain.</p>\n<p>We were on our way to Centralia, Pennsylvania. The Burning Town.</p>\n<p>The coal that made this valley famous accreted in layers over tens of thousands of years, organic swamp matter turning first to peat, and then compressed over millennia into billions of tons of anthracite—the densest and most pure form of coal—the stuff that made this region of Pennsylvania famous. Mines first opened here in 1856 and Centralia was incorporated as a town a decade later. Through the years bitter labor disputes broke out over exploitative treatment of the (largely Irish immigrant) miners, leading to regular outbreaks of violence. Add to that the boom and bust cycle of the coal industry—and the environmental desolation and impoverishment of the region—and you end up with a town that is deeply scarred, both literally and metaphorically.</p>\n<p>But the story that made Centralia famous began in May 1962, when officials set fire to the trash in a local landfill in an open strip-mine pit. This wasn’t the first year they’d done this, and there were firefighters stationed to ensure the blaze didn’t get out of control. After two days, the trash fire seemed to have burned itself out. But this time, for whatever reason (the actual cause was never fully determined), something went wrong. The landfill burn had lit the coal mines beneath the town.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106279/image.jpg\" width=\"auto\" /></figure>\n<p>Over the years, numerous attempts were made to put out the fire. Nothing worked. In all, federal, state, and local governments spent over $3.3 million on the blaze, which raged on, uncontrollably. Over time, residents reported that their basements were strangely hot, and in 1979, the mayor John Coddington lowered a thermometer into an underground fuel tank at the gas station he owned, only to discover that the gasoline was 172 degrees Fahrenheit. And then on Valentine’s Day, 1981, a twelve-year old boy fell into a four-foot-wide sinkhole that opened up in his grandmother’s backyard, barely rescued by his fourteen year-old cousin. A plume of lethal carbon monoxide bellowed out from the hole.</p>\n<p>Realizing that topsoil was the only thing separating the town from a massive, raging inferno, the federal government finally decided to clear the town. The United States Congress allocated money for a buyout, which nearly all of the town’s 1,000 or so residents took. By 1990, 63 people remained in the town. Two years later, governor Bob Casey invoked eminent domain and condemned all the remaining buildings. By 2021, only five homes were still left standing.</p>\n<p>I had come here expecting that we would find ruin and neglect, toxicity and destitution. I expected Centralia to be an exemplar of the <em>eerie: </em>A place where once there had been a town, place of thriving life, and instead now was only absence, an emptiness, a void.</p>\n<p>What we found instead, strangely, was beauty. Centralia, despite everything I’d been led to expect, was thriving.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106274/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>The Burning Town has come to stand in as a kind of exemplar of a post-industrial wasteland, a place where human folly reached its apex, scorching the land. All but abandoned, it became known primarily for the vents that poured smoke from the fire below, and for Graffiti Highway—a closed stretch of Route 61 covered in tags, doodles of genitalia, and declarations of love.</p>\n<p>When adapting the video game franchise <em>Silent Hill </em>for film, screenwriter Roger Avary used Centralia as a model for both the town’s backstory and its look. For years it drew curious onlookers and legend trippers, while the name “Centralia” itself became an almost byword for late capitalism: a term for that mixture of rapacious profit-seeking and thoughtless stewardship that created America’s own Chernobyl.</p>\n<p>Locals see the story a little differently, though their version borrows from similar themes. Phil, a tour guide at Pioneer Tunnel in neighboring Ashland, pointed out that while the grim toil of the mines claimed many human lives, their closure left the valley with little else to offer. He explained how the families that didn’t leave Centralia were harassed, as government forces tried to drive them off their land. Those that stayed had to go to court to defend their right to live on this abandoned land, all because they wanted to keep the mineral rights to their property. So now, people like Phil assume that the government is just waiting them out. Once they’re gone, putting out the fire will be easy enough. “They’ll take all that red hot coals, but also they’re going to get that rich anthracite coal,” he told us. “And I’m sure they’ll sell that. But are the people or the relatives going to get anything? It’s very doubtful. It’ll probably go to the federal government. Or the coal baron, maybe?”</p>\n<p>His voice, I noticed after a while, has a peculiar kind of nostalgia for the worst times in the world. Like so many others in these towns, he seems to long for a return, another chance for Pennsylvanians to throw their children back into the maw of the mine. Anything for a chance to get the coal jobs will come back. Anything in service of waking the Mountain once more.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106256/image.jpg\" width=\"auto\" /></figure>\n<p>When we finally got to Centralia, we were met not with destruction or despair, but with what seemed at first simply like nothing. The streets are still laid out, and there are still a handful of houses left, but the graffiti highway has been covered over. Any abandoned buildings have long been torn down.</p>\n<p>It’s why, if you ask around these days, folks will tell you there’s nothing to see in Centralia. “I drove through Centralia 2 weeks ago,” one local commented on a <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1cw0xqc/looking_to_visit_centralia_is_it_still_legal_to_go/\">Reddit thread</a>. “I didn’t realize till after I had already passed it. That should tell you everything you need to know.” In another thread a different local <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1ikd2rs/i_have_some_questions_regarding_traveling_through/\">commented</a>, “What is the draw? It’s just empty ground now.”</p>\n<p>But emptiness can tell its own story. Standing on the empty streets of Centralia, I thought mainly of Cal Flynn’s <em>Islands of Abandonment: Nature Rebounding in the Post-Human Landscape. </em>Flynn travels the world to places that have been forsworn by humanity: not the pristine, untouched wilderness, but places abandoned, like Chernobyl and the exclusion zone that divides the island of Cyprus between its Greek and Turkish halves. Places where, Flynn writes, “nature has been allowed to work unfettered.” Such places are often thriving with plant and animal life. Abandonment, she writes, “<em>is </em>rewilding, in a very pure sense, as humans draw back and nature reclaims what once was hers.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106273/image.jpg\" width=\"auto\" /></figure>\n<p>What Flynn makes clear is that while we tend to think of human activity on the landscape as not only damaging but <em>irreversible</em>, this may not always be the case. We believe, in our hubris, that we have the power to wreck nature for good. And while it’s true that places like the Bikini Atoll and Chernobyl will be radioactive for unimaginable human lifetimes, that doesn’t mean that other species haven’t moved in and, left unmolested by human activity, found ways to flourish.</p>\n<p>Flynn’s book catalogs a variety of ways in which nature has reclaimed places that we’ve left behind, often with surprising speed. When Estonia, for example, became independent of the Soviet Union, some 245 million square miles of collectivist farmlands were simply abandoned. They weren’t plowed over, repurposed, or re-seeded. They simply were left alone. Flora immediately went to work: soon these fields were covered in wildflowers and weeds, and then thorn bushes and brambles, and then the skinny shoots of young spruce trees. Now, thirty-five years later, Estonia is now one of the most forested countries in Europe, having nearly doubled the size of its forests by doing … nothing. Half the country is now a forest, and over 90 percent of those forests have naturally regenerated.</p>\n<p>When I say that Centralia is <em>thriving, </em>this is what I mean. It is a landscape pulsing with life, overflowing with lush greenery. The old grid of streets is still visible, and there are still a handful of houses with carefully mowed lawns sitting in defiance. But everything else is the wild and vital province of nature. Turkeyfoot, broom-sedge, and switchgrass and silky dogwood. Young white oaks and linden trees push their way through this cacophony of life. Everywhere that’s not asphalt is a riot of green in every possible shade. And all of this is possible, at least in part, because the state and federal governments have forbidden any new human settlement, giving the wild and the lush and untrammeled room to grow.</p>\n<p>Not all of this is just nature. In 2021, the Eastern Pennsylvania Coalition for Abandoned Mine Reclamation planted 250 apple trees in the hope of attracting butterflies. EPCAMR has hosted annual trash clean-ups in the town, but a few years ago turned to planting and furthering the former town’s potential as an unofficial wildlife sanctuary. “We’re trying to get that area designated as a monarch way station eventually,” Robert “Bobby” Hughes, executive director of EPCAMR said at the time. But as vital as this work is, it seems primarily that the rewilding of Centralia is simply the work of leaving it alone.</p>\n<p>Standing in what was once a small, otherwise forgettable town, I came to understand how folly, mistake, calamitous hubris, neglect, and plain stupidity—could all be weapons in an arsenal to rewild and reforest the Earth, a future waiting in places we mistakenly believe we have irredeemably scarred.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106280/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>Beyond the town itself, the thing people have come to mourn here is the Graffiti Highway, which for years was a strange destination before it was covered over in 2020. It began, as these things often do, as spontaneous tagging and defacement. But over time, more taggers added their names, their designs, their art, and their stories, until it had become a makeshift historical record of the people who live here.</p>\n<p>Over time, it had begun to encroach on the natural history that was also unfolding, spilling out beyond the asphalt and into the forest, as trees and plants started to get defaced. It became an attractive nuisance, repeated bonfires and ATV crashes straining local resources, so when coal company Pagnotti Enterprises bought the land in 2018, they chose to bury the road in dirt and erased it for good. There is now, in the words of many Redditors, no reason to go to Centralia. But the company’s decision also obliterated what some saw as a vital piece in the region’s history. Pagnotti’s<a href=\"https://www.google.com/search?q=pagnotti+enterprises&amp;oq=pagnotti+enterprises&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM4MjBqMGo3qAIAsAIA&amp;sourceid=chrome&amp;ie=UTF-8#lrd=0x89c51a61c01ed687:0x1b1a2cd6c4d6b514,1,,,,\"> reviews</a> on Google are uniformly one-star ratings alongside comments like “You ruined graffiti highway,” “ruined a landmark, nice piles of dirt, go die,” and so on.</p>\n<p>For those who contributed to the Graffiti Highway, it had marked loves and losses, honored the dead and celebrated the living, all in a hundred different colors. (Park Street in Centralia has since begun to take the place of the old Graffiti Highway, decorated with a variety of tags, but at the moment it has nowhere near the density of the original Graffiti Highway. Some monuments take time to rebuild.)</p>\n<p>Kutztown University professor Deryl Johnson has called the story of Graffiti Highway an “epilogue” to the story of Centralia itself, but I’m not sure I agree. The story of Centralia is still very much unfolding—it did not end in 1982, and it did not end in 2020. Now that the highway is gone, the tourist attraction draw of this place has waned, leaving even more space for the natural world to reclaim the land. A new chapter has begun, and there may be other chapters in the story yet to come—chapters whose shape and direction we can only guess at.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106277/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>If you think of Centralia in terms of human habitation, it’s a ghost town, a few stubborn holdouts fighting against entropy and inertia. If you think of Centralia in terms of legend tripping and ruin porn, it’s nothing at all, barely a wide spot in the road. But if you think of Centralia as an unintended nature preserve, it is absolutely bursting with life and potential and possibility.</p>\n<p>Yet still the ground burns. Just out of the grid of streets that was once the town, down Big Mine Run Road, are the vents themselves: small holes in the sides of the hills like something out of Tolkien that lead down to inferno below. These days, the smoke itself is rarely visible, but when rain filters down to the fires, it comes back out as steam. So on the rainy day of our visit, we watched as these vents let out a small, steady stream of white steam, proof of the heat somewhere beneath our feet.</p>\n<p>It was an odd sensation. The wisps seemed peaceful, laconic, almost soothing. And at the same time, it seemed as though at any moment the entire valley would explode. Somehow it felt like both of these things at once.</p>\n<p>Looking at these gentle wisps of smoke, it is difficult to picture the smoldering inferno they emerged from. A fire that has raged out of control for sixty years, unending and older than most people you know. You try and you fail every time.</p>\n<p>Which is to say, Centralia’s mine fire is a thing that should not be. I can describe to you its history, the actions of the people involved. I can describe to you what the surface looks like, the species of plants, the words etched into the tombstones at the Odd Fellows Cemetery. But the secret, raging, burning heart of the Valley remains elusive.</p>\n<p>The plumes are a subtle reminder, easy to miss, that there is a reason for this pristine, thriving wildness all around us. That the coal mines underground are a price that has to be paid, paid to an underworld god that must be forever fed.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 17:18:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591721Z",
        "tags": [
          {
            "name": "transformation",
            "score": 9
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 19,
        "timeliness_score": 3,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "title": "Inside Thomas Edison’s Botanical Laboratory",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>Thomas Edison and his family had a ritual. Every winter, they would leave freezing cold New Jersey and head down to Fort Myers, Florida. Back then, Fort Myers was out there. Think swamps and mosquitoes. It was actually easier to get around by boat than over land.</p>\n<p>The Edisons would do vacation stuff: go fishing, go on boat rides, collect interesting plants. And in 1914, they invited a different branch of American inventing royalty to join them. That year, Henry Ford, of the Model T Ford, came down to Florida with his wife, Clara.</p>\n<p>Ford must have been psyched because Edison was actually his hero. They’d met briefly years before at a conference when Ford was still a low-level employee at an Edison company. Now they were meeting on something like equal terms.</p>\n<p>So to celebrate the occasion, Ford had some Model Ts shipped down to Fort Myers. Everyone went out joyriding around the swamps. The cars flooded, their campsite got soaked. Clara Ford was really afraid of snakes, and there were snakes everywhere. Henry tried to scare them away by shooting off a pistol. Needless to say, it was a trip.</p>\n<p>But soon, once the smoke from Ford’s pistol had cleared and the Model Ts had dried out, Edison and Ford would become more than just travel buddies. They were actually about to embark on an enormous inventing project, a project that would turn Edison’s Florida house into a full-fledged botanical laboratory and would become the last great obsession of Edison’s life.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. Today’s episode is brought to you in partnership with Fort Myers – Islands, Beaches and Neighborhoods. Maybe when you think of Henry Ford and Thomas Edison, you think technology, cars, light bulbs, electricity. But the success of both of their inventions depended on plants. That is why they had come to Florida: to experiment.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106299/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Plants were actually the reason Thomas Edison had fallen in love with Fort Myers in the first place. Around 30 years before that camping trip with Ford, Edison was working away in his Menlo Park lab on one of his most famous projects.</p>\n<p><strong>Karen Maxwell:</strong> Many people are under the misimpression he invented the light bulb. He actually perfected it.</p>\n<p><strong>Kelly: </strong>This is Karen Maxwell. She’s the horticulture director at the Edison and Ford Winter Estates.</p>\n<p><strong>Karen: </strong>So, at this time, there are about 20 different varieties of incandescent light bulbs, but none of them burned for very long.</p>\n<p><strong>Kelly:</strong> The problem was this teeny tiny piece inside the bulb called a filament. When electricity passes through, the filament heats up and glows and we get light. But none of these early filaments could glow long enough to make a practical light bulb.</p>\n<p>So Edison set out to change that, testing thousands and thousands of different materials. Cotton, platinum, cedar, and finally, bamboo.</p>\n<p><strong>Karen: </strong>And he had his team—I’m glad I wasn’t one of them then—they stayed up and did shifts to record how long it burned. That filament burned for 1,200 hours. And that made the incandescent light bulb a national product.</p>\n<p><strong>Kelly:</strong> Edison, already a famous inventor, was now a legend. But by the end of the project, his personal life was a mess.</p>\n<p><strong>Karen:</strong> He was 38 years old, burned out, and had lost his first wife, Mary. Three children. His doctor says, Thomas, you need to go south, take a vacation, and take a break. He ends up arriving in St. Augustine during the winter and finds that is really too cold. It didn’t meet what his doctor had prescribed. So one of his friends takes him further down the river and they end up going by the property, which is currently today what we know as the Edison and Ford Winter Estates. What does he see but stands of bamboo growing along the riverside? He bought it on the spot.</p>\n<p><strong>Kelly:</strong> Edison remarried, and soon he and his second wife, Mina, started transforming the Florida property and its stand of bamboo into their wintertime home away from home. Edison even had an old laboratory shipped down from New Jersey in case inspiration struck while he was on vacation. You know, his lab away from lab.</p>\n<p>At first, he did some experimenting with bamboo, but then in 1905, the invention of the tungsten filament for the light bulb made the bamboo one obsolete. Soon enough, though, he would have another project to focus on.</p>\n<p>After the Fords joined the Edison family vacation in 1914, it was time for Ford to invite Edison on a trip. They went to San Francisco, and Ford introduced Edison to some friends: a botanist named Luther Burbank, who was interested in plant hybridization, and the tire magnate, Harvey Firestone, of Firestone Tires. It wasn’t long before their conversation turned to rubber.</p>\n<p>And the thing was, in order to make cars, you needed tires, and in order to make tires, you needed rubber. Back then, there was no such thing as synthetic rubber. All of it came from plants. Most natural rubber was grown in Southeast Asia, in British and Dutch colonies, and that meant the British and Dutch set rubber prices. The crew became convinced that America needed its own domestic rubber supply. Edison got to work right away.</p>\n<p><strong>Karen:</strong> So he starts looking for a product that can grow quickly, produce latex. Latex is what makes rubber. Latex is a milky white substance. If you break open the stem, out comes a sticky white milky product. That is latex and that is the basis of all natural rubber.</p>\n<p>Over 17,000 plants are brought in and studied. There were botanists, volunteers, they even engaged the Union Pacific Railroad, who instructed every section chief to collect any plants growing along their extensive miles of right-of-way and forward them to Edison’s laboratory.</p>\n<p><strong>Kelly:</strong> The Florida House essentially became a latex distilling factory. Today, if you visit, you can still see a lot of these plants that Edison was experimenting on. There’s a spiny vine called crown of thorns, which looks like a cactus; a scrubby desert shrub called guayule, which is native to Mexico; and the most spectacular specimen, or at least the biggest, was the banyan tree.</p>\n<p><strong>Karen:</strong> It’s been in place for 100 years. And over the years, it’s grown extensively. We’ve had to maintain trimming so it doesn’t just eat up the buildings. The first impression people have is they’re looking at a forest of trees.</p>\n<p><strong>Kelly</strong>: Today, the tree covers nearly an entire acre of land. It’s the largest banyan tree in the continental U.S. But unfortunately for Edison, it just did not produce enough latex.</p>\n<p><strong>Karen:</strong> In 1928, he discovers, right here in his backyard, the plant that produces the most latex is goldenrod.</p>\n<p><strong>Kelly: </strong>Goldenrod is a very fast-growing weed with yellow flowers. Looks a lot like ragweed. So Edison ripped out rows and rows of his wife Mina’s citrus trees to plant goldenrod, which I’m sure she wasn’t thrilled about.</p>\n<p><strong>Karen:</strong> He mows them all down and he transforms their estate-like atmosphere to just a conglomeration of disorderly beds with markers and irrigation ditches all around, 500 plots of yellow goldenrod. And as you can imagine, that did little to kindle her enthusiasm for his work.</p>\n<p><strong>Kelly:</strong> Speaking of Mina’s view of his work, she was annoyed about the citrus trees, yes, but she was also worried about her husband’s health. Edison was in his 80s now and still keeping pretty long hours.</p>\n<p>Mina wrote, “He thinks of nothing else now. He has no time for anything else, no recreation,” and, “Everything turned to rubber in the family. We talked rubber, thought rubber, dreamed rubber.”</p>\n<p>There was also some tension between her and Henry Ford. For one thing, Ford had bought the house right next door. That’s why the museum today is known as the Edison and Ford Estates. And another thing: Ford had convinced Edison to let him dismantle his Florida lab and ship it up to Michigan. Because Ford wanted to start a museum dedicated to American innovation, and he said he simply needed his hero’s lab. Mina was not too happy about this. Though, with the help of Ford and Firestone, Edison did end up building a brand new botanical lab.</p>\n<p>Still, by the end of the 1920s, Edison’s health got worse. He came down with pneumonia and by the fall of 1931 was bedridden in New Jersey. At one point on his deathbed, as he was slipping in and out of consciousness, someone came in with a package sent from the Florida house.</p>\n<p>Inside was a small piece of rubber made from Edison’s goldenrod plants. According to biographer Michele Albion, he had a moment of lucidity, and then sunk into a coma. Just a few days later, he died on October 18th, 1931. The Edison family kept the botanical research lab going until 1934, when it was transferred over to the Department of Agriculture.</p>\n<p><strong>Karen:</strong> But it turned out his vision of the importance became true because when World War II came about, Japan captured Malaysia, Singapore, and most of the Pacific Rim rubber plantations.</p>\n<p><strong>Kelly: </strong>During the war, there were serious rubber shortages in the U.S. The government rationed gasoline and lowered speed limits just to make tires last longer.</p>\n<p><strong>Karen:</strong> But it was shortly after that that synthetic rubber ended the goldenrod destiny. That was in 1944. And It was pretty much what Tungsten did for his carbonized bamboo filament, the synthetic rubber did to his goldenrod rubber research. But he was right. I mean, he kept people going in the right direction. Without that foundation, we probably wouldn’t have been here today.</p>\n<p><strong>Kelly: </strong>Today, the Ford and Edison Winter Estates are combined into one big museum property. You can spend hours wandering around the grounds and seeing many of the plants that we talked about in this episode. The bamboo, the goldenrod, the banyan tree, and of course, the botanical laboratory itself.</p>\n<p><strong>Karen: </strong>It’s a 21-acre paradise of discovery for people that enjoy gardens and enjoy the different textures, the structures, the colors. There’s something blooming every single day. Many, many things.</p>\n<p><strong>Kelly:</strong> In our episode description, we will post a link to more info about visiting the Edison and Ford winter estates. And if you enjoyed today’s show, check out another episode of ours called <a href=\"https://www.atlasobscura.com/articles/podcast-fordlandia\">Fordlandia</a>. It’s all about Henry Ford’s very unsuccessful attempt to start an industrial rubber town in Brazil.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. This episode was produced by Amanda McGowan. The production team for this episode includes Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Jerome Campbell, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 28 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591703Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "title": "Atlas Obscura’s Guide to Sun Valley, Idaho’s Most Fascinating Places",
        "summary": "<p>From top to bottom, Sun Valley is full of surprises. Only in this fascinating pocket of central Idaho can you experience an annual heritage festival that parades thousands of sheep from the mountains to Main Street by day, then discover some of the darkest night skies in the world for mind-blowing star gazing.</p>\n<p>In between, you’ll relax in a botanical garden’s meditative nook, and visit the gravesite of one of the world’s most notable writers and explore a moon-like national park full of caves and lava flows. Enjoy this guide to 10 wonderful ways to start your Sun Valley adventure.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">The Roundhouse</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106296/image.jpg\" width=\"auto\" /></figure>\n<p>The Roundhouse, a staple of Sun Valley Resort since 1939, elevates any dining experience—literally. Located 7,700 feet above sea level on Bald Mountain, the restaurant has been a featured fine dining spot since 1939, and is open seasonally, December through March. The octagonal restaurant, featuring 46 windows, is only accessible only by gondola, and the sweeping views of the entire valley make the views as impressive as the menu. Inside oozes with a ski chalet-style, cozy ambiance, especially the four-sided fireplace. A popular starter, the Fondue For Two, comes with artisan bread, Granny Smith apples, grapes, and gherkins. You can also add specialty meats and vegetables for an extra charge. A Wagyu burger, lobster rolls, scallops, and elk Swedish meatballs all make the menu here.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Central Idaho Dark Sky Reserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106289/image.jpg\" width=\"auto\" /></figure>\n<p>Grab your tent and experience the awe-inspiring wonder of Central Idaho’s starry, night sky in the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/the-dark-skies-of-sun-valley-id/\">Central Idaho Dark Sky Reserve</a>. One of the last remaining areas of this level of nighttime natural darkness in the world, the reserve encompasses just under 1,500 miles of public lands inside the Sawtooth National Forest. Certified by the International Dark Sky Association in 2017, and given its highest “gold tier” status, the reserve features an ultra-dark core, plus dark periphery that helps protect the central dark area. Meteor showers, lunar eclipses, spring equinox and the summer solstice are just a few of the many public viewing events held at the reserve annually. The protected wilderness areas under these dark skies are also home to a stunning array of wildlife, including bears, wolverines, elk, wolves, and sandhill cranes.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Trailing of the Sheep</strong> <strong>Festival</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106286/image.jpg\" width=\"auto\" /></figure>\n<p>Each fall, a woolly throng of sheep, roughly 1,200 in all, parade down the main street of Ketchum, Idaho, for the <a href=\"https://visitsunvalley.com/events/annual-trailing-of-the-sheep-festival/\">Trailing of the Sheep Festival</a>. The treasured annual event commemorates the time-honored migration of sheep from Idaho’s high mountain summer pastures to the warmer, grazing and lambing grounds found farther south. For five days, the community celebrates the history, culture, and traditions of the region’s longstanding sheep ranchers, which include Basques, Peruvians, and Scots. Signature events include lamb-centered culinary classes, woolmaking workshops, a heritage fair, and national sheepdog trials. The 2026 festival is October 7-11.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Craters of the Moon National Monument and Preserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106287/image.jpg\" width=\"auto\" /></figure>\n<p>A trip to Central Idaho’s Snake River Plain is just about as close to the moon as most of us will ever get. Aptly described as “a weird and scenic landscape” by President Calvin Coolidge when he established the 750,000-acre federally protected site in 1924, the <a href=\"https://www.atlasobscura.com/places/craters-of-the-moon-national-monument-and-preserve\">Craters of the Moon National Monument and Preserve</a> features a vast, lunar-like landscape of lava flows, cinder cones, and sagebrush. The unique environment was created thousands of years ago by a series of major eruptions along the 52-mile stretch of deep cracks in the Earth’s crust called the Great Rift. For generations, the park has garnered attention and profound fascination, and the wild terrain even served as a training ground for Apollo astronauts in the 1960s. Today, explorers enjoy discovering the park’s many lava tube caves and trails, and viewing the impressive overlooks while driving along the 7-mile Loop Road. Nature lovers and photographers also flock to the park for its surprising diversity of birds and other wildlife, plus it’s a designated dark sky park.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>Sun Valley Museum of Art</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106293/image.jpg\" width=\"auto\" /></figure>\n<p>In downtown Ketchum, the <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> is just one of the many ways to explore the rich culture of the region—off the slopes. Now an integral part of Sun Valley’s arts and culture community, this free museum opened in 1971 and has grown to feature works from greats like Andy Warhol to important pieces from local and regional artists. Equal parts museum and educational hub, the center also features interesting lecture series, live music, films, and hands-on art classes and workshops throughout the year. The exhibit, \"Hidden Gems: Idaho Collects,\" brings art held in private collections in the region into public view through February 28, 2026. The exhibit aims to illuminate the region's community through the art they make and collect</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">Pioneer Saloon</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106285/image.jpg\" width=\"auto\" /></figure>\n<p>One part time capsule, one part fine dining, the Pioneer Saloon is a beloved go-to for Ketchum locals and visitors alike. Located on Main Street, and affectionately called “the Pio,” the <a href=\"https://visitsunvalley.com/dining-shopping/the-pioneer-saloon/\">Pioneer Saloon</a> opened in the 1940s as a casino, despite gambling being outlawed in Idaho. Originally called the Commercial Club, the gambling hub closed its doors after just a few years, and the American Legion turned it into a meeting hall. For a short time, the facility also served as a dry goods store until, in 1950, a man named Whitey Hirschman, turned it back into a casino. Containing decades of local lore and history, the saloon won a 2025 James Beard America's Classics Award. Today, the menu consists of hearty steaks, prime rib, ribs, and seafood, including Idaho trout. Order the signature “Jim Spud,” and you’ll get a hot baked potato with teriyaki beef, cheese, and other toppings. There’s even a “Hemingway Margarita” that pays homage to the famed author whose final resting place is in Sun Valley. Amid the rustic décor inside, you’ll find antiques and artifacts, including Hemingway’s hunting rifle, Western posters and artwork, a Native American canoe and arrowheads, and more.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ernest Hemingway’s Grave</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106288/image.jpg\" width=\"auto\" /></figure>\n<p>Despite Ernest Hemingway’s flamboyant, hard-living nature, the <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">famed writer’s final resting place</a> is a simple slab in a Sun Valley cemetery. Known for his heavy drinking, hunting, and womanizing lifestyle, Hemingway lived all over, from Spain and Cuba to Florida, penning works like, “The Sun Also Rises,” “For Whom the Bell Tolls,” and the Pulitzer Prize-awarded “The Old Man and the Sea.” He visited central Idaho many times before moving to the area prior to his death in 1961. Placed alongside his wife, Mary, under two towering spruce trees, the grave is a modest rectangular marker including just the writer’s name and dates of birth and death. In addition to the expected flowers, fans also pay respects by leaving behind booze bottles, coins, matches, and pens.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Sawtooth Botanical Garden</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106297/image.jpg\" width=\"auto\" /></figure>\n<p>For a serene escape, head to the <a href=\"https://visitsunvalley.com/services/sawtooth-botanical-garden\">Sawtooth Botanical Garden</a> in Ketchum. Located on five acres, the garden, which is also an educational non profit, centers on five major display gardens that represent the varied biomes in central Idaho. One must-see feature is the colorful Tibetan prayer wheel in the Garden of Infinite Compassion. It’s the only such wheel commissioned and blessed by the Dalai Lama in North America and the only one powered by flowing water. The 1,100-pound wheel is said to symbolize peace, healing and the dissemination prayers when turned.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Wood River Museum of History &amp; Culture</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106283/image.jpg\" width=\"auto\" /></figure>\n<p>This free cultural museum in downtown Ketchum celebrates the rich and varied history of central Idaho, from its native people and immigrants to the iconic Bald Mountain and its effect on the local landscape. One exhibit at the <a href=\"https://visitsunvalley.com/to-do/wood-river-museum-of-history-and-culture/\">Wood River Museum</a>, “A Writer in the New Country: Hemingway in 1939,” highlights Ernest Hemingway’s first trip to Sun Valley, a place that was dear to the writer up until his death in 1961. Sheep shears, a telegraph key, and vintage skis are all part of the interactive Cabinet of Wonders, which houses important regional artifacts. At the museum’s entrance, another exhibit honors the Shoshone-Bannock native peoples, who first inhabited central Idaho.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ore Wagon Museum</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106298/image.jpg\" width=\"auto\" /></figure>\n<p>This <a href=\"https://visitsunvalley.com/events/ore-wagon-museum/\">history museum in Ketchum</a> highlights the importance of ore wagons during the region’s rich mining boom of the 1880s. These sturdy wagons, donated to the museum by the Lewis family, whose Fast Freight Line was integral in transporting silver ore from remote mines to in-town railheads, are reportedly the only of their kind in existence. In honor of its mining roots, the city hosts a heritage festival, Wagon Days, every Labor Day weekend. The beloved event features live music, food vendors, cultural presentations, and culminates with the Big Hitch, a parade of these historic, non-motorized vehicles that served as the backbone of the region’s economy before the development of the railroads.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 26 Jan 2026 14:00:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591712Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591726Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "title": "Pedro Rodriguez Is on a Quest for Freshness",
        "summary": "<p>When Pedro Rodriguez is in his Kissimmee, Florida restaurant, Sajoma Latin Fusion, he makes sure to check in on the kitchen. And when he does, there’s a rule that all of his cooks must follow.</p>\n<p>“I better not catch you with anything that’s artificial,” he says. Sajoma’s sancocho, for example, is made from scratch, not with bouillon, which many cooks use to build flavor quickly.</p>\n<p>The approach has paid off. Sajoma has developed an avid following in Central Florida for its approach to Latin cuisine, rooted in good ingredients and creative cooking. Pedro, gregarious and perceptive with a quick smile and a salt and pepper beard, is proud of his brainchild. He’s a grocery supplier by trade; the restaurant business is relatively new for him.</p>\n<p>Sajoma is Pedro’s most personal project yet, the capstone of a lifelong obsession with good food and good produce. And it all started on his family’s farm.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106304/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Feeding Off the Land</h3>\n<p>Until the age of 12, Pedro grew up in the town of San Jose de las Matas in the Dominican Republic. The municipality is known for its natural beauty and mineral water. “It’s almost like one of the greenest towns there,” he says. Sajoma, as the town is called for short, boasts dramatic hills, lush vegetation, and rolling rivers.</p>\n<p>And even in a beautiful town, Pedro lived a particularly idyllic life. His family owned a 120-acre farm with animals like cows, chickens, and goats, and crops including rice, beans, coffee, and yams. “We pretty much used to feed off the land,” he says. Beef was one of the only basic foodstuffs that he recalls leaving their property to obtain.</p>\n<p>The family home sat on the top of a hill. From there, Pedro could see a 360-degree view of mountains, greenery, and livestock grazing in the meadow. After school, he would hang around the house and play with the animals on their property.</p>\n<p>The men who worked for his family would hunt for crabs in caves. Pedro would go with them on their hunts, but he would watch from the side, apprehensive, as they stuck their bare hands into the darkness for huge, snapping crabs. He enjoyed the result, though: a dish called locrio where stewed crab meat releases its flavors into brown rice.</p>\n<p>Pedro grew up loving food, and it’s easy to see why. His mother was—and still is—a great cook who can turn any ingredient into a special meal. And she had the pick of ingredients in their family home. Milk from their own cows, yams dug up from their own soil. Pedro remembers his mother cooking cerdo guisado, or stewed pork, with onions and cubanelle peppers; and pasta with cooked green bananas.</p>\n<p>“The food was, like, unexplainably good, because everything was natural,” Pedro says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106305/image.jpg\" width=\"auto\" /></figure>\n<p>Twenty years ago in New York City, Pedro met his wife, Marisol, who was born in the U.S. to Dominican parents. When they were dating, she cooked him a meal that was, somehow, even better than his mother’s cooking. Pedro went home and told his mother; she was thrilled that her son had found a worthy match. And Marisol shares her in-laws’ dedication to natural cooking. “She does not use anything artificial,” Pedro says. “She’s very big on that.” That means no bouillon, and no pre-made seasonings, like the dried adobo mix that supermarkets sell.</p>\n<p>With Sajoma, Pedro’s goal was to let good ingredients sing without any additives. Customers have taken notice. Pedro says that when he walks the floor of the restaurant, diners tell him, “I literally feel like I’m eating this at home.”</p>\n<p>He believes this is testament to the power of simple cooking with no shortcuts. “Sometimes people think that you could force flavor. You don’t force flavor,” Pedro insists. With natural ingredients, “Flavor is very easy to accomplish.”</p>\n<h3 class=\"article-second-subheading-pre-rd\">From the Dominican Republic to the World</h3>\n<p>If the Rodriguez family farm was Pedro’s first culinary education, the multicultural restaurants of New York were his second. When Pedro was 12, his parents moved to New York and sent Pedro, his brother, and his sister to the city of Santiago to live with his grandparents. When Pedro was 14, his parents brought their children to the Big Apple.</p>\n<p>One might think moving from verdant island to concrete jungle would be difficult. For Pedro, it wasn’t.</p>\n<p>He received a warm welcome from his extended family, most of whom had settled in New York by the time he and his siblings got there. His first summer in New York, relatives toured him and his siblings around to the city’s parks and botanic garden. He loved the communal culture of 1980s Brooklyn, where he would wile away the day outdoors, playing ball on the streets and hanging out with his cousins. When Pedro’s mother offered to send him back to the Dominican Republic the following winter, he declined.</p>\n<p>Chief among these new experiences were the city’s food offerings. A family member blew Pedro’s mind when he took him for his first glazed donut. “I was like, ‘Holy shit!’” He remembers. “Where has this been all my life?”</p>\n<p>Pedro had a similar reaction to his first Chinese meal. Before he learned to speak English, his cousin took him to a restaurant where the staff spoke fluent Spanish with customers before calling out orders to the kitchen in Chinese. Pedro and his cousin bought fried rice with a half chicken and tostones, or fried plantains, and ate it outside on one of their stoops. “I fell in love with that,” he says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106306/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Starting Small and Expanding Slowly</h3>\n<p>The excited, food-loving child is very much alive in 53-year-old Pedro. He describes with equal relish his recent meal at a Peruvian restaurant as well as the locrio he ate on his family’s farm growing up. But food is also his business. In addition to Sajoma Latin Fusion in Kissimmee, Pedro owns four restaurants in New York and runs a fleet of trucks that he says supply most of New York City’s independent grocers. When asked about his secret to success in business, he uses a distinctly Dominican analogy: “I compare it to baseball players.”</p>\n<p>Many baseball players grow up playing on poorly kept fields. A ball might hit a rock, and smack you in the face. “It’s harder when you’re in the minor leagues,” he says. But, “You got to make sure that you could do that. Because once you go to the majors, the field is perfect now.”</p>\n<p>The message: “Start small,” he says, master your craft, and expand slowly.</p>\n<p>For Pedro, starting small meant working at his uncle’s grocery stores in Far Rockaway, Queens during high school. On Saturdays, he traveled with him to produce markets to stock the store. When Pedro graduated high school, he decided that he would rather spend the next few years growing a business. “What do I know at the time and what do I like at the time? Produce,” he says.</p>\n<p>So Pedro bought a van, and started delivering groceries to supermarkets, drawing on the connections he had built while working for his uncle. Soon, he bought a large truck, then two trucks. Today, he runs a fleet of 20 trucks.</p>\n<p>The road has not been easy. His equivalent of errant baseballs that threaten to hit you in the face were snowstorms that he had to fight through to deliver groceries. For years, he worked 18-hour shifts, rain, shine or snow. “I’d come home and eat, sleep for three or four hours, and go right back out there,” he remembers. He has since stepped back from physically driving trucks and delivering produce, but still helms the business.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106307/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">A Foothold in Florida</h3>\n<p>Over the years, many family members of Pedro’s have moved to Kissimmee. A friend told him about an open lot, wondering whether Pedro would be interested in opening a restaurant there. When Pedro saw the place, disparate threads of his life knit together: his childhood spent eating fresh produce on a Dominican farm; his exposure to cuisines from every corner of the world in New York; the New York hustle that had become his way of being.</p>\n<p>“Oh my god, this is perfect,” he remembers thinking after laying eyes on the space. He wanted to build a restaurant that combined fresh ingredients, Latin American cuisine, international influences, and New York service. And he would name it “Sajoma,” after the town that started his journey.</p>\n<p>After a period of renovation and menu-tweaking, Pedro opened Sajoma Latin Fusion in August of 2022. The restaurant’s interior is sleek and spacious, with an outdoor patio and plush couches. The team makes sure the produce is fresh, hand-picking it themselves from local independent supermarkets rather than large suppliers. Sajoma’s menu dances between Latin America—especially the Caribbean—and other parts of the world, like Europe, Asia, and North America. Their tuna tartare comes on a bed of guacamole and corn chips; their burger is topped with sweet plantains; and their sancocho is made from scratch with no additives.</p>\n<p>A pair of elderly Puerto Rican ladies recently visited the restaurant and made a point of telling Pedro how much they appreciated the sancocho. “We’ve had something like this at a house,” they told him. But “we have never tried anything like this at a restaurant.” They would spread the word to their family, they said.</p>\n<p>The word, it seems, has already gotten out. The restaurant has a loyal and growing following, and it becomes a party on weekends, when DJs and bands play salsa, bachata, merengue, and more.</p>\n<p>Much of Pedro’s work has been helping the team emulate the type of prompt, attentive service that one finds at a restaurant in New York. Achieving that has taken a lot of repetition, but they’ve pulled it off. “I’m just so proud, you know?” he says.</p>\n<p>Pedro says he approaches restaurant ownership as an eater, not a cook. He is actually not much of a chef, having been blessed with great cooking in his mother’s and wife’s kitchens, and in restaurants around the world.</p>\n<p>He constantly tries new restaurants, and he acts as the president of a group of around 40 New York supermarket industry professionals that call themselves the “Friday club” because they meet up at restaurants for food and wine every Friday. It’s easy to see why he would be named president: He knows good food and has the gift of gab.</p>\n<p>Pedro’s love of conversation and a good time is part of what draws him to the restaurant business, and when he is not checking on the kitchen at Sajoma, he is walking the floor, entertaining guests. He knows what it is to work hard all week and turn to a restaurant to provide delicious food and a space to connect with friends.</p>\n<p>“I don’t have to know how to cook,” in order to run a good restaurant, he says. “I have to know how to eat.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 30 Jan 2026 13:15:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591698Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "title": "Why Did Henry Ford Build a Midwestern Town in the Amazon Rainforest?",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Elah Feder: </strong>Johanna, do you ever buy lottery tickets?</p>\n<p><strong>Johanna Mayer:</strong> No, never. Not a lottery ticket kind of gal.</p>\n<p><strong>Elah:</strong> I actually just got shamed by the man selling me lottery tickets for wasting my money.</p>\n<p><strong>Johanna: </strong>You buy lottery tickets?</p>\n<p><strong>Elah: </strong>I do buy lottery tickets. And I think what I really like about it is fantasizing that, you know, if I have enough money, I will finally be able to do whatever I want.</p>\n<p><strong>Johanna: </strong>And this is the appeal of being a multimillionaire, Elah.</p>\n<p><strong>Elah:</strong> Right, right.</p>\n<p><strong>Johanna:</strong> You’re not the first one to have this impulse.</p>\n<p><strong>Elah: </strong>I have this crazy, wild notion that money will give me power. And the story that we’re going to talk about today is about a lot of things. But one of them is a lesson about how even with unlimited money, from time to time, the world refuses to do your bidding. So I want to take you back to the 1920s and tell you about Henry Ford. The 1920s was a time when Henry Ford was incredibly wealthy. Classic story. He started off as a simple Michigan farm boy, started tinkering. And then in 1908, he created the Model T, the first ever affordable mass-produced car, which made him incredibly rich. But it also reshaped America in the process. He decided that well-paid workers weren’t going to quit, so he brought in higher wages. He also brought in the eight-hour workday.</p>\n<p><strong>Johanna: </strong>It’s funny, I was just talking last weekend with my partner about Ford a little bit, where we were like, he is the reason that we have a car-centric society. But he was surprisingly good to his workers. Complicated figure.</p>\n<p><strong>Elah: </strong>He started off good to his workers. We’ll get there. But in the late 1920s, Ford, despite all of his wealth, he was forced to cave on a couple of pretty big things. He was forced to finally update his cars after years of resisting even a simple color change. Even more humiliating, a defamation suit forced him to apologize to Jewish people, which was very difficult for him because he loved talking about Jews before that. So in the late ’20s, Ford was realizing he was not all-powerful. But then in 1927, an incredible opportunity presented itself. A real chance to enact his vision of society, maybe without having to compromise this time. It was a place called Fordlândia in Brazil. And it didn’t quite make the biography on the Ford website for reasons that I think will soon become clear.</p>\n<p>I’m Johanna Mayer, and this is <em>Atlas Obscura</em>.</p>\n<p>And I’m Elah Feder. And today, the story of Fordlândia, Henry Ford’s attempt to build a wholesome Midwestern town in the Amazon rainforest.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/105971/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Johanna: </strong>Okay, I am intrigued. Why the rainforest? Why did Ford decide to build his vision of utopia in the Amazon rainforest?</p>\n<p><strong>Elah: </strong>So, it didn’t start out with a town. It started with rubber. So, as you know, cars need rubber for tires, for hoses. Today, most rubber is synthetic. The 1920s, it pretty much all came from rubber trees.</p>\n<p><strong>Johanna: </strong>So I did know this, and I can picture a rubber tree, which I think has a lot of big roots and like a wide trunk and stuff.</p>\n<p><strong>Elah:</strong> Massive.</p>\n<p><strong>Johanna:</strong> But I have never understood exactly how you get rubber from these trees.</p>\n<p><strong>Elah:</strong> It’s not too complicated. Ancient Mesoamericans figured this out. All you need to do is injure the tree.</p>\n<p><strong>Johanna:</strong> It saps it out?</p>\n<p><strong>Elah:</strong> It’s not technically sap. It’s another substance that oozes out of the tree. It kind of looks like coconut milk. It’s sticky and white and full of defense compounds. And that substance is called latex. So if you peel the bark of a rubber tree and let the latex drip out into a bucket, and then you dry it out, you get this bendy, bouncy material that we call rubber. So Ford decides he’s going to grow these rubber trees where they came from: the Amazon rainforest in Brazil.</p>\n<p><strong>Johanna: </strong>Seems like a solid plan.</p>\n<p><strong>Elah:</strong> It does seem that way. I should say it wasn’t actually Ford’s idea. He was actually being courted pretty aggressively by Brazilians. There was a Brazilian diplomat who really wanted to bring Ford to Brazil. There was a wealthy Brazilian businessman. And the idea was that bringing Ford, this wealthy industrialist, could potentially revive a really impoverished region, the northeast of Brazil.</p>\n<p>Ford very quickly agreed, and the company acquired 2.5 million acres of land, which they called Fordlândia. So, Fordlândia was on the east side of the Tapajos River, which is a tributary of the Amazon. This land is really deep in the rainforest. There were no roads, no railways. It took about 18 hours by boat to get there from the nearest city.</p>\n<p>So just imagine your classic kind of jungle. Towering trees, thick vines, tons of insects, birds, thousands of species, and, of course, rubber trees.</p>\n<p><strong>Johanna:</strong> Okay, goal is to create a rubber plantation. Makes sense to go to the Amazon. The part that I’m snagging on is the Midwestern town aspect.</p>\n<p><strong>Elah:</strong> Right.</p>\n<p><strong>Johanna:</strong> How does that come in?</p>\n<p><strong>Elah:</strong> So, a plantation obviously doesn’t run itself. It needs people. You need people to tap the trees, harvest the rubber. And then you need other people to feed those people, provide medical care. If you have families coming with the workers, then you’re going to need schools. You might need entertainment. You really need a whole town.</p>\n<p>And at Fordlândia, that’s what Ford created. Although not Ford himself, Ford didn’t go to Brazil. He had a crew of Ford company men who were dedicated to making this place according to Henry Ford’s vision.</p>\n<p><strong>Johanna:</strong> It’s how it usually goes.</p>\n<p><strong>Elah:</strong> So the town itself, it took a little bit of time to build. People started showing up well before there was a town. People who needed work came, and they brought their families. So they needed a place to live. They slapped together temporary shelters using planks from packing crates for walls and palm leaves for roofs.</p>\n<p>But within a couple of years, there was the start of a recognizable American-style town. They had a power plant, a hospital, a neighborhood with wooden houses with sidewalks and street lamps. A little later would come tennis courts, a dance hall, a movie theater, a golf course.</p>\n<p>But this was not just a lovely oasis in the Amazon. Because Henry Ford was a man with very particular ideas about how a society should be run. So increasingly, as he got older, he had this nostalgia for his old pastoral life. But at the same time, he hated cows.</p>\n<p><strong>Johanna:</strong> What’s wrong with cows?</p>\n<p><strong>Elah:</strong> Well, he thought they were very crude and inefficient machines. And he thought—</p>\n<p><strong>Johanna: </strong>Was—</p>\n<p><strong>Elah:</strong> Sorry, go ahead. I don’t think he was vegetarian.</p>\n<p><strong>Johanna:</strong> That’s what I was going to ask, yeah.</p>\n<p><strong>Elah:</strong> But he was a big fan of soy.</p>\n<p><strong>Johanna:</strong> Okay.</p>\n<p><strong>Elah: </strong>One time he built a full soy body. He had a suit made out of soy fibers.</p>\n<p><strong>Johanna:</strong> This is a whole other podcast episode.</p>\n<p><strong>Elah:</strong> The cow thing kind of threw me for a loop. But some of his ideas were actually really good. Like we mentioned, he thought people should be well paid, shouldn’t work super long hours. He also thought it was important that people be healthy. So he didn’t think they should drink or smoke. But he took this wholesome lifestyle thing a little far. He thought, for example, that dancing was good, but should not involve too much touching.</p>\n<p><strong>Johanna:</strong> No sexy dancing allowed.</p>\n<p><strong>Elah:</strong> Yes. Too many people were sexy dancing, which he blamed on Jewish people. So …</p>\n<p><strong>Johanna: </strong>What?</p>\n<p><strong>Elah:</strong> You’re welcome for that. I’m sure a lot of us have our own idiosyncratic spin on what makes a good life. The difference between Henry Ford and most of us is that he actually had the power to make his vision happen, to fashion a world in his image. This is not necessarily a good power for everyone to have.</p>\n<p>Henry Ford didn’t just encourage good habits and provide healthy food to his workers. He forced these things on them, not just in Fordlândia, but in all of his facilities. But as you can imagine, workers in the Amazon did not get the royal treatment.</p>\n<p>They were supposed to eat Henry Ford prescribed healthy meals at the company mess hall. They had to report any sexually transmitted infections to the company or risk getting caught at random STI inspections. They were not allowed to drink. A team of men would actually do spot searches of people’s homes and confiscate any alcohol that they found.</p>\n<p><strong>Johanna:</strong> It strikes me that this may not be the best route to creating the utopian society that you desire. The difference between Ford’s utopian society, Fordlândia, and a lot of other ones that come up throughout history is that in other utopian societies, people are signing up. They’re actively joining them of their own volition because they supposedly believe in some sort of common vision. Not the case here.</p>\n<p><strong>Elah: </strong>People just came to make rubber and get a paycheck. They did not come to have every aspect of their lives controlled. There were also unique challenges in the Amazon that Ford’s men did not anticipate. It turns out that you cannot just build an American town exactly as it is in America, wherever you want.</p>\n<p><strong>Johanna:</strong> Wait, you can’t?</p>\n<p><strong>Elah: </strong>Yeah. Revise life plan. For example, the houses that they had built. People were used to these houses with dirt floors and thatched roofs. These new houses had concrete floors and metal roofs. It impressed the journalists that visited, but they were unbearably hot in this climate. You do not want to be cooking under a metal roof, and you want good airflow. The Ford company provided free medical care for the workers, at least.</p>\n<p><strong>Johanna: </strong>Sounds good.</p>\n<p><strong>Elah:</strong> Despite that, a lot of people died. It is hard going in the Amazon. Both the American families and the Brazilian workers, a lot of people died of tropical diseases. People were being bitten by vipers when they were trying to clear jungle. This one guy whose job was to saw timber, he ended up preparing a lot of the wood they needed for coffins. He estimated they were averaging a death a day.</p>\n<p>In 1930, so just two years into the project, frustrations were at an all-time high. Ford’s men were also realizing that they weren’t really doing a good job of keeping people in line. In December of that year, 1930, one of Ford’s officials decides they need to make a change. Ford, as you know, wanted people to eat healthy. Apparently, he prescribed that people eat oatmeal and canned peaches for breakfast.</p>\n<p><strong>Johanna: </strong>That sounds good.</p>\n<p><strong>Elah: </strong>And rice and whole wheat bread for dinner. But—</p>\n<p><strong>Johanna:</strong> Sounds less good.</p>\n<p><strong>Elah: </strong>People wanted to eat whatever they wanted. And so they were getting food elsewhere. And this Ford employee decided that the solution was to feed them food from the cafeteria and deduct it from their wages.</p>\n<p>And that is when people snapped. It started when a guy named Manuel Caetano de Jesus, who was a brick mason, he decided to confront a payroll worker in the dining hall. And Manuel was yelling at him in Portuguese, which apparently this guy did not understand. But then Manuel hands him his badge, which he did understand. And this payroll worker’s reaction is to laugh.</p>\n<p>And that’s when the whole place erupts. People are suddenly smashing plates, pots, sinks, and they go and find all the Ford cars and smash them up. According to one person who was there, people started chanting “Brazil for Brazilians, kill all the Americans.” This was a massive riot across Fordlândia. And by the time that things calm down, the place is basically in ruins.</p>\n<p><strong>Johanna:</strong> Is that it? Is that the end of Fordlândia?</p>\n<p><strong>Elah:</strong> Weirdly not. Somehow.</p>\n<p><strong>Johanna:</strong> Incredible.</p>\n<p><strong>Elah:</strong> Yeah. So they end up firing most of the workers, but keep a skeleton crew and start to rebuild. And a few years later, they end up acquiring another plot of land nearby and building a second town and more plantations. And Fordlândia chugs along. The bigger problem, at least for the Ford company, is not that the workers hate them. It’s that Fordlândia isn’t actually doing the one thing it’s supposed to do, which is produce rubber.</p>\n<p><strong>Johanna: </strong>God, this has been such a journey, I forgot that they were supposed to be producing rubber this whole time.</p>\n<p><strong>Elah: </strong>That was the point of all of this. So it does take time, right? And they’d had many false starts. You know, they planted trees in the dry season. That didn’t work well. But eventually they get it together. And by 1940, they have three million trees planted across 30,000 acres of land.</p>\n<p><strong>Johanna:</strong> Whoa.</p>\n<p><strong>Elah:</strong> But here’s the thing. It turns out Brazil is not actually the best place to grow Brazilian rubber trees.</p>\n<p><strong>Johanna: </strong>What?</p>\n<p><strong>Elah: </strong>Because Brazil, the place the trees are native to, also has all of the trees’ natural enemies.</p>\n<p><strong>Johanna:</strong> Ah, interesting.</p>\n<p><strong>Elah: </strong>When trees are scattered throughout a forest, the trees manage to grow okay. But then imagine you are a rubber tree-eating bug or fungus, and you come upon all of these rubber trees jam-packed together in one place. You are going to come out and feast. You’re going to reproduce. You’re going to hop from tree to tree. It’s a massive buffet.</p>\n<p><strong>Johanna:</strong> Like, here we are!</p>\n<p><strong>Elah:</strong> Yeah. So by 1940, 70 percent of Fordlândia’s rubber trees were infected with a fungal blight. They get through that. But then in 1942, they’re hit with caterpillars.</p>\n<p><strong>Johanna:</strong> Dun, dun, dun.</p>\n<p><strong>Elah:</strong> I mean, caterpillars had always been a problem. But for a few years, the workers managed to keep them at bay. But in 1942, there is a total caterpillar explosion that they just can’t keep up with. And just as the situation was starting to get under control, they were hit with a second wave of fungal blight. And combined, it’s a pretty fatal blow. And just a few years later, in November of 1945, the company decides it is time to abandon this project. Apparently, they did not give the local workers much notice. Many Brazilians didn’t even know the Americans were leaving until the day they got on the ships. And that was how they found out they were unemployed.</p>\n<p><strong>Johanna: </strong>Oh, my God.</p>\n<p><strong>Elah: </strong>Yeah. By this point, Ford himself was over 80. He wasn’t doing well. And two years later, he died.</p>\n<p><strong>Johanna: </strong>You said that they just picked up and left and got on ships. What happened to the town? Are the buildings still there? Does anyone still live there? What happened to Fordlândia? <strong>Elah:</strong> So a lot of the story I’ve told you is based on a book by Greg Grandin called <a href=\"https://us.macmillan.com/books/9780312429621/fordlandia/\"><em>Fordlandia</em></a>, which came out in 2009. When he visited, a lot of the old structures were there. The old factory buildings, the sawmill, the warehouse, they’re kind of falling apart but standing. And a few of the old houses were there, too, apparently full of bats and just covered in guano.</p>\n<p>And back when Greg Grandin visited, one of the main sources of income was cattle ranching. Apparently, there were cows grazing on the old golf course. The old tennis courts had been turned into cattle stalls. And the hillsides that used to be planted with rubber trees were turned into pasture land for cows.</p>\n<p><strong>Johanna: </strong>Yes, justice for the cows. This was a totally fascinating story, Elah. Thank you.</p>\n<p><strong>Elah: </strong>Thanks for having me, Johanna. The town of Fordlândia is still around. And since Greg Grandin’s visit, it’s had a bit of a resurgence. An estimated 3,000 people live there. There’s now a tall Catholic church, a guest house, a bar, a restaurant. And scattered throughout, crumbling remains of Henry Ford’s failed American town.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Stitcher Studios. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 27 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591707Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/odilia-alvarado-kissimmee",
        "title": "How La Mexicana Became a Kissimmee Institution",
        "summary": "<p>Though Odilia Alvarado is responsible for 80 employees, the first people she attends to in the mornings are her children. Every day by 8:00 a.m., she drops her 8-year-old daughter and 10-year-old son off at school. Then it’s off to La Mexicana Restaurant, or the nearby affiliated bakery, for breakfast service.</p>\n<p>In the last three decades, Odilia has helped her mother, father, siblings, aunts, and uncles, build a series of Mexican food businesses that have taken Central Florida by storm, usually under the moniker “La Mexicana.” In 2011, she and her husband struck out on their own and opened the first Kissimmee outpost of La Mexicana. Today, she runs a restaurant, supermarket, tortilleria, bakery, and ice cream shop in Kissimmee that can barely keep up with demand for their delicious treats.</p>\n<p>If you ask Odilia, she’ll attribute her success to her faith in God, and her tight family that has supported her every step of the way. Her dedication to perfecting dishes inspired by the southwestern region of Mexico hasn’t hurt, either.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106355/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">From the Mountains of Mexico to Central Florida</h3>\n<p>Odilia Alvarado spent her early childhood in the town of Tenanguillo de las Cañas in the mountainous state of Guerrero. To buy groceries or clothing in the larger town nearby, her family would travel by car down a dirt road that took 20 minutes to traverse. But the rural setting came with upsides too, like the widespread practice of home-growing fresh herbs and vegetables, which Odilia believes is a big part of what makes the region’s cuisine so special.</p>\n<p>Odilia also draws inspiration from her grandmother, Angela Guadarrama Millan: a prodigious cook who supplied many of the recipes that made La Mexicana locally famous.</p>\n<p>She remembers hiking up rocky mountains with her grandmother to reach her vegetable patch, where she cultivated beans. Angela would harvest the beans, clean them, cook them, and grind them down in a molino, a mortar and pestle. She would then stuff the ground beans into homemade corn dough that she would toast on a comal, a traditional Mexican griddle, to make gorditas. The gorditas, plus a homemade salsa picante made from tomatillos and dried chiles de arbol would make up many of their meals.</p>\n<p>“We would eat really good,” said Odilia. “That’s all we’d eat, mainly.” They would also have the occasional bean soup, flavored with the medicinal-tasting epazote herb and lapped up with tortillas.</p>\n<p>When Odilia was around six years old, her mother, Paulina Cervantes, and father, Alejandrino Honorato Guadarrama, left their hometown to stake out a home for the family in the United States. Odilia, the second-oldest and the only girl among eight children, spent a year living with her grandmother and her older brother. A year later, Odilia’s parents brought Odilia and her older brother to Apopka, Florida. Odilia remembers being happy to be reunited with her parents, and the world taking on a sheen of novelty.</p>\n<p>Odilia was seven when she arrived, and she initially struggled in her new school, where there was limited support for Spanish-speaking students. But she soon transferred to a school with a bilingual education program. “My brain just started to pop up,” she remembers. She started soaking up English and getting good grades. In her first year in the new school, she made honor roll and won a trip to Disney World, an experience that she describes as “magical.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106300/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">The Birth of a Restaurant Family</h3>\n<p>When Odilia was twelve, she and Paulina started cooking tacos de barbacoa, a slow cooked, richly-spiced shredded beef, on weekends. Odilia was in charge of making the tortillas by hand with a mechanical stamp. They would sell them to her Alejandrino’s colleagues at his job at a greenhouse. The tacos were a hit, and customers started asking for Paulina to bring the tacos to their soccer and basketball games.</p>\n<p>When Odilia was 14, the Alvarados opened a brick-and-mortar taqueria called La Mexicana in a plaza in Apopka. It was a family business: Odilia’s mother and grandmother prepared the meat, Alejandrino and Odilia’s uncle made the tortillas, and Odilia would chop the garnishes before preparing the tacos with her cousins.</p>\n<p>People clamored for their carnitas, carne asada, pollo, and, most of all, Odilia’s grandmother’s adobada, pork chunks marinated in a complex, spicy red sauce. “We had lines and lines of people waiting for the food, for the tacos,” Odilia says.</p>\n<p>From that first taquería, the Alvarado family sprang a bunch of other iterations of La Mexicana across Central Florida. Different branches were operated by different family members who would work closely together, and it expanded to encompass tortilla-making, baking, ice cream, and Mexican groceries. Odilia worked hard alongside her parents and brothers. Along the way, she discovered that she loved cooking. “Even when I was making the tortillas,” Odilia says, she was in her happy place. Today, she cooks dinner for her husband and kids after work, often inspired by videos on Facebook and Instagram that advertise the dishes in restaurants and Mexican pueblos. She says it’s worth it to cook for her family, even though she owns a restaurant that could easily supply them with cooked meals. “When you see them eat and they like your food,” she says, “I feel more happy.”</p>\n<p>In 2011, Odilia and her husband were working together with Odilia’s mother, father, and two brothers in the family’s Orlando location. “We didn’t fit there anymore,” Odilia says. Her younger brother came across a space for rent in a shopping plaza in Kissimmee, but he didn’t yet have the money for it. “You go—you try over there,” he told his sister.</p>\n<p>Odilia and her husband opened up the Kissimmee branch of La Mexicana in December 2011. Their original plan was to open a taquería, but Odilia’s father Alejandrino said that they should take a shot at opening a supermarket and a restaurant, like they had opened in Orlando. She was intimidated, but he encouraged them. “If you’re going to go for it, go for something big. You don’t go for something small,” Odilia remembers Alejandrino telling her.</p>\n<p>So Odilia went for it, opening a supermarket with a small restaurant in a 2,000-square-foot space.</p>\n<p>“We were scared at the beginning, because we were starting to struggle,” she remembers. The first two years were rough. Odilia and her husband would do much of the cooking themselves, and would often spend their entire days in the restaurant.</p>\n<p>Odilia emerged from the first hard years, and eventually was able to expand the supermarket, and open a tortilleria and bakery.</p>\n<p>Odilia took her creative leap with the opening of a large, colorful, full-service sit-down restaurant a few years ago. This time, she didn’t need any convincing from her father: she and her husband spearheaded the process from start to finish. She drew a sketch of what she wanted the restaurant to look like, and handed it to an architect. She and her husband sourced decorative animals and hand-carved tables from Mexico. The space is playful and colorful with an emphasis on the natural world, because “it brings you back to Mexico” and evokes fresh, natural food.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106301/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Secrets to Success</h3>\n<p>Over the years, Odilia’s father has developed a few rules to success. “Clean area, good service, and good food. The three main things that we always keep in mind,” Odilia says. She and her staff remember customers’ names and make sure to always be friendly.</p>\n<p>As for the food, she uses recipes from the matriarchs that form the backbone of the La Mexicana empire. She helps create the restaurant’s menu, but she isn’t usually in the kitchen cooking for customers. Her kitchen prepares nopales, or prickly pear cactus, according to her grandmother’s method; and a healthy green juice according to her mother’s recipe that also includes its fair share of nopal.</p>\n<p>The restaurant serves a wide range of Mexican dishes, from rich soups to crispy tacos. Many of them have their roots in Guerrero, such as their golden-fried quesadillas and their green and red salsas. The tacos de birria, a choice of goat or beef stewed in a rich consummé, are a customer favorite.</p>\n<p>Odilia says that when it comes to her success, faith is a major factor. For as long as Odilia can remember, her family has believed that “if you have God in your life, you’re good,” she says. She keeps an image of the Virgin Mary in each of her businesses, to protect her family and bring them blessings.</p>\n<p>Odilia thanks her family for helping her achieve her goals. Her husband, whom she met when she served him at La Mexicana in Orlando, has been a constant support as well. He jokes that he picked the right wife—someone who could make his belly happy.</p>\n<p>But the truth is that he helps her, too. He takes initiative and is constantly strategic and ambitious about the restaurant. At the same time, he encourages Odilia’s ideas. If she and her partner did not have such good teamwork, “we would not have what we have,” she said.</p>\n<p>She is also thankful for the mentorship of her father and other family members. “I have learned a lot from my dad and my family,” she says. These lessons are “something that you want to pass on to your kids.”</p>\n<p>Odilia has seven children, and it seems as if her third child may follow in her footsteps and become an entrepreneur. “She looks like she wants to open her own business,” Odilia says. “It makes me very proud.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 20 Feb 2026 12:36:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591625Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591730Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/visiting-every-museum-in-new-york-city-a-q-a-with-jane-august",
        "title": "Visiting every museum in New York City",
        "summary": "<p>Jane August has made it her mission to visit every museum in New York City and five years in, she’s still discovering new ones. What began as a pandemic-era way to leave the house has turned into a sprawling, spreadsheet-powered project that’s connected her to hidden institutions, museum professionals, and a growing community of fellow culture lovers. Known as \"the museum girl\" among her fans, August documents her explorations across multiple <a href=\"https://www.janeaugust.co/every-museum-in-nyc\" rel=\"noopener noreferrer\" target=\"_blank\">social channels,</a> where she has amassed thousands of followers, and has even launched a <a href=\"https://podcasts.apple.com/us/podcast/the-next-stop-is-with-jane-august/id1740787173\" rel=\"noopener noreferrer\" target=\"_blank\">podcast.</a></p>\n<p>Atlas Obscura Executive Editor Emma Patti spoke with August about how the quest began, what’s surprised her most, and how to explore New York like a museum insider.</p>\n<p><strong>Atlas Obscura: </strong>How did this quest to visit every museum in New York City even begin?</p>\n<p><strong>Jane August:</strong> I was furloughed during the pandemic. I work in live music, bars, and venues, and suddenly all of that stopped. In the fall of 2020, some friends and I went to the Brooklyn Museum, because museums were really the only cultural spaces that had reopened.</p>\n<p>By that winter, I was like, I need to leave my house. I need to do <em>something</em> this year. All the things I usually did—shows, parties, places where people gather—weren’t options. Museums were one of the only places you could go alone and still feel like you were doing something meaningful.</p>\n<p>I thought, “There can’t be that many museums. Maybe I’ll visit them all and be done in a year or two.” That was five years ago.</p>\n<p><strong>AO:</strong> Were you surprised by how long it’s taken?</p>\n<p><strong>August:</strong> Completely. I originally thought there were maybe 150 or 160 museums in the city. I’m at about 150 visited now, so I <em>should</em> be done.</p>\n<p>But museums keep appearing. Some come out of the woodwork and say, “We don’t really post online—we’re kind of a secret museum.” Others reopen, or I’m still trying to figure out if they even exist. I’m emailing board members and stalking LinkedIn trying to confirm whether a place is real or permanently closed. The spreadsheet keeps growing.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106345/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> When you started, did you imagine this would turn into such a public project? </p>\n<p><strong>August:</strong> Not at all. Like everyone else in 2020, I was playing around on TikTok. I realized people liked New York City content, and I thought maybe some people would be interested in this project.</p>\n<p>I didn’t expect it to become my identity. I didn’t expect to be introduced as “the museum girl,” or for museum-going to become part of my brand. That part really surprised me.</p>\n<p><strong>AO:</strong> Do you visit museums outside New York the same way?</p>\n<p><strong>August:</strong> Not on this scale. When I travel, I go to museums I <em>want</em> to see. I don’t feel obligated. That’s actually when I enjoy museums the most—when I’m not thinking about how I’ll document it or explain it to other people.</p>\n<p><strong>AO:</strong> After visiting so many museums, do you have favorites?</p>\n<p><strong>August:</strong> Picking favorites is hard when you’ve been to so many. But the ones I return to a lot include Poster House—it wasn’t even on my radar at first, and now I take everyone there.</p>\n<p>I love the Museum of the City of New York and New-York Historical Society. I realized early on that I like history museums more than art museums. I just love learning things.</p>\n<p>The Museum of the Moving Image is a favorite, especially for film and TV. I also love the Nicholas Roerich Museum, the Transit Museum, the Red Hook Pinball Museum, and the Brooklyn Seltzer Museum.</p>\n<p>And then there are the big ones—the Guggenheim, the Whitney—where I now sometimes get to experience them when they’re empty or after hours. That still feels surreal.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106341/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Have any museums totally surprised you?</p>\n<p><strong>August:</strong> Definitely. The Maritime Industry Museum at Fort Schuyler was a big one. There were no photos online, and it took me over two hours to get there. I thought, “If this is one small room, I’m going to be devastated.”</p>\n<p>But it was huge. We got lost inside. It’s in a fort and covers every nautical thing you can imagine. My parents work in the maritime industry, so it was especially meaningful.</p>\n<p>I was also surprised by the New York Sign Museum, which is inside an operating sign shop, and by the Salvador Mundi Museum in Brooklyn. That one really made me think about what <em>counts</em> as a museum—it has a gift shop, a café, rotating exhibits, and events, just scaled way down. It’s almost conceptual art about museums themselves.</p>\n<p><strong>AO:</strong> How do you keep track of all this?</p>\n<p><strong>August:</strong> I have a very intense spreadsheet. I studied stage management in college, so spreadsheets are my love language.</p>\n<p>It tracks every museum, when it’s open, the neighborhood, whether I’ve contacted them, when I visited, who I went with, whether I’ve posted the video yet. Some entries are marked in red because they’re still a mystery: “Do they exist? Find out.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106342/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Do people send you tips now?</p>\n<p><strong>August:</strong> All the time. That’s how a lot of this has grown. Museum founders DM me, followers tell me about new openings, and organizations reach out when they start doing exhibitions.</p>\n<p>Sometimes I also just find museums by dragging around Google Maps. I’ll be walking to work and realize, “Wait—that’s a museum I didn’t know existed.” Then it goes on the list.</p>\n<p><strong>AO:</strong> Has this connected you to the museum world in unexpected ways?</p>\n<p><strong>August:</strong> Absolutely. I’ve met so many people in museum marketing, social media, and public engagement, and they all seem to move between institutions. Suddenly I’m being invited to places because I know someone from somewhere else.</p>\n<p>A lot of these people also have their own art practices or side projects, and I love being able to highlight that through my platform or my podcast.</p>\n<p><strong>AO:</strong> Speaking of which—how did your podcast come about?</p>\n<p><strong>August:</strong> I had a radio show in college, and I missed interviewing people. Through this museum project, I kept meeting fascinating people, but I only had a short window to tell their stories.</p>\n<p>The podcast lets me expand beyond museums. I’ve had theater people, musicians, authors—people whose stories don’t fit neatly into one niche.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106344/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Any tips for visiting museums?</p>\n<p><strong>August:</strong> I go in completely blind. I don’t research much beforehand, and I like being surprised. I wander.</p>\n<p>My one consistent rule is: always go to the gift shop. I buy a postcard at every museum. I send one to my mom, and whoever I go with has to send one to me. If I go alone, I’ll mail one to myself.</p>\n<p>Postcards are my way of documenting what I’ve seen. I have a giant box full of them.</p>\n<p><strong>AO:</strong> If someone had one day to explore museums in a single New York neighborhood, where should they go?</p>\n<p><strong>August:</strong> Prospect Park and Crown Heights are great—you’ve got the Brooklyn Museum, the Botanic Garden, and Lefferts Historic House.</p>\n<p>The Lower East Side is another favorite. You can do the Tenement Museum, the International Center of Photography, and the new Automatic Photo Booth Museum, plus a bunch of smaller institutions nearby.</p>\n<p>Lower Manhattan is underrated for museums, especially National Park Service sites—and you can get Junior Ranger badges at any age, which I love.</p>\n<p>And Staten Island’s Snug Harbor is basically a museum campus with multiple institutions in one beautiful area.</p>\n<p>Honestly, museums are everywhere in New York. Even after five years, I’m still finding new ones.</p>\n<hr style=\"border: 1px solid black;\" />\n<p>Jane also appeared on the Atlas Obscura podcast. Listen to her episode here.</p>\n<p></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 10 Feb 2026 08:00:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591689Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://www.atlasobscura.com/articles/the-obscura-society",
        "title": "Welcome to The Obscura Society",
        "summary": "<p>What if Atlas Obscura wasn't just a guide, but also a doorway? The Obscura Society invites you into a living, digital world where stories respond, environments listen and curiosity shapes the experience itself.</p>\n<p>Designed as a living, digital space, The Obscura Society is always on. Guests can drop in from anywhere, at any time, to meet others, share discoveries and take part in unfolding stories, whether they’re visiting through a mobile device, personal computer or VR headset.</p>\n<p>At the heart of The Obscura Society is an AI bartender who welcomes every guest. Like a great local bar anywhere in the world, they serve imaginative, global drinks such as: Fröccs, Horchata Lojana, Panther Milk, Nectar Soda, Cheese Tea, the Pegu Club Cocktail and more! Share the surprising stories and learn about the cultural origins behind them, all drawn from Atlas Obscura’s vast archive of curiosities.</p>\n<p>Surrounding visitors of the world is a richly layered space inspired by real places across the globe. Photographs from Atlas Obscura contributors line the walls, while an interactive world map gives you access to the full Atlas Obscura database. From here, portals open into the complete Atlas Obscura VR app, along with pathways to books, articles and other Atlas Obscura experiences.</p>\n<p>It's an evolving digital world that will continue to change over time as your experience also evolves with each visit to The Obscura Society. Every session offers new conversations, discoveries and opportunities to connect with others as you explore the endlessly strange, wondrous and unexpected stories that define Atlas Obscura.</p>\n<p></p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 02 Feb 2026 00:46:00 -0500",
        "fetched_at": "2026-02-20T23:26:03.591693Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-02-20T23:24:42.954468Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-02-20T23:24:42.954877Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-02-20T23:24:42.954166Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-02-20T23:24:42.956107Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-02-20T23:24:42.955484Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.scmp.com/economy/global-economy/article/3344137/what-would-blocking-strait-hormuz-mean-global-oil-and-lng-shipments?utm_source=rss_feed",
        "title": "What would blocking the Strait of Hormuz mean for global oil and LNG shipments?",
        "summary": "Iran partially and temporarily closed the strategic Strait of Hormuz during a military drill on Tuesday, thrusting the vital shipping route under the global spotlight once again.\nThe hours-long suspension was the first time Tehran had restricted traffic through the strait since US President Donald Trump’s warning last month that Washington could take military action over Iran’s nuclear programme, with tensions still high between the two sides despite recent bilateral talks in Geneva.\nHere, we...",
        "source": "www.scmp.com",
        "published": "Fri, 20 Feb 2026 09:15:11 +0000",
        "fetched_at": "2026-02-20T23:24:37.634850Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-02-20T23:24:42.956411Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-02-20T23:24:42.956529Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-02-20T23:24:42.960242Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/27/huawei-vivo-and-oppo-help-establish-first-global-fast-charging-standard-under-itu/",
        "title": "Huawei, vivo, and OPPO help establish first global fast-charging standard under ITU",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/charger-marcus-urbenz-4xMAiJZPQXI-unsplash.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>The International Telecommunication Union (ITU) has approved and released L.1004, a universal fast-charging standard for mobile terminals co-authored by China’s CAICT with Huawei, vivo, and OPPO. The standard enables cross-brand and cross-device fast charging and is intended to reduce charger duplication and electronic waste. [TechNode reporting]",
        "source": "technode.com",
        "published": "Mon, 27 Oct 2025 10:51:44 +0000",
        "fetched_at": "2026-02-20T23:24:42.954968Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
        "title": "danielmiessler/Personal_AI_Infrastructure",
        "summary": "<p>Agentic AI Infrastructure for magnifying HUMAN capabilities.</p><hr /><div align=\"center\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"PAI Logo\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-logo-v7.png\" width=\"300\" /> \n  \n <br /> \n <br /> \n <h1>Personal AI Infrastructure</h1> \n <p><a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure\"><img alt=\"Typing SVG\" src=\"https://readme-typing-svg.demolab.com?font=Fira+Code&amp;weight=500&amp;size=24&amp;pause=1000&amp;color=60A5FA&amp;center=true&amp;vCenter=true&amp;width=600&amp;lines=Everyone+needs+access+to+the+best+AI.;AI+should+magnify+everyone.;Your+personal+AI+stack.\" /></a></p> \n <br /> \n <!-- Social Proof --> \n <p><img alt=\"Stars\" src=\"https://img.shields.io/github/stars/danielmiessler/Personal_AI_Infrastructure?style=social\" /> <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/danielmiessler/Personal_AI_Infrastructure?style=social\" /> <img alt=\"Watchers\" src=\"https://img.shields.io/github/watchers/danielmiessler/Personal_AI_Infrastructure?style=social\" /></p> \n <!-- Project Health --> \n <p><img alt=\"Release\" src=\"https://img.shields.io/github/v/release/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=8B5CF6\" /> <img alt=\"Last Commit\" src=\"https://img.shields.io/github/last-commit/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=git&amp;color=22C55E\" /> <img alt=\"Open Issues\" src=\"https://img.shields.io/github/issues/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=F97316\" /> <img alt=\"Open PRs\" src=\"https://img.shields.io/github/issues-pr/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=EC4899\" /> <img alt=\"License\" src=\"https://img.shields.io/github/license/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;color=60A5FA\" /></p> \n <!-- Metrics --> \n <p><img alt=\"Discussions\" src=\"https://img.shields.io/github/discussions/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;label=Discussions&amp;color=EAB308\" /> <img alt=\"Commit Activity\" src=\"https://img.shields.io/github/commit-activity/m/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=git&amp;label=Commits%2Fmo&amp;color=F59E0B\" /> <img alt=\"Repo Size\" src=\"https://img.shields.io/github/repo-size/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=database&amp;label=Repo%20Size&amp;color=D97706\" /></p> \n <!-- Content --> \n <p><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-installation\"><img alt=\"Get Started\" src=\"https://img.shields.io/badge/%F0%9F%9A%80_Get_Started-Install-22C55E?style=flat\" /></a> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/\"><img alt=\"Release v3.0\" src=\"https://img.shields.io/badge/%F0%9F%93%A6_Release-v3.0-8B5CF6?style=flat\" /></a> <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/graphs/contributors\"><img alt=\"Contributors\" src=\"https://img.shields.io/github/contributors/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=githubsponsors&amp;logoColor=white&amp;label=Contributors&amp;color=EC4899\" /></a></p> \n <!-- Tech Stack --> \n <p><a href=\"https://claude.ai\"><img alt=\"Built with Claude\" src=\"https://img.shields.io/badge/Built_with-Claude-D4A574?style=flat&amp;logo=anthropic&amp;logoColor=white\" /></a> <a href=\"https://www.typescriptlang.org/\"><img alt=\"TypeScript\" src=\"https://img.shields.io/badge/TypeScript-3178C6?style=flat&amp;logo=typescript&amp;logoColor=white\" /></a> <a href=\"https://bun.sh\"><img alt=\"Bun\" src=\"https://img.shields.io/badge/Bun-000000?style=flat&amp;logo=bun&amp;logoColor=white\" /></a> <a href=\"https://danielmiessler.com/upgrade\"><img alt=\"UL Community\" src=\"https://img.shields.io/badge/UL_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white\" /></a></p> \n <br /> \n <p><strong>Overview:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-purpose-of-this-project\">Purpose</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#what-is-pai\">What is PAI?</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#new-to-this-start-here\">New to AI?</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-pai-principles\">Principles</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#pai-primitives\">Primitives</a></p> \n <p><strong>Get Started:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-installation\">Installation</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/\">Releases</a></p> \n <p><strong>Resources:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-faq\">FAQ</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-roadmap\">Roadmap</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-community\">Community</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-contributing\">Contributing</a></p> \n <br /> \n <p><a href=\"https://youtu.be/Le0DLrn7ta0\"><img alt=\"PAI Overview Video\" src=\"https://img.youtube.com/vi/Le0DLrn7ta0/maxresdefault.jpg\" /></a></p> \n <p><strong><a href=\"https://youtu.be/Le0DLrn7ta0\">Watch the full PAI walkthrough</a></strong> | <strong><a href=\"https://danielmiessler.com/blog/real-internet-of-things\">Read: The Real Internet of Things</a></strong></p> \n <hr /> \n</div> \n<blockquote> \n <p>[!IMPORTANT] <strong>PAI v3.0.0 Released</strong> — The Algorithm Matures: Constraint Extraction, Build Drift Prevention, Persistent PRDs, and Parallel Loop Execution.</p> \n <p><strong><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/README.md\">Release notes →</a></strong> | <strong><a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/releases/tag/v3.0.0\">GitHub Release →</a></strong></p> \n</blockquote> \n<div align=\"center\"> \n <h1>AI should magnify everyone—not just the top 1%.</h1> \n</div> \n<h2>The Purpose of This Project</h2> \n<p><strong>PAI exists to solve what I believe is the <a href=\"https://danielmiessler.com/telos\">P0 problem</a> in the world:</strong></p> \n<h3>Only a tiny fraction of humanity's creative potential is activated on Earth.</h3> \n<p>Most people don't believe they have valuable contributions to make. They think there are \"special\" people—and they aren't one of them. They've never asked who they are, what they're about, and have never articulated or written it down. This makes them catastrophically vulnerable to AI displacement. Without activation, there is no high-agency.</p> \n<p>So our goal with PAI is to activate people.</p> \n<p><strong>PAI's mission is twofold:</strong></p> \n<ol> \n <li><strong>Activate as many people as possible</strong> — Help people identify, articulate, and pursue their own purpose in life through AI-augmented self-discovery</li> \n <li><strong>Make the best AI available in the world accessible to everyone</strong> — Ensure this quality of AI infrastructure isn't reserved for just the rich or technical elite.</li> \n</ol> \n<p>That's why this is an open-source project instead of private.</p> \n<hr /> \n<h2>New to This? Start Here</h2> \n<p>You've probably used ChatGPT or Claude. Type a question, get an answer. Simple.</p> \n<p>You can think of AI systems as <strong>three levels</strong>:</p> \n<p align=\"center\"> <img alt=\"The AI Evolution - From chatbots to your personal AI system\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-eli5-diagram.png\" width=\"800\" /> </p> \n<h3>Chatbots</h3> \n<p>ChatGPT, Claude, Gemini—you ask something, it answers, and then it forgets everything. Next conversation starts fresh. No memory of you, your preferences, or what you talked about yesterday.</p> \n<p><strong>The pattern:</strong> Ask → Answer → Forget</p> \n<h3>Agentic Platforms</h3> \n<p>Tools like Claude Code. The AI can actually <em>do</em> things—write code, browse the web, edit files, run commands.</p> \n<p><strong>The pattern:</strong> Ask → Use tools → Get result</p> \n<p>More capable, but it still doesn't know <em>you</em>—your goals, your preferences, your history.</p> \n<h3>PAI (Personal AI Infrastructure)</h3> \n<p>Now your DA <strong>learns and improves</strong>:</p> \n<ul> \n <li><strong>Captures every signal</strong> — Ratings, sentiment, verification outcomes</li> \n <li><strong>Learns from mistakes</strong> — Failures get analyzed and fixed</li> \n <li><strong>Gets better over time</strong> — Success patterns get reinforced</li> \n <li><strong>Upgrades itself</strong> — Skills, workflows, even the core behavior evolves</li> \n</ul> \n<p>Plus it knows:</p> \n<ul> \n <li><strong>Your goals</strong> — What you're working toward</li> \n <li><strong>Your preferences</strong> — How you like things done</li> \n <li><strong>Your history</strong> — Past decisions and learnings</li> \n</ul> \n<p><strong>The pattern:</strong> Observe → Think → Plan → Execute → Verify → <strong>Learn</strong> → Improve</p> \n<p>The key difference: <strong>PAI learns from feedback</strong>. Every interaction makes it better at helping <em>you</em> specifically.</p> \n<hr /> \n<h2>What is PAI?</h2> \n<p>PAI is a Personalized AI Platform designed to magnify your capabilities.</p> \n<p>It's designed for humans most of all, but can be used by teams, companies, or Federations of Planets desiring to be better versions of themselves.</p> \n<p>The scale of the entity doesn't matter: It's a system for understanding, articulating, and realizing its principal's goals using a full-featured Agentic AI Platform.</p> \n<h3>Who is PAI for?</h3> \n<p><strong>Everyone, full stop.</strong> It's the anti-gatekeeping AI project.</p> \n<ul> \n <li><strong>Small business owners</strong> who aren't technical but want AI to handle invoicing, scheduling, customer follow-ups, and marketing</li> \n <li><strong>Companies</strong> who want to understand their data, optimize operations, and make better decisions</li> \n <li><strong>Managers</strong> who want to run their teams more effectively—tracking projects, preparing for reviews, and communicating clearly</li> \n <li><strong>Artists and creatives</strong> who want to find local events, galleries, and opportunities to showcase their work</li> \n <li><strong>Everyday people</strong> who want to improve their lives—better fitness routines, stronger social connections, personal finance, or just getting organized</li> \n <li><strong>Developers</strong> using AI coding assistants who want persistent memory and custom workflows</li> \n <li><strong>Power users</strong> who want their AI to know their goals, preferences, and context</li> \n <li><strong>Teams</strong> building shared AI infrastructure with consistent capabilities</li> \n <li><strong>Experimenters</strong> interested in AI system design and personal AI patterns</li> \n</ul> \n<h3>What makes PAI different?</h3> \n<p>The first thing people ask is:</p> \n<blockquote> \n <p>How is this different from Claude Code, or any of the other agentic systems?</p> \n</blockquote> \n<p>Most agentic systems are built around tools with the user being an afterthought. They are also mostly task-based instead of being goal-based using all the context available to them. PAI is the opposite.</p> \n<p><strong>Three core differentiators:</strong></p> \n<ol> \n <li> <p><strong>Goal Orientation</strong> — PAI's primary focus is on the human running it and what they're trying to do in the world, not the tech. This is built into how the system executes all tasks.</p> </li> \n <li> <p><strong>Pursuit of Optimal Output</strong> — The system's outer loop and everything it does is trying to produce the exact right output given the current situation and all the contexts around it.</p> </li> \n <li> <p><strong>Continuous Learning</strong> — The system constantly captures signals about what was done, what changes were made, what outputs were produced for each request, and then how you liked or disliked the results.</p> </li> \n</ol> \n<hr /> \n<h2>The PAI Principles</h2> \n<p>These principles guide how PAI systems are designed and built. <strong><a href=\"https://danielmiessler.com/blog/personal-ai-infrastructure\">Full breakdown →</a></strong></p> \n<table> \n <thead> \n  <tr> \n   <th>#</th> \n   <th>Principle</th> \n   <th>Summary</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>1</td> \n   <td><strong>User Centricity</strong></td> \n   <td>PAI is built around you, not tooling. Your goals, preferences, and context come first—the infrastructure exists to serve them.</td> \n  </tr> \n  <tr> \n   <td>2</td> \n   <td><strong>The Foundational Algorithm</strong></td> \n   <td>The scientific method as a universal problem-solving loop: Observe → Think → Plan → Build → Execute → Verify → Learn. Define the ideal state, iterate until you reach it.</td> \n  </tr> \n  <tr> \n   <td>3</td> \n   <td><strong>Clear Thinking First</strong></td> \n   <td>Good prompts come from clear thinking. Clarify the problem before writing the prompt.</td> \n  </tr> \n  <tr> \n   <td>4</td> \n   <td><strong>Scaffolding &gt; Model</strong></td> \n   <td>System architecture matters more than which model you use.</td> \n  </tr> \n  <tr> \n   <td>5</td> \n   <td><strong>Deterministic Infrastructure</strong></td> \n   <td>AI is probabilistic; your infrastructure shouldn't be. Use templates and patterns.</td> \n  </tr> \n  <tr> \n   <td>6</td> \n   <td><strong>Code Before Prompts</strong></td> \n   <td>If you can solve it with a bash script, don't use AI.</td> \n  </tr> \n  <tr> \n   <td>7</td> \n   <td><strong>Spec / Test / Evals First</strong></td> \n   <td>Write specifications and tests before building. Measure if the system works.</td> \n  </tr> \n  <tr> \n   <td>8</td> \n   <td><strong>UNIX Philosophy</strong></td> \n   <td>Do one thing well. Make tools composable. Use text interfaces.</td> \n  </tr> \n  <tr> \n   <td>9</td> \n   <td><strong>ENG / SRE Principles</strong></td> \n   <td>Treat AI infrastructure like production software: version control, automation, monitoring.</td> \n  </tr> \n  <tr> \n   <td>10</td> \n   <td><strong>CLI as Interface</strong></td> \n   <td>Command-line interfaces are faster, more scriptable, and more reliable than GUIs.</td> \n  </tr> \n  <tr> \n   <td>11</td> \n   <td><strong>Goal → Code → CLI → Prompts → Agents</strong></td> \n   <td>The decision hierarchy: clarify goal, then code, then CLI, then prompts, then agents.</td> \n  </tr> \n  <tr> \n   <td>12</td> \n   <td><strong>Skill Management</strong></td> \n   <td>Modular capabilities that route intelligently based on context.</td> \n  </tr> \n  <tr> \n   <td>13</td> \n   <td><strong>Memory System</strong></td> \n   <td>Everything worth knowing gets captured. History feeds future context.</td> \n  </tr> \n  <tr> \n   <td>14</td> \n   <td><strong>Agent Personalities</strong></td> \n   <td>Different work needs different approaches. Specialized agents with unique voices.</td> \n  </tr> \n  <tr> \n   <td>15</td> \n   <td><strong>Science as Meta-Loop</strong></td> \n   <td>Hypothesis → Experiment → Measure → Iterate.</td> \n  </tr> \n  <tr> \n   <td>16</td> \n   <td><strong>Permission to Fail</strong></td> \n   <td>Explicit permission to say \"I don't know\" prevents hallucinations.</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>PAI Primitives</h2> \n<p>While the Principles describe the <em>philosophy</em> of PAI, the Primitives are the <em>architecture</em>—the core systems that make everything work.</p> \n<p align=\"center\"> <img alt=\"PAI Primitives - A system that knows you, not a tool harness\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-unique-components-diagram.png\" width=\"800\" /> </p> \n<p>These primitives work together to create the experience of working with a system that understands and knows you—as opposed to a tool harness that just executes commands.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Assistant vs Agent-Based Interaction\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-1-assistant-vs-agent.png\" width=\"700\" /> </p> \n<h3>Assistant vs. Agent-Based AI Interaction</h3> \n<p>PAI treats AI as a <a href=\"https://danielmiessler.com/blog/personal-ai-maturity-model\">persistent assistant, friend, coach, and mentor</a> rather than a stateless agent that runs tasks. An assistant knows your goals, remembers your preferences, and improves over time. An agent executes commands and forgets.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"TELOS - Deep Goal Understanding\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-telos.png\" width=\"700\" /> </p> \n<h3>TELOS (Deep Goal Understanding)</h3> \n<p>10 files that capture who you are: MISSION.md, GOALS.md, PROJECTS.md, BELIEFS.md, MODELS.md, STRATEGIES.md, NARRATIVES.md, LEARNED.md, CHALLENGES.md, IDEAS.md. Your DA knows what you're working toward because it's all documented.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"User/System Separation\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-user-system-separation.png\" width=\"700\" /> </p> \n<h3>User/System Separation</h3> \n<p>Your customizations live in USER/. PAI infrastructure lives in SYSTEM/. When PAI upgrades, your files are untouched. Portable identity, upgrade-safe.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Granular Customization\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-customization.png\" width=\"700\" /> </p> \n<h3>Granular Customization</h3> \n<p>Six layers of customization: Identity (name, voice, personality), Preferences (tech stack, tools), Workflows (how skills execute), Skills (what capabilities exist), Hooks (how events are handled), and Memory (what gets captured). Start with defaults, customize when needed.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Skill System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-2-skill-system.png\" width=\"700\" /> </p> \n<h3>Skill System</h3> \n<p>Highly focused on consistent results. It has a structure that puts <em>deterministic outcomes first</em> by going from CODE -&gt; CLI-BASED-TOOL -&gt; PROMPT -&gt; SKILL instead of a haphazard structure.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Memory System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-3-memory-system.png\" width=\"700\" /> </p> \n<h3>Memory System</h3> \n<p>Focused on continuous learning. Every interaction generates signals—ratings, sentiment, successes, failures—that feed back into improving the system. Three-tier architecture (hot/warm/cold) with phase-based learning directories.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Hook System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-6-hook-system.png\" width=\"700\" /> </p> \n<h3>Hook System</h3> \n<p>Responds to lifecycle events—session start, tool use, task completion, and more. 8 event types enable voice notifications, automatic context loading, session capture, security validation, and observability.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Security System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-5-security-system.png\" width=\"700\" /> </p> \n<h3>Security System</h3> \n<p>Defines system and user-level security policies by default. You don't have to run with <code>--dangerously-skip-permissions</code> to have an uninterrupted experience. PAI's security hooks validate commands before execution, blocking dangerous operations while allowing normal workflows to proceed smoothly.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"AI-Based Installation\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-4-ai-installation.png\" width=\"700\" /> </p> \n<h3>AI-Based Installation</h3> \n<p>The GUI installer handles everything—prerequisites, configuration, and setup. No manual configuration, no guessing.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Notification System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-8-notification-system.png\" width=\"700\" /> </p> \n<h3>Notification System</h3> \n<p>Keeps you informed without being intrusive. Push notifications via ntfy for mobile alerts, Discord integration for team updates, and duration-aware routing that escalates for long-running tasks. Fire-and-forget design means notifications never block your workflow.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Voice System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-9-voice-system.png\" width=\"700\" /> </p> \n<h3>Voice System</h3> \n<p>Powered by ElevenLabs TTS. Hear task completions, session summaries, and important updates spoken aloud. Prosody enhancement makes speech sound natural. Your AI has a voice.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Terminal-Based UI\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-7-terminal-ui.png\" width=\"700\" /> </p> \n<h3>Terminal-Based UI</h3> \n<p>Rich tab titles and pane management. Dynamic status lines show learning signals, context usage, and current task state. Your terminal is a command center.</p> \n<hr /> \n<h2>🚀 Installation</h2> \n<blockquote> \n <p>[!CAUTION] <strong>Project in Active Development</strong> — PAI is evolving rapidly. Expect breaking changes, restructuring, and frequent updates. We are working on stable and development branches, but currently it's all combined.</p> \n</blockquote> \n<pre><code class=\"language-bash\"># Clone the repo\ngit clone https://github.com/danielmiessler/Personal_AI_Infrastructure.git\ncd Personal_AI_Infrastructure/Releases/v3.0\n\n# Copy the release and run the installer\ncp -r .claude ~/ &amp;&amp; cd ~/.claude &amp;&amp; bash PAI-Install/install.sh\n</code></pre> \n<p><strong>The installer will:</strong></p> \n<ul> \n <li>Detect your system and install prerequisites (Bun, Git, Claude Code)</li> \n <li>Ask for your name, AI assistant name, and timezone</li> \n <li>Clone/configure the PAI repository into <code>~/.claude/</code></li> \n <li>Set up voice features with ElevenLabs (optional)</li> \n <li>Configure your shell alias and verify the installation</li> \n</ul> \n<p><strong>After installation:</strong> Run <code>source ~/.zshrc &amp;&amp; pai</code> to launch PAI.</p> \n<hr /> \n<h2>❓ FAQ</h2> \n<h3>How is PAI different from just using Claude Code?</h3> \n<p>PAI is built natively on Claude Code and designed to stay that way. We chose Claude Code because its hook system, context management, and agentic architecture are the best foundation available for personal AI infrastructure.</p> \n<p>PAI isn't a replacement for Claude Code — it's the layer on top that makes Claude Code <em>yours</em>:</p> \n<ul> \n <li><strong>Persistent memory</strong> — Your DA remembers past sessions, decisions, and learnings</li> \n <li><strong>Custom skills</strong> — Specialized capabilities for the things you do most</li> \n <li><strong>Your context</strong> — Goals, contacts, preferences—all available without re-explaining</li> \n <li><strong>Intelligent routing</strong> — Say \"research this\" and the right workflow triggers automatically</li> \n <li><strong>Self-improvement</strong> — The system modifies itself based on what it learns</li> \n</ul> \n<p>Think of it this way: Claude Code is the engine. PAI is everything else that makes it <em>your</em> car.</p> \n<h3>What's the difference between PAI and Claude Code's built-in features?</h3> \n<p>Claude Code provides powerful primitives — hooks, slash commands, MCP servers, context files. These are individual building blocks.</p> \n<p>PAI is the complete system built on those primitives. It connects everything together: your goals inform your skills, your skills generate memory, your memory improves future responses. PAI turns Claude Code's building blocks into a coherent personal AI platform.</p> \n<h3>Is PAI only for Claude Code?</h3> \n<p>PAI is Claude Code native. We believe Claude Code's hook system, context management, and agentic capabilities make it the best platform for personal AI infrastructure, and PAI is designed to take full advantage of those features.</p> \n<p>That said, PAI's concepts (skills, memory, algorithms) are universal, and the code is TypeScript, Python, and Bash — so community members are welcome to adapt it for other platforms.</p> \n<h3>How is this different from fabric?</h3> \n<p><a href=\"https://github.com/danielmiessler/fabric\">Fabric</a> is a collection of AI prompts (patterns) for specific tasks. It's focused on <em>what to ask AI</em>.</p> \n<p>PAI is infrastructure for <em>how your DA operates</em>—memory, skills, routing, context, self-improvement. They're complementary. Many PAI users integrate Fabric patterns into their skills.</p> \n<h3>What if I break something?</h3> \n<p>Recovery is straightforward:</p> \n<ul> \n <li><strong>Git-backed</strong> — Version control everything, roll back when needed</li> \n <li><strong>History is preserved</strong> — Your DA's memory survives mistakes</li> \n <li><strong>DA can fix it</strong> — Your DA helped build it, it can help repair it</li> \n <li><strong>Re-install</strong> — Run the installer again to reset to a clean state</li> \n</ul> \n<hr /> \n<h2>🎯 Roadmap</h2> \n<table> \n <thead> \n  <tr> \n   <th>Feature</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Local Model Support</strong></td> \n   <td>Run PAI with local models (Ollama, llama.cpp) for privacy and cost control</td> \n  </tr> \n  <tr> \n   <td><strong>Granular Model Routing</strong></td> \n   <td>Route different tasks to different models based on complexity</td> \n  </tr> \n  <tr> \n   <td><strong>Remote Access</strong></td> \n   <td>Access your PAI from anywhere—mobile, web, other devices</td> \n  </tr> \n  <tr> \n   <td><strong>Outbound Phone Calling</strong></td> \n   <td>Voice capabilities for outbound calls</td> \n  </tr> \n  <tr> \n   <td><strong>External Notifications</strong></td> \n   <td>Robust notification system for Email, Discord, Telegram, Slack</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>🌐 Community</h2> \n<p><strong>GitHub Discussions:</strong> <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/discussions\">Join the conversation</a></p> \n<p><strong>UL Community Discord:</strong> PAI is discussed in the <a href=\"https://danielmiessler.com/upgrade\">Unsupervised Learning community</a> along with other AI projects</p> \n<p><strong>Twitter/X:</strong> <a href=\"https://twitter.com/danielmiessler\">@danielmiessler</a></p> \n<p><strong>Blog:</strong> <a href=\"https://danielmiessler.com\">danielmiessler.com</a></p> \n<h3>Star History</h3> \n<a href=\"https://star-history.com/#danielmiessler/Personal_AI_Infrastructure&amp;Date\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=danielmiessler/Personal_AI_Infrastructure&amp;type=Date\" /> \n  </a> \n<hr /> \n<h2>🤝 Contributing</h2> \n<p>We welcome contributions! See our <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/issues\">GitHub Issues</a> for open tasks.</p> \n<ol> \n <li><strong>Fork the repository</strong></li> \n <li><strong>Make your changes</strong> — Bug fixes, new skills, documentation improvements</li> \n <li><strong>Test thoroughly</strong> — Install in a fresh system to verify</li> \n <li><strong>Submit a PR</strong> with examples and testing evidence</li> \n</ol> \n<hr /> \n<h2>📜 License</h2> \n<p>MIT License - see <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE\">LICENSE</a> for details.</p> \n<hr /> \n<h2>🙏 Credits</h2> \n<p><strong>Anthropic and the Claude Code team</strong> — First and foremost. You are moving AI further and faster than anyone right now. Claude Code is the foundation that makes all of this possible.</p> \n<p><strong><a href=\"https://www.youtube.com/@indydevdan\">IndyDevDan</a></strong> — For great videos on meta-prompting and custom agents that have inspired parts of PAI.</p> \n<h3>Contributors</h3> \n<p><strong><a href=\"https://github.com/fayerman-source\">fayerman-source</a></strong> — Google Cloud TTS provider integration and Linux audio support for the voice system.</p> \n<p><strong>Matt Espinoza</strong> — Extensive testing, ideas, and feedback for the PAI 2.3 release, plus roadmap contributions.</p> \n<hr /> \n<h2>💜 Support This Project</h2> \n<div align=\"center\"> \n <p><a href=\"https://github.com/sponsors/danielmiessler\"><img alt=\"Sponsor\" src=\"https://img.shields.io/badge/Sponsor-❤️-EA4AAA?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white\" /></a></p> \n <p><strong>PAI is free and open-source forever. If you find it valuable, you can <a href=\"https://github.com/sponsors/danielmiessler\">sponsor the project</a>.</strong></p> \n</div> \n<hr /> \n<h2>📚 Related Reading</h2> \n<ul> \n <li><a href=\"https://danielmiessler.com/blog/real-internet-of-things\">The Real Internet of Things</a> — The vision behind PAI</li> \n <li><a href=\"https://danielmiessler.com/blog/ai-predictable-path-7-components-2024\">AI's Predictable Path: 7 Components</a> — Visual walkthrough of where AI is heading</li> \n <li><a href=\"https://danielmiessler.com/blog/personal-ai-infrastructure\">Building a Personal AI Infrastructure</a> — Full PAI walkthrough with examples</li> \n</ul> \n<hr /> \n<details> \n <strong>📜 Update History</strong> \n <br /> \n <p><strong>v3.0.0 (2026-02-15) — The Algorithm Matures</strong></p> \n <ul> \n  <li>Algorithm v1.4.0 with constraint extraction and build drift prevention</li> \n  <li>Persistent PRDs and parallel loop execution</li> \n  <li>Full installer with GUI wizard</li> \n  <li>10 new skills, agent teams/swarm, voice personality system</li> \n  <li>38 skills, 20 hooks, 162 workflows</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.5.0 (2026-01-30) — Think Deeper, Execute Faster</strong></p> \n <ul> \n  <li>Two-Pass Capability Selection: Hook hints validated against ISC in THINK phase</li> \n  <li>Thinking Tools with Justify-Exclusion: Opt-OUT, not opt-IN for Council, RedTeam, FirstPrinciples, etc.</li> \n  <li>Parallel-by-Default Execution: Independent tasks run concurrently via parallel agent spawning</li> \n  <li>28 skills, 17 hooks, 356 workflows</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.5/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.4.0 (2026-01-23) — The Algorithm</strong></p> \n <ul> \n  <li>Universal problem-solving system with ISC (Ideal State Criteria) tracking</li> \n  <li>29 skills, 15 hooks, 331 workflows</li> \n  <li>Euphoric Surprise as the outcome metric</li> \n  <li>Enhanced security with AllowList enforcement</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.4/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.3.0 (2026-01-15) — Full Releases Return</strong></p> \n <ul> \n  <li>Complete <code>.claude/</code> directory releases with continuous learning</li> \n  <li>Explicit and implicit rating capture</li> \n  <li>Enhanced hook system with 14 production hooks</li> \n  <li>Status line with learning signal display</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.3/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.1.1 (2026-01-09) — MEMORY System Migration</strong></p> \n <ul> \n  <li>History system merged into core as MEMORY System</li> \n </ul> \n <p><strong>v2.1.0 (2025-12-31) — Modular Architecture</strong></p> \n <ul> \n  <li>Source code in real files instead of embedded markdown</li> \n </ul> \n <p><strong>v2.0.0 (2025-12-28) — PAI v2 Launch</strong></p> \n <ul> \n  <li>Modular architecture with independent skills</li> \n  <li>Claude Code native design</li> \n </ul> \n</details> \n<hr /> \n<div align=\"center\"> \n <p><strong>Built with ❤️ by <a href=\"https://danielmiessler.com\">Daniel Miessler</a> and the PAI community</strong></p> \n <p><em>Augment yourself.</em></p> \n</div>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-20T23:24:54.959619Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 30,
        "timeliness_score": 1,
        "final_score": 15.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/ruvnet/wifi-densepose",
        "title": "ruvnet/wifi-densepose",
        "summary": "<p>Production-ready implementation of InvisPose - a revolutionary WiFi-based dense human pose estimation system that enables real-time full-body tracking through walls using commodity mesh routers</p><hr /><h1>WiFi DensePose</h1> \n<p><a href=\"https://www.python.org/downloads/\"><img alt=\"Python 3.8+\" src=\"https://img.shields.io/badge/python-3.8+-blue.svg?sanitize=true\" /></a> <a href=\"https://fastapi.tiangolo.com/\"><img alt=\"FastAPI\" src=\"https://img.shields.io/badge/FastAPI-0.95+-green.svg?sanitize=true\" /></a> <a href=\"https://opensource.org/licenses/MIT\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true\" /></a> <a href=\"https://pypi.org/project/wifi-densepose/\"><img alt=\"PyPI version\" src=\"https://img.shields.io/pypi/v/wifi-densepose.svg?sanitize=true\" /></a> <a href=\"https://pypi.org/project/wifi-densepose/\"><img alt=\"PyPI downloads\" src=\"https://img.shields.io/pypi/dm/wifi-densepose.svg?sanitize=true\" /></a> <a href=\"https://github.com/ruvnet/wifi-densepose\"><img alt=\"Test Coverage\" src=\"https://img.shields.io/badge/coverage-100%25-brightgreen.svg?sanitize=true\" /></a> <a href=\"https://hub.docker.com/r/ruvnet/wifi-densepose\"><img alt=\"Docker\" src=\"https://img.shields.io/badge/docker-ready-blue.svg?sanitize=true\" /></a></p> \n<p>A cutting-edge WiFi-based human pose estimation system that leverages Channel State Information (CSI) data and advanced machine learning to provide real-time, privacy-preserving pose detection without cameras.</p> \n<h2>🚀 Key Features</h2> \n<ul> \n <li><strong>Privacy-First</strong>: No cameras required - uses WiFi signals for pose detection</li> \n <li><strong>Real-Time Processing</strong>: Sub-50ms latency with 30 FPS pose estimation</li> \n <li><strong>Multi-Person Tracking</strong>: Simultaneous tracking of up to 10 individuals</li> \n <li><strong>Domain-Specific Optimization</strong>: Healthcare, fitness, smart home, and security applications</li> \n <li><strong>Enterprise-Ready</strong>: Production-grade API with authentication, rate limiting, and monitoring</li> \n <li><strong>Hardware Agnostic</strong>: Works with standard WiFi routers and access points</li> \n <li><strong>Comprehensive Analytics</strong>: Fall detection, activity recognition, and occupancy monitoring</li> \n <li><strong>WebSocket Streaming</strong>: Real-time pose data streaming for live applications</li> \n <li><strong>100% Test Coverage</strong>: Thoroughly tested with comprehensive test suite</li> \n</ul> \n<h2>🦀 Rust Implementation (v2)</h2> \n<p>A high-performance Rust port is available in <code>/rust-port/wifi-densepose-rs/</code>:</p> \n<h3>Performance Benchmarks (Validated)</h3> \n<table> \n <thead> \n  <tr> \n   <th>Operation</th> \n   <th>Python (v1)</th> \n   <th>Rust (v2)</th> \n   <th>Speedup</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>CSI Preprocessing (4x64)</td> \n   <td>~5ms</td> \n   <td><strong>5.19 µs</strong></td> \n   <td>~1000x</td> \n  </tr> \n  <tr> \n   <td>Phase Sanitization (4x64)</td> \n   <td>~3ms</td> \n   <td><strong>3.84 µs</strong></td> \n   <td>~780x</td> \n  </tr> \n  <tr> \n   <td>Feature Extraction (4x64)</td> \n   <td>~8ms</td> \n   <td><strong>9.03 µs</strong></td> \n   <td>~890x</td> \n  </tr> \n  <tr> \n   <td>Motion Detection</td> \n   <td>~1ms</td> \n   <td><strong>186 ns</strong></td> \n   <td>~5400x</td> \n  </tr> \n  <tr> \n   <td><strong>Full Pipeline</strong></td> \n   <td>~15ms</td> \n   <td><strong>18.47 µs</strong></td> \n   <td>~810x</td> \n  </tr> \n </tbody> \n</table> \n<h3>Throughput Metrics</h3> \n<table> \n <thead> \n  <tr> \n   <th>Component</th> \n   <th>Throughput</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>CSI Preprocessing</td> \n   <td>49-66 Melem/s</td> \n  </tr> \n  <tr> \n   <td>Phase Sanitization</td> \n   <td>67-85 Melem/s</td> \n  </tr> \n  <tr> \n   <td>Feature Extraction</td> \n   <td>7-11 Melem/s</td> \n  </tr> \n  <tr> \n   <td>Full Pipeline</td> \n   <td><strong>~54,000 fps</strong></td> \n  </tr> \n </tbody> \n</table> \n<h3>Resource Comparison</h3> \n<table> \n <thead> \n  <tr> \n   <th>Feature</th> \n   <th>Python (v1)</th> \n   <th>Rust (v2)</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Memory Usage</td> \n   <td>~500MB</td> \n   <td>~100MB</td> \n  </tr> \n  <tr> \n   <td>WASM Support</td> \n   <td>❌</td> \n   <td>✅</td> \n  </tr> \n  <tr> \n   <td>Binary Size</td> \n   <td>N/A</td> \n   <td>~10MB</td> \n  </tr> \n  <tr> \n   <td>Test Coverage</td> \n   <td>100%</td> \n   <td>107 tests</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Quick Start (Rust):</strong></p> \n<pre><code class=\"language-bash\">cd rust-port/wifi-densepose-rs\ncargo build --release\ncargo test --workspace\ncargo bench --package wifi-densepose-signal\n</code></pre> \n<h3>Validation Tests</h3> \n<p>Mathematical correctness validated:</p> \n<ul> \n <li>✅ Phase unwrapping: 0.000000 radians max error</li> \n <li>✅ Amplitude RMS: Exact match</li> \n <li>✅ Doppler shift: 33.33 Hz (exact)</li> \n <li>✅ Correlation: 1.0 for identical signals</li> \n <li>✅ Phase coherence: 1.0 for coherent signals</li> \n</ul> \n<p>See <a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/rust-port/wifi-densepose-rs/docs/\">Rust Port Documentation</a> for ADRs and DDD patterns.</p> \n<h2>🚨 WiFi-Mat: Disaster Response Module</h2> \n<p>A specialized extension for <strong>search and rescue operations</strong> - detecting and localizing survivors trapped in rubble, earthquakes, and natural disasters.</p> \n<h3>Key Capabilities</h3> \n<table> \n <thead> \n  <tr> \n   <th>Feature</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Vital Signs Detection</strong></td> \n   <td>Breathing (4-60 BPM), heartbeat via micro-Doppler</td> \n  </tr> \n  <tr> \n   <td><strong>3D Localization</strong></td> \n   <td>Position estimation through debris up to 5m depth</td> \n  </tr> \n  <tr> \n   <td><strong>START Triage</strong></td> \n   <td>Automatic Immediate/Delayed/Minor/Deceased classification</td> \n  </tr> \n  <tr> \n   <td><strong>Real-time Alerts</strong></td> \n   <td>Priority-based notifications with escalation</td> \n  </tr> \n </tbody> \n</table> \n<h3>Use Cases</h3> \n<ul> \n <li>Earthquake search and rescue</li> \n <li>Building collapse response</li> \n <li>Avalanche victim location</li> \n <li>Mine collapse detection</li> \n <li>Flood rescue operations</li> \n</ul> \n<h3>Quick Example</h3> \n<pre><code class=\"language-rust\">use wifi_densepose_mat::{DisasterResponse, DisasterConfig, DisasterType, ScanZone, ZoneBounds};\n\nlet config = DisasterConfig::builder()\n    .disaster_type(DisasterType::Earthquake)\n    .sensitivity(0.85)\n    .max_depth(5.0)\n    .build();\n\nlet mut response = DisasterResponse::new(config);\nresponse.initialize_event(location, \"Building collapse\")?;\nresponse.add_zone(ScanZone::new(\"North Wing\", ZoneBounds::rectangle(0.0, 0.0, 30.0, 20.0)))?;\nresponse.start_scanning().await?;\n\n// Get survivors prioritized by triage status\nlet immediate = response.survivors_by_triage(TriageStatus::Immediate);\nprintln!(\"{} survivors require immediate rescue\", immediate.len());\n</code></pre> \n<h3>Documentation</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/wifi-mat-user-guide.md\">WiFi-Mat User Guide</a></strong> - Complete setup, configuration, and field deployment</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/adr/ADR-001-wifi-mat-disaster-detection.md\">Architecture Decision Record</a></strong> - Design decisions and rationale</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/ddd/wifi-mat-domain-model.md\">Domain Model</a></strong> - DDD bounded contexts and entities</li> \n</ul> \n<p><strong>Build:</strong></p> \n<pre><code class=\"language-bash\">cd rust-port/wifi-densepose-rs\ncargo build --release --package wifi-densepose-mat\ncargo test --package wifi-densepose-mat\n</code></pre> \n<h2>📋 Table of Contents</h2> \n<table> \n <tbody>\n  <tr> \n   <td width=\"50%\"> <p><strong>🚀 Getting Started</strong></p> \n    <ul> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-key-features\">Key Features</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-rust-implementation-v2\">Rust Implementation (v2)</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-wifi-mat-disaster-response-module\">WiFi-Mat Disaster Response</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-system-architecture\">System Architecture</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-installation\">Installation</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#using-pip-recommended\">Using pip (Recommended)</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#from-source\">From Source</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#using-docker\">Using Docker</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#system-requirements\">System Requirements</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-quick-start\">Quick Start</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#1-basic-setup\">Basic Setup</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#2-start-the-system\">Start the System</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#3-using-the-rest-api\">Using the REST API</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#4-real-time-streaming\">Real-time Streaming</a></li> \n      </ul> </li> \n    </ul> <p><strong>🖥️ Usage &amp; Configuration</strong></p> \n    <ul> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-cli-usage\">CLI Usage</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#cli-installation\">Installation</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#basic-commands\">Basic Commands</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#configuration-commands\">Configuration Commands</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#cli-examples\">Examples</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-documentation\">Documentation</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-core-documentation\">Core Documentation</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-quick-links\">Quick Links</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-api-overview\">API Overview</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-hardware-setup\">Hardware Setup</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#supported-hardware\">Supported Hardware</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#physical-setup\">Physical Setup</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#network-configuration\">Network Configuration</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#environment-calibration\">Environment Calibration</a></li> \n      </ul> </li> \n    </ul> </td> \n   <td width=\"50%\"> <p><strong>⚙️ Advanced Topics</strong></p> \n    <ul> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-configuration\">Configuration</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#environment-variables\">Environment Variables</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#domain-specific-configurations\">Domain-Specific Configurations</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#advanced-configuration\">Advanced Configuration</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-testing\">Testing</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#running-tests\">Running Tests</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#test-categories\">Test Categories</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#mock-testing\">Mock Testing</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#continuous-integration\">Continuous Integration</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-deployment\">Deployment</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#production-deployment\">Production Deployment</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#infrastructure-as-code\">Infrastructure as Code</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#monitoring-and-logging\">Monitoring and Logging</a></li> \n      </ul> </li> \n    </ul> <p><strong>📊 Performance &amp; Community</strong></p> \n    <ul> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-performance-metrics\">Performance Metrics</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#benchmark-results\">Benchmark Results</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#performance-optimization\">Performance Optimization</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#load-testing\">Load Testing</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-contributing\">Contributing</a> \n      <ul> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#development-setup\">Development Setup</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#code-standards\">Code Standards</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#contribution-process\">Contribution Process</a></li> \n       <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#code-review-checklist\">Code Review Checklist</a></li> \n      </ul> </li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-license\">License</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-acknowledgments\">Acknowledgments</a></li> \n     <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-support\">Support</a></li> \n    </ul> </td> \n  </tr> \n </tbody>\n</table> \n<h2>🏗️ System Architecture</h2> \n<p>WiFi DensePose consists of several key components working together:</p> \n<pre><code>┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n│   WiFi Router   │    │   WiFi Router   │    │   WiFi Router   │\n│   (CSI Source)  │    │   (CSI Source)  │    │   (CSI Source)  │\n└─────────┬───────┘    └─────────┬───────┘    └─────────┬───────┘\n          │                      │                      │\n          └──────────────────────┼──────────────────────┘\n                                 │\n                    ┌─────────────▼─────────────┐\n                    │     CSI Data Collector    │\n                    │   (Hardware Interface)    │\n                    └─────────────┬─────────────┘\n                                  │\n                    ┌─────────────▼─────────────┐\n                    │    Signal Processor       │\n                    │  (Phase Sanitization)     │\n                    └─────────────┬─────────────┘\n                                  │\n                    ┌─────────────▼─────────────┐\n                    │   Neural Network Model    │\n                    │    (DensePose Head)       │\n                    └─────────────┬─────────────┘\n                                  │\n                    ┌─────────────▼─────────────┐\n                    │   Person Tracker          │\n                    │  (Multi-Object Tracking)  │\n                    └─────────────┬─────────────┘\n                                  │\n          ┌───────────────────────┼───────────────────────┐\n          │                       │                       │\n┌─────────▼─────────┐   ┌─────────▼─────────┐   ┌─────────▼─────────┐\n│   REST API        │   │  WebSocket API    │   │   Analytics       │\n│  (CRUD Operations)│   │ (Real-time Stream)│   │  (Fall Detection) │\n└───────────────────┘   └───────────────────┘   └───────────────────┘\n</code></pre> \n<h3>Core Components</h3> \n<ul> \n <li><strong>CSI Processor</strong>: Extracts and processes Channel State Information from WiFi signals</li> \n <li><strong>Phase Sanitizer</strong>: Removes hardware-specific phase offsets and noise</li> \n <li><strong>DensePose Neural Network</strong>: Converts CSI data to human pose keypoints</li> \n <li><strong>Multi-Person Tracker</strong>: Maintains consistent person identities across frames</li> \n <li><strong>REST API</strong>: Comprehensive API for data access and system control</li> \n <li><strong>WebSocket Streaming</strong>: Real-time pose data broadcasting</li> \n <li><strong>Analytics Engine</strong>: Advanced analytics including fall detection and activity recognition</li> \n</ul> \n<h2>📦 Installation</h2> \n<h3>Using pip (Recommended)</h3> \n<p>WiFi-DensePose is now available on PyPI for easy installation:</p> \n<pre><code class=\"language-bash\"># Install the latest stable version\npip install wifi-densepose\n\n# Install with specific version\npip install wifi-densepose==1.0.0\n\n# Install with optional dependencies\npip install wifi-densepose[gpu]  # For GPU acceleration\npip install wifi-densepose[dev]  # For development\npip install wifi-densepose[all]  # All optional dependencies\n</code></pre> \n<h3>From Source</h3> \n<pre><code class=\"language-bash\">git clone https://github.com/ruvnet/wifi-densepose.git\ncd wifi-densepose\npip install -r requirements.txt\npip install -e .\n</code></pre> \n<h3>Using Docker</h3> \n<pre><code class=\"language-bash\">docker pull ruvnet/wifi-densepose:latest\ndocker run -p 8000:8000 ruvnet/wifi-densepose:latest\n</code></pre> \n<h3>System Requirements</h3> \n<ul> \n <li><strong>Python</strong>: 3.8 or higher</li> \n <li><strong>Operating System</strong>: Linux (Ubuntu 18.04+), macOS (10.15+), Windows 10+</li> \n <li><strong>Memory</strong>: Minimum 4GB RAM, Recommended 8GB+</li> \n <li><strong>Storage</strong>: 2GB free space for models and data</li> \n <li><strong>Network</strong>: WiFi interface with CSI capability</li> \n <li><strong>GPU</strong>: Optional but recommended (NVIDIA GPU with CUDA support)</li> \n</ul> \n<h2>🚀 Quick Start</h2> \n<h3>1. Basic Setup</h3> \n<pre><code class=\"language-bash\"># Install the package\npip install wifi-densepose\n\n# Copy example configuration\ncp example.env .env\n\n# Edit configuration (set your WiFi interface)\nnano .env\n</code></pre> \n<h3>2. Start the System</h3> \n<pre><code class=\"language-python\">from wifi_densepose import WiFiDensePose\n\n# Initialize with default configuration\nsystem = WiFiDensePose()\n\n# Start pose estimation\nsystem.start()\n\n# Get latest pose data\nposes = system.get_latest_poses()\nprint(f\"Detected {len(poses)} persons\")\n\n# Stop the system\nsystem.stop()\n</code></pre> \n<h3>3. Using the REST API</h3> \n<pre><code class=\"language-bash\"># Start the API server\nwifi-densepose start\n\n# Start with custom configuration\nwifi-densepose -c /path/to/config.yaml start\n\n# Start with verbose logging\nwifi-densepose -v start\n\n# Check server status\nwifi-densepose status\n</code></pre> \n<p>The API will be available at <code>http://localhost:8000</code></p> \n<ul> \n <li><strong>API Documentation</strong>: <a href=\"http://localhost:8000/docs\">http://localhost:8000/docs</a></li> \n <li><strong>Health Check</strong>: <a href=\"http://localhost:8000/api/v1/health\">http://localhost:8000/api/v1/health</a></li> \n <li><strong>Latest Poses</strong>: <a href=\"http://localhost:8000/api/v1/pose/latest\">http://localhost:8000/api/v1/pose/latest</a></li> \n</ul> \n<h3>4. Real-time Streaming</h3> \n<pre><code class=\"language-python\">import asyncio\nimport websockets\nimport json\n\nasync def stream_poses():\n    uri = \"ws://localhost:8000/ws/pose/stream\"\n    async with websockets.connect(uri) as websocket:\n        while True:\n            data = await websocket.recv()\n            poses = json.loads(data)\n            print(f\"Received poses: {len(poses['persons'])} persons detected\")\n\n# Run the streaming client\nasyncio.run(stream_poses())\n</code></pre> \n<h2>🖥️ CLI Usage</h2> \n<p>WiFi DensePose provides a comprehensive command-line interface for easy system management, configuration, and monitoring.</p> \n<h3>CLI Installation</h3> \n<p>The CLI is automatically installed with the package:</p> \n<pre><code class=\"language-bash\"># Install WiFi DensePose with CLI\npip install wifi-densepose\n\n# Verify CLI installation\nwifi-densepose --help\nwifi-densepose version\n</code></pre> \n<h3>Basic Commands</h3> \n<p>The WiFi-DensePose CLI provides the following commands:</p> \n<pre><code class=\"language-bash\">wifi-densepose [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  -c, --config PATH  Path to configuration file\n  -v, --verbose      Enable verbose logging\n  --debug            Enable debug mode\n  --help             Show this message and exit.\n\nCommands:\n  config   Configuration management commands.\n  db       Database management commands.\n  start    Start the WiFi-DensePose API server.\n  status   Show the status of the WiFi-DensePose API server.\n  stop     Stop the WiFi-DensePose API server.\n  tasks    Background task management commands.\n  version  Show version information.\n</code></pre> \n<h4>Server Management</h4> \n<pre><code class=\"language-bash\"># Start the WiFi-DensePose API server\nwifi-densepose start\n\n# Start with custom configuration\nwifi-densepose -c /path/to/config.yaml start\n\n# Start with verbose logging\nwifi-densepose -v start\n\n# Start with debug mode\nwifi-densepose --debug start\n\n# Check server status\nwifi-densepose status\n\n# Stop the server\nwifi-densepose stop\n\n# Show version information\nwifi-densepose version\n</code></pre> \n<h3>Configuration Commands</h3> \n<h4>Configuration Management</h4> \n<pre><code class=\"language-bash\"># Configuration management commands\nwifi-densepose config [SUBCOMMAND]\n\n# Examples:\n# Show current configuration\nwifi-densepose config show\n\n# Validate configuration file\nwifi-densepose config validate\n\n# Create default configuration\nwifi-densepose config init\n\n# Edit configuration\nwifi-densepose config edit\n</code></pre> \n<h4>Database Management</h4> \n<pre><code class=\"language-bash\"># Database management commands\nwifi-densepose db [SUBCOMMAND]\n\n# Examples:\n# Initialize database\nwifi-densepose db init\n\n# Run database migrations\nwifi-densepose db migrate\n\n# Check database status\nwifi-densepose db status\n\n# Backup database\nwifi-densepose db backup\n\n# Restore database\nwifi-densepose db restore\n</code></pre> \n<h4>Background Tasks</h4> \n<pre><code class=\"language-bash\"># Background task management commands\nwifi-densepose tasks [SUBCOMMAND]\n\n# Examples:\n# List running tasks\nwifi-densepose tasks list\n\n# Start background tasks\nwifi-densepose tasks start\n\n# Stop background tasks\nwifi-densepose tasks stop\n\n# Check task status\nwifi-densepose tasks status\n</code></pre> \n<h3>Command Examples</h3> \n<h4>Complete CLI Reference</h4> \n<pre><code class=\"language-bash\"># Show help for main command\nwifi-densepose --help\n\n# Show help for specific command\nwifi-densepose start --help\nwifi-densepose config --help\nwifi-densepose db --help\n\n# Use global options with commands\nwifi-densepose -v status          # Verbose status check\nwifi-densepose --debug start      # Start with debug logging\nwifi-densepose -c custom.yaml start  # Start with custom config\n</code></pre> \n<h4>Common Usage Patterns</h4> \n<pre><code class=\"language-bash\"># Basic server lifecycle\nwifi-densepose start              # Start the server\nwifi-densepose status             # Check if running\nwifi-densepose stop               # Stop the server\n\n# Configuration management\nwifi-densepose config show        # View current config\nwifi-densepose config validate    # Check config validity\n\n# Database operations\nwifi-densepose db init            # Initialize database\nwifi-densepose db migrate         # Run migrations\nwifi-densepose db status          # Check database health\n\n# Task management\nwifi-densepose tasks list         # List background tasks\nwifi-densepose tasks status       # Check task status\n\n# Version and help\nwifi-densepose version            # Show version info\nwifi-densepose --help             # Show help message\n</code></pre> \n<h3>CLI Examples</h3> \n<h4>Complete Setup Workflow</h4> \n<pre><code class=\"language-bash\"># 1. Check version and help\nwifi-densepose version\nwifi-densepose --help\n\n# 2. Initialize configuration\nwifi-densepose config init\n\n# 3. Initialize database\nwifi-densepose db init\n\n# 4. Start the server\nwifi-densepose start\n\n# 5. Check status\nwifi-densepose status\n</code></pre> \n<h4>Development Workflow</h4> \n<pre><code class=\"language-bash\"># Start with debug logging\nwifi-densepose --debug start\n\n# Use custom configuration\nwifi-densepose -c dev-config.yaml start\n\n# Check database status\nwifi-densepose db status\n\n# Manage background tasks\nwifi-densepose tasks start\nwifi-densepose tasks list\n</code></pre> \n<h4>Production Workflow</h4> \n<pre><code class=\"language-bash\"># Start with production config\nwifi-densepose -c production.yaml start\n\n# Check system status\nwifi-densepose status\n\n# Manage database\nwifi-densepose db migrate\nwifi-densepose db backup\n\n# Monitor tasks\nwifi-densepose tasks status\n</code></pre> \n<h4>Troubleshooting</h4> \n<pre><code class=\"language-bash\"># Enable verbose logging\nwifi-densepose -v status\n\n# Check configuration\nwifi-densepose config validate\n\n# Check database health\nwifi-densepose db status\n\n# Restart services\nwifi-densepose stop\nwifi-densepose start\n</code></pre> \n<h2>📚 Documentation</h2> \n<p>Comprehensive documentation is available to help you get started and make the most of WiFi-DensePose:</p> \n<h3>📖 Core Documentation</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/user_guide.md\">User Guide</a></strong> - Complete guide covering installation, setup, basic usage, and examples</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md\">API Reference</a></strong> - Detailed documentation of all public classes, methods, and endpoints</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/deployment.md\">Deployment Guide</a></strong> - Production deployment, Docker setup, Kubernetes, and scaling strategies</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/troubleshooting.md\">Troubleshooting Guide</a></strong> - Common issues, solutions, and diagnostic procedures</li> \n</ul> \n<h3>🚀 Quick Links</h3> \n<ul> \n <li><strong>Interactive API Docs</strong>: <a href=\"http://localhost:8000/docs\">http://localhost:8000/docs</a> (when running)</li> \n <li><strong>Health Check</strong>: <a href=\"http://localhost:8000/api/v1/health\">http://localhost:8000/api/v1/health</a></li> \n <li><strong>Latest Poses</strong>: <a href=\"http://localhost:8000/api/v1/pose/latest\">http://localhost:8000/api/v1/pose/latest</a></li> \n <li><strong>System Status</strong>: <a href=\"http://localhost:8000/api/v1/system/status\">http://localhost:8000/api/v1/system/status</a></li> \n</ul> \n<h3>📋 API Overview</h3> \n<p>The system provides a comprehensive REST API and WebSocket streaming:</p> \n<h4>Key REST Endpoints</h4> \n<pre><code class=\"language-bash\"># Pose estimation\nGET /api/v1/pose/latest          # Get latest pose data\nGET /api/v1/pose/history         # Get historical data\nGET /api/v1/pose/zones/{zone_id} # Get zone-specific data\n\n# System management\nGET /api/v1/system/status        # System health and status\nPOST /api/v1/system/calibrate    # Calibrate environment\nGET /api/v1/analytics/summary    # Analytics dashboard data\n</code></pre> \n<h4>WebSocket Streaming</h4> \n<pre><code class=\"language-javascript\">// Real-time pose data\nws://localhost:8000/ws/pose/stream\n\n// Analytics events (falls, alerts)\nws://localhost:8000/ws/analytics/events\n\n// System status updates\nws://localhost:8000/ws/system/status\n</code></pre> \n<h4>Python SDK Quick Example</h4> \n<pre><code class=\"language-python\">from wifi_densepose import WiFiDensePoseClient\n\n# Initialize client\nclient = WiFiDensePoseClient(base_url=\"http://localhost:8000\")\n\n# Get latest poses with confidence filtering\nposes = client.get_latest_poses(min_confidence=0.7)\nprint(f\"Detected {len(poses)} persons\")\n\n# Get zone occupancy\noccupancy = client.get_zone_occupancy(\"living_room\")\nprint(f\"Living room occupancy: {occupancy.person_count}\")\n</code></pre> \n<p>For complete API documentation with examples, see the <a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md\">API Reference Guide</a>.</p> \n<h2>🔧 Hardware Setup</h2> \n<h3>Supported Hardware</h3> \n<p>WiFi DensePose works with standard WiFi equipment that supports CSI extraction:</p> \n<h4>Recommended Routers</h4> \n<ul> \n <li><strong>ASUS AX6000</strong> (RT-AX88U) - Excellent CSI quality</li> \n <li><strong>Netgear Nighthawk AX12</strong> - High performance</li> \n <li><strong>TP-Link Archer AX73</strong> - Budget-friendly option</li> \n <li><strong>Ubiquiti UniFi 6 Pro</strong> - Enterprise grade</li> \n</ul> \n<h4>CSI-Capable Devices</h4> \n<ul> \n <li>Intel WiFi cards (5300, 7260, 8260, 9260)</li> \n <li>Atheros AR9300 series</li> \n <li>Broadcom BCM4366 series</li> \n <li>Qualcomm QCA9984 series</li> \n</ul> \n<h3>Physical Setup</h3> \n<ol> \n <li><strong>Router Placement</strong>: Position routers to create overlapping coverage areas</li> \n <li><strong>Height</strong>: Mount routers 2-3 meters high for optimal coverage</li> \n <li><strong>Spacing</strong>: 5-10 meter spacing between routers depending on environment</li> \n <li><strong>Orientation</strong>: Ensure antennas are positioned for maximum signal diversity</li> \n</ol> \n<h3>Network Configuration</h3> \n<pre><code class=\"language-bash\"># Configure WiFi interface for CSI extraction\nsudo iwconfig wlan0 mode monitor\nsudo iwconfig wlan0 channel 6\n\n# Set up CSI extraction (Intel 5300 example)\necho 0x4101 | sudo tee /sys/kernel/debug/ieee80211/phy0/iwlwifi/iwldvm/debug/monitor_tx_rate\n</code></pre> \n<h3>Environment Calibration</h3> \n<pre><code class=\"language-python\">from wifi_densepose import Calibrator\n\n# Run environment calibration\ncalibrator = Calibrator()\ncalibrator.calibrate_environment(\n    duration_minutes=10,\n    environment_id=\"room_001\"\n)\n\n# Apply calibration\ncalibrator.apply_calibration()\n</code></pre> \n<h2>⚙️ Configuration</h2> \n<h3>Environment Variables</h3> \n<p>Copy <code>example.env</code> to <code>.env</code> and configure:</p> \n<pre><code class=\"language-bash\"># Application Settings\nAPP_NAME=WiFi-DensePose API\nVERSION=1.0.0\nENVIRONMENT=production  # development, staging, production\nDEBUG=false\n\n# Server Settings\nHOST=0.0.0.0\nPORT=8000\nWORKERS=4\n\n# Security Settings\nSECRET_KEY=your-secure-secret-key-here\nJWT_ALGORITHM=HS256\nJWT_EXPIRE_HOURS=24\n\n# Hardware Settings\nWIFI_INTERFACE=wlan0\nCSI_BUFFER_SIZE=1000\nHARDWARE_POLLING_INTERVAL=0.1\n\n# Pose Estimation Settings\nPOSE_CONFIDENCE_THRESHOLD=0.7\nPOSE_PROCESSING_BATCH_SIZE=32\nPOSE_MAX_PERSONS=10\n\n# Feature Flags\nENABLE_AUTHENTICATION=true\nENABLE_RATE_LIMITING=true\nENABLE_WEBSOCKETS=true\nENABLE_REAL_TIME_PROCESSING=true\nENABLE_HISTORICAL_DATA=true\n</code></pre> \n<h3>Domain-Specific Configurations</h3> \n<h4>Healthcare Configuration</h4> \n<pre><code class=\"language-python\">config = {\n    \"domain\": \"healthcare\",\n    \"detection\": {\n        \"confidence_threshold\": 0.8,\n        \"max_persons\": 5,\n        \"enable_tracking\": True\n    },\n    \"analytics\": {\n        \"enable_fall_detection\": True,\n        \"enable_activity_recognition\": True,\n        \"alert_thresholds\": {\n            \"fall_confidence\": 0.9,\n            \"inactivity_timeout\": 300\n        }\n    },\n    \"privacy\": {\n        \"data_retention_days\": 30,\n        \"anonymize_data\": True,\n        \"enable_encryption\": True\n    }\n}\n</code></pre> \n<h4>Fitness Configuration</h4> \n<pre><code class=\"language-python\">config = {\n    \"domain\": \"fitness\",\n    \"detection\": {\n        \"confidence_threshold\": 0.6,\n        \"max_persons\": 20,\n        \"enable_tracking\": True\n    },\n    \"analytics\": {\n        \"enable_activity_recognition\": True,\n        \"enable_form_analysis\": True,\n        \"metrics\": [\"rep_count\", \"form_score\", \"intensity\"]\n    }\n}\n</code></pre> \n<h3>Advanced Configuration</h3> \n<pre><code class=\"language-python\">from wifi_densepose.config import Settings\n\n# Load custom configuration\nsettings = Settings(\n    pose_model_path=\"/path/to/custom/model.pth\",\n    neural_network={\n        \"batch_size\": 64,\n        \"enable_gpu\": True,\n        \"inference_timeout\": 500\n    },\n    tracking={\n        \"max_age\": 30,\n        \"min_hits\": 3,\n        \"iou_threshold\": 0.3\n    }\n)\n</code></pre> \n<h2>🧪 Testing</h2> \n<p>WiFi DensePose maintains 100% test coverage with comprehensive testing:</p> \n<h3>Running Tests</h3> \n<pre><code class=\"language-bash\"># Run all tests\npytest\n\n# Run with coverage report\npytest --cov=wifi_densepose --cov-report=html\n\n# Run specific test categories\npytest tests/unit/          # Unit tests\npytest tests/integration/   # Integration tests\npytest tests/e2e/          # End-to-end tests\npytest tests/performance/  # Performance tests\n</code></pre> \n<h3>Test Categories</h3> \n<h4>Unit Tests (95% coverage)</h4> \n<ul> \n <li>CSI processing algorithms</li> \n <li>Neural network components</li> \n <li>Tracking algorithms</li> \n <li>API endpoints</li> \n <li>Configuration validation</li> \n</ul> \n<h4>Integration Tests</h4> \n<ul> \n <li>Hardware interface integration</li> \n <li>Database operations</li> \n <li>WebSocket connections</li> \n <li>Authentication flows</li> \n</ul> \n<h4>End-to-End Tests</h4> \n<ul> \n <li>Complete pose estimation pipeline</li> \n <li>Multi-person tracking scenarios</li> \n <li>Real-time streaming</li> \n <li>Analytics generation</li> \n</ul> \n<h4>Performance Tests</h4> \n<ul> \n <li>Latency benchmarks</li> \n <li>Throughput testing</li> \n <li>Memory usage profiling</li> \n <li>Stress testing</li> \n</ul> \n<h3>Mock Testing</h3> \n<p>For development without hardware:</p> \n<pre><code class=\"language-bash\"># Enable mock mode\nexport MOCK_HARDWARE=true\nexport MOCK_POSE_DATA=true\n\n# Run tests with mocked hardware\npytest tests/ --mock-hardware\n</code></pre> \n<h3>Continuous Integration</h3> \n<pre><code class=\"language-yaml\"># .github/workflows/test.yml\nname: Test Suite\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install -e .\n      - name: Run tests\n        run: pytest --cov=wifi_densepose --cov-report=xml\n      - name: Upload coverage\n        uses: codecov/codecov-action@v1\n</code></pre> \n<h2>🚀 Deployment</h2> \n<h3>Production Deployment</h3> \n<h4>Using Docker</h4> \n<pre><code class=\"language-bash\"># Build production image\ndocker build -t wifi-densepose:latest .\n\n# Run with production configuration\ndocker run -d \\\n  --name wifi-densepose \\\n  -p 8000:8000 \\\n  -v /path/to/data:/app/data \\\n  -v /path/to/models:/app/models \\\n  -e ENVIRONMENT=production \\\n  -e SECRET_KEY=your-secure-key \\\n  wifi-densepose:latest\n</code></pre> \n<h4>Using Docker Compose</h4> \n<pre><code class=\"language-yaml\"># docker-compose.yml\nversion: '3.8'\nservices:\n  wifi-densepose:\n    image: wifi-densepose:latest\n    ports:\n      - \"8000:8000\"\n    environment:\n      - ENVIRONMENT=production\n      - DATABASE_URL=postgresql://user:pass@db:5432/wifi_densepose\n      - REDIS_URL=redis://redis:6379/0\n    volumes:\n      - ./data:/app/data\n      - ./models:/app/models\n    depends_on:\n      - db\n      - redis\n\n  db:\n    image: postgres:13\n    environment:\n      POSTGRES_DB: wifi_densepose\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\n  redis:\n    image: redis:6-alpine\n    volumes:\n      - redis_data:/data\n\nvolumes:\n  postgres_data:\n  redis_data:\n</code></pre> \n<h4>Kubernetes Deployment</h4> \n<pre><code class=\"language-yaml\"># k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wifi-densepose\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: wifi-densepose\n  template:\n    metadata:\n      labels:\n        app: wifi-densepose\n    spec:\n      containers:\n      - name: wifi-densepose\n        image: wifi-densepose:latest\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: \"production\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: wifi-densepose-secrets\n              key: database-url\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n</code></pre> \n<h3>Infrastructure as Code</h3> \n<h4>Terraform (AWS)</h4> \n<pre><code class=\"language-hcl\"># terraform/main.tf\nresource \"aws_ecs_cluster\" \"wifi_densepose\" {\n  name = \"wifi-densepose\"\n}\n\nresource \"aws_ecs_service\" \"wifi_densepose\" {\n  name            = \"wifi-densepose\"\n  cluster         = aws_ecs_cluster.wifi_densepose.id\n  task_definition = aws_ecs_task_definition.wifi_densepose.arn\n  desired_count   = 3\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.wifi_densepose.arn\n    container_name   = \"wifi-densepose\"\n    container_port   = 8000\n  }\n}\n</code></pre> \n<h4>Ansible Playbook</h4> \n<pre><code class=\"language-yaml\"># ansible/playbook.yml\n- hosts: servers\n  become: yes\n  tasks:\n    - name: Install Docker\n      apt:\n        name: docker.io\n        state: present\n\n    - name: Deploy WiFi DensePose\n      docker_container:\n        name: wifi-densepose\n        image: wifi-densepose:latest\n        ports:\n          - \"8000:8000\"\n        env:\n          ENVIRONMENT: production\n          DATABASE_URL: \"{{ database_url }}\"\n        restart_policy: always\n</code></pre> \n<h3>Monitoring and Logging</h3> \n<h4>Prometheus Metrics</h4> \n<pre><code class=\"language-yaml\"># monitoring/prometheus.yml\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'wifi-densepose'\n    static_configs:\n      - targets: ['localhost:8000']\n    metrics_path: '/metrics'\n</code></pre> \n<h4>Grafana Dashboard</h4> \n<pre><code class=\"language-json\">{\n  \"dashboard\": {\n    \"title\": \"WiFi DensePose Monitoring\",\n    \"panels\": [\n      {\n        \"title\": \"Pose Detection Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(pose_detections_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Processing Latency\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, pose_processing_duration_seconds_bucket)\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre> \n<h2>📊 Performance Metrics</h2> \n<h3>Benchmark Results</h3> \n<h4>Latency Performance</h4> \n<ul> \n <li><strong>Average Processing Time</strong>: 45.2ms per frame</li> \n <li><strong>95th Percentile</strong>: 67ms</li> \n <li><strong>99th Percentile</strong>: 89ms</li> \n <li><strong>Real-time Capability</strong>: 30 FPS sustained</li> \n</ul> \n<h4>Accuracy Metrics</h4> \n<ul> \n <li><strong>Pose Detection Accuracy</strong>: 94.2% (compared to camera-based systems)</li> \n <li><strong>Person Tracking Accuracy</strong>: 91.8%</li> \n <li><strong>Fall Detection Sensitivity</strong>: 96.5%</li> \n <li><strong>Fall Detection Specificity</strong>: 94.1%</li> \n</ul> \n<h4>Resource Usage</h4> \n<ul> \n <li><strong>CPU Usage</strong>: 65% (4-core system)</li> \n <li><strong>Memory Usage</strong>: 2.1GB RAM</li> \n <li><strong>GPU Usage</strong>: 78% (NVIDIA RTX 3080)</li> \n <li><strong>Network Bandwidth</strong>: 15 Mbps (CSI data)</li> \n</ul> \n<h4>Scalability</h4> \n<ul> \n <li><strong>Maximum Concurrent Users</strong>: 1000+ WebSocket connections</li> \n <li><strong>API Throughput</strong>: 10,000 requests/minute</li> \n <li><strong>Data Storage</strong>: 50GB/month (with compression)</li> \n <li><strong>Multi-Environment Support</strong>: Up to 50 simultaneous environments</li> \n</ul> \n<h3>Performance Optimization</h3> \n<h4>Hardware Optimization</h4> \n<pre><code class=\"language-python\"># Enable GPU acceleration\nconfig = {\n    \"neural_network\": {\n        \"enable_gpu\": True,\n        \"batch_size\": 64,\n        \"mixed_precision\": True\n    },\n    \"processing\": {\n        \"num_workers\": 4,\n        \"prefetch_factor\": 2\n    }\n}\n</code></pre> \n<h4>Software Optimization</h4> \n<pre><code class=\"language-python\"># Enable performance optimizations\nconfig = {\n    \"caching\": {\n        \"enable_redis\": True,\n        \"cache_ttl\": 300\n    },\n    \"database\": {\n        \"connection_pool_size\": 20,\n        \"enable_query_cache\": True\n    }\n}\n</code></pre> \n<h3>Load Testing</h3> \n<pre><code class=\"language-bash\"># API load testing with Apache Bench\nab -n 10000 -c 100 http://localhost:8000/api/v1/pose/latest\n\n# WebSocket load testing\npython scripts/websocket_load_test.py --connections 1000 --duration 300\n</code></pre> \n<h2>🤝 Contributing</h2> \n<p>We welcome contributions to WiFi DensePose! Please follow these guidelines:</p> \n<h3>Development Setup</h3> \n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/ruvnet/wifi-densepose.git\ncd wifi-densepose\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install development dependencies\npip install -r requirements-dev.txt\npip install -e .\n\n# Install pre-commit hooks\npre-commit install\n</code></pre> \n<h3>Code Standards</h3> \n<ul> \n <li><strong>Python Style</strong>: Follow PEP 8, enforced by Black and Flake8</li> \n <li><strong>Type Hints</strong>: Use type hints for all functions and methods</li> \n <li><strong>Documentation</strong>: Comprehensive docstrings for all public APIs</li> \n <li><strong>Testing</strong>: Maintain 100% test coverage for new code</li> \n <li><strong>Security</strong>: Follow OWASP guidelines for security</li> \n</ul> \n<h3>Contribution Process</h3> \n<ol> \n <li><strong>Fork</strong> the repository</li> \n <li><strong>Create</strong> a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> \n <li><strong>Commit</strong> your changes (<code>git commit -m 'Add amazing feature'</code>)</li> \n <li><strong>Push</strong> to the branch (<code>git push origin feature/amazing-feature</code>)</li> \n <li><strong>Open</strong> a Pull Request</li> \n</ol> \n<h3>Code Review Checklist</h3> \n<ul> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Code follows style guidelines</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Tests pass and coverage is maintained</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Documentation is updated</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Security considerations addressed</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Performance impact assessed</li> \n <li><input disabled=\"disabled\" type=\"checkbox\" /> Backward compatibility maintained</li> \n</ul> \n<h3>Issue Templates</h3> \n<h4>Bug Report</h4> \n<pre><code class=\"language-markdown\">**Describe the bug**\nA clear description of the bug.\n\n**To Reproduce**\nSteps to reproduce the behavior.\n\n**Expected behavior**\nWhat you expected to happen.\n\n**Environment**\n- OS: [e.g., Ubuntu 20.04]\n- Python version: [e.g., 3.8.10]\n- WiFi DensePose version: [e.g., 1.0.0]\n</code></pre> \n<h4>Feature Request</h4> \n<pre><code class=\"language-markdown\">**Feature Description**\nA clear description of the feature.\n\n**Use Case**\nDescribe the use case and benefits.\n\n**Implementation Ideas**\nAny ideas on how to implement this feature.\n</code></pre> \n<h2>📄 License</h2> \n<p>This project is licensed under the MIT License - see the <a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/LICENSE\">LICENSE</a> file for details.</p> \n<pre><code>MIT License\n\nCopyright (c) 2025 WiFi DensePose Contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre> \n<h2>🙏 Acknowledgments</h2> \n<ul> \n <li><strong>Research Foundation</strong>: Based on groundbreaking research in WiFi-based human sensing</li> \n <li><strong>Open Source Libraries</strong>: Built on PyTorch, FastAPI, and other excellent open source projects</li> \n <li><strong>Community</strong>: Thanks to all contributors and users who make this project possible</li> \n <li><strong>Hardware Partners</strong>: Special thanks to router manufacturers for CSI support</li> \n</ul> \n<h2>📞 Support</h2> \n<ul> \n <li><strong>Documentation</strong>: \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/user_guide.md\">User Guide</a> - Complete setup and usage guide</li> \n   <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md\">API Reference</a> - Detailed API documentation</li> \n   <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/deployment.md\">Deployment Guide</a> - Production deployment instructions</li> \n   <li><a href=\"https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/troubleshooting.md\">Troubleshooting Guide</a> - Common issues and solutions</li> \n  </ul> </li> \n <li><strong>Issues</strong>: <a href=\"https://github.com/ruvnet/wifi-densepose/issues\">GitHub Issues</a></li> \n <li><strong>Discussions</strong>: <a href=\"https://github.com/ruvnet/wifi-densepose/discussions\">GitHub Discussions</a></li> \n <li><strong>PyPI Package</strong>: <a href=\"https://pypi.org/project/wifi-densepose/\">https://pypi.org/project/wifi-densepose/</a></li> \n <li><strong>Email</strong>: <a href=\"mailto:support@wifi-densepose.com\">support@wifi-densepose.com</a></li> \n <li><strong>Discord</strong>: <a href=\"https://discord.gg/wifi-densepose\">Join our community</a></li> \n</ul> \n<hr /> \n<p><strong>WiFi DensePose</strong> - Revolutionizing human pose estimation through privacy-preserving WiFi technology.</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-20T23:24:54.959587Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 26,
        "timeliness_score": 1,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/hypertextcoffeepot/activity-in-wonderland-distributed-tracing-with-opentelemetry-and-net-2ehe",
        "title": "Activity in Wonderland - Distributed Tracing with OpenTelemetry and .NET",
        "summary": "<p><em>(I am not AI and I too can make mistakes, but I did not write this with AI [only some technical parts]. I do not want to perpetuate the overuse of AI in the arts, or writing or creative world so enjoy some human-generated content)</em></p>\n\n<h2>\n  \n  \n  The Plot - Why We Need Effective Tracing\n</h2>\n\n<p>If you've ever found yourself in a production situation where you \"lost\" a request and had no insight, no tangible logs, no links to what happened, you'll know the pain and suffering of trying to develop without proper logging and tracing. Having lived and worked in multiple styles of logging configurations I now know which types are my favorite, but there's more to it than just picking your preferred sink(s). Given the importance of traceability as a developer, I felt it would be good to dig deeper, learn more and write about distributed tracing with OpenTelemetry and .NET.</p>\n\n<blockquote>\n<p>I'm not a huge fan of explaining what something is in a nutshell when I write about topics, since there's already a plethora of information available at your fingertips. But if you are in need of a refresher here's a link with <a href=\"https://opentelemetry.io/docs/what-is-opentelemetry/\" rel=\"noopener noreferrer\">an overview of what OpenTelemetry is</a> and a link <a href=\"https://learn.microsoft.com/en-us/dotnet/core/diagnostics/distributed-tracing\" rel=\"noopener noreferrer\">explaining the basics of distributed tracing in .NET</a>.</p>\n</blockquote>\n\n<h2>\n  \n  \n  Distributed Systems, Distributed Headaches\n</h2>\n\n<p>One of the added complexities of working with distributed systems is tracing or correlating a request with another request. This could be an HTTP request from your Single Page Application (SPA) front-end that goes through a Web Application Firewall (WAF) which gets proxied to your backend API, which then that API likely makes calls into a database and repeats all of the steps above by making calls to other APIs. All of these events occur on their own, and without a Correlation ID, Trace ID, or some form of identifier there's no way to track a single request all the way through the pipeline. This makes debugging a needle-in-a-haystack form of cruel punishment for anyone trying to find out what happened and often a wasted effort.</p>\n\n<blockquote>\n<p>There's a subtle nuance to some of the terminology used in tracing. A Correlation ID and a Trace ID are essentially the same thing and will likely be used interchangeably. But technically speaking (I won't fault anyone if they do use them to mean the same thing, I do so myself) a Correlation ID is an older term where you did this manually using an identifier such as a GUID and set an <code>X-Correlation-ID</code> header yourself on every request. A Trace ID is the more modern term which is native to the OpenTelemetry specification and by design uses a header name of <code>traceparent</code>.</p>\n</blockquote>\n\n<h2>\n  \n  \n  A Brief History of the Activity Class in .NET\n</h2>\n\n<p>There's a little excerpt from the Microsoft team right on the <a href=\"https://learn.microsoft.com/en-us/dotnet/core/diagnostics/distributed-tracing-concepts\" rel=\"noopener noreferrer\"><strong>.NET distributed tracing concepts</strong></a> page that gives us a hint about why you don't find a direct 1:1 implementation of the OpenTelemetry (OTel) standard as part of the .NET Base Class Libraries:</p>\n\n<blockquote>\n<p>Another common industry name for units of work in a distributed trace are 'Spans'. .NET adopted the term 'Activity' many years ago, before the name 'Span' was well established for this concept.</p>\n</blockquote>\n\n<p>Hat tip to the developers at Microsoft as they naturally ran into the problem of needing some sort of standardization to solve for tracing in such a vast and complex system years before OpenTelemetry was a thing. So, what they came up with was their <a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.activity?view=net-10.0\" rel=\"noopener noreferrer\">System.Diagnostics.Activity</a> class. Interestingly enough had they tried to use the term <code>Span</code> they'd have clashed with <a href=\"https://learn.microsoft.com/en-us/dotnet/standard/memory-and-spans/\" rel=\"noopener noreferrer\">an already existing class called System.Span</a> so instead of trying to sort that out they just left their original implementation of the <code>Activity</code> class and made it work with OTel.</p>\n\n<p>This, at least for me, is where some confusion sets in. I find some of the utility and system classes in .NET difficult to remember simply because they can get so low-level and require a good bit of mental power to keep straight. They are also often named rather vague or ambiguously, which I get why, but this doesn't help with abstract thought turning into applied logic. That's why if something can simply be mirrored 1:1 to a broader standard and shared terminology I prefer that option. So, to help commit this to permanent memory reading a lot about it and really understanding the nuances was my only option.</p>\n\n<h2>\n  \n  \n  How to Use Activity and OpenTelemetry in .NET\n</h2>\n\n<h3>\n  \n  \n  Client and Backend Configured to Use OpenTelemetry Libraries\n</h3>\n\n<blockquote>\n<p>Each time a new request is received by an application, it can be associated with a trace. In application components written in .NET, units of work in a trace are represented by instances of <a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.activity\" rel=\"noopener noreferrer\">System.Diagnostics.Activity</a> and the trace as a whole forms a tree of these Activities, potentially spanning across many distinct processes. The first Activity created for a new request forms the root of the trace tree and it tracks the overall duration and success/failure handling the request. <a href=\"https://learn.microsoft.com/en-us/dotnet/core/diagnostics/distributed-tracing-concepts#traces-and-activities\" rel=\"noopener noreferrer\">- <strong>Traces and Activities, Microsoft Docs</strong></a></p>\n</blockquote>\n\n<p>So, let's do this using a very simple front-end web page that will follow the OpenTelemetry standard, send a request to a .NET backend, capture the Activity tree, create a nested Activity and send back the trace logs to the client. I'll provide links to a repo that I stored all this code in, so all I'll do in the following sections is highlight the main parts that wire up OTel to work properly.</p>\n\n<p>Without getting too into the weeds here I'll just focus on the important bits. Luckily, there's no need to reinvent the wheel when it comes to our client-side implementation of OpenTelemetry as there are libraries available to help out. Some extra Googling or AI use will help you get what you need, but for purposes of this example, which I'm just using VanillaJS and no frameworks, here's how to get started in your client app to configure it for OTel. In this example I'm not even using any libraries, this is just manually configured.</p>\n\n<h3>\n  \n  \n  1) Configure Client Functions to Generate a Trace ID\n</h3>\n\n<p><a href=\"https://github.com/hyper-text-coffee-pot/distributed-tracing-dotnet\" rel=\"noopener noreferrer\">Get the Full Code Sample in My Repo Here</a></p>\n\n<p><em>Note: This is not recommended for large or production-grade apps. I'm just showing this as the fastest way to get started. I'd recommend using npm with webpack or something similar to use this in a production app and relying on proper OpenTelemetry packages in various frameworks. Some Googling will give you the most up-to-date versions for your framework.</em></p>\n\n<h3>\n  \n  \n  Add JavaScript to generate your Trace IDs\n</h3>\n\n<p>Here's a snippet of the code needed to help generate our custom Trace IDs that follow the OpenTelemetry standard formatting:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight javascript\"><code>       <span class=\"c1\">// Generate a random trace ID (128-bit hex)</span>\n        <span class=\"kd\">function</span> <span class=\"nf\">generateTraceId</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">bytes</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nc\">Uint8Array</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">);</span>           <span class=\"c1\">// 16 bytes</span>\n            <span class=\"nx\">crypto</span><span class=\"p\">.</span><span class=\"nf\">getRandomValues</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">);</span>               <span class=\"c1\">// Random values</span>\n            <span class=\"k\">return</span> <span class=\"nb\">Array</span><span class=\"p\">.</span><span class=\"k\">from</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">,</span> <span class=\"nx\">byte</span> <span class=\"o\">=&gt;</span> <span class=\"nx\">byte</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">).</span><span class=\"nf\">padStart</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"dl\">'</span><span class=\"s1\">0</span><span class=\"dl\">'</span><span class=\"p\">)).</span><span class=\"nf\">join</span><span class=\"p\">(</span><span class=\"dl\">''</span><span class=\"p\">);</span>\n            <span class=\"c1\">// Each byte becomes 2 hex chars → 16 bytes × 2 = 32 characters</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">// Generate a random span ID (64-bit hex)</span>\n        <span class=\"kd\">function</span> <span class=\"nf\">generateSpanId</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">bytes</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nc\">Uint8Array</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">);</span>\n            <span class=\"nx\">crypto</span><span class=\"p\">.</span><span class=\"nf\">getRandomValues</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">);</span>\n            <span class=\"k\">return</span> <span class=\"nb\">Array</span><span class=\"p\">.</span><span class=\"k\">from</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">,</span> <span class=\"nx\">byte</span> <span class=\"o\">=&gt;</span> <span class=\"nx\">byte</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">).</span><span class=\"nf\">padStart</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"dl\">'</span><span class=\"s1\">0</span><span class=\"dl\">'</span><span class=\"p\">)).</span><span class=\"nf\">join</span><span class=\"p\">(</span><span class=\"dl\">''</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">// Create W3C traceparent header</span>\n        <span class=\"c1\">// Format: version-traceId-spanId-flags</span>\n        <span class=\"kd\">function</span> <span class=\"nf\">createTraceParent</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">version</span> <span class=\"o\">=</span> <span class=\"dl\">'</span><span class=\"s1\">00</span><span class=\"dl\">'</span><span class=\"p\">;</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">traceId</span> <span class=\"o\">=</span> <span class=\"nf\">generateTraceId</span><span class=\"p\">();</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">spanId</span> <span class=\"o\">=</span> <span class=\"nf\">generateSpanId</span><span class=\"p\">();</span>\n            <span class=\"kd\">const</span> <span class=\"nx\">flags</span> <span class=\"o\">=</span> <span class=\"dl\">'</span><span class=\"s1\">01</span><span class=\"dl\">'</span><span class=\"p\">;</span> <span class=\"c1\">// sampled</span>\n\n            <span class=\"k\">return</span> <span class=\"p\">{</span>\n                <span class=\"na\">header</span><span class=\"p\">:</span> <span class=\"s2\">`</span><span class=\"p\">${</span><span class=\"nx\">version</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">traceId</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">spanId</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">flags</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span>\n                <span class=\"na\">traceId</span><span class=\"p\">:</span> <span class=\"nx\">traceId</span><span class=\"p\">,</span>\n                <span class=\"na\">spanId</span><span class=\"p\">:</span> <span class=\"nx\">spanId</span>\n            <span class=\"p\">};</span>\n        <span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p><strong>The generateTraceId() Function</strong></p>\n\n<p>The <code>generateTraceId()</code> function creates a <strong>32-character hex string</strong>, representing a 128-bit (16 bytes) random ID:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight javascript\"><code><span class=\"kd\">function</span> <span class=\"nf\">generateTraceId</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">bytes</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nc\">Uint8Array</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">);</span>           <span class=\"c1\">// 16 bytes</span>\n    <span class=\"nx\">crypto</span><span class=\"p\">.</span><span class=\"nf\">getRandomValues</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">);</span>               <span class=\"c1\">// Random values</span>\n    <span class=\"k\">return</span> <span class=\"nb\">Array</span><span class=\"p\">.</span><span class=\"k\">from</span><span class=\"p\">(</span><span class=\"nx\">bytes</span><span class=\"p\">,</span> <span class=\"nx\">byte</span> <span class=\"o\">=&gt;</span> <span class=\"nx\">byte</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">).</span><span class=\"nf\">padStart</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"dl\">'</span><span class=\"s1\">0</span><span class=\"dl\">'</span><span class=\"p\">)).</span><span class=\"nf\">join</span><span class=\"p\">(</span><span class=\"dl\">''</span><span class=\"p\">);</span>\n    <span class=\"c1\">// Each byte becomes 2 hex chars → 16 bytes × 2 = 32 characters</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p><strong>The generateTraceParent() Function</strong></p>\n\n<p>The <code>'00'</code> prefix is added <strong>separately</strong> in the <code>createTraceParent()</code> function as the <strong>version</strong> field:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight javascript\"><code><span class=\"kd\">function</span> <span class=\"nf\">createTraceParent</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">version</span> <span class=\"o\">=</span> <span class=\"dl\">'</span><span class=\"s1\">00</span><span class=\"dl\">'</span><span class=\"p\">;</span>                    <span class=\"c1\">// ← W3C version prefix</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">traceId</span> <span class=\"o\">=</span> <span class=\"nf\">generateTraceId</span><span class=\"p\">();</span>       <span class=\"c1\">// ← 32 hex chars</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">spanId</span> <span class=\"o\">=</span> <span class=\"nf\">generateSpanId</span><span class=\"p\">();</span>         <span class=\"c1\">// ← 16 hex chars</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">flags</span> <span class=\"o\">=</span> <span class=\"dl\">'</span><span class=\"s1\">01</span><span class=\"dl\">'</span><span class=\"p\">;</span>                      <span class=\"c1\">// ← sampling flags</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span>\n        <span class=\"na\">header</span><span class=\"p\">:</span> <span class=\"s2\">`</span><span class=\"p\">${</span><span class=\"nx\">version</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">traceId</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">spanId</span><span class=\"p\">}</span><span class=\"s2\">-</span><span class=\"p\">${</span><span class=\"nx\">flags</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span>\n        <span class=\"c1\">// Final format: 00-{32 chars}-{16 chars}-01</span>\n        <span class=\"na\">traceId</span><span class=\"p\">:</span> <span class=\"nx\">traceId</span><span class=\"p\">,</span>\n        <span class=\"na\">spanId</span><span class=\"p\">:</span> <span class=\"nx\">spanId</span>\n    <span class=\"p\">};</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p>So the final structure of the Trace ID when these functions are all put together looks like this when sent to the server using the <code>traceparent</code> header:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01\n│ └────── 32 chars ──────┘ └─ 16 chars ─┘ │\nversion (W3C v1.0)                      span ID       sampled flag\n</code></pre>\n\n</div>\n\n\n\n<p>When you finally make the call from the client to the server you will see this header added to every network request with a Trace ID:</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F8uidmqibpsoi5c4be9fu.png\"><img alt=\"A screenshot of the chrome dev tools Traceparent header being added to each API call\" height=\"593\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F8uidmqibpsoi5c4be9fu.png\" width=\"800\" /></a></p>\n\n<h3>\n  \n  \n  2) Wire up the final call to your .NET API backend\n</h3>\n\n<p>The code to call your backend creates a traceparent ID, uses the fetch API to make the call and adds the <code>traceparent</code> header to the request and then displays the output on the page:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight javascript\"><code><span class=\"k\">async</span> <span class=\"kd\">function</span> <span class=\"nf\">callApi</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">button</span> <span class=\"o\">=</span> <span class=\"nb\">document</span><span class=\"p\">.</span><span class=\"nf\">getElementById</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">callApiBtn</span><span class=\"dl\">'</span><span class=\"p\">);</span>\n    <span class=\"kd\">const</span> <span class=\"nx\">output</span> <span class=\"o\">=</span> <span class=\"nb\">document</span><span class=\"p\">.</span><span class=\"nf\">getElementById</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">outputContent</span><span class=\"dl\">'</span><span class=\"p\">);</span>\n\n    <span class=\"c1\">// Disable button during request</span>\n    <span class=\"nx\">button</span><span class=\"p\">.</span><span class=\"nx\">disabled</span> <span class=\"o\">=</span> <span class=\"kc\">true</span><span class=\"p\">;</span>\n\n    <span class=\"c1\">// Show loading state</span>\n    <span class=\"nx\">output</span><span class=\"p\">.</span><span class=\"nx\">innerHTML</span> <span class=\"o\">=</span> <span class=\"dl\">'</span><span class=\"s1\">&lt;div class=\"loading\"&gt;Sending request to backend...&lt;/div&gt;</span><span class=\"dl\">'</span><span class=\"p\">;</span>\n\n    <span class=\"k\">try</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Generate trace context</span>\n        <span class=\"kd\">const</span> <span class=\"nx\">trace</span> <span class=\"o\">=</span> <span class=\"nf\">createTraceParent</span><span class=\"p\">();</span>\n\n        <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nf\">log</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">Sending request with traceparent:</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"nx\">trace</span><span class=\"p\">.</span><span class=\"nx\">header</span><span class=\"p\">);</span>\n\n        <span class=\"c1\">// Make the fetch request with traceparent header</span>\n        <span class=\"kd\">const</span> <span class=\"nx\">response</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nf\">fetch</span><span class=\"p\">(</span><span class=\"nx\">API_URL</span><span class=\"p\">,</span> <span class=\"p\">{</span>\n            <span class=\"na\">method</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">GET</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n            <span class=\"na\">headers</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n                <span class=\"dl\">'</span><span class=\"s1\">traceparent</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"nx\">trace</span><span class=\"p\">.</span><span class=\"nx\">header</span><span class=\"p\">,</span>\n                <span class=\"dl\">'</span><span class=\"s1\">Content-Type</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">application/json</span><span class=\"dl\">'</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">});</span>\n\n        <span class=\"k\">if </span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">ok</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nc\">Error</span><span class=\"p\">(</span><span class=\"s2\">`HTTP </span><span class=\"p\">${</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">status</span><span class=\"p\">}</span><span class=\"s2\">: </span><span class=\"p\">${</span><span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nx\">statusText</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"kd\">const</span> <span class=\"nx\">data</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">response</span><span class=\"p\">.</span><span class=\"nf\">json</span><span class=\"p\">();</span>\n\n        <span class=\"c1\">// Display the results</span>\n        <span class=\"nf\">displayResults</span><span class=\"p\">(</span><span class=\"nx\">data</span><span class=\"p\">,</span> <span class=\"nx\">trace</span><span class=\"p\">);</span>\n\n    <span class=\"p\">}</span> <span class=\"k\">catch </span><span class=\"p\">(</span><span class=\"nx\">error</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nf\">error</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">Error calling API:</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"nx\">error</span><span class=\"p\">);</span>\n        <span class=\"nx\">output</span><span class=\"p\">.</span><span class=\"nx\">innerHTML</span> <span class=\"o\">=</span> <span class=\"s2\">`\n            &lt;div class=\"error\"&gt;\n                &lt;strong&gt;Error:&lt;/strong&gt; </span><span class=\"p\">${</span><span class=\"nx\">error</span><span class=\"p\">.</span><span class=\"nx\">message</span><span class=\"p\">}</span><span class=\"s2\">\n                &lt;br&gt;&lt;br&gt;\n                Make sure your .NET backend is running on </span><span class=\"p\">${</span><span class=\"nx\">API_URL</span><span class=\"p\">}</span><span class=\"s2\">\n            &lt;/div&gt;\n        `</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span> <span class=\"k\">finally</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Re-enable button</span>\n        <span class=\"nx\">button</span><span class=\"p\">.</span><span class=\"nx\">disabled</span> <span class=\"o\">=</span> <span class=\"kc\">false</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  3) All Client Code Coming Together\n</h3>\n\n<p>The full <a href=\"https://github.com/hyper-text-coffee-pot/distributed-tracing-dotnet\" rel=\"noopener noreferrer\">code for this process will be available in my GitHub repo</a>, for purposes of keeping this readable and somewhat short I'll skip some code here. Please visit my repo to copy out exactly what I used in my example. Here's a look at the final request and response from my client app to my backend:</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fcloudmate-test.s3.us-east-1.amazonaws.com%2Fuploads%2Fcovers%2F5f4820633ba45c3bb00ee80c%2F71d1a837-da83-4446-9406-a331a4b12b2c.png%2520align%3D\"><img alt=\"An image of the response results from my call to my backend api. Purple background with text data about trace ids.\" height=\"400\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fcloudmate-test.s3.us-east-1.amazonaws.com%2Fuploads%2Fcovers%2F5f4820633ba45c3bb00ee80c%2F71d1a837-da83-4446-9406-a331a4b12b2c.png%2520align%3D\" width=\"800\" /></a></p>\n\n<h2>\n  \n  \n  Configuring Our .NET Backend\n</h2>\n\n<p>I know at this point this is getting rather verbose, I'm trying my best to make it make sense and flow. But, honestly this sort of highlights exactly why I felt the need to go deeper in learning about distributed tracing and furthermore why I wanted to write about it. I find writing and explaining solidifies something much more effectively in my mind that simply reading about it. At this point, after several hours of research and typing, I can tell I already have a much better grasp on all the moving parts. So, I'll keep trying to keep this as clear and concise as possible. Stick with me!</p>\n\n<h3>\n  \n  \n  1) Update your Program.cs file in .NET to accept headers\n</h3>\n\n<p>I'm making a few assumptions here, but the requirements for this next part are as simple or as complex as you want them to be. All I did was create a brand new <a href=\"http://ASP.NET\" rel=\"noopener noreferrer\">ASP.NET</a> Web API project in Visual Studio 2022 and made these minors modifications. The first step is to update the <code>Program.cs</code> file so that it accepts our <code>traceparent</code> header:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight csharp\"><code><span class=\"c1\">// Program.cs file - add this</span>\n<span class=\"n\">builder</span><span class=\"p\">.</span><span class=\"n\">Services</span><span class=\"p\">.</span><span class=\"nf\">AddCors</span><span class=\"p\">(</span><span class=\"n\">options</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n    <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"nf\">AddDefaultPolicy</span><span class=\"p\">(</span><span class=\"n\">policy</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n        <span class=\"n\">policy</span><span class=\"p\">.</span><span class=\"nf\">WithOrigins</span><span class=\"p\">(</span><span class=\"s\">\"http://localhost:5500\"</span><span class=\"p\">)</span> <span class=\"c1\">// Or your client port</span>\n              <span class=\"p\">.</span><span class=\"nf\">AllowAnyMethod</span><span class=\"p\">()</span>\n              <span class=\"p\">.</span><span class=\"nf\">WithHeaders</span><span class=\"p\">(</span><span class=\"s\">\"traceparent\"</span><span class=\"p\">)</span> <span class=\"c1\">// Necessary!</span>\n              <span class=\"p\">.</span><span class=\"nf\">WithExposedHeaders</span><span class=\"p\">(</span><span class=\"s\">\"traceparent\"</span><span class=\"p\">);</span>\n    <span class=\"p\">});</span>\n<span class=\"p\">});</span>\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  2) Configure .NET Routing to Capture, Create and Return Activity\n</h3>\n\n<p>Now that all the plumbing is in place we can finally start to work with the incoming Trace, or more specifically the <code>Traceparent</code> header that our client now sends in every request. In our .NET app we'll create a controller endpoint to test this out. Stub in the following code as follows into a new <code>TraceController.cs</code> file:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight csharp\"><code><span class=\"c1\">// TraceController.cs file</span>\n<span class=\"k\">using</span> <span class=\"nn\">Microsoft.AspNetCore.Mvc</span><span class=\"p\">;</span>\n<span class=\"k\">using</span> <span class=\"nn\">System.Diagnostics</span><span class=\"p\">;</span>\n\n<span class=\"k\">namespace</span> <span class=\"nn\">OpenTelemetry.Controllers</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">[</span><span class=\"n\">ApiController</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"nf\">Route</span><span class=\"p\">(</span><span class=\"s\">\"api/[controller]\"</span><span class=\"p\">)]</span>\n    <span class=\"k\">public</span> <span class=\"k\">class</span> <span class=\"nc\">TraceController</span> <span class=\"p\">:</span> <span class=\"n\">ControllerBase</span>\n    <span class=\"p\">{</span>\n        <span class=\"c1\">// ActivitySource for creating custom activities</span>\n        <span class=\"k\">private</span> <span class=\"k\">static</span> <span class=\"k\">readonly</span> <span class=\"n\">ActivitySource</span> <span class=\"n\">ActivitySource</span> <span class=\"p\">=</span> <span class=\"k\">new</span><span class=\"p\">(</span><span class=\"s\">\"OpenTelemetry.Demo\"</span><span class=\"p\">,</span> <span class=\"s\">\"1.0.0\"</span><span class=\"p\">);</span>\n\n        <span class=\"k\">private</span> <span class=\"k\">readonly</span> <span class=\"n\">ILogger</span><span class=\"p\">&lt;</span><span class=\"n\">TraceController</span><span class=\"p\">&gt;</span> <span class=\"n\">_logger</span><span class=\"p\">;</span>\n\n        <span class=\"k\">public</span> <span class=\"nf\">TraceController</span><span class=\"p\">(</span><span class=\"n\">ILogger</span><span class=\"p\">&lt;</span><span class=\"n\">TraceController</span><span class=\"p\">&gt;</span> <span class=\"n\">logger</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">_logger</span> <span class=\"p\">=</span> <span class=\"n\">logger</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">/// &lt;summary&gt;</span>\n        <span class=\"c1\">/// Demonstrates OpenTelemetry distributed tracing with automatic W3C Trace Context propagation</span>\n        <span class=\"c1\">/// &lt;/summary&gt;</span>\n        <span class=\"p\">[</span><span class=\"n\">HttpGet</span><span class=\"p\">]</span>\n        <span class=\"k\">public</span> <span class=\"n\">IActionResult</span> <span class=\"nf\">GetTraceInfo</span><span class=\"p\">()</span>\n        <span class=\"p\">{</span>\n            <span class=\"c1\">// Create a custom activity that will inherit the trace context from the incoming traceparent header</span>\n            <span class=\"k\">using</span> <span class=\"nn\">var</span> <span class=\"n\">activity</span> <span class=\"p\">=</span> <span class=\"n\">ActivitySource</span><span class=\"p\">.</span><span class=\"nf\">StartActivity</span><span class=\"p\">(</span><span class=\"s\">\"ProcessDemoRequest\"</span><span class=\"p\">);</span>\n\n            <span class=\"c1\">// Add some custom tags/attributes to the activity</span>\n            <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetTag</span><span class=\"p\">(</span><span class=\"s\">\"demo.type\"</span><span class=\"p\">,</span> <span class=\"s\">\"blog-example\"</span><span class=\"p\">);</span>\n            <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetTag</span><span class=\"p\">(</span><span class=\"s\">\"demo.purpose\"</span><span class=\"p\">,</span> <span class=\"s\">\"opentelemetry-demonstration\"</span><span class=\"p\">);</span>\n            <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetTag</span><span class=\"p\">(</span><span class=\"s\">\"demo.timestamp\"</span><span class=\"p\">,</span> <span class=\"n\">DateTime</span><span class=\"p\">.</span><span class=\"n\">UtcNow</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">(</span><span class=\"s\">\"o\"</span><span class=\"p\">));</span>\n\n            <span class=\"c1\">// Get the current activity (which has the trace context from the incoming request)</span>\n            <span class=\"kt\">var</span> <span class=\"n\">currentActivity</span> <span class=\"p\">=</span> <span class=\"n\">Activity</span><span class=\"p\">.</span><span class=\"n\">Current</span><span class=\"p\">;</span>\n\n            <span class=\"c1\">// Create a list of log messages to return</span>\n            <span class=\"kt\">var</span> <span class=\"n\">logs</span> <span class=\"p\">=</span> <span class=\"k\">new</span> <span class=\"n\">List</span><span class=\"p\">&lt;</span><span class=\"kt\">string</span><span class=\"p\">&gt;</span>\n            <span class=\"p\">{</span>\n                <span class=\"s\">\"Processing demo request\"</span><span class=\"p\">,</span>\n                <span class=\"s\">\"Custom activity created successfully\"</span><span class=\"p\">,</span>\n                <span class=\"s\">$\"TraceId: </span><span class=\"p\">{</span><span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">}</span><span class=\"s\">\"</span><span class=\"p\">,</span>\n                <span class=\"s\">$\"SpanId: </span><span class=\"p\">{</span><span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">SpanId</span><span class=\"p\">}</span><span class=\"s\">\"</span><span class=\"p\">,</span>\n                <span class=\"s\">$\"Current time: </span><span class=\"p\">{</span><span class=\"n\">DateTime</span><span class=\"p\">.</span><span class=\"n\">UtcNow</span><span class=\"p\">:</span><span class=\"n\">yyyy</span><span class=\"p\">-</span><span class=\"n\">MM</span><span class=\"p\">-</span><span class=\"n\">dd</span> <span class=\"n\">HH</span><span class=\"p\">:</span><span class=\"n\">mm</span><span class=\"p\">:</span><span class=\"n\">ss</span><span class=\"p\">}</span><span class=\"s\"> UTC\"</span>\n            <span class=\"p\">};</span>\n\n            <span class=\"c1\">// Log these messages using structured logging (in production, these would go to your logging provider)</span>\n            <span class=\"n\">_logger</span><span class=\"p\">.</span><span class=\"nf\">LogInformation</span><span class=\"p\">(</span><span class=\"s\">\"Processing demo request with TraceId: {TraceId}\"</span><span class=\"p\">,</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">);</span>\n            <span class=\"n\">_logger</span><span class=\"p\">.</span><span class=\"nf\">LogInformation</span><span class=\"p\">(</span><span class=\"s\">\"Custom activity '{ActivityName}' created\"</span><span class=\"p\">,</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">DisplayName</span><span class=\"p\">);</span>\n\n            <span class=\"c1\">// Additional demonstration: simulate some work</span>\n            <span class=\"n\">Thread</span><span class=\"p\">.</span><span class=\"nf\">Sleep</span><span class=\"p\">(</span><span class=\"m\">10</span><span class=\"p\">);</span> <span class=\"c1\">// Simulate processing time</span>\n            <span class=\"n\">logs</span><span class=\"p\">.</span><span class=\"nf\">Add</span><span class=\"p\">(</span><span class=\"s\">\"Simulated processing completed\"</span><span class=\"p\">);</span>\n\n            <span class=\"c1\">// Build the response object</span>\n            <span class=\"kt\">var</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"k\">new</span> <span class=\"n\">TraceInfoResponse</span>\n            <span class=\"p\">{</span>\n                <span class=\"n\">TraceId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">()</span> <span class=\"p\">??</span> <span class=\"s\">\"N/A\"</span><span class=\"p\">,</span>\n                <span class=\"n\">SpanId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">SpanId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">()</span> <span class=\"p\">??</span> <span class=\"s\">\"N/A\"</span><span class=\"p\">,</span>\n                <span class=\"n\">ParentSpanId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">ParentSpanId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">()</span> <span class=\"p\">??</span> <span class=\"s\">\"N/A\"</span><span class=\"p\">,</span>\n                <span class=\"n\">ActivityName</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">DisplayName</span> <span class=\"p\">??</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">OperationName</span> <span class=\"p\">??</span> <span class=\"s\">\"N/A\"</span><span class=\"p\">,</span>\n                <span class=\"n\">Logs</span> <span class=\"p\">=</span> <span class=\"n\">logs</span><span class=\"p\">,</span>\n                <span class=\"n\">AdditionalData</span> <span class=\"p\">=</span> <span class=\"k\">new</span> <span class=\"n\">Dictionary</span><span class=\"p\">&lt;</span><span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"kt\">object</span><span class=\"p\">&gt;</span>\n                <span class=\"p\">{</span>\n                    <span class=\"p\">{</span> <span class=\"s\">\"timestamp\"</span><span class=\"p\">,</span> <span class=\"n\">DateTime</span><span class=\"p\">.</span><span class=\"n\">UtcNow</span> <span class=\"p\">},</span>\n                    <span class=\"p\">{</span> <span class=\"s\">\"serverTime\"</span><span class=\"p\">,</span> <span class=\"n\">DateTime</span><span class=\"p\">.</span><span class=\"n\">Now</span> <span class=\"p\">},</span>\n                    <span class=\"p\">{</span> <span class=\"s\">\"activityDuration\"</span><span class=\"p\">,</span> <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"n\">Duration</span><span class=\"p\">.</span><span class=\"n\">TotalMilliseconds</span> <span class=\"p\">??</span> <span class=\"m\">0</span> <span class=\"p\">},</span>\n                    <span class=\"p\">{</span> <span class=\"s\">\"customMessage\"</span><span class=\"p\">,</span> <span class=\"s\">\"This demonstrates distributed tracing!\"</span> <span class=\"p\">},</span>\n                    <span class=\"p\">{</span> <span class=\"s\">\"tags\"</span><span class=\"p\">,</span> <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"n\">Tags</span><span class=\"p\">.</span><span class=\"nf\">ToDictionary</span><span class=\"p\">(</span><span class=\"n\">t</span> <span class=\"p\">=&gt;</span> <span class=\"n\">t</span><span class=\"p\">.</span><span class=\"n\">Key</span><span class=\"p\">,</span> <span class=\"n\">t</span> <span class=\"p\">=&gt;</span> <span class=\"n\">t</span><span class=\"p\">.</span><span class=\"n\">Value</span><span class=\"p\">)</span> <span class=\"p\">??</span> <span class=\"k\">new</span> <span class=\"n\">Dictionary</span><span class=\"p\">&lt;</span><span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"kt\">string</span><span class=\"p\">?&gt;()</span> <span class=\"p\">}</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">};</span>\n\n            <span class=\"n\">_logger</span><span class=\"p\">.</span><span class=\"nf\">LogInformation</span><span class=\"p\">(</span><span class=\"s\">\"Returning trace information. TraceId matched: {Matched}\"</span><span class=\"p\">,</span> \n                <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span> <span class=\"p\">!=</span> <span class=\"k\">null</span><span class=\"p\">);</span>\n\n            <span class=\"k\">return</span> <span class=\"nf\">Ok</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">/// &lt;summary&gt;</span>\n    <span class=\"c1\">/// Response model for trace information</span>\n    <span class=\"c1\">/// &lt;/summary&gt;</span>\n    <span class=\"k\">public</span> <span class=\"k\">class</span> <span class=\"nc\">TraceInfoResponse</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">public</span> <span class=\"kt\">string</span> <span class=\"n\">TraceId</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span> <span class=\"p\">=</span> <span class=\"kt\">string</span><span class=\"p\">.</span><span class=\"n\">Empty</span><span class=\"p\">;</span>\n        <span class=\"k\">public</span> <span class=\"kt\">string</span> <span class=\"n\">SpanId</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span> <span class=\"p\">=</span> <span class=\"kt\">string</span><span class=\"p\">.</span><span class=\"n\">Empty</span><span class=\"p\">;</span>\n        <span class=\"k\">public</span> <span class=\"kt\">string</span> <span class=\"n\">ParentSpanId</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span> <span class=\"p\">=</span> <span class=\"kt\">string</span><span class=\"p\">.</span><span class=\"n\">Empty</span><span class=\"p\">;</span>\n        <span class=\"k\">public</span> <span class=\"kt\">string</span> <span class=\"n\">ActivityName</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span> <span class=\"p\">=</span> <span class=\"kt\">string</span><span class=\"p\">.</span><span class=\"n\">Empty</span><span class=\"p\">;</span>\n        <span class=\"k\">public</span> <span class=\"n\">List</span><span class=\"p\">&lt;</span><span class=\"kt\">string</span><span class=\"p\">&gt;</span> <span class=\"n\">Logs</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span> <span class=\"p\">=</span> <span class=\"k\">new</span><span class=\"p\">();</span>\n        <span class=\"k\">public</span> <span class=\"n\">Dictionary</span><span class=\"p\">&lt;</span><span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"kt\">object</span><span class=\"p\">&gt;?</span> <span class=\"n\">AdditionalData</span> <span class=\"p\">{</span> <span class=\"k\">get</span><span class=\"p\">;</span> <span class=\"k\">set</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  The Aha! Moment Behind .NET's Implementation\n</h3>\n\n<p>This, for me, was a fun revelation. If you look at our class, and our <code>Program.cs</code> file you'll notice we never had to import any new libraries to work with our client OpenTelemetry implementation. This is exactly the genius behind why <code>Activity</code> still exists and why the developers at Microsoft chose to do it this way. They already had the necessary plumbing in place, that serendipitously was nearly identical in contract to OTel, but years before it became a thing. So, when in Rome, I suppose!</p>\n\n<p>And because of this we just need to be aware of the way things map between the OTel definitions and the Activity definitions. <strong><em>Full transparency</em></strong>, because I'm not in the mood to spend hours putting this together, I did use Copilot to help generate a cheat sheet for how the two designs map to each other. So, here's a breakdown of how the .NET Activity API maps to the OpenTelemetry spec:</p>\n\n<h3>\n  \n  \n  Core Properties &amp; Methods of How Activity Maps to OTel\n</h3>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<colgroup>\n<col />\n<col />\n<col />\n<col />\n</colgroup>\n<tbody>\n<tr>\n<th colspan=\"1\" rowspan=\"1\"><p>.NET Activity API</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>OpenTelemetry Concept</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>Description</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>Usage Example</p></th>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>Activity.Current</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Current Span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Gets the current activity in the execution context (automatically set by <a href=\"http://ASP.NET\" rel=\"noopener noreferrer nofollow\">ASP.NET</a> Core)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>var traceId = Activity.Current?.TraceId</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>TraceId</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Trace ID</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>128-bit unique identifier for the entire distributed trace</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity.TraceId.ToString()</code> → <code>\"abc123...\"</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>SpanId</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span ID</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>64-bit unique identifier for this specific span/activity</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity.SpanId.ToString()</code> → <code>\"def456...\"</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>ParentSpanId</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Parent Span ID</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span ID of the parent activity (from <code>traceparent</code> header)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity.ParentSpanId.ToString()</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>ActivitySource</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Tracer</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Creates and manages activities/spans for a logical component</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>new ActivitySource(\"MyService\", \"1.0.0\")</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>StartActivity()</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Start Span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Creates a new child activity/span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>source.StartActivity(\"OperationName\")</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>SetTag(key, value)</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Set Attribute</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Adds metadata key-value pairs to the span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.SetTag(\"http.method\", \"GET\")</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>SetStatus()</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Set Status</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Sets the span status (Ok, Error, Unset)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.SetStatus(ActivityStatusCode.Error)</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>ActivityKind</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span Kind</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Type of span: Server, Client, Internal, Producer, Consumer</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>ActivityKind.Server</code> (auto-set for HTTP requests)</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>Duration</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span Duration</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>How long the activity took (auto-calculated)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.Duration.TotalMilliseconds</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>DisplayName</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span Name</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Human-readable name for the operation</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.DisplayName</code> or <code>OperationName</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>AddEvent()</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Add Event</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Adds a timestamped event to the span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.AddEvent(new(\"Cache miss\"))</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>Context</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Span Context</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Propagation context (TraceId, SpanId, TraceFlags)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Used internally for propagation</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>Baggage</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Baggage</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Key-value pairs propagated across service boundaries</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.SetBaggage(\"userId\", \"123\")</code></p></td>\n</tr>\n</tbody>\n</table></div>\n\n<h3>\n  \n  \n  W3C Trace Context Mapping\n</h3>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<colgroup>\n<col />\n<col />\n<col />\n<col />\n</colgroup>\n<tbody>\n<tr>\n<th colspan=\"1\" rowspan=\"1\"><p>Component</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>Format</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>.NET Activity Property</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>Notes</p></th>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>traceparent header</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>00-{traceId}-{spanId}-{flags}</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Auto-extracted by <a href=\"http://ASP.NET\" rel=\"noopener noreferrer nofollow\">ASP.NET</a> Core</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Sets <code>Activity.Current</code></p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p>Version</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>00</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>N/A (handled internally)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>W3C Trace Context v1.0</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p>Trace ID</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>32 hex chars (128-bit)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>Activity.TraceId</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Immutable across entire trace</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p>Span ID</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>16 hex chars (64-bit)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>Activity.SpanId</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Unique to this activity</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p>Trace Flags</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>2 hex chars (8-bit)</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>Activity.ActivityTraceFlags</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>01</code> = sampled</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><strong>tracestate header</strong></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Vendor-specific data</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p><code>Activity.TraceStateString</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Optional, rarely used</p></td>\n</tr>\n</tbody>\n</table></div>\n\n<h3>\n  \n  \n  Essential Methods You Should Know\n</h3>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<colgroup>\n<col />\n<col />\n<col />\n</colgroup>\n<tbody>\n<tr>\n<th colspan=\"1\" rowspan=\"1\"><p>Method</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>Purpose</p></th>\n<th colspan=\"1\" rowspan=\"1\"><p>When to Use</p></th>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><code>ActivitySource.StartActivity(name)</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Create a new span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Tracing a specific operation or method</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.SetTag(key, value)</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Add metadata</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Enriching spans with context (user ID, request params, etc.)</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.SetStatus(status, description)</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Mark success/failure</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Error handling, operation result</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.AddEvent(event)</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Log timestamped event</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Significant moments during span lifecycle</p></td>\n</tr>\n<tr>\n<td colspan=\"1\" rowspan=\"1\"><p><code>activity?.Dispose()</code></p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>End the span</p></td>\n<td colspan=\"1\" rowspan=\"1\"><p>Always use <code>using</code> statement for auto-disposal</p></td>\n</tr>\n</tbody>\n</table></div>\n\n<h3>\n  \n  \n  Common Patterns You'll Use as a .NET Developer with Activity\n</h3>\n\n<p><strong>Pattern 1: Access Current Trace Context</strong></p>\n\n<p>Important things to note are that <code>Activity.Current</code> is a static property that returns the current activity instance for the current execution context. I.e. it's available anywhere during a request lifecycle. Some more fun facts around it are that <code>Activity.Current</code> uses <code>AsyncLocal&lt;T&gt;</code> under the hood, which means that it's <strong>thread-safe</strong> (each thread has its own current activity), it's <strong>async-safe</strong> (flows through async/await automatically) and <strong>request scoped</strong> (each HTTP request has its own activity context. So, what does this all mean? You can access it anywhere in your request like this:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight csharp\"><code><span class=\"c1\">// In your controller</span>\n<span class=\"k\">public</span> <span class=\"n\">IActionResult</span> <span class=\"nf\">MyAction</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">var</span> <span class=\"n\">traceId</span> <span class=\"p\">=</span> <span class=\"n\">Activity</span><span class=\"p\">.</span><span class=\"n\">Current</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">;</span> <span class=\"c1\">// Gets current activity</span>\n\n    <span class=\"nf\">DoSomeWork</span><span class=\"p\">();</span>\n    <span class=\"k\">return</span> <span class=\"nf\">Ok</span><span class=\"p\">();</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// In a service class (same request context)</span>\n<span class=\"k\">public</span> <span class=\"k\">void</span> <span class=\"nf\">DoSomeWork</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">var</span> <span class=\"n\">traceId</span> <span class=\"p\">=</span> <span class=\"n\">Activity</span><span class=\"p\">.</span><span class=\"n\">Current</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">;</span> <span class=\"c1\">// Same trace ID</span>\n\n    <span class=\"k\">await</span> <span class=\"nf\">DoAsync</span><span class=\"p\">();</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// Even after async calls</span>\n<span class=\"k\">public</span> <span class=\"k\">async</span> <span class=\"n\">Task</span> <span class=\"nf\">DoAsync</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">await</span> <span class=\"n\">Task</span><span class=\"p\">.</span><span class=\"nf\">Delay</span><span class=\"p\">(</span><span class=\"m\">100</span><span class=\"p\">);</span>\n    <span class=\"kt\">var</span> <span class=\"n\">traceId</span> <span class=\"p\">=</span> <span class=\"n\">Activity</span><span class=\"p\">.</span><span class=\"n\">Current</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">;</span> <span class=\"c1\">// Still the same trace ID</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// Other ways to get the current activity</span>\n<span class=\"kt\">var</span> <span class=\"n\">currentActivity</span> <span class=\"p\">=</span> <span class=\"n\">Activity</span><span class=\"p\">.</span><span class=\"n\">Current</span><span class=\"p\">;</span>\n<span class=\"kt\">var</span> <span class=\"n\">traceId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">TraceId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">();</span>\n<span class=\"kt\">var</span> <span class=\"n\">spanId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">SpanId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">();</span>\n<span class=\"kt\">var</span> <span class=\"n\">parentSpanId</span> <span class=\"p\">=</span> <span class=\"n\">currentActivity</span><span class=\"p\">?.</span><span class=\"n\">ParentSpanId</span><span class=\"p\">.</span><span class=\"nf\">ToString</span><span class=\"p\">();</span>\n</code></pre>\n\n</div>\n\n\n\n<p><strong>Pattern 2: Create Custom Activity</strong></p>\n\n<p>If you want to create, capture or trace your own custom activity it's as simple as wiring things up like the example below. This can be useful for things like isolating specific tasks, like database calls, API calls or some long running bit of business logic. You could capture diagnostic information about how long something took and view that in a meaningful way in your logs. To create a custom activity, you set it up like the following:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight csharp\"><code><span class=\"k\">private</span> <span class=\"k\">static</span> <span class=\"k\">readonly</span> <span class=\"n\">ActivitySource</span> <span class=\"n\">Source</span> <span class=\"p\">=</span> <span class=\"k\">new</span><span class=\"p\">(</span><span class=\"s\">\"MyService\"</span><span class=\"p\">,</span> <span class=\"s\">\"1.0.0\"</span><span class=\"p\">);</span>\n\n<span class=\"k\">using</span> <span class=\"nn\">var</span> <span class=\"n\">activity</span> <span class=\"p\">=</span> <span class=\"n\">Source</span><span class=\"p\">.</span><span class=\"nf\">StartActivity</span><span class=\"p\">(</span><span class=\"s\">\"ProcessOrder\"</span><span class=\"p\">);</span>\n<span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetTag</span><span class=\"p\">(</span><span class=\"s\">\"order.id\"</span><span class=\"p\">,</span> <span class=\"n\">orderId</span><span class=\"p\">);</span>\n<span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetTag</span><span class=\"p\">(</span><span class=\"s\">\"customer.id\"</span><span class=\"p\">,</span> <span class=\"n\">customerId</span><span class=\"p\">);</span>\n<span class=\"c1\">// Work happens here</span>\n<span class=\"c1\">// Activity automatically ends when disposed</span>\n</code></pre>\n\n</div>\n\n\n\n<p><strong>Pattern 3: Error Handling</strong></p>\n\n<p>And to really round things out here is how you can handle errors when using the Activity class and tracing. This helps to enrich your logs with very human-readable information and to be able to pinpoint exactly where errors are happening with context included. Which when you're pouring over thousands of rows of log data this becomes a powerful tool to have:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight csharp\"><code><span class=\"k\">try</span> \n<span class=\"p\">{</span>\n    <span class=\"c1\">// Work</span>\n    <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetStatus</span><span class=\"p\">(</span><span class=\"n\">ActivityStatusCode</span><span class=\"p\">.</span><span class=\"n\">Ok</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n<span class=\"k\">catch</span> <span class=\"p\">(</span><span class=\"n\">Exception</span> <span class=\"n\">ex</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">SetStatus</span><span class=\"p\">(</span><span class=\"n\">ActivityStatusCode</span><span class=\"p\">.</span><span class=\"n\">Error</span><span class=\"p\">,</span> <span class=\"n\">ex</span><span class=\"p\">.</span><span class=\"n\">Message</span><span class=\"p\">);</span>\n    <span class=\"n\">activity</span><span class=\"p\">?.</span><span class=\"nf\">RecordException</span><span class=\"p\">(</span><span class=\"n\">ex</span><span class=\"p\">);</span> <span class=\"c1\">// .NET 7+</span>\n    <span class=\"k\">throw</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<blockquote>\n<p>(End of AI assisted info generation. I'm trying not to use AI to actually write anything for me, but this one made sense as it's a lot of code-heavy technical samples)</p>\n</blockquote>\n\n<h2>\n  \n  \n  Wrapping Things Up\n</h2>\n\n<p>Honestly, I'd hoped writing this wasn't going to be very involved, but that was a huge oversight on my part. I should have known that a topic so in-depth and also so powerful wouldn't just be a simple summary in the end. But, I learned a lot myself, I now feel like I could certainly configure, use and customize the <strong>.NET Activity</strong> class and use in a lot of ways.</p>\n\n<p>Most of my professional life now is in the land of Azure App Insights, which captures troves of data across hundreds of distributed systems, so the motivation here was really to fully grasp what's going on and how to implement from scratch the modern OpenTelemetry spec, but to also use the native BCL <strong>Activity</strong> components that exist in the .NET framework. Libraries specifically for OTel do exist but being able to tap into tools and features that are already there, reduce yet another dependency, and are just as robust seems like a win-win.</p>\n\n<p>If you found this post helpful, or even if you found it not super helpful, I'd love to hear from you. I also would love to hear how in-depth, or how often other devs find themselves taking a deep dive into this or similar topics to help them debug and maintain their sanity.</p>\n\n<p>Otherwise, thanks for reading, and happy coding!</p>\n\n<p><strong><em>~ Charles</em></strong></p>\n\n<p><em>P.S. if you enjoyed reading this, you'll surely enjoy reading my ramblings about how</em> <a href=\"https://blog.hypertextcoffeepot.com/ai-didnt-kill-software-development-and-heres-why-it-never-will\" rel=\"noopener noreferrer\"><strong><em>AI Didn't Kill Software Development, and Here's Why It Never Will</em></strong></a></p>\n\n\n\n\n<h3>\n  \n  \n  Helpful Links\n</h3>\n\n<ul>\n<li><p><a href=\"https://learn.microsoft.com/en-us/dotnet/core/diagnostics/distributed-tracing\" rel=\"noopener noreferrer\">Distributed tracing - .NET | Microsoft Learn</a></p></li>\n<li><p><a href=\"https://opentelemetry.io/docs/what-is-opentelemetry/\" rel=\"noopener noreferrer\">What is OpenTelemetry? | OpenTelemetry</a></p></li>\n<li><p><a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.activity?view=net-10.0\" rel=\"noopener noreferrer\">Activity Class (System.Diagnostics) | Microsoft Learn</a></p></li>\n<li><p><a href=\"https://github.com/hyper-text-coffee-pot/distributed-tracing-dotnet\" rel=\"noopener noreferrer\">GitHub - hyper-text-coffee-pot/distributed-tracing-dotnet: A repo backing my research and blog about using Activity in .NET and OpenTelemetry standards.</a></p></li>\n</ul>",
        "source": "dev.to",
        "published": "Fri, 20 Feb 2026 22:54:08 +0000",
        "fetched_at": "2026-02-20T23:24:59.177484Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 33,
        "timeliness_score": 2,
        "final_score": 11.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/rabin-shrestha/bimi-logos-in-enterprise-email-end-to-end-mechanics-common-failures-and-fixes-2inf",
        "title": "BIMI Logo in Enterprise Email: End‑to‑End Mechanics, Common Failures, and Fixes",
        "summary": "<h2>\n  \n  \n  Overview\n</h2>\n\n<p>Brand Indicators for Message Identification (<a href=\"https://bimigroup.org/\" rel=\"noopener noreferrer\">BIMI</a>) offers a straightforward solution: a verified brand‑controlled logo displayed alongside authenticated emails. However, successful implementation in enterprise environments relies on the seamless integration of various systems, including email authentication, DNS, HTTPS hosting, strict image standards, certificate validation, and mailbox‑provider policies. When all components function correctly, the logo is visible; if any single element fails, the logo may vanish without notice.</p>\n\n<p>This post delves into the essentials of BIMI, its significance, and the mechanics behind its operation. It highlights common pitfalls in enterprise deployments and provides strategies for diagnosing and resolving these issues. The focus is on real‑world challenges, offering a practical diagnostic and remediation guide, along with a robust framework to ensure the stability of BIMI in production settings.</p>\n\n<h2>\n  \n  \n  What Is BIMI and Why It Matters?\n</h2>\n\n<p><strong>BIMI</strong> is an email standard that displays a brand's verified logo beside messages in a recipient’s inbox. It works by having the brand publish a record in their DNS (Domain Name System) that tells email providers where to find their official logo. This visual cue acts as a trust signal, and it's only possible if the sender has strong <a href=\"https://dmarc.org/\" rel=\"noopener noreferrer\">DMARC</a> email authentication in place, which confirms the email's legitimacy. The benefits are clear: better security, stronger brand recognition, and more people actually opening your emails.</p>\n\n<ul>\n<li>\n<strong>Instant trust at first glance:</strong> A verified logo signals legitimacy before opening, reducing hesitation and doubt.</li>\n<li>\n<strong>Measurable engagement impact:</strong> Clear sender recognition correlates with higher open rates. According to <a href=\"https://abion.com/wp-content/uploads/2021/10/consumer-interaction-with-visual-brands-in-email-002.pdf\" rel=\"noopener noreferrer\"> Red Sift | Entrust - Research</a>, in the US market, open rates increase up to 10% for established brands and up to a 21% increase for previously unknown brands.</li>\n<li>\n<strong>Stronger defense against impersonation:</strong> Attackers cannot display your logo without controlling your domain and passing DMARC, making spoofed emails easier to detect.</li>\n<li>\n<strong>Controlled brand representation:</strong> Ensures your official logo appears consistently instead of generic initials or mailbox‑assigned avatars.</li>\n<li>\n<strong>Visible return on security investment:</strong> BIMI converts backend authentication ( <a href=\"https://www.valimail.com/spf/\" rel=\"noopener noreferrer\">SPF</a>, <a href=\"https://www.valimail.com/dkim/\" rel=\"noopener noreferrer\">DKIM</a>, <a href=\"https://www.valimail.com/dmarc/\" rel=\"noopener noreferrer\">DMARC</a> )  into a customer‑facing trust signal.</li>\n</ul>\n\n<h2>\n  \n  \n  How BIMI Works (End-to-End)\n</h2>\n\n<p>When a mailbox provider receives an email claiming to be from your domain (e.g., <code>brand.example.com</code>), it runs through a strict technical checklist before displaying your brand’s logo. Here is how that process unfolds:</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3dbkaqx8wa2jb0fh4ww4.png\"><img alt=\"BIMI Mechanics - End To End\" height=\"436\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3dbkaqx8wa2jb0fh4ww4.png\" width=\"800\" /></a></p>\n\n<ol>\n<li><p><strong>Authenticate the Email</strong>:  First, the provider checks <strong>SPF</strong> and/or <strong>DKIM</strong> protocols to verify that the email genuinely originated from the domain it claims to represent.</p></li>\n<li><p><strong>Validate DMARC Enforcement</strong>: Next, <strong>DMARC</strong> is evaluated. For a domain to be eligible for BIMI, the email must pass DMARC alignment, and the domain itself must be fully protected by a strict enforcement policy (either <code>p=quarantine</code> or <code>p=reject</code>).</p></li>\n<li><p><strong>Look Up the BIMI Record</strong>: Once DMARC passes, the provider queries the domain's DNS for a BIMI record (typically located at <code>default._bimi.brand.example.com</code>). This record acts as a directory, pointing to the brand’s logo file and referencing an ownership certificate, if one exists.</p></li>\n<li><p><strong>Fetch and Verify the Logo</strong>: The provider retrieves the logo via a secure HTTPS connection. It then validates that the file adheres to strict <strong>SVG Tiny PS</strong> (Portable Secure) standards, ensuring the image is secure and properly formatted for inbox display.</p></li>\n<li><p><strong>Validate the Certificate</strong>: If the brand's BIMI record includes a <strong>Verified Mark Certificate (VMC)</strong> or a <strong>Common Mark Certificate (CMC)</strong>, the provider fetches and cross-checks it. This step legally confirms that the logo officially belongs to the sending brand. Not all providers require this step, but it adds an extra layer of trust and legal verification.</p></li>\n<li><p><strong>Make the Final Display Decision</strong>: Even when all technical checks pass, the mailbox provider decides whether to display the logo. It considers sender reputation, user engagement history, caching rules, and its rollout policies before rendering the logo next to the email.</p></li>\n</ol>\n\n<h2>\n  \n  \n  Why isn’t my BIMI logo showing? Common Failures and Its Fixes\n</h2>\n\n<p>For your brand logo to be displayed in the email inbox, it must satisfy several specific requirements. BIMI is <em>not</em> a standalone feature or simple toggle; rather, it represents the final step in a sequence of dependent processes, each of which must function correctly. Even a minor misconfiguration will prevent BIMI logo, there wont be any clear error message, no alert, bounce, or explicit indication. Your emails will still be delivered, but the brand logo will not be displayed. Additionally, in some instances, despite correct configuration, certain email clients may not show the logo because BIMI is not universally supported across all platforms. In practical terms, troubleshooting BIMI focuses less on the question “Is BIMI supported?” and more on identifying “Which dependency in the chain has failed?”</p>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th><strong>Primary Issue</strong></th>\n<th><strong>Typical Causes</strong></th>\n<th><strong>Common Symptoms</strong></th>\n<th><strong>Fix / key actions</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DMARC policy is not truly enforced</td>\n<td><ul>\n<li>p=none still in place</li>\n<li>pct set below 100</li>\n<li>Policy applied on a subdomain but not the aligned “From” domain</li>\n</ul></td>\n<td><ul>\n<li>Mail delivers normally but no logo appears</li>\n<li>Logo appears inconsistently across streams</li>\n</ul></td>\n<td><ul>\n<li>Set DMARC to <code>p=quarantine</code> or <code>p=reject</code>\n</li>\n<li>For major mailbox providers that support BIMI, ensure <code>pct=100</code>\n</li>\n<li>Enforce DMARC on the exact <code>From</code> domain where email is sent</li>\n</ul></td>\n</tr>\n<tr>\n<td>BIMI DNS record errors (syntax / wrong hostname / caching)</td>\n<td><ul>\n<li>Record published at <code>_bimi.domain.com</code> instead of <code>default._bimi.domain.com</code>\n</li>\n<li>TXT value malformed (missing semicolons, stray quotes/spaces)</li>\n<li>High TTL or resolver caching delays changes</li>\n<li>Wrong domain name used</li>\n<li>DNS changes still cached / high TTL delaying propagation</li>\n</ul></td>\n<td><ul>\n<li>Provider cannot find a valid BIMI record</li>\n<li>Fix appears correct but takes time to show</li>\n<li>BIMI lookup fails or returns invalid data, so the provider can’t reliably associate the logo with the domain.</li>\n</ul></td>\n<td><ul>\n<li>Use the correct BIMI hostname (for example, <code>default._bimi.domain.com</code>)</li>\n<li>Validate BIMI TXT record syntax after publishing</li>\n<li>Use reasonable TTL and allow time for propagation and provider refresh</li>\n<li>Publish TXT at <code>default._bimi.&lt;domain&gt;</code>\n</li>\n<li>Use <code>v=BIMI1; l=&lt;HTTPS-URL-to-SVG&gt;; a=&lt;HTTPS-URL-to-VMC-or-CMC&gt;;</code> inside the TXT record value</li>\n</ul></td>\n</tr>\n<tr>\n<td>VMC/CMC Certificate Issue (Where required )<br />Verified Mark Certificate (VMC)<br />Common Mark Certificate (CMC)</td>\n<td><ul>\n<li>Certificate expired</li>\n<li>Certificate URL unreachable</li>\n<li>Logo changed but certificate not reissued</li>\n<li>Certificate chain/format problemsVMC is expired</li>\n</ul></td>\n<td><ul>\n<li>BIMI works at some providers but not those requiring verified evidence</li>\n<li>Where required ( Client like gmail), the VMC is proof of logo ownership. Without a valid, reachable certificate, the logo is treated as unverified and not shown.</li>\n</ul></td>\n<td><ul>\n<li>Track VMC/CMC expiration dates the same way you track TLS certificates. And Renew the VMC/CMC well before its expiration date</li>\n<li>Reissue the VMC/CMC whenever the logo changes</li>\n<li>Ensure the VMC/CMC hosting URL is publicly reachable and accessible over the internet</li>\n</ul></td>\n</tr>\n<tr>\n<td>SVG is not tiny-ps compliant</td>\n<td><ul>\n<li>Logo image exported as regular SVG instead of SVG Tiny 1.2 Portable/Secure</li>\n<li>Logo includes embedded raster images, scripts, or external references</li>\n<li>Complex effects or has non-solid transparent backgrounds</li>\n<li>Unsupported gradients or filters</li>\n<li>Logo is not centered within the square canvas</li>\n<li>Missing required attributes or &lt;title&gt;</li>\n<li>Unnecessarily large file size (for example, &gt; 32 KB, which may cause issues with some providers)</li>\n</ul></td>\n<td><ul>\n<li>Logo never renders despite correct DNS</li>\n<li>SVG fails validation tools</li>\n</ul></td>\n<td>Open the SVG file in a text editor and manually adjust the following:<ul>\n<li>Change <code>baseProfile=\"tiny\"</code> to <code>baseProfile=\"tiny-ps\"</code> and version=\"1.2\"</li>\n<li>Remove any <code>x=</code> or <code>y=</code> attributes from the <code>&lt;svg&gt;</code> tag. Add a <code>&lt;title&gt;</code> element (max 64 characters)</li>\n<li>Ensure no embedded bitmap images (search for <code>img/</code> or <code>xlink:href=\"data:img/png;base64</code>)</li>\n<li>Remove scripts, external reference, filters, animations, embedded images</li>\n<li>Keep square canvas, centered mark, and small file size</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>DMARC passes ‘sometimes’ (alignment drift)</td>\n<td><ul>\n<li>New vendor sends with your From domain but signs DKIM with a different domain</li>\n<li>SPF breaks due to missing includes, syntax errors, or lookup limits</li>\n<li>Gateways or footers modify the message and break DKIM</li>\n</ul></td>\n<td><ul>\n<li>Logo appears for some mail types but not others</li>\n<li>DMARC aggregate reports show intermittent alignment failures</li>\n</ul></td>\n<td><ul>\n<li>Require aligned DKIM for all sending vendors</li>\n<li>Maintain SPF within limits and validate syntax</li>\n<li>Treat any non-aligned sender stream as a BIMI blocker until fixed</li>\n</ul></td>\n</tr>\n<tr>\n<td>HTTPS hosting / MIME type problems</td>\n<td><ul>\n<li>Expired TLS certificate on logo URL</li>\n<li>Broken or excessive HTTP→HTTPS redirects</li>\n<li>Auth required to fetch file</li>\n<li>CDN serving wrong MIME type (e.g., <code>text/plain</code>)</li>\n</ul></td>\n<td><ul>\n<li>DNS is correct but providers silently fail to retrieve assets</li>\n<li>Mailbox providers that support BIMI automatically fetch the logo when evaluating eligible messages.</li>\n</ul></td>\n<td><ul>\n<li>Host logo on a stable <strong>HTTPS</strong> endpoint</li>\n<li>Keep TLS cert valid and monitored</li>\n<li>Serve SVG as <code>image/svg+xml</code>\n</li>\n<li>Avoid redirects and any access controls on the logo URL</li>\n</ul></td>\n</tr>\n<tr>\n<td>Everything is correct’ but the logo still doesn’t show (provider behavior / expectations)</td>\n<td><ul>\n<li>Client does not support BIMI rendering</li>\n<li>Not all the mailbox providers support BIMI. A primary example is <strong>Microsoft Outlook</strong>, including <a href=\"http://Outlook.com\" rel=\"noopener noreferrer\">Outlook.com</a>, Hotmail, and Microsoft 365/Office 365–backed Outlook.</li>\n<li>Some client who support BIMI (e.g Gmail, Yahoo Mail, Fastmail) can have a different requirements and eligibility gating (reputation, engagement, bulk-mail heuristics)</li>\n<li>Provider caching/refresh cadence</li>\n<li>Many desktop and enterprise email clients do not support BIMI at all</li>\n</ul></td>\n<td><ul>\n<li>Inconsistent display across providers</li>\n<li>Delayed appearance after fixes</li>\n<li>BIMI is <strong>eligibility‑based and not guaranteed</strong>. Even with perfect setup, providers may choose not to display the logo.</li>\n</ul></td>\n<td><ul>\n<li>Confirm whether each target mailbox provider/client in your audience actually supports BIMI Logo</li>\n<li>Recognize that BIMI logo display is controlled by provider policies, domain/IP reputation, caching, and internal decisions, not solely by your configuration</li>\n<li>Maintain strong sending reputation</li>\n<li>Allow for caching delays and keep URLs stable</li>\n</ul></td>\n</tr>\n</tbody>\n</table></div>\n\n<h2>\n  \n  \n  Current BIMI Adoption Snapshot\n</h2>\n\n<p>BIMI adoption remains early but is steadily increasing as more organizations reach DMARC enforcement. Today, adoption is driven primarily by large consumer mailbox providers, with Gmail, Yahoo Mail, Apple/iCloud Mail, and Fastmail supporting BIMI logo display under provider‑specific requirements. Among these, Gmail and Apple enforce stricter verification models, while others allow limited self‑asserted implementations. In contrast, Microsoft Outlook and Exchange Online do not currently render BIMI logos as receiving platforms, representing the most notable gap in major mailbox support.</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F21m0bgz1q7cbqgd7lmvq.png\"><img alt=\"BIMI - Client Adoption description\" height=\"370\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F21m0bgz1q7cbqgd7lmvq.png\" width=\"800\" /></a></p>\n\n<h2>\n  \n  \n  Troubleshooting Runbook (Do This in Order)\n</h2>\n\n<ol>\n<li>Confirm which mailbox providers and clients your recipients use; BIMI display depends on provider/client support.</li>\n<li>Verify DMARC Record:  <a href=\"https://bimigroup.org/bimi-generator/?bimi_domain=example.com&amp;bimi_selector=default\" rel=\"noopener noreferrer\">BIMI Inspector Tool</a>\n</li>\n</ol>\n\n<ul>\n<li>DMARC is at enforcement (<code>p=quarantine</code> or <code>p=reject</code>) and (for major programs) <code>pct=100</code> on the aligned <code>From</code> domain.\n</li>\n<li>\n<p>Verify DMARC passes with alignment for real messages from every sender stream (vendors included).</p>\n\n<ol>\n<li>Verify the BIMI TXT record exists at <code>default._bimi.&lt;your email domain&gt;</code> and is syntactically correct.\n</li>\n<li>Go to Terminal and execute <code>dig</code> command for your domain:\n<code>dig TXT default._bimi.example.com</code>\nYou should expect something as below that follows the following syntax:\n<code>v=BIMI1; l=&lt;HTTPS URL to SVG&gt;; a=&lt;HTTPS URL to VMC/CMC&gt;;</code>\n</li>\n</ol>\n<pre class=\"highlight plaintext\"><code>  default._bimi.example.com. 3600 IN TXT\n  \"v=BIMI1; l=https://example.com/.well-known/bimi/logo.svg; a=https://example.com/.well-known/bimi/vmc.pem;\"\n</code></pre>\n\n</li>\n</ul>\n\n<ol>\n<li>Verify the SVG is tiny‑ps compliant and accessible over HTTPS without redirects/auth; validate content‑type.</li>\n<li>If required by target providers, validate VMC/CMC reachability and expiry.\nWhen issuing a new Verified Mark Certificate (VMC), it is essential to use a BIMI‑compliant SVG Tiny Portable/Secure (SVG Tiny‑PS 1.2) logo. A Verified Mark Certificate (VMC) is an X.509 certificate that cryptographically binds a trademarked logo to the sending domain, ensuring that only the legitimate trademark owner can display that logo in supported mailboxes. (CMC provides a similar binding without the trademark requirement, where supported.)</li>\n<li>Account for caching and provider policy gating; changes may take time to appear. While BIMI DNS records typically propagate within 24–48 hours, mailbox providers cache BIMI data independently, and consistent logo display across major providers can take up to a few days.</li>\n</ol>\n\n<h2>\n  \n  \n  Operational Best Practices for Stable BIMI\n</h2>\n\n<p>To reduce recurring outages and stabilize BIMI, the following actions should be taken:</p>\n\n<ul>\n<li>Assign shared ownership across key teams: Security (DMARC), Email Ops (sending), DNS, Web/CDN (hosting), and Brand/Legal (trademark/certs).</li>\n<li>Continuously monitor DMARC alignment and enforce aligned DKIM for all senders and new vendors.</li>\n<li>Manage the VMC/CMC lifecycle like production certificates, including inventory, expiry alerts, and renewal runbooks.</li>\n<li>Implement change control for SVG/logo updates and revalidate after any rebranding or vendor changes.</li>\n<li>Maintain test inboxes across multiple providers (e.g., Gmail, Yahoo, Apple) to detect regressions and issues early.</li>\n<li>Use stable URLs and simple hosting for BIMI assets, avoiding redirects or anti‑bot controls.</li>\n<li>Treat BIMI as a production service, ensuring continuous monitoring of DMARC alignment and the health of HTTPS and TLS for BIMI assets.</li>\n<li>Track SVG and VMC changes through formal change control processes, something like GitHub.</li>\n</ul>\n\n<h2>\n  \n  \n  Conclusion\n</h2>\n\n<p>BIMI is often perceived as “just a logo,” but in practice it reflects a deeper level of operational maturity in email security and brand trust. Achieving consistent logo visibility requires disciplined execution across authentication, asset management, and mailbox‑provider requirements, rather than a one‑time configuration. Organizations that succeed recognize BIMI as a governed capability with clear ownership and ongoing controls.</p>\n\n<p>When BIMI fails, the root cause is rarely complex; most issues stem from configuration drift across otherwise well‑understood dependencies. Effective troubleshooting follows a structured approach built on systematic validation, repeatable checks, and operational discipline instead of ad‑hoc investigation. By managing DMARC enforcement, DNS records, certificates, and logo formats as controlled components of the email ecosystem, BIMI behavior becomes predictable, recoverable, and reliable.</p>\n\n<h2>\n  \n  \n  References &amp; Common BIMI Tools\n</h2>\n\n<ul>\n<li>\n<p><strong>Official BIMI Resources</strong></p>\n\n<ul>\n<li><a href=\"https://bimigroup.org/\" rel=\"noopener noreferrer\">BIMI Introduction</a></li>\n<li><a href=\"https://bimigroup.org/implementation-guide/\" rel=\"noopener noreferrer\">BIMI Group – Implementation Guide</a></li>\n<li><a href=\"https://bimigroup.org/creating-bimi-svg-logo-files/\" rel=\"noopener noreferrer\">BIMI Group – Creating BIMI SVG Logo Files</a></li>\n</ul>\n\n\n</li>\n\n<li>\n\n<p><strong>Email Authentication (Valimail Resources)</strong></p>\n\n<ul>\n<li><a href=\"https://www.valimail.com/spf/\" rel=\"noopener noreferrer\">SPF Overview</a></li>\n<li><a href=\"https://www.valimail.com/dkim/\" rel=\"noopener noreferrer\">DKIM Overview</a></li>\n<li><a href=\"https://www.valimail.com/what-is-dmarc/\" rel=\"noopener noreferrer\">DMARC Overview</a></li>\n</ul>\n\n\n</li>\n\n<li>\n\n<p><strong>Lookup &amp; Validation Tools</strong></p>\n\n<ul>\n<li><a href=\"https://mxtoolbox.com/SuperTool.aspx\" rel=\"noopener noreferrer\">MxToolbox – BIMI / Domain Lookup Tool</a></li>\n<li><a href=\"https://bimigroup.org/bimi-generator/\" rel=\"noopener noreferrer\">BIMI Group – Validate DMARC Record / BIMI Generator</a></li>\n<li><a href=\"https://easydmarc.com/tools/bimi-lookup\" rel=\"noopener noreferrer\">EasyDMARC – BIMI Lookup (Logo &amp; Certificate Validation)</a></li>\n</ul>\n\n\n</li>\n\n<li>\n\n<p><strong>Research &amp; Industry Insights</strong></p>\n\n<ul>\n<li><a href=\"https://abion.com/wp-content/uploads/2021/10/consumer-interaction-with-visual-brands-in-email-002.pdf\" rel=\"noopener noreferrer\">Red Sift / Entrust – Business Impact of BIMI</a></li>\n</ul>\n\n\n</li>\n\n</ul>",
        "source": "dev.to",
        "published": "Fri, 20 Feb 2026 23:16:54 +0000",
        "fetched_at": "2026-02-20T23:24:59.177445Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 25,
        "timeliness_score": 2,
        "final_score": 8.9,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/hermes_lekkas_ebf9fb25130/beyond-the-prompt-why-every-llm-pipeline-needs-a-reliability-layer-in-2026-1cof",
        "title": "Beyond the Prompt: Why Every LLM Pipeline Needs a Reliability Layer in 2026",
        "summary": "<p>The industry has reached a consensus: scaling models is no longer the primary challenge—<strong>trust is.</strong> As we move from simple chatbots to autonomous agents that manage real-world workflows, the \"hallucination problem\" has graduated from a nuisance to a critical systemic risk.</p>\n\n<p>HalluciGuard is the breakthrough middleware designed to solve this. It is the industry's first open-source reliability layer that enforces truthfulness in real-time, bridging the gap between \"unpredictable AI\" and \"production-ready systems.\"</p>\n\n<p><strong>GitHub Repository:</strong> <a href=\"https://github.com/Hermes-Lekkas/HalluciGuard\" rel=\"noopener noreferrer\">https://github.com/Hermes-Lekkas/HalluciGuard</a></p>\n\n\n\n\n<h2>\n  \n  \n  Deep Integration: Securing Autonomous Agents (OpenClaw)\n</h2>\n\n<p>One of the most significant breakthroughs in HalluciGuard is the native integration with <strong>OpenClaw</strong>, the autonomous agent framework. While chat hallucinations are a nuisance, agentic hallucinations—where an AI autonomously executes commands based on false premises—can be catastrophic.</p>\n\n<p>HalluciGuard provides a dedicated <code>OpenClawInterceptor</code> that hooks into the agent’s execution loop. It doesn’t just monitor final output; it verifies the agent’s internal \"thoughts\" and intended actions against the truth-layer before they are ever committed to your system or messaged to a user. This makes HalluciGuard the essential safety buffer for the next generation of autonomous workflows.</p>\n\n<h2>\n  \n  \n  The Architecture of Trust\n</h2>\n\n<p>HalluciGuard does not rely on a single prompt-engineering strategy. Instead, it employs a modular detection and scoring architecture:</p>\n\n<ol>\n<li> <strong>Factual Claim Extraction:</strong> Leverages lightweight LLMs to atomize complex responses into discrete, verifiable factual claims.</li>\n<li> <strong>Multi-Signal Verification:</strong> Each claim is cross-referenced using several independent signals:\n\n<ul>\n<li>  <strong>LLM Self-Consistency:</strong> Secondary model validation.</li>\n<li>  <strong>Linguistic Heuristics:</strong> Identifying uncertainty language and high-risk patterns.</li>\n<li>  <strong>RAG-Awareness:</strong> Verifying content directly against the provided document context.</li>\n<li>  <strong>Real-time Web Search:</strong> Cross-referencing against live data via search providers like Tavily.</li>\n</ul>\n</li>\n<li> <strong>Risk Flagging:</strong> Returns an overall \"Trust Score\" and categorizes claims by risk level (SAFE, MEDIUM, CRITICAL).</li>\n</ol>\n\n<h2>\n  \n  \n  Key Features for 2026 AI Workflows\n</h2>\n\n<ul>\n<li>  <strong>Provider Agnostic:</strong> Out-of-the-box support for OpenAI (GPT-5.x), Anthropic (Claude 4.x), Google Gemini (google-genai), and local models via Ollama.</li>\n<li>  <strong>Agentic Interception (OpenClaw):</strong> Native hooks for the OpenClaw autonomous agent framework to monitor and verify agent thoughts and actions before they impact systems.</li>\n<li>  <strong>LangChain Integration:</strong> A drop-in <code>CallbackHandler</code> allowing for immediate integration into existing LangChain-based applications.</li>\n<li>  <strong>Cost-Optimization Layer:</strong> Local hashing and caching of verification results to reduce API overhead and latency for frequently checked facts.</li>\n<li>  <strong>Privacy-Focused:</strong> Infrastructure to support local fine-tuned models (GGUF/HF) for air-gapped or high-security deployments.</li>\n</ul>\n\n<h2>\n  \n  \n  Integration Example\n</h2>\n\n<p>Implementation is designed to be minimal and non-disruptive to existing codebases:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight python\"><code><span class=\"kn\">from</span> <span class=\"n\">halluciGuard</span> <span class=\"kn\">import</span> <span class=\"n\">Guard</span>\n<span class=\"kn\">from</span> <span class=\"n\">openai</span> <span class=\"kn\">import</span> <span class=\"n\">OpenAI</span>\n\n<span class=\"c1\"># Initialize the Guard middleware\n</span><span class=\"n\">guard</span> <span class=\"o\">=</span> <span class=\"nc\">Guard</span><span class=\"p\">(</span><span class=\"n\">provider</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">openai</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"n\">api_key</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">your_api_key</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Route chat calls through the Guard\n</span><span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">guard</span><span class=\"p\">.</span><span class=\"nf\">chat</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"sh\">\"</span><span class=\"s\">gpt-5.2-thinking</span><span class=\"sh\">\"</span><span class=\"p\">,</span>\n    <span class=\"n\">messages</span><span class=\"o\">=</span><span class=\"p\">[{</span><span class=\"sh\">\"</span><span class=\"s\">role</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">user</span><span class=\"sh\">\"</span><span class=\"p\">,</span> <span class=\"sh\">\"</span><span class=\"s\">content</span><span class=\"sh\">\"</span><span class=\"p\">:</span> <span class=\"sh\">\"</span><span class=\"s\">What is the status of the 2026 Orbital Treaty?</span><span class=\"sh\">\"</span><span class=\"p\">}],</span>\n    <span class=\"n\">rag_context</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"sh\">\"</span><span class=\"s\">Context document here...</span><span class=\"sh\">\"</span><span class=\"p\">],</span>\n    <span class=\"n\">enable_web_verification</span><span class=\"o\">=</span><span class=\"bp\">True</span>\n<span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"nf\">is_trustworthy</span><span class=\"p\">(</span><span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">):</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Alert: </span><span class=\"si\">{</span><span class=\"nf\">len</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">flagged_claims</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s\"> potential hallucinations detected.</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"sh\">\"</span><span class=\"s\">Trust Score: </span><span class=\"si\">{</span><span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">trust_score</span><span class=\"si\">}</span><span class=\"sh\">\"</span><span class=\"p\">)</span>\n</code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  The Hallucination Leaderboard\n</h2>\n\n<p>As part of our commitment to transparency, we maintain a Public Hallucination Leaderboard. We benchmark major models against a standardized set of factual \"traps\" to provide developers with data-driven insights into which LLMs are most grounded for specific tasks.</p>\n\n<h2>\n  \n  \n  Roadmap and Community\n</h2>\n\n<p>The project is licensed under AGPLv3, ensuring that the community owns the \"Truth Layer\" of the emerging AI stack. Our upcoming v0.9 release will focus on <strong>Lookahead Auto-Correction</strong>, moving from passive detection to real-time stream editing to enforce truthfulness based on provided reference data.</p>\n\n<p>We invite the community to explore the library, contribute to our scoring heuristics, and report edge cases to help build a more reliable AI future.</p>",
        "source": "dev.to",
        "published": "Fri, 20 Feb 2026 22:56:15 +0000",
        "fetched_at": "2026-02-20T23:24:59.177478Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 23,
        "timeliness_score": 2,
        "final_score": 8.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/harvard-edge/cs249r_book",
        "title": "harvard-edge/cs249r_book",
        "summary": "<p>Introduction to Machine Learning Systems</p><hr /><h1>Machine Learning Systems</h1> \n<p><em>Principles and Practices of Engineering Artificially Intelligent Systems</em></p> \n<p align=\"center\"> <a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/README.md\">English</a> • <a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/README/README_zh.md\">中文</a> • <a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/README/README_ja.md\">日本語</a> • <a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/README/README_ko.md\">한국어</a> </p> \n<div align=\"center\"> \n <p align=\"center\"> </p>\n <p><a href=\"https://github.com/harvard-edge/cs249r_book/actions/workflows/book-validate-dev.yml\"><img alt=\"Book\" src=\"https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/book-validate-dev.yml?branch=dev&amp;label=Book&amp;logo=githubactions&amp;cacheSeconds=300\" /></a> <a href=\"https://github.com/harvard-edge/cs249r_book/actions/workflows/tinytorch-validate-dev.yml\"><img alt=\"TinyTorch\" src=\"https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/tinytorch-validate-dev.yml?branch=dev&amp;label=TinyTorch&amp;logo=python&amp;cacheSeconds=300\" /></a> <img alt=\"Updated\" src=\"https://img.shields.io/github/last-commit/harvard-edge/cs249r_book/dev?label=Updated&amp;logo=git&amp;cacheSeconds=300\" /></p> \n <p><a href=\"https://github.com/harvard-edge/cs249r_book/raw/dev/LICENSE.md\"><img alt=\"License\" src=\"https://img.shields.io/badge/License-CC--BY--NC--ND%204.0-blue.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/#-citation--license\"><img alt=\"Cite\" src=\"https://img.shields.io/badge/Cite-IEEE%202024-blue?logo=ieee\" /></a> <a href=\"https://opencollective.com/mlsysbook\"><img alt=\"Fund Us\" src=\"https://img.shields.io/badge/Fund%20Us-Open%20Collective-blue.svg?logo=open-collective\" /></a></p> \n <p></p> \n <p align=\"center\"> \n  <!-- Reader Navigation --> </p>\n <p><strong><a href=\"https://mlsysbook.ai\">📖 Read Online</a></strong> • <strong><a href=\"https://mlsysbook.ai/tinytorch\">Tiny🔥Torch</a></strong> • <strong><a href=\"https://mlsysbook.ai/book/assets/downloads/Machine-Learning-Systems.pdf\">📄 Download PDF</a></strong> • <strong><a href=\"https://mlsysbook.ai/epub\">📓 Download EPUB</a></strong> • <strong><a href=\"https://mlsysbook.org\">🌐 Explore Ecosystem</a></strong></p> \n <p></p> \n <p>📚 <strong>Hardcopy edition coming 2026 with MIT Press.</strong></p> \n</div> \n<hr /> \n<h2>Mission</h2> \n<p><strong>The world is rushing to build AI systems. It is not engineering them.</strong></p> \n<p>That gap is what we mean by AI engineering.</p> \n<p><strong>AI engineering is the discipline of building efficient, reliable, safe, and robust intelligent systems that operate in the real world, not just models in isolation.</strong></p> \n<p><strong>Our mission:</strong> Establish AI engineering as a foundational discipline, alongside software engineering and computer engineering, by teaching how to design, build, and evaluate end to end intelligent systems. The long term impact of AI will be shaped by engineers who can turn ideas into working, dependable systems.</p> \n<hr /> \n<h2>What’s in this repo</h2> \n<p>This repository is the open learning stack for AI systems engineering.</p> \n<p>It includes the textbook source, TinyTorch, hardware kits, and upcoming co-labs that connect principles to runnable code and real devices.</p> \n<hr /> \n<h2>Start Here</h2> \n<p>Choose a path based on your goal.</p> \n<p><strong>READ</strong> Start with the <a href=\"https://mlsysbook.ai\">textbook</a>. Try <a href=\"https://www.mlsysbook.ai/book/contents/core/introduction/introduction.html\">Chapter 1</a> and the <a href=\"https://mlsysbook.ai/book/contents/core/benchmarking/benchmarking.html\">Benchmarking chapter</a>.</p> \n<p><strong>BUILD</strong> Start TinyTorch with the <a href=\"https://mlsysbook.ai/tinytorch/getting-started.html\">getting started guide</a>. Begin with Module 01 and work up from CNNs to transformers and the MLPerf benchmarks.</p> \n<p><strong>DEPLOY</strong> Pick a <a href=\"https://mlsysbook.ai/kits\">hardware kit</a> and run the labs on Arduino, Raspberry Pi, and other edge devices.</p> \n<p><strong>CONNECT</strong> Say hello in <a href=\"https://github.com/harvard-edge/cs249r_book/discussions\">Discussions</a>. We will do our best to reply.</p> \n<hr /> \n<h2>The Learning Stack</h2> \n<p>The learning stack below shows how the textbook connects to hands on work and deployment. Read the textbook, then pick your path:</p> \n<pre><code>┌───────────────────────────────────────────────────────────────────────────────┐\n│                                                                               │\n│                           MACHINE LEARNING SYSTEMS                            │\n│                              Read the Textbook                                │\n│                                                                               │\n│                    Theory • Concepts • Best Practices                         │\n│                                                                               │\n└───────────────────────────────────────┬───────────────────────────────────────┘\n                                        │\n                          ┌─────────────┼─────────────┐\n                          │             │             │\n                          ▼             ▼             ▼\n┌───────────────────────────────────────────────────────────────────────────────┐\n│                            HANDS-ON ACTIVITIES                                │\n│                           (pick one or all)                                   │\n│                                                                               │\n│     ┌─────────────────┐      ┌─────────────────┐      ┌─────────────────┐     │\n│     │                 │      │                 │      │                 │     │\n│     │    SOFTWARE     │      │    TINYTORCH    │      │    HARDWARE     │     │\n│     │    CO-LABS      │      │    FRAMEWORK    │      │      LABS       │     │\n│     │                 │      │                 │      │                 │     │\n│     │ EXPLORE         │      │ BUILD           │      │ DEPLOY          │     │\n│     │                 │      │                 │      │                 │     │\n│     │ Run controlled  │      │ Understand      │      │ Engineer under  │     │\n│     │ experiments on  │      │ frameworks by   │      │ real constraints│     │\n│     │ latency, memory,│      │ implementing    │      │ memory, power,  │     │\n│     │ energy, cost    │      │ them            │      │ timing, safety  │     │\n│     │                 │      │                 │      │                 │     │\n│     │ (coming 2026)   │      │                 │      │ Arduino, Pi     │     │\n│     └─────────────────┘      └─────────────────┘      └─────────────────┘     │\n│                                                                               │\n│           EXPLORE                  BUILD                   DEPLOY             │\n│                                                                               │\n└───────────────────────────────────────┬───────────────────────────────────────┘\n                                        │\n                                        ▼\n┌───────────────────────────────────────────────────────────────────────────────┐\n│                                                                               │\n│                                  AI OLYMPICS                                  │\n│                                 Prove Mastery                                 │\n│                                                                               │\n│       Compete across all tracks • University teams • Public leaderboards      │\n│                                                                               │\n│                                (coming 2026)                                  │\n│                                                                               │\n└───────────────────────────────────────────────────────────────────────────────┘\n</code></pre> \n<table> \n <thead> \n  <tr> \n   <th></th> \n   <th>Component</th> \n   <th>What You Do</th> \n   <th>Link</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>READ</strong></td> \n   <td><a href=\"https://mlsysbook.ai\">📖 Textbook</a></td> \n   <td>Understand ML systems concepts</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/book/README.md\">book/</a></td> \n  </tr> \n  <tr> \n   <td><strong>EXPLORE</strong></td> \n   <td>🔮 Software Co-Labs</td> \n   <td>Run controlled experiments on latency, memory, energy, cost</td> \n   <td><em>Coming 2026</em></td> \n  </tr> \n  <tr> \n   <td><strong>BUILD</strong></td> \n   <td><a href=\"https://mlsysbook.ai/tinytorch\">🔥 TinyTorch</a></td> \n   <td>Understand frameworks by implementing them</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/README.md\">tinytorch/</a></td> \n  </tr> \n  <tr> \n   <td><strong>DEPLOY</strong></td> \n   <td><a href=\"https://mlsysbook.ai/kits\">🔧 Hardware Kits</a></td> \n   <td>Engineer under real constraints: memory, power, timing, safety</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/kits/README.md\">kits/</a></td> \n  </tr> \n  <tr> \n   <td><strong>PROVE</strong></td> \n   <td>🏆 AI Olympics</td> \n   <td>Compete and benchmark across all tracks</td> \n   <td><em>Coming 2026</em></td> \n  </tr> \n </tbody> \n</table> \n<p><strong>What each path teaches:</strong></p> \n<ul> \n <li><strong>EXPLORE</strong> teaches <em>why</em> — Understand tradeoffs. Change batch sizes, precision, model architectures and see how latency, memory, and accuracy shift.</li> \n <li><strong>BUILD</strong> teaches <em>how</em> — Understand internals. Implement autograd, optimizers, and attention from scratch to see how TensorFlow and PyTorch actually work.</li> \n <li><strong>DEPLOY</strong> teaches <em>where</em> — Understand constraints. Face real memory limits, power budgets, and latency requirements on actual hardware.</li> \n</ul> \n<hr /> \n<h2>What You Will Learn</h2> \n<p>This textbook teaches you to think at the intersection of machine learning and systems engineering. Each chapter bridges algorithmic concepts with the infrastructure that makes them work in practice.</p> \n<h3>The ML ↔ Systems Bridge</h3> \n<table> \n <thead> \n  <tr> \n   <th>ML Concept</th> \n   <th>Systems Concept</th> \n   <th>What You Learn</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Model parameters</td> \n   <td>Memory constraints</td> \n   <td>How to fit large models on resource-limited devices</td> \n  </tr> \n  <tr> \n   <td>Inference latency</td> \n   <td>Hardware acceleration</td> \n   <td>How GPUs, TPUs, and accelerators execute neural networks</td> \n  </tr> \n  <tr> \n   <td>Training convergence</td> \n   <td>Compute efficiency</td> \n   <td>How mixed-precision and optimization techniques reduce cost</td> \n  </tr> \n  <tr> \n   <td>Model accuracy</td> \n   <td>Quantization and pruning</td> \n   <td>How to compress models while preserving performance</td> \n  </tr> \n  <tr> \n   <td>Data requirements</td> \n   <td>Pipeline infrastructure</td> \n   <td>How to build efficient data loading and preprocessing</td> \n  </tr> \n  <tr> \n   <td>Model deployment</td> \n   <td>MLOps practices</td> \n   <td>How to monitor, version, and update models in production</td> \n  </tr> \n  <tr> \n   <td>Privacy constraints</td> \n   <td>On-device learning</td> \n   <td>How to train and adapt models without sending data to the cloud</td> \n  </tr> \n </tbody> \n</table> \n<h3>Book Structure</h3> \n<table> \n <thead> \n  <tr> \n   <th>Part</th> \n   <th>Focus</th> \n   <th>Chapters</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>I. Foundations</strong></td> \n   <td>Core concepts</td> \n   <td>Introduction, ML Systems, DL Primer, Architectures</td> \n  </tr> \n  <tr> \n   <td><strong>II. Design</strong></td> \n   <td>Building blocks</td> \n   <td>Workflow, Data Engineering, Frameworks, Training</td> \n  </tr> \n  <tr> \n   <td><strong>III. Performance</strong></td> \n   <td>Making it fast</td> \n   <td>Efficient AI, Optimizations, HW Acceleration, Benchmarking</td> \n  </tr> \n  <tr> \n   <td><strong>IV. Deployment</strong></td> \n   <td>Making it work</td> \n   <td>MLOps, On-device Learning, Privacy, Robustness</td> \n  </tr> \n  <tr> \n   <td><strong>V. Trust</strong></td> \n   <td>Making it right</td> \n   <td>Responsible AI, Sustainable AI, AI for Good</td> \n  </tr> \n  <tr> \n   <td><strong>VI. Frontiers</strong></td> \n   <td>What's next</td> \n   <td>Emerging trends and future directions</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>What Makes This Different</h2> \n<p>This is a living textbook. We keep it updated as the field grows, with community input along the way.</p> \n<p>AI may feel like it is moving at lightning speed, but the engineering building blocks that make it work do not change as quickly as the headlines. This project is built around those stable foundations.</p> \n<p>Think of it like LEGO. New sets arrive all the time, but the bricks themselves stay the same. Once you learn how the bricks fit together, you can build anything. Here, those \"AI bricks\" are the solid systems principles that make AI work.</p> \n<p>Whether you are reading a chapter, running a lab, or sharing feedback, you are helping make these ideas more accessible to the next learner.</p> \n<h3>Research to Teaching Loop</h3> \n<p>We use the same loop for research and teaching: define the system problem, build a reference implementation, benchmark it, then turn it into curriculum and tooling so others can reproduce and extend it.</p> \n<table> \n <thead> \n  <tr> \n   <th>Loop Step</th> \n   <th>Research Artifacts</th> \n   <th>Teaching Artifacts</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Measure</strong></td> \n   <td>Benchmarks, suites, metrics</td> \n   <td>Benchmarking chapter, assignments</td> \n  </tr> \n  <tr> \n   <td><strong>Build</strong></td> \n   <td>Reference systems, compilers, runtimes</td> \n   <td>TinyTorch modules, co-labs</td> \n  </tr> \n  <tr> \n   <td><strong>Deploy</strong></td> \n   <td>Hardware targets, constraints, reliability</td> \n   <td>Hardware labs, kits</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>Support This Work</h2> \n<p>We are working toward <strong>1 million learners by 2030</strong> so that AI engineering becomes a shared, teachable discipline, not a collection of isolated practices. Every star, share, and contribution helps move this effort forward.</p> \n<h3>Why GitHub Stars Matter</h3> \n<div align=\"center\"> \n <p><em>What gets measured gets improved.</em></p> \n <p>Each star is a learner, educator, or supporter who believes AI systems should be engineered with rigor and real world constraints in mind.</p> \n <p><a href=\"https://github.com/harvard-edge/cs249r_book/stargazers\"><img alt=\"Stars\" src=\"https://img.shields.io/github/stars/harvard-edge/cs249r_book?style=for-the-badge&amp;logo=github&amp;color=gold\" /></a></p> \n <p><a href=\"https://star-history.com/#harvard-edge/cs249r_book&amp;Date\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=harvard-edge/cs249r_book&amp;type=Date\" /></a></p> \n <p>1 learner → 10 learners → 100 learners → 1,000 learners → <strong>10,000 learners</strong> → 100,000 learners → <strong>1M learners</strong></p> \n</div> \n<p>Stars are not the goal. They are a signal.</p> \n<p>A visible, growing community makes it easier for universities, foundations, and industry partners to adopt this material, donate hardware, and fund workshops. That momentum lowers the barrier for the next institution, the next classroom, and the next cohort of learners.</p> \n<p>Support raised through this signal flows into <a href=\"https://opencollective.com/mlsysbook\">Open Collective</a> and funds concrete outcomes such as TinyML4D workshops, hardware kits for underserved classrooms, and the infrastructure required to keep this resource free and open.</p> \n<p>One click can unlock the next classroom, the next contributor, and the next generation of AI engineers.</p> \n<h3>Fund the Mission</h3> \n<div align=\"center\"> \n <p>All contributions go to <a href=\"https://opencollective.com/mlsysbook\">Open Collective</a>, a transparent fund that supports educational outreach.</p> \n <p><a href=\"https://opencollective.com/mlsysbook\"><img alt=\"Open Collective\" src=\"https://img.shields.io/badge/%F0%9F%92%9D%20Support%20AI%20Education-Open%20Collective-blue.svg?style=for-the-badge\" /></a></p> \n</div> \n<hr /> \n<h2>Community and Resources</h2> \n<table> \n <thead> \n  <tr> \n   <th>Resource</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><a href=\"https://mlsysbook.ai\">📖 <strong>Textbook</strong></a></td> \n   <td>Interactive online textbook</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://mlsysbook.ai/tinytorch\">🔥 <strong>TinyTorch</strong></a></td> \n   <td>Build ML frameworks from scratch</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://mlsysbook.ai/kits\">🔧 <strong>Hardware Kits</strong></a></td> \n   <td>Deploy to Arduino, Raspberry Pi, edge devices</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://mlsysbook.org\">🌐 <strong>Ecosystem</strong></a></td> \n   <td>Resources, workshops, and community</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://github.com/harvard-edge/cs249r_book/discussions\">💬 <strong>Discussions</strong></a></td> \n   <td>Questions and ideas</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>Contributing</h2> \n<p>We welcome contributions to the book, TinyTorch, and hardware kits!</p> \n<table> \n <thead> \n  <tr> \n   <th>I want to...</th> \n   <th>Go here</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Fix a typo or improve a chapter</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/book/docs/CONTRIBUTING.md\">book/docs/CONTRIBUTING.md</a></td> \n  </tr> \n  <tr> \n   <td>Add a TinyTorch module or fix a bug</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/CONTRIBUTING.md\">tinytorch/CONTRIBUTING.md</a></td> \n  </tr> \n  <tr> \n   <td>Improve hardware labs</td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/kits/README.md\">kits/README.md</a></td> \n  </tr> \n  <tr> \n   <td>Report an issue</td> \n   <td><a href=\"https://github.com/harvard-edge/cs249r_book/issues\">GitHub Issues</a></td> \n  </tr> \n  <tr> \n   <td>Ask a question</td> \n   <td><a href=\"https://github.com/harvard-edge/cs249r_book/discussions\">GitHub Discussions</a></td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>Citation &amp; License</h2> \n<h3>Citation</h3> \n<pre><code class=\"language-bibtex\">@inproceedings{reddi2024mlsysbook,\n  title        = {MLSysBook.AI: Principles and Practices of Machine Learning Systems Engineering},\n  author       = {Reddi, Vijay Janapa},\n  booktitle    = {2024 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},\n  pages        = {41--42},\n  year         = {2024},\n  organization = {IEEE},\n  url          = {https://mlsysbook.org}\n}\n</code></pre> \n<h3>License</h3> \n<p>This project uses a dual-license structure:</p> \n<table> \n <thead> \n  <tr> \n   <th>Component</th> \n   <th>License</th> \n   <th>What It Means</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Book content</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/LICENSE.md\">CC BY-NC-ND 4.0</a></td> \n   <td>Share freely with attribution; no commercial use; no derivatives</td> \n  </tr> \n  <tr> \n   <td><strong>TinyTorch code</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/LICENSE\">Apache 2.0</a></td> \n   <td>Use, modify, and distribute freely; includes patent protection</td> \n  </tr> \n </tbody> \n</table> \n<p>The textbook content (chapters, figures, explanations) is educational material that should circulate with attribution and without commercial exploitation. The software framework is a tool designed to be easy for anyone to use, modify, or integrate into their own projects.</p> \n<hr /> \n<h2>Contributors</h2> \n<p>Thanks goes to these wonderful people who have contributed to making this resource better for everyone!</p> \n<p><strong>Legend:</strong> 🪲 Bug Hunter · 🧑‍💻 Code Contributor · ✍️ Doc Wizard · 🎨 Design Artist · 🧠 Idea Spark · 🔎 Code Reviewer · 🧪 Test Tinkerer · 🛠️ Tool Builder</p> \n<h3>📖 Textbook Contributors</h3> \n<!-- BOOK-CONTRIBUTORS-START --> \n<!-- prettier-ignore-start --> \n<!-- markdownlint-disable --> \n<table> \n <tbody> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/profvjreddi\"><img alt=\"Vijay Janapa Reddi\" src=\"https://avatars.githubusercontent.com/profvjreddi?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Vijay Janapa Reddi</b></sub></a><br />🪲 🧑‍💻 🎨 ✍️ 🧠 🔎 🧪 🛠️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Mjrovai\"><img alt=\"Marcelo Rovai\" src=\"https://avatars.githubusercontent.com/Mjrovai?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Marcelo Rovai</b></sub></a><br />🧑‍💻 🎨 🧪</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/GabrielAmazonas\"><img alt=\"Gabriel Amazonas\" src=\"https://avatars.githubusercontent.com/GabrielAmazonas?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Gabriel Amazonas</b></sub></a><br />🪲 ✍️ 🧠</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/kai4avaya\"><img alt=\"Kai Kleinbard\" src=\"https://avatars.githubusercontent.com/kai4avaya?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Kai Kleinbard</b></sub></a><br />🧑‍💻 🛠️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/didier-durand\"><img alt=\"Didier Durand\" src=\"https://avatars.githubusercontent.com/didier-durand?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Didier Durand</b></sub></a><br />✍️ 🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/hzeljko\"><img alt=\"Zeljko Hrcek\" src=\"https://avatars.githubusercontent.com/hzeljko?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Zeljko Hrcek</b></sub></a><br />🧑‍💻</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jasonjabbour\"><img alt=\"Jason Jabbour\" src=\"https://avatars.githubusercontent.com/jasonjabbour?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jason Jabbour</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/uchendui\"><img alt=\"Ikechukwu Uchendu\" src=\"https://avatars.githubusercontent.com/uchendui?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Ikechukwu Uchendu</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Naeemkh\"><img alt=\"Naeem Khoshnevis\" src=\"https://avatars.githubusercontent.com/Naeemkh?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Naeem Khoshnevis</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Sara-Khosravi\"><img alt=\"Sara Khosravi\" src=\"https://avatars.githubusercontent.com/Sara-Khosravi?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Sara Khosravi</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/V0XNIHILI\"><img alt=\"Douwe den Blanken\" src=\"https://avatars.githubusercontent.com/V0XNIHILI?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Douwe den Blanken</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/18jeffreyma\"><img alt=\"Jeffrey Ma\" src=\"https://avatars.githubusercontent.com/18jeffreyma?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jeffrey Ma</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/shanzehbatool\"><img alt=\"shanzehbatool\" src=\"https://avatars.githubusercontent.com/shanzehbatool?v=4?s=50\" width=\"50px;\" /><br /><sub><b>shanzehbatool</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/eliasab16\"><img alt=\"Elias\" src=\"https://avatars.githubusercontent.com/eliasab16?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Elias</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/JaredP94\"><img alt=\"Jared Ping\" src=\"https://avatars.githubusercontent.com/JaredP94?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jared Ping</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/ishapira1\"><img alt=\"Itai Shapira\" src=\"https://avatars.githubusercontent.com/ishapira1?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Itai Shapira</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Maximilian Lam\" src=\"https://www.gravatar.com/avatar/8863743b4f26c1a20e730fcf7ebc3bc0?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Maximilian Lam</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jaysonzlin\"><img alt=\"Jayson Lin\" src=\"https://avatars.githubusercontent.com/jaysonzlin?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jayson Lin</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/sophiacho1\"><img alt=\"Sophia Cho\" src=\"https://avatars.githubusercontent.com/sophiacho1?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Sophia Cho</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/andreamurillomtz\"><img alt=\"Andrea\" src=\"https://avatars.githubusercontent.com/andreamurillomtz?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Andrea</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/alxrod\"><img alt=\"Alex Rodriguez\" src=\"https://avatars.githubusercontent.com/alxrod?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Alex Rodriguez</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/korneelf1\"><img alt=\"Korneel Van den Berghe\" src=\"https://avatars.githubusercontent.com/korneelf1?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Korneel Van den Berghe</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/foundingnimo\"><img alt=\"Nimo\" src=\"https://avatars.githubusercontent.com/foundingnimo?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Nimo</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/colbybanbury\"><img alt=\"Colby Banbury\" src=\"https://avatars.githubusercontent.com/colbybanbury?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Colby Banbury</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/zishenwan\"><img alt=\"Zishen Wan\" src=\"https://avatars.githubusercontent.com/zishenwan?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Zishen Wan</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/mmaz\"><img alt=\"Mark Mazumder\" src=\"https://avatars.githubusercontent.com/mmaz?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Mark Mazumder</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/ma3mool\"><img alt=\"Abdulrahman Mahmoud\" src=\"https://avatars.githubusercontent.com/ma3mool?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Abdulrahman Mahmoud</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/DivyaAmirtharaj\"><img alt=\"Divya Amirtharaj\" src=\"https://avatars.githubusercontent.com/DivyaAmirtharaj?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Divya Amirtharaj</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/srivatsankrishnan\"><img alt=\"Srivatsan Krishnan\" src=\"https://avatars.githubusercontent.com/srivatsankrishnan?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Srivatsan Krishnan</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/arnaumarin\"><img alt=\"marin-llobet\" src=\"https://avatars.githubusercontent.com/arnaumarin?v=4?s=50\" width=\"50px;\" /><br /><sub><b>marin-llobet</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/aptl26\"><img alt=\"Aghyad Deeb\" src=\"https://avatars.githubusercontent.com/aptl26?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Aghyad Deeb</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/James-QiuHaoran\"><img alt=\"Haoran Qiu\" src=\"https://avatars.githubusercontent.com/James-QiuHaoran?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Haoran Qiu</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Ekhao\"><img alt=\"Emil Njor\" src=\"https://avatars.githubusercontent.com/Ekhao?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Emil Njor</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/ELSuitorHarvard\"><img alt=\"ELSuitorHarvard\" src=\"https://avatars.githubusercontent.com/ELSuitorHarvard?v=4?s=50\" width=\"50px;\" /><br /><sub><b>ELSuitorHarvard</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/kaiM0ves\"><img alt=\"kaiM0ves\" src=\"https://avatars.githubusercontent.com/kaiM0ves?v=4?s=50\" width=\"50px;\" /><br /><sub><b>kaiM0ves</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/oishib\"><img alt=\"oishib\" src=\"https://avatars.githubusercontent.com/oishib?v=4?s=50\" width=\"50px;\" /><br /><sub><b>oishib</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jared-ni\"><img alt=\"Jared Ni\" src=\"https://avatars.githubusercontent.com/jared-ni?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jared Ni</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/AditiR-42\"><img alt=\"Aditi Raju\" src=\"https://avatars.githubusercontent.com/AditiR-42?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Aditi Raju</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/MichaelSchnebly\"><img alt=\"Michael Schnebly\" src=\"https://avatars.githubusercontent.com/MichaelSchnebly?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Michael Schnebly</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/VThuong99\"><img alt=\"Thuong Duong\" src=\"https://avatars.githubusercontent.com/VThuong99?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Thuong Duong</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/leo47007\"><img alt=\"Yu-Shun Hsiao\" src=\"https://avatars.githubusercontent.com/leo47007?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Yu-Shun Hsiao</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/BaeHenryS\"><img alt=\"Henry Bae\" src=\"https://avatars.githubusercontent.com/BaeHenryS?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Henry Bae</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/eimlav\"><img alt=\"Eimhin Laverty\" src=\"https://avatars.githubusercontent.com/eimlav?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Eimhin Laverty</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jaywonchung\"><img alt=\"Jae-Won Chung\" src=\"https://avatars.githubusercontent.com/jaywonchung?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jae-Won Chung</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/ShvetankPrakash\"><img alt=\"Shvetank Prakash\" src=\"https://avatars.githubusercontent.com/ShvetankPrakash?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Shvetank Prakash</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/marcozennaro\"><img alt=\"Marco Zennaro\" src=\"https://avatars.githubusercontent.com/marcozennaro?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Marco Zennaro</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/aryatschand\"><img alt=\"Arya Tschand\" src=\"https://avatars.githubusercontent.com/aryatschand?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Arya Tschand</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/arbass22\"><img alt=\"Andrew Bass\" src=\"https://avatars.githubusercontent.com/arbass22?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Andrew Bass</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/pongtr\"><img alt=\"Pong Trairatvorakul\" src=\"https://avatars.githubusercontent.com/pongtr?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Pong Trairatvorakul</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/euranofshin\"><img alt=\"Eura Nofshin\" src=\"https://avatars.githubusercontent.com/euranofshin?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Eura Nofshin</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Matthew Stewart\" src=\"https://www.gravatar.com/avatar/0c931fcfd03cd548d44c90602dd773ba?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Matthew Stewart</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Emeka Ezike\" src=\"https://www.gravatar.com/avatar/af39c27c6090c50a1921a9b6366e81cc?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Emeka Ezike</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jianqingdu\"><img alt=\"jianqingdu\" src=\"https://avatars.githubusercontent.com/jianqingdu?v=4?s=50\" width=\"50px;\" /><br /><sub><b>jianqingdu</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jzhou1318\"><img alt=\"Jennifer Zhou\" src=\"https://avatars.githubusercontent.com/jzhou1318?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jennifer Zhou</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/vitasam\"><img alt=\"The Random DIY\" src=\"https://avatars.githubusercontent.com/vitasam?v=4?s=50\" width=\"50px;\" /><br /><sub><b>The Random DIY</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Fatima Shah\" src=\"https://www.gravatar.com/avatar/468ef35acc69f3266efd700992daa369?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Fatima Shah</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/BrunoScaglione\"><img alt=\"Bruno Scaglione\" src=\"https://avatars.githubusercontent.com/BrunoScaglione?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Bruno Scaglione</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Allen-Kuang\"><img alt=\"Allen-Kuang\" src=\"https://avatars.githubusercontent.com/Allen-Kuang?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Allen-Kuang</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Tess314\" src=\"https://www.gravatar.com/avatar/4ad8cdf19eb3b666ace97d3eedb19278?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Tess314</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/taunoe\"><img alt=\"Tauno Erik\" src=\"https://avatars.githubusercontent.com/taunoe?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Tauno Erik</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/gnodipac886\"><img alt=\"gnodipac886\" src=\"https://avatars.githubusercontent.com/gnodipac886?v=4?s=50\" width=\"50px;\" /><br /><sub><b>gnodipac886</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/serco425\"><img alt=\"Sercan Aygün\" src=\"https://avatars.githubusercontent.com/serco425?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Sercan Aygün</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/TheHiddenLayer\"><img alt=\"TheHiddenLayer\" src=\"https://avatars.githubusercontent.com/TheHiddenLayer?v=4?s=50\" width=\"50px;\" /><br /><sub><b>TheHiddenLayer</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Gjain234\"><img alt=\"Gauri Jain\" src=\"https://avatars.githubusercontent.com/Gjain234?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Gauri Jain</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/FinAminToastCrunch\"><img alt=\"Fin Amin\" src=\"https://avatars.githubusercontent.com/FinAminToastCrunch?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Fin Amin</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/alex-oesterling\"><img alt=\"Alex Oesterling\" src=\"https://avatars.githubusercontent.com/alex-oesterling?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Alex Oesterling</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/AbenezerKb\"><img alt=\"Abenezer Angamo\" src=\"https://avatars.githubusercontent.com/AbenezerKb?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Abenezer Angamo</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/BravoBaldo\"><img alt=\"Baldassarre Cesarano\" src=\"https://avatars.githubusercontent.com/BravoBaldo?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Baldassarre Cesarano</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Jahnic-kb\"><img alt=\"Jahnic Beck\" src=\"https://avatars.githubusercontent.com/Jahnic-kb?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jahnic Beck</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/aethernavshulkraven-allain\"><img alt=\"अरनव शुक्ला | Arnav Shukla\" src=\"https://avatars.githubusercontent.com/aethernavshulkraven-allain?v=4?s=50\" width=\"50px;\" /><br /><sub><b>अरनव शुक्ला | Arnav Shukla</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/RinZ27\"><img alt=\"Rin\" src=\"https://avatars.githubusercontent.com/RinZ27?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Rin</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/bilgeacun\"><img alt=\"Bilge Acun\" src=\"https://avatars.githubusercontent.com/bilgeacun?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Bilge Acun</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/atcheng2\"><img alt=\"Andy Cheng\" src=\"https://avatars.githubusercontent.com/atcheng2?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Andy Cheng</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/arighosh05\"><img alt=\"Aritra Ghosh\" src=\"https://avatars.githubusercontent.com/arighosh05?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Aritra Ghosh</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/abigailswallow\"><img alt=\"abigailswallow\" src=\"https://avatars.githubusercontent.com/abigailswallow?v=4?s=50\" width=\"50px;\" /><br /><sub><b>abigailswallow</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/YangZhou1997\"><img alt=\"Yang Zhou\" src=\"https://avatars.githubusercontent.com/YangZhou1997?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Yang Zhou</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/XaicuL\"><img alt=\"JEON HYUNJUN(Luciano)\" src=\"https://avatars.githubusercontent.com/XaicuL?v=4?s=50\" width=\"50px;\" /><br /><sub><b>JEON HYUNJUN(Luciano)</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/emmanuel2406\"><img alt=\"Emmanuel Rassou\" src=\"https://avatars.githubusercontent.com/emmanuel2406?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Emmanuel Rassou</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jasonlyik\"><img alt=\"Jason Yik\" src=\"https://avatars.githubusercontent.com/jasonlyik?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jason Yik</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jessicaquaye\"><img alt=\"Jessica Quaye\" src=\"https://avatars.githubusercontent.com/jessicaquaye?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jessica Quaye</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/cursoragent\"><img alt=\"Cursor Agent\" src=\"https://avatars.githubusercontent.com/cursoragent?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Cursor Agent</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/happyappledog\"><img alt=\"happyappledog\" src=\"https://avatars.githubusercontent.com/happyappledog?v=4?s=50\" width=\"50px;\" /><br /><sub><b>happyappledog</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/snuggs\"><img alt=\"Snuggs\" src=\"https://avatars.githubusercontent.com/snuggs?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Snuggs</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/swilcock0\"><img alt=\"Sam Wilcock\" src=\"https://avatars.githubusercontent.com/swilcock0?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Sam Wilcock</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/sjohri20\"><img alt=\"Shreya Johri\" src=\"https://avatars.githubusercontent.com/sjohri20?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Shreya Johri</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/skmur\"><img alt=\"Sonia Murthy\" src=\"https://avatars.githubusercontent.com/skmur?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Sonia Murthy</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Costin-Andrei Oncescu\" src=\"https://www.gravatar.com/avatar/fc4f3460cdfb9365ab59bdeafb06413e?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Costin-Andrei Oncescu</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"formlsysbookissue\" src=\"https://www.gravatar.com/avatar/0d6b8616427d8b19d425c9808692e347?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>formlsysbookissue</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Annie Laurie Cook\" src=\"https://www.gravatar.com/avatar/7cd8d5dfd83071f23979019d97655dc5?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Annie Laurie Cook</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Parampreet Singh\" src=\"https://www.gravatar.com/avatar/5aa037840c0ca11ee42784ed4843c655?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Parampreet Singh</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Vijay Edupuganti\" src=\"https://www.gravatar.com/avatar/b15b6e0e9adf58099905c1a0fd474cb9?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Vijay Edupuganti</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Jothi Ramaswamy\" src=\"https://www.gravatar.com/avatar/f88052cca4f401d9b0f43aed0a53434a?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Jothi Ramaswamy</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Batur Arslan\" src=\"https://www.gravatar.com/avatar/35a8d9ffd03f05e79a2c6ce6206a56f2?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Batur Arslan</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Curren Iyer\" src=\"https://www.gravatar.com/avatar/bd53d146aa888548c8db4da02bf81e7a?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Curren Iyer</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Edward Jin\" src=\"https://www.gravatar.com/avatar/8d8410338458e08bd5e4b96f58e1c217?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Edward Jin</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Tess Watt\" src=\"https://www.gravatar.com/avatar/28c6123d2c9f75578d3ccdedb0df3d11?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Tess Watt</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"bluebaer7\" src=\"https://www.gravatar.com/avatar/ef139181fe00190f21730f6912532e9e?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>bluebaer7</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"yanjingl\" src=\"https://www.gravatar.com/avatar/f5d58ba6aa9b00189d4c018d370e8f43?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>yanjingl</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"a-saraf\" src=\"https://www.gravatar.com/avatar/a5a47df988ab1720dd706062e523ca32?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>a-saraf</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"songhan\" src=\"https://www.gravatar.com/avatar/c2dc311aa8122d5f5f061e1db14682b1?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>songhan</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"jvijay\" src=\"https://www.gravatar.com/avatar/4814aad67982ab07a69006a1ce9d2a72?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>jvijay</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harvard-edge/cs249r_book/graphs/contributors\"><img alt=\"Zishen\" src=\"https://www.gravatar.com/avatar/43b1feff77c8a95fd581774fb8ec891f?d=identicon&amp;s=100?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Zishen</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/BunningsWarehouseOfficial\"><img alt=\"Kristian Radoš\" src=\"https://avatars.githubusercontent.com/u/49220945?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Kristian Radoš</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/minhdang26403\"><img alt=\"Dang Truong\" src=\"https://avatars.githubusercontent.com/u/86156224?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Dang Truong</b></sub></a><br />🧑‍💻</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/pipme\"><img alt=\"pipme\" src=\"https://avatars.githubusercontent.com/pipme?v=4?s=50\" width=\"50px;\" /><br /><sub><b>pipme</b></sub></a><br />✍️</td> \n  </tr> \n </tbody> \n</table> \n<!-- markdownlint-restore --> \n<!-- prettier-ignore-end --> \n<!-- BOOK-CONTRIBUTORS-END --> \n<hr /> \n<h3>🔥 TinyTorch Contributors</h3> \n<!-- TINYTORCH-CONTRIBUTORS-START --> \n<!-- prettier-ignore-start --> \n<!-- markdownlint-disable --> \n<table> \n <tbody> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/profvjreddi\"><img alt=\"Vijay Janapa Reddi\" src=\"https://avatars.githubusercontent.com/profvjreddi?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Vijay Janapa Reddi</b></sub></a><br />🪲 🧑‍💻 🎨 ✍️ 🧠 🔎 🧪 🛠️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/kai4avaya\"><img alt=\"kai\" src=\"https://avatars.githubusercontent.com/kai4avaya?v=4?s=50\" width=\"50px;\" /><br /><sub><b>kai</b></sub></a><br />🪲 🧑‍💻 🎨 ✍️ 🧪</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/minhdang26403\"><img alt=\"Dang Truong\" src=\"https://avatars.githubusercontent.com/minhdang26403?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Dang Truong</b></sub></a><br />🪲 🧑‍💻 ✍️ 🧪</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/didier-durand\"><img alt=\"Didier Durand\" src=\"https://avatars.githubusercontent.com/didier-durand?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Didier Durand</b></sub></a><br />🪲 🧑‍💻 ✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/karthikdani\"><img alt=\"Karthik Dani\" src=\"https://avatars.githubusercontent.com/karthikdani?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Karthik Dani</b></sub></a><br />🪲 🧑‍💻</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/avikde\"><img alt=\"Avik De\" src=\"https://avatars.githubusercontent.com/avikde?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Avik De</b></sub></a><br />🪲 🧪</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Takosaga\"><img alt=\"Takosaga\" src=\"https://avatars.githubusercontent.com/Takosaga?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Takosaga</b></sub></a><br />🪲 ✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/rnjema\"><img alt=\"rnjema\" src=\"https://avatars.githubusercontent.com/rnjema?v=4?s=50\" width=\"50px;\" /><br /><sub><b>rnjema</b></sub></a><br />🧑‍💻 🛠️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/joeswagson\"><img alt=\"joeswagson\" src=\"https://avatars.githubusercontent.com/joeswagson?v=4?s=50\" width=\"50px;\" /><br /><sub><b>joeswagson</b></sub></a><br />🧑‍💻 🛠️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/AndreaMattiaGaravagno\"><img alt=\"AndreaMattiaGaravagno\" src=\"https://avatars.githubusercontent.com/u/22458187?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>AndreaMattiaGaravagno</b></sub></a><br />🧑‍💻 ✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/AmirAlasady\"><img alt=\"Amir Alasady\" src=\"https://avatars.githubusercontent.com/AmirAlasady?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Amir Alasady</b></sub></a><br />🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/jettythek\"><img alt=\"jettythek\" src=\"https://avatars.githubusercontent.com/jettythek?v=4?s=50\" width=\"50px;\" /><br /><sub><b>jettythek</b></sub></a><br />🧑‍💻</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/wz1114841863\"><img alt=\"wzz\" src=\"https://avatars.githubusercontent.com/wz1114841863?v=4?s=50\" width=\"50px;\" /><br /><sub><b>wzz</b></sub></a><br />🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/ngbolin\"><img alt=\"Ng Bo Lin\" src=\"https://avatars.githubusercontent.com/u/9389997?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Ng Bo Lin</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/keo-dara\"><img alt=\"keo-dara\" src=\"https://avatars.githubusercontent.com/u/175544368?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>keo-dara</b></sub></a><br />🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Kobra299\"><img alt=\"Wayne Norman\" src=\"https://avatars.githubusercontent.com/u/4283156?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Wayne Norman</b></sub></a><br />🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/lalalostcode\"><img alt=\"Ilham Rafiqin\" src=\"https://avatars.githubusercontent.com/u/149884766?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Ilham Rafiqin</b></sub></a><br />🪲</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/oscarf189\"><img alt=\"Oscar Flores\" src=\"https://avatars.githubusercontent.com/u/28113740?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Oscar Flores</b></sub></a><br />✍️</td> \n  </tr> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/harishb00a\"><img alt=\"harishb00a\" src=\"https://avatars.githubusercontent.com/harishb00a?v=4?s=50\" width=\"50px;\" /><br /><sub><b>harishb00a</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/sotoblanco\"><img alt=\"Pastor Soto\" src=\"https://avatars.githubusercontent.com/u/46135649?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Pastor Soto</b></sub></a><br />✍️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Pratham-ja\"><img alt=\"Pratham Chaudhary\" src=\"https://avatars.githubusercontent.com/u/114498234?v=4?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Pratham Chaudhary</b></sub></a><br />✍️</td> \n  </tr> \n </tbody> \n</table> \n<!-- markdownlint-restore --> \n<!-- prettier-ignore-end --> \n<!-- TINYTORCH-CONTRIBUTORS-END --> \n<hr /> \n<h3>🛠️ Hardware Kits Contributors</h3> \n<!-- KITS-CONTRIBUTORS-START --> \n<!-- prettier-ignore-start --> \n<!-- markdownlint-disable --> \n<table> \n <tbody> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/profvjreddi\"><img alt=\"Vijay Janapa Reddi\" src=\"https://avatars.githubusercontent.com/profvjreddi?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Vijay Janapa Reddi</b></sub></a><br />🪲 🧑‍💻 🎨 ✍️ 🧪 🛠️</td> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/Mjrovai\"><img alt=\"Marcelo Rovai\" src=\"https://avatars.githubusercontent.com/Mjrovai?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Marcelo Rovai</b></sub></a><br />✍️ 🧑‍💻 🎨 </td> \n  </tr> \n </tbody> \n</table> \n<!-- markdownlint-restore --> \n<!-- prettier-ignore-end --> \n<!-- KITS-CONTRIBUTORS-END --> \n<hr /> \n<h3>🧪 Labs Contributors</h3> \n<!-- LABS-CONTRIBUTORS-START --> \n<!-- prettier-ignore-start --> \n<!-- markdownlint-disable --> \n<table> \n <tbody> \n  <tr> \n   <td align=\"center\" valign=\"top\" width=\"11.11%\"><a href=\"https://github.com/profvjreddi\"><img alt=\"Vijay Janapa Reddi\" src=\"https://avatars.githubusercontent.com/profvjreddi?v=4?s=50\" width=\"50px;\" /><br /><sub><b>Vijay Janapa Reddi</b></sub></a><br />🧑‍💻 🎨 ✍️</td> \n  </tr> \n </tbody> \n</table> \n<!-- markdownlint-restore --> \n<!-- prettier-ignore-end --> \n<!-- LABS-CONTRIBUTORS-END --> \n<hr /> \n<div align=\"center\"> \n <p><strong><a href=\"https://github.com/harvard-edge/cs249r_book#support-this-work\">⭐ Star us on GitHub</a> • <a href=\"https://buttondown.email/mlsysbook\">✉️ Subscribe</a> • <a href=\"https://github.com/harvard-edge/cs249r_book/discussions\">💬 Join discussions</a> • <a href=\"https://mlsysbook.ai\">🌐 Visit mlsysbook.ai</a></strong></p> \n <p><strong>Made with ❤️ for AI engineers</strong><br /> <em>in the making, around the world</em> 🌎</p> \n</div>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-20T23:24:53.746962Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 8.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/open-mercato/open-mercato",
        "title": "open-mercato/open-mercato",
        "summary": "<p>AI‑supportive CRM / ERP foundation framework — built to power R&amp;D, new processes, operations, and growth. It’s modular, extensible, and designed for teams that want strong defaults with room to customize everything. Better than Django, Retool and other alternatives - and Enterprise Grade!</p><hr /><p align=\"center\"> <img alt=\"Open Mercato logo\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/mercato/public/open-mercato.svg?sanitize=true\" width=\"120\" /> </p> \n<h1>Open Mercato</h1> \n<p><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/LICENSE\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-green.svg?sanitize=true\" /></a> <a href=\"https://docs.openmercato.com/\"><img alt=\"Docs\" src=\"https://img.shields.io/badge/docs-openmercato.com-1F7AE0.svg?sanitize=true\" /></a> <a href=\"https://github.com/open-mercato/open-mercato/issues\"><img alt=\"PRs Welcome\" src=\"https://img.shields.io/badge/PRs-welcome-ff69b4.svg?sanitize=true\" /></a> <a href=\"https://nextjs.org/\"><img alt=\"Built with Next.js\" src=\"https://img.shields.io/badge/Built%20with-Next.js-black?logo=next.js\" /></a></p> \n<p>Open Mercato is a new‑era, AI‑supportive platform for shipping enterprise‑grade CRMs, ERPs, and commerce backends. It’s modular, extensible, and designed so teams can mix their own modules, entities, and workflows while keeping the guardrails of a production-ready stack.</p> \n<h2>Start with 80% done.</h2> \n<p><strong>Buy vs. build?</strong> Now, you can have best of both. Use <strong>Open Mercato</strong> enterprise ready business features like CRM, Sales, OMS, Encryption and build the remaining <strong>20%</strong> that really makes the difference for your business.</p> \n<p><a href=\"https://www.youtube.com/watch?v=53jsDjAXXhQ\"><img alt=\"Watch: What “Start with 80% done” means\" src=\"https://img.youtube.com/vi/53jsDjAXXhQ/maxresdefault.jpg\" /></a></p> \n<h2>Core Use Cases</h2> \n<ul> \n <li>💼 <strong>CRM</strong> – model customers, opportunities, and bespoke workflows with infinitely flexible data definitions.</li> \n <li>🏭 <strong>ERP</strong> – manage orders, production, and service delivery while tailoring modules to match your operational reality.</li> \n <li>🛒 <strong>Commerce</strong> – launch CPQ flows, B2B ordering portals, or full commerce backends with reusable modules.</li> \n <li>🤝 <strong>Self-service system</strong> – spin up customer or partner portals with configurable forms, guided flows, and granular permissions.</li> \n <li>🔄 <strong>Workflows</strong> – orchestrate custom data lifecycles and document workflows per tenant or team.</li> \n <li>🧵 <strong>Production</strong> – coordinate production management with modular entities, automation hooks, and reporting.</li> \n <li>🌐 <strong>Headless/API platform</strong> – expose rich, well-typed APIs for mobile and web apps using the same extensible data model.</li> \n</ul> \n<h2>Highlights</h2> \n<ul> \n <li>🧩 <strong>Modular architecture</strong> – drop in your own modules, pages, APIs, and entities with auto-discovery and overlay overrides.</li> \n <li>🧬 <strong>Custom entities &amp; dynamic forms</strong> – declare fields, validators, and UI widgets per module and manage them live from the admin.</li> \n <li>🏢 <strong>Multi-tenant by default</strong> – SaaS-ready tenancy with strict organization/tenant scoping for every entity and API.</li> \n <li>🏛️ <strong>Multi-hierarchical organizations</strong> – built-in organization trees with role- and user-level visibility controls.</li> \n <li>🛡️ <strong>Feature-based RBAC</strong> – combine per-role and per-user feature flags with organization scoping to gate any page or API.</li> \n <li>⚡ <strong>Data indexing &amp; caching</strong> – hybrid JSONB indexing and smart caching for blazing-fast queries across base and custom fields.</li> \n <li>🔔 <strong>Event subscribers &amp; workflows</strong> – publish domain events and process them via persistent subscribers (local or Redis).</li> \n <li>✅ <strong>Growing test coverage</strong> – expanding unit and integration tests ensure modules stay reliable as you extend them.</li> \n <li>🧠 <strong>AI-supportive foundation</strong> – structured for assistive workflows, automation, and conversational interfaces.</li> \n <li>⚙️ <strong>Modern stack</strong> – Next.js App Router, TypeScript, zod, Awilix DI, MikroORM, and bcryptjs out of the box.</li> \n</ul> \n<h2>Screenshots</h2> \n<table> \n <tbody>\n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-shipments.png\"><img alt=\"Order shipments timeline\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-shipments.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-edit-organization.png\"><img alt=\"Editing an organization\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-edit-organization.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-users-management.png\"><img alt=\"Users management view\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-users-management.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Order Shipments</td> \n   <td style=\"text-align: center;\">Organizations</td> \n   <td style=\"text-align: center;\">Users</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-managing-roles.png\"><img alt=\"Managing roles and permissions\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-managing-roles.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-define-custom-fields.png\"><img alt=\"Defining custom fields\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-define-custom-fields.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-custom-entity-records.png\"><img alt=\"Managing custom entity records\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-custom-entity-records.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Roles &amp; ACL</td> \n   <td style=\"text-align: center;\">Custom Fields</td> \n   <td style=\"text-align: center;\">Custom Entity Records</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-people-add-new.png\"><img alt=\"Add new customer form\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-people-add-new.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-deals-listing.png\"><img alt=\"Deals pipeline board\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-deals-listing.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-people-notes.png\"><img alt=\"Customer notes timeline\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-people-notes.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Add New Customer</td> \n   <td style=\"text-align: center;\">Deals Pipeline</td> \n   <td style=\"text-align: center;\">Customer Notes</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-sales-pipeline.png\"><img alt=\"Sales pipeline board view\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-sales-pipeline.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-shipments.png\"><img alt=\"Order shipments timeline\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-shipments.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-totals.png\"><img alt=\"Order totals breakdown\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-orders-order-totals.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Sales Pipeline</td> \n   <td style=\"text-align: center;\">Order Shipments</td> \n   <td style=\"text-align: center;\">Order Totals</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-catalog-products.png\"><img alt=\"Catalog products list\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-catalog-products.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-sales-channels.png\"><img alt=\"Sales channels overview\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-sales-channels.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-all-sales-channels-offers.png\"><img alt=\"Sales channel offers listing\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-all-sales-channels-offers.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Catalog Products</td> \n   <td style=\"text-align: center;\">Sales Channels</td> \n   <td style=\"text-align: center;\">Channel Offers</td> \n  </tr> \n  <tr> \n   <td colspan=\"3\" style=\"text-align: center;\"> <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-homepage.png\"><img alt=\"Home page showing enabled modules\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-homepage.png\" width=\"520\" /></a> </td> \n  </tr> \n  <tr> \n   <td colspan=\"3\" style=\"text-align: center;\">Home overview with enabled modules list</td> \n  </tr> \n </tbody>\n</table> \n<h2>Architecture Overview</h2> \n<ul> \n <li>🧩 Modules: Each feature lives under <code>src/modules/&lt;module&gt;</code> with auto‑discovered frontend/backend pages, APIs, CLI, i18n, and DB entities.</li> \n <li>🗃️ Database: MikroORM with per‑module entities and migrations; no global schema. Migrations are generated and applied per module.</li> \n <li>🧰 Dependency Injection: Awilix container constructed per request. Modules can register and override services/components via <code>di.ts</code>.</li> \n <li>🏢 Multi‑tenant: Core <code>directory</code> module defines <code>tenants</code> and <code>organizations</code>. Most entities carry <code>tenant_id</code> + <code>organization_id</code>.</li> \n <li>🔐 Security: RBAC roles, zod validation, bcryptjs hashing, JWT sessions, role‑based access in routes and APIs.</li> \n</ul> \n<p>Read more on the <a href=\"https://docs.openmercato.com/architecture/system-overview\">Open Mercato Architecture</a></p> \n<h2>AI Assistant</h2> \n<p>Open Mercato includes a built-in AI Assistant that can discover and interact with your data model and APIs. The assistant uses MCP (Model Context Protocol) to expose tools for schema discovery and API execution.</p> \n<table> \n <tbody>\n  <tr> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-chat.png\"><img alt=\"AI Assistant chat interface\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-chat.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-settings.png\"><img alt=\"AI Assistant settings\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-settings.png\" width=\"260\" /></a></td> \n   <td><a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-mcp.png\"><img alt=\"AI Assistant MCP tools\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-ai-assistant-mcp.png\" width=\"260\" /></a></td> \n  </tr> \n  <tr> \n   <td style=\"text-align: center;\">Chat Interface</td> \n   <td style=\"text-align: center;\">Settings</td> \n   <td style=\"text-align: center;\">MCP Tools</td> \n  </tr> \n </tbody>\n</table> \n<p><strong>Key capabilities:</strong></p> \n<ul> \n <li>🔍 <strong>Schema Discovery</strong> – Query database entity schemas including fields, types, and relationships</li> \n <li>🔗 <strong>API Discovery</strong> – Search for API endpoints using natural language queries</li> \n <li>⚡ <strong>API Execution</strong> – Execute API calls with automatic tenant context and authentication</li> \n <li>🧠 <strong>Hybrid Search</strong> – Uses Meilisearch for fast fulltext + vector search across schemas and endpoints</li> \n</ul> \n<p><strong>MCP Tools:</strong></p> \n<table> \n <thead> \n  <tr> \n   <th>Tool</th> \n   <th>Purpose</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>discover_schema</code></td> \n   <td>Search entity schemas by name or keyword</td> \n  </tr> \n  <tr> \n   <td><code>find_api</code></td> \n   <td>Find API endpoints by natural language query</td> \n  </tr> \n  <tr> \n   <td><code>call_api</code></td> \n   <td>Execute API calls with tenant context</td> \n  </tr> \n  <tr> \n   <td><code>context_whoami</code></td> \n   <td>Get current authentication context</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Integration modes:</strong></p> \n<ul> \n <li><strong>Development</strong> (<code>yarn mcp:dev</code>) – For Claude Code and local development with API key auth</li> \n <li><strong>Production</strong> (<code>yarn mcp:serve</code>) – For web AI chat with session tokens</li> \n</ul> \n<p>See the <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/.ai/specs/SPEC-012-2026-01-27-ai-assistant-schema-discovery.md\">AI Assistant specification</a> for detailed documentation on entity extraction, OpenAPI integration, and search indexing.</p> \n<h2>Data Encryption</h2> \n<p>Open Mercato ships with tenant-scoped, field-level data encryption so PII and sensitive business data stay protected while you keep the flexibility of custom entities and fields. Encryption maps live in the admin UI/database, letting you pick which system and custom columns are encrypted; MikroORM hooks automatically encrypt on write and decrypt on read while keeping deterministic hashes (e.g., <code>email_hash</code>) for lookups.</p> \n<p>Architecture in two lines: Vault/KMS (or a derived-key fallback) issues per-tenant DEKs and caches them so performance stays snappy; AES-GCM wrappers sit in the ORM lifecycle, storing ciphertext at rest while CRUD and APIs keep working with plaintext. Read the docs to dive deeper: <a href=\"https://docs.openmercato.com/user-guide/encryption\">docs.openmercato.com/user-guide/encryption</a>.</p> \n<h2>Migration Guide</h2> \n<p>We have migrated Open Mercato to a monorepo structure. If you're upgrading from a previous version, please note the following changes:</p> \n<h3>File Structure</h3> \n<p>The codebase is now organized into:</p> \n<ul> \n <li><code>packages/</code> - Shared libraries and modules (<code>@open-mercato/core</code>, <code>@open-mercato/ui</code>, <code>@open-mercato/shared</code>, <code>@open-mercato/cli</code>, <code>@open-mercato/cache</code>, <code>@open-mercato/events</code>, <code>@open-mercato/queue</code>, <code>@open-mercato/content</code>, <code>@open-mercato/onboarding</code>, <code>@open-mercato/search</code>)</li> \n <li><code>apps/</code> - Applications (main app in <code>apps/mercato</code>, docs in <code>apps/docs</code>)</li> \n</ul> \n<p><strong>Important note on storage:</strong> The storage folder has been moved to the <code>apps/mercato</code> folder as well. If you instance has got any attachments uploaded, please make sure you run:</p> \n<pre><code class=\"language-bash\">mv storage apps/mercato/storage\n</code></pre> \n<p>... from the root Open Mercato folder.</p> \n<h3>Import Aliases</h3> \n<p>Import aliases have changed from path-based to package-based imports:</p> \n<ul> \n <li><strong>Before:</strong> <code>@/lib/...</code>, <code>@/components/...</code>, <code>@/modules/...</code></li> \n <li><strong>After:</strong> <code>@open-mercato/shared/lib/...</code>, <code>@open-mercato/ui/components/...</code>, <code>@open-mercato/core/modules/...</code>, etc.</li> \n</ul> \n<h3>Environment Variables</h3> \n<p>The <code>.env</code> file now must live in <code>apps/mercato</code> instead of the project root. The fastest way to start is to copy the example file:</p> \n<pre><code class=\"language-bash\">cp apps/mercato/.env.example apps/mercato/.env\n</code></pre> \n<p>At minimum, set <code>DATABASE_URL</code>, <code>JWT_SECRET</code>, and <code>REDIS_URL</code> (or <code>EVENTS_REDIS_URL</code>) before bootstrapping.</p> \n<h3>Package Manager</h3> \n<p>Yarn 4 is now required. Ensure you have Yarn 4+ installed before proceeding.</p> \n<h2>Getting Started</h2> \n<p>This is a quickest way to get Open Mercato up and running on your localhost / server - ready for testing / demoing or for <code>Core development</code>!</p> \n<p><a href=\"https://youtu.be/-ba8Bmc56EQ\"><img alt=\"Watch on YouTube\" src=\"https://img.youtube.com/vi/-ba8Bmc56EQ/maxresdefault.jpg\" /></a></p> \n<h3>Installation update</h3> \n<p><strong>Node.js 24.x is required</strong></p> \n<pre><code class=\"language-bash\"># macOS (Homebrew)\nbrew install node@24\n\n# Windows (Chocolatey)\nchoco install nodejs --version=24.x\n\n# Or use nvm (any platform)\nnvm install 24\nnvm use 24\n</code></pre> \n<p><strong>Windows:</strong> Use <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/#docker-setup\">Docker Setup</a> for native setup.</p> \n<h3>Quick Start (Monorepo)</h3> \n<p><strong>Prerequisites:</strong> Yarn 4+</p> \n<pre><code class=\"language-bash\">git clone https://github.com/open-mercato/open-mercato.git\ncd open-mercato\ngit checkout develop\nyarn install\n\ncp apps/mercato/.env.example apps/mercato/.env # EDIT this file to set up your specific files\n#At minimum, set `DATABASE_URL`, `JWT_SECRET`, and `REDIS_URL` (or `EVENTS_REDIS_URL`) before bootstrapping.\n\nyarn generate\nyarn initialize # or yarn reinstall\nyarn dev\n</code></pre> \n<p>For a fresh greenfield boot (build packages, generate registries, reinstall modules, then start dev), run:</p> \n<pre><code class=\"language-bash\">yarn dev:greenfield\n</code></pre> \n<p>Navigate to <code>http://localhost:3000/backend</code> and sign in with the default credentials printed by <code>yarn initialize</code>.</p> \n<p>Full installation guide (including prerequisites, Docker setup, and cloud deployment): <a href=\"https://docs.openmercato.com/installation/setup\">docs.openmercato.com/installation/setup</a></p> \n<h2>Docker Setup</h2> \n<p>Open Mercato offers two Docker Compose configurations — one for <strong>development</strong> (with hot reload) and one for <strong>production</strong>. Both run the full stack (app + PostgreSQL + Redis + Meilisearch) in containers. The dev mode is the <strong>recommended setup for Windows</strong> users.</p> \n<h3>Dev mode (hot reload)</h3> \n<p>Run the entire stack with source code mounted from the host. File changes trigger automatic rebuilds — no local Node.js or Yarn required.</p> \n<pre><code class=\"language-bash\">git clone https://github.com/open-mercato/open-mercato.git\ncd open-mercato\ngit checkout develop\ndocker compose -f docker-compose.fullapp.dev.yml up --build\n</code></pre> \n<p><strong>Windows users:</strong> Ensure WSL 2 backend is enabled in Docker Desktop and clone with <code>git config --global core.autocrlf input</code> to avoid line-ending issues.</p> \n<h3>Production mode</h3> \n<pre><code class=\"language-bash\">docker compose -f docker-compose.fullapp.yml up --build\n</code></pre> \n<p><strong>Common operations:</strong></p> \n<ul> \n <li>Start: <code>docker compose -f docker-compose.fullapp.yml up -d</code></li> \n <li>Logs: <code>docker compose -f docker-compose.fullapp.yml logs -f app</code></li> \n <li>Stop: <code>docker compose -f docker-compose.fullapp.yml down</code></li> \n <li>Rebuild: <code>docker compose -f docker-compose.fullapp.yml up --build</code></li> \n</ul> \n<p>Navigate to <code>http://localhost:3000/backend</code> and sign in with the default credentials (<a href=\"mailto:admin@example.com\">admin@example.com</a>).</p> \n<h3>Docker Environment Variables</h3> \n<p>Before starting, you may want to configure the following environment variables. Create a <code>.env</code> file in the project root or export them in your shell:</p> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Required</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>JWT_SECRET</code></td> \n   <td>For production</td> \n   <td><code>JWT</code></td> \n   <td>Secret key for JWT token signing. <strong>Use a strong, unique value in production.</strong></td> \n  </tr> \n  <tr> \n   <td><code>POSTGRES_PASSWORD</code></td> \n   <td>For production</td> \n   <td><code>postgres</code></td> \n   <td>PostgreSQL database password. <strong>Use a strong password in production.</strong></td> \n  </tr> \n  <tr> \n   <td><code>POSTGRES_USER</code></td> \n   <td>No</td> \n   <td><code>postgres</code></td> \n   <td>PostgreSQL database user</td> \n  </tr> \n  <tr> \n   <td><code>POSTGRES_DB</code></td> \n   <td>No</td> \n   <td><code>open-mercato</code></td> \n   <td>PostgreSQL database name</td> \n  </tr> \n  <tr> \n   <td><code>POSTGRES_PORT</code></td> \n   <td>No</td> \n   <td><code>5432</code></td> \n   <td>PostgreSQL exposed port</td> \n  </tr> \n  <tr> \n   <td><code>REDIS_PORT</code></td> \n   <td>No</td> \n   <td><code>6379</code></td> \n   <td>Redis exposed port</td> \n  </tr> \n  <tr> \n   <td><code>MEILISEARCH_MASTER_KEY</code></td> \n   <td>For production</td> \n   <td><code>meilisearch-dev-key</code></td> \n   <td>Meilisearch API key. <strong>Use a strong key in production.</strong></td> \n  </tr> \n  <tr> \n   <td><code>MEILISEARCH_PORT</code></td> \n   <td>No</td> \n   <td><code>7700</code></td> \n   <td>Meilisearch exposed port</td> \n  </tr> \n  <tr> \n   <td><code>OPENAI_API_KEY</code></td> \n   <td>No</td> \n   <td>-</td> \n   <td>OpenAI API key (enables AI features)</td> \n  </tr> \n  <tr> \n   <td><code>ANTHROPIC_API_KEY</code></td> \n   <td>No</td> \n   <td>-</td> \n   <td>Anthropic API key (for opencode service)</td> \n  </tr> \n  <tr> \n   <td><code>OPENCODE_PORT</code></td> \n   <td>No</td> \n   <td><code>4096</code></td> \n   <td>Opencode service exposed port</td> \n  </tr> \n </tbody> \n</table> \n<p>Example <code>.env</code> file for production:</p> \n<pre><code class=\"language-bash\">JWT_SECRET=your-strong-secret-key-here\nPOSTGRES_PASSWORD=your-strong-db-password\nMEILISEARCH_MASTER_KEY=your-strong-meilisearch-key\nOPENAI_API_KEY=sk-...  # Optional, for AI features\n</code></pre> \n<h3>VPS Deployment</h3> \n<p><a href=\"https://www.youtube.com/watch?v=xau17YBP9ek\"><img alt=\"Watch: Deploy Open Mercato on a VPS\" src=\"https://img.youtube.com/vi/xau17YBP9ek/maxresdefault.jpg\" /></a></p> \n<p>For production deployments, ensure strong <code>JWT_SECRET</code>, secure database credentials, and consider managed database services. See the <a href=\"https://docs.openmercato.com/installation/setup#docker-deployment-full-stack\">full Docker deployment guide</a> for detailed configuration and production tips.</p> \n<h2>Standalone App &amp; Customization</h2> \n<p>The <strong>recommended way to build on Open Mercato</strong> without modifying the core is to create a standalone app. This gives you a self-contained project that pulls Open Mercato packages from npm — your own modules, overrides, and customizations live in your repo while core stays untouched and upgradeable.</p> \n<h3>Create a standalone app</h3> \n<pre><code class=\"language-bash\">npx create-mercato-app my-store\ncd my-store\ncp .env.example .env   # configure DATABASE_URL, JWT_SECRET, REDIS_URL\ndocker compose up -d   # start PostgreSQL, Redis, Meilisearch\nyarn install\nyarn initialize\nyarn dev\n</code></pre> \n<p>Navigate to <code>http://localhost:3000/backend</code> and sign in with the credentials printed by <code>yarn initialize</code>.</p> \n<h3>Add custom modules</h3> \n<p>Drop your own modules into <code>src/modules/</code> and register them in <code>src/modules.ts</code> with <code>from: '@app'</code>:</p> \n<pre><code class=\"language-ts\">export const enabledModules: ModuleEntry[] = [\n  // ... core modules\n  { id: 'inventory', from: '@app' },\n]\n</code></pre> \n<p>Run <code>yarn generate</code> and <code>yarn dev</code> — your module's pages, APIs, and entities are auto-discovered.</p> \n<h3>Eject core modules for deep customization</h3> \n<p>When you need to change the internals of a core module (entities, business logic, UI), <strong>eject</strong> it. The <code>mercato eject</code> command copies the module source into your <code>src/modules/</code> directory and switches it to local, so you can modify it freely while all other modules keep receiving package updates.</p> \n<pre><code class=\"language-bash\"># See which modules support ejection\nyarn mercato eject --list\n\n# Eject a module (e.g., currencies)\nyarn mercato eject currencies\nyarn mercato generate all\nyarn dev\n</code></pre> \n<p>Currently ejectable: <code>catalog</code>, <code>currencies</code>, <code>customers</code>, <code>perspectives</code>, <code>planner</code>, <code>resources</code>, <code>sales</code>, <code>staff</code>, <code>workflows</code>.</p> \n<p>Full guide: <a href=\"https://docs.openmercato.com/customization/standalone-app\">docs.openmercato.com/customization/standalone-app</a> · CLI reference: <a href=\"https://docs.openmercato.com/cli/eject\">docs.openmercato.com/cli/eject</a></p> \n<h2>Live demo</h2> \n<p><a href=\"https://demo.openmercato.com\"><img alt=\"Explore the Open Mercato live demo\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/docs/static/screenshots/open-mercato-onboarding-showoff.png\" /></a></p> \n<h2>Documentation</h2> \n<p>Browse the full documentation at <a href=\"https://docs.openmercato.com/\">docs.openmercato.com</a>.</p> \n<ul> \n <li><a href=\"https://docs.openmercato.com/introduction/overview\">Introduction</a></li> \n <li><a href=\"https://docs.openmercato.com/installation/setup\">Installation</a></li> \n <li><a href=\"https://docs.openmercato.com/user-guide/overview\">User Guide</a></li> \n <li><a href=\"https://docs.openmercato.com/tutorials/first-app\">Tutorials</a></li> \n <li><a href=\"https://docs.openmercato.com/customization/build-first-app\">Customization</a></li> \n <li><a href=\"https://docs.openmercato.com/architecture/system-overview\">Architecture</a></li> \n <li><a href=\"https://docs.openmercato.com/framework/modules/overview\">Framework</a></li> \n <li><a href=\"https://docs.openmercato.com/api/overview\">API Reference</a></li> \n <li><a href=\"https://docs.openmercato.com/cli/overview\">CLI Reference</a></li> \n <li><a href=\"https://docs.openmercato.com/appendix/troubleshooting\">Appendix</a></li> \n</ul> \n<h2>Spec Driven Development</h2> \n<p>Open Mercato follows a <strong>spec-first development approach</strong>. Before implementing new features or making significant changes, we document the design in the <code>.ai/specs/</code> folder.</p> \n<h3>Why Specs?</h3> \n<ul> \n <li><strong>Clarity</strong>: Specs ensure everyone understands the feature before coding starts</li> \n <li><strong>Consistency</strong>: Design decisions are documented and can be referenced by humans and AI agents</li> \n <li><strong>Traceability</strong>: Each spec maintains a changelog tracking the evolution of the feature</li> \n</ul> \n<h3>How It Works</h3> \n<ol> \n <li><strong>Before coding</strong>: Check if a spec exists in <code>.ai/specs/</code> (named <code>SPEC-###-YYYY-MM-DD-title.md</code>)</li> \n <li><strong>New features</strong>: Create or update the spec with your design before implementation</li> \n <li><strong>After changes</strong>: Update the spec's changelog with a dated summary</li> \n</ol> \n<p><strong>Naming convention</strong>: Specs use the format <code>SPEC-{number}-{date}-{title}.md</code> (e.g., <code>SPEC-007-2026-01-26-sidebar-reorganization.md</code>)</p> \n<p>See <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/.ai/specs/README.md\"><code>.ai/specs/README.md</code></a> for the full specification directory and <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/.ai/specs/AGENTS.md\"><code>.ai/specs/AGENTS.md</code></a> for detailed guidelines on maintaining specs.</p> \n<h2>Join us on Discord</h2> \n<p>Connect with the team and other builders in our Discord community: <a href=\"https://discord.gg/f4qwPtJ3qA\">https://discord.gg/f4qwPtJ3qA</a>.</p> \n<h2>Contributing</h2> \n<p>We welcome contributions of all sizes—from fixes and docs updates to new modules. Start by reading <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for branching conventions (<code>main</code>, <code>develop</code>, <code>feat/&lt;feature&gt;</code>), release flow, and the full PR checklist. Then check the open issues or propose an idea in a discussion, and:</p> \n<ol> \n <li>Fork the repository and create a branch that reflects your change.</li> \n <li>Install dependencies with <code>yarn install</code> and bootstrap via <code>yarn mercato init</code> (add <code>--no-examples</code> to skip demo CRM content; <code>--stresstest</code> for thousands of synthetic contacts, companies, deals, and timeline interactions; or <code>--stresstest --lite</code> for high-volume contacts without the heavier extras).</li> \n <li>Develop and validate your changes (<code>yarn lint</code>, <code>yarn test</code>, or the relevant module scripts).</li> \n <li>Open a pull request referencing any related issues and outlining the testing you performed.</li> \n</ol> \n<p>Refer to <a href=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/AGENTS.md\">AGENTS.md</a> for deeper guidance on architecture and conventions when extending modules.</p> \n<p>Open Mercato is proudly supported by <a href=\"https://catchthetornado.com/\">Catch The Tornado</a>.</p> \n<div align=\"center\"> \n <a href=\"https://catchthetornado.com/\"> <img alt=\"Catch The Tornado logo\" src=\"https://raw.githubusercontent.com/open-mercato/open-mercato/main/apps/mercato//public/catch-the-tornado-logo.png\" width=\"96\" /> </a> \n</div> \n<h2>CLI Commands</h2> \n<p>Open Mercato let the module developers to expose the custom CLI commands for variouse maintenance tasks. Read more on the <a href=\"https://docs.openmercato.com/cli/overview\">CLI documentation</a></p> \n<h2>License</h2> \n<ul> \n <li>MIT — see <code>LICENSE</code> for details.</li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-20T23:24:53.746979Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/ziizium/security-news-weekly-round-up-20th-february-2026-2kmg",
        "title": "Security news weekly round-up - 20th February 2026",
        "summary": "<p>Cybersecurity education is a must for everyone. Take a few minutes of your time, and go through what I have for you in this week's security review. You'll learn a thing or two, and in the process, you become more aware of the threats that are out there.</p>\n\n\n\n\n<h2>\n  \n  \n  <a href=\"https://www.welivesecurity.com/en/kids-online/children-selfies-online/\" rel=\"noopener noreferrer\">Is it OK to let your children post selfies online?</a>\n</h2>\n\n<p>No. And before you scold your children about this, check yourself. Still, you might think: what's there? I can tell you that there is a lot. The least? Misuse of the image, and with the popularity of AI, the image can be transformed into something that you never thought of before. If you're on X, you know what I am talking about.</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>As soon as a selfie is posted onto a social media site, your child loses a certain amount of control over it. Even if they delete it, your child may find that the image has been reposted and shared by their friends and followers.</p>\n\n<p>There’s also a growing body of evidence to suggest that social media use, including the posting of selfies, could result in psychological harm. A 2017 study of eighth to 12th graders found a 33% increase in depressive symptoms between 2010-2015.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://thehackernews.com/2026/02/microsoft-finds-summarize-with-ai.html\" rel=\"noopener noreferrer\">Microsoft Finds “Summarize with AI” Prompts Manipulating Chatbot Recommendations</a>\n</h2>\n\n<p>Everyone with access to AI, wants the best from it even if they have to manipulate it as this article shows. If Microsoft brings this to the public, it's a message to whoever is involved: we are watching you and we know what you are doing </p>\n\n<p>Here is what's going on:</p>\n\n<blockquote>\n<p>The new AI hijacking technique has been codenamed AI Recommendation Poisoning by the Microsoft Defender Security Research Team. The tech giant described it as a case of an AI memory poisoning attack that's used to induce bias and deceive the AI system to generate responses that artificially boost visibility and skew recommendations.</p>\n\n<p>The attack is made possible via specially crafted URLs for various AI chatbots that pre-populate the prompt with instructions to manipulate the assistant's memory once clicked. These URLs, as observed in other AI-focused attacks like Reprompt, leverage the query string (\"?q=\") parameter to inject memory manipulation prompts and serve biased recommendations.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/\" rel=\"noopener noreferrer\">Password managers’ promise that they can’t see your vaults isn’t always true</a>\n</h2>\n\n<p>A really long read. However, the message is clear: when it comes to password managers, they are not hack-proof as they are advertised.</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>Another avenue for attackers or adversaries with control of a server is to target the backward compatibility that all three password managers provide to support older, less-secure versions. Despite incremental changes designed to harden the apps against the very attacks described in the paper, all three password managers continue to support the versions without these improvements.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://www.securityweek.com/new-keenadu-android-malware-found-on-thousands-of-devices/\" rel=\"noopener noreferrer\">New Keenadu Android Malware Found on Thousands of Devices</a>\n</h2>\n\n<p>While reading the title of the article, you should ask one question: What type of malicious activity does Keenadu perform when it infects a device? The answer: Ad Fraud.</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>The malware gives its operators full control of the infected device, but it seems to be mainly used for ad fraud. Kaspersky researchers have seen Keenadu payloads designed to hijack browser search engines, monetize new app installs, and click on ads.</p>\n\n<p>In many cases the malware was preinstalled on devices, but the security firm has also seen it being distributed through various application stores (including Google Play and Xiaomi GetApps) disguised as smart camera apps.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://thehackernews.com/2026/02/critical-flaws-found-in-four-vs-code.html\" rel=\"noopener noreferrer\">Critical Flaws Found in Four VS Code Extensions with Over 125 Million Installs</a>\n</h2>\n\n<p>At the time of writing, only Microsoft Live Preview has received a patch in September 2025. The rest? They remain unpatched.</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>Poorly written extensions, overly permissive extensions, or malicious ones can execute code, modify files, and allow attackers to take over a machine and exfiltrate information.</p>\n\n<p>Keeping vulnerable extensions installed on a machine is an immediate threat to an organization's security posture: it may take only one click, or a downloaded repository, to compromise everything.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://techcrunch.com/2026/02/19/fbi-says-atm-jackpotting-attacks-are-on-the-rise-and-netting-hackers-millions-in-stolen-cash/\" rel=\"noopener noreferrer\">FBI says ATM ‘jackpotting’ attacks are on the rise, and netting hackers millions in stolen cash</a>\n</h2>\n\n<p>Work legally for your money and don't steal! That's it, I said it. Meanwhile, there is a bit of good news here. The hackers found a way to drain the ATMs without affecting the user account.</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>According to a new security bulletin issued by the FBI, hackers have rapidly ramped up their attacks in recent years, with more than 700 attacks on cash dispensers during 2025 alone, netting hackers at least $20 million in stolen cash.</p>\n\n<p>Per the bulletin, the FBI says hackers are using a mix of physical access to ATM machines, such as generic keys for unlocking front panels and accessing hard drives, and digital tools, like planting malware that can force ATMs to rapidly dispense cash in a flash.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <a href=\"https://www.securityweek.com/promptspy-android-malware-abuses-gemini-ai-at-runtime-for-persistence/\" rel=\"noopener noreferrer\">PromptSpy Android Malware Abuses Gemini AI at Runtime for Persistence</a>\n</h2>\n\n<p>Original research from the team at ESET called <a href=\"https://www.welivesecurity.com/en/eset-research/promptspy-ushers-in-era-android-threats-using-genai/\" rel=\"noopener noreferrer\">PromptSpy</a>. This is another news that threat actors are using Generative AI for malicious purposes, and who knows what they are cooking or what they have already that's not yet discovered by security researchers?</p>\n\n<p>From the article:</p>\n\n<blockquote>\n<p>PromptSpy can collect device information, capture the lockscreen PIN or password, record the screen to obtain the device’s unlock pattern, and take screenshots.</p>\n\n<p>For persistence, the Android malware uses a novel approach at runtime that involves sending a prompt to Google’s Gemini gen-AI chatbot along with an XML file containing data about the various UI elements displayed on the screen.</p>\n</blockquote>\n\n<h2>\n  \n  \n  <strong>Credits</strong>\n</h2>\n\n<p>Cover photo by <a href=\"https://unsplash.com/@hudsoncrafted\" rel=\"noopener noreferrer\">Debby Hudson on Unsplash</a>.</p>\n\n\n\n\n<p>That's it for this week, and I'll see you next time.</p>",
        "source": "dev.to",
        "published": "Fri, 20 Feb 2026 22:51:54 +0000",
        "fetched_at": "2026-02-20T23:24:59.177489Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 19,
        "timeliness_score": 2,
        "final_score": 7.1,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/annotateai/annotateai-medical-ai-insights-33k8",
        "title": "AnnotateAI Medical AI Insights",
        "summary": "<p><strong>#Revolutionizing Medical Imaging: How AI is Transforming Brain Tumor Detection</strong></p>\n\n<h2>\n  \n  \n  The Challenge of Accurate Diagnosis\n</h2>\n\n<p>Brain tumors are a leading cause of cancer-related deaths worldwide. Accurate diagnosis and treatment planning rely heavily on radiologists' expertise in interpreting medical images. However, the complexity and variability of brain tumor morphology can lead to misdiagnosis or delayed diagnosis, resulting in poor patient outcomes.</p>\n\n<p>According to a study published in the Journal of Neuro-Oncology, up to 30% of brain tumors are initially misdiagnosed, leading to unnecessary treatment delays and potential complications (1). The medical imaging market is projected to reach $45 billion by 2030, driven largely by the growing demand for AI-powered diagnostic tools (2).</p>\n\n<h2>\n  \n  \n  The Rise of Medical AI: A Solution in Sight\n</h2>\n\n<p>Recent advancements in deep learning have led to significant improvements in medical image analysis. YOLOv11, a state-of-the-art object detection algorithm, has achieved unprecedented accuracy rates in detecting brain tumors with 96.8% precision (3). However, the adoption of AI-powered diagnostic tools is hindered by concerns over data security, regulatory compliance, and interoperability.</p>\n\n<p>To address these challenges, AnnotateAI Medical offers a HIPAA/SOC2 compliant platform that enables seamless integration of AI-powered diagnostic tools into existing clinical workflows. Our brain tumor detection solution leverages YOLOv11 to provide accurate and timely diagnoses, empowering radiologists to focus on high-value tasks.</p>\n\n<h2>\n  \n  \n  Practical Insights: Implementing AI in Clinical Practice\n</h2>\n\n<p>Implementing AI-powered diagnostic tools requires careful consideration of several factors:</p>\n\n<ul>\n<li>  <strong>Data quality</strong>: High-quality training data is essential for developing accurate AI models. This includes annotated images with precise labels and metadata.</li>\n<li>  <strong>Regulatory compliance</strong>: Ensuring adherence to regulations such as HIPAA and SOC2 is crucial for maintaining patient trust and avoiding costly penalties.</li>\n<li>  <strong>Interoperability</strong>: Seamlessly integrating AI-powered diagnostic tools into existing clinical workflows requires careful consideration of data formats, interfaces, and APIs.</li>\n</ul>\n\n<p>By addressing these challenges, medical institutions can unlock the full potential of AI-powered diagnostic tools, improving patient outcomes and reducing healthcare costs.</p>\n\n<h2>\n  \n  \n  Conclusion\n</h2>\n\n<p>The integration of AI-powered diagnostic tools is transforming the field of radiology. By leveraging state-of-the-art algorithms like YOLOv11 and compliant platforms like AnnotateAI Medical, clinicians can improve accuracy, efficiency, and patient care. Try it free at annotateai.tech/medical to explore how our brain tumor detection solution can enhance your clinical practice.</p>\n\n<p>References:</p>\n\n<p>(1) Journal of Neuro-Oncology: \"Diagnostic errors in brain tumor diagnosis\"</p>\n\n<p>(2) MarketsandMarkets: \"Medical Imaging Market by Modality, Technology, and Region - Global Forecast to 2030\"</p>\n\n<p>(3) arXiv: \"YOLOv11: Real-time object detection with 96.8% precision\"</p>\n\n\n\n\n<p>🧠 <strong>About AnnotateAI Medical</strong>: Clinical-grade brain tumor detection with 96.8% accuracy. HIPAA/SOC2 compliant. Try it free at <a href=\"https://annotateai.tech/medical\" rel=\"noopener noreferrer\">annotateai.tech/medical</a></p>\n\n<p><em>This article was written by the AnnotateAI team — building the future of AI-assisted medical imaging.</em></p>",
        "source": "dev.to",
        "published": "Fri, 20 Feb 2026 22:45:13 +0000",
        "fetched_at": "2026-02-20T23:24:59.177499Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 17,
        "timeliness_score": 2,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/summarize",
        "title": "steipete/summarize",
        "summary": "<p>Point at any URL/YouTube/Podcast or file. Get the gist. CLI and Chrome Extension.</p><hr /><h1>Summarize 📝 — Chrome Side Panel + CLI</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=Summarize%F0%9F%93%9D&amp;subheader=Chrome+Side+Panel+%2B+CLI&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast summaries from URLs, files, and media. Works in the terminal, a Chrome Side Panel and Firefox Sidebar.</p> \n<p><strong>0.11.0 preview (unreleased):</strong> this README reflects the upcoming release.</p> \n<h2>0.11.0 preview highlights (most interesting first)</h2> \n<ul> \n <li>Chrome Side Panel <strong>chat</strong> (streaming agent + history) inside the sidebar.</li> \n <li><strong>YouTube slides</strong>: screenshots + OCR + transcript cards, timestamped seek, OCR/Transcript toggle.</li> \n <li>Media-aware summaries: auto‑detect video/audio vs page content.</li> \n <li>Streaming Markdown + metrics + cache‑aware status.</li> \n <li>CLI supports URLs, files, podcasts, YouTube, audio/video, PDFs.</li> \n</ul> \n<h2>Feature overview</h2> \n<ul> \n <li>URLs, files, and media: web pages, PDFs, images, audio/video, YouTube, podcasts, RSS.</li> \n <li>Slide extraction for video sources (YouTube/direct media) with OCR + timestamped cards.</li> \n <li>Transcript-first media flow: published transcripts when available, Whisper fallback when not.</li> \n <li>Streaming output with Markdown rendering, metrics, and cache-aware status.</li> \n <li>Local, paid, and free models: OpenAI‑compatible local endpoints, paid providers, plus an OpenRouter free preset.</li> \n <li>Output modes: Markdown/text, JSON diagnostics, extract-only, metrics, timing, and cost estimates.</li> \n <li>Smart default: if content is shorter than the requested length, we return it as-is (use <code>--force-summary</code> to override).</li> \n</ul> \n<h2>Get the extension (recommended)</h2> \n<p><img alt=\"Summarize extension screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-extension.png\" /></p> \n<p>One‑click summarizer for the current tab. Chrome Side Panel + Firefox Sidebar + local daemon for streaming Markdown.</p> \n<p><strong>Chrome Web Store:</strong> <a href=\"https://chromewebstore.google.com/detail/summarize/cejgnmmhbbpdmjnfppjdfkocebngehfg\">Summarize Side Panel</a></p> \n<p>YouTube slide screenshots (from the browser):</p> \n<p><img alt=\"Summarize YouTube slide screenshots\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/youtube-slides.png\" /></p> \n<h3>Beginner quickstart (extension)</h3> \n<ol> \n <li>Install the CLI (choose one): \n  <ul> \n   <li><strong>npm</strong> (cross‑platform): <code>npm i -g @steipete/summarize</code></li> \n   <li><strong>Homebrew</strong> (macOS arm64): <code>brew install steipete/tap/summarize</code></li> \n  </ul> </li> \n <li>Install the extension (Chrome Web Store link above) and open the Side Panel.</li> \n <li>The panel shows a token + install command. Run it in Terminal: \n  <ul> \n   <li><code>summarize daemon install --token &lt;TOKEN&gt;</code></li> \n  </ul> </li> \n</ol> \n<p>Why a daemon/service?</p> \n<ul> \n <li>The extension can’t run heavy extraction inside the browser. It talks to a local background service on <code>127.0.0.1</code> for fast streaming and media tools (yt‑dlp, ffmpeg, OCR, transcription).</li> \n <li>The service autostarts (launchd/systemd/Scheduled Task) so the Side Panel is always ready.</li> \n</ul> \n<p>If you only want the <strong>CLI</strong>, you can skip the daemon install entirely.</p> \n<p>Notes:</p> \n<ul> \n <li>Summarization only runs when the Side Panel is open.</li> \n <li>Auto mode summarizes on navigation (incl. SPAs); otherwise use the button.</li> \n <li>Daemon is localhost-only and requires a shared token.</li> \n <li>Autostart: macOS (launchd), Linux (systemd user), Windows (Scheduled Task).</li> \n <li>Tip: configure <code>free</code> via <code>summarize refresh-free</code> (needs <code>OPENROUTER_API_KEY</code>). Add <code>--set-default</code> to set model=<code>free</code>.</li> \n</ul> \n<p>More:</p> \n<ul> \n <li>Step-by-step install: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/README.md\">apps/chrome-extension/README.md</a></li> \n <li>Architecture + troubleshooting: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/chrome-extension.md\">docs/chrome-extension.md</a></li> \n <li>Firefox compatibility notes: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/docs/firefox.md\">apps/chrome-extension/docs/firefox.md</a></li> \n</ul> \n<h3>Slides (extension)</h3> \n<ul> \n <li>Select <strong>Video + Slides</strong> in the Summarize picker.</li> \n <li>Slides render at the top; expand to full‑width cards with timestamps.</li> \n <li>Click a slide to seek the video; toggle <strong>Transcript/OCR</strong> when OCR is significant.</li> \n <li>Requirements: <code>yt-dlp</code> + <code>ffmpeg</code> for extraction; <code>tesseract</code> for OCR. Missing tools show an in‑panel notice.</li> \n</ul> \n<h3>Advanced (unpacked / dev)</h3> \n<ol> \n <li>Build + load the extension (unpacked): \n  <ul> \n   <li>Chrome: <code>pnpm -C apps/chrome-extension build</code> \n    <ul> \n     <li><code>chrome://extensions</code> → Developer mode → Load unpacked</li> \n     <li>Pick: <code>apps/chrome-extension/.output/chrome-mv3</code></li> \n    </ul> </li> \n   <li>Firefox: <code>pnpm -C apps/chrome-extension build:firefox</code> \n    <ul> \n     <li><code>about:debugging#/runtime/this-firefox</code> → Load Temporary Add-on</li> \n     <li>Pick: <code>apps/chrome-extension/.output/firefox-mv3/manifest.json</code></li> \n    </ul> </li> \n  </ul> </li> \n <li>Open Side Panel/Sidebar → copy token.</li> \n <li>Install daemon in dev mode: \n  <ul> \n   <li><code>pnpm summarize daemon install --token &lt;TOKEN&gt; --dev</code></li> \n  </ul> </li> \n</ol> \n<h2>CLI</h2> \n<p><img alt=\"Summarize CLI screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-cli.png\" /></p> \n<h3>Install</h3> \n<p>Requires Node 22+.</p> \n<ul> \n <li>npx (no install):</li> \n</ul> \n<pre><code class=\"language-bash\">npx -y @steipete/summarize \"https://example.com\"\n</code></pre> \n<ul> \n <li>npm (global):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i -g @steipete/summarize\n</code></pre> \n<ul> \n <li>npm (library / minimal deps):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i @steipete/summarize-core\n</code></pre> \n<pre><code class=\"language-ts\">import { createLinkPreviewClient } from \"@steipete/summarize-core/content\";\n</code></pre> \n<ul> \n <li>Homebrew (custom tap):</li> \n</ul> \n<pre><code class=\"language-bash\">brew install steipete/tap/summarize\n</code></pre> \n<p>Apple Silicon only (arm64).</p> \n<h3>CLI vs extension</h3> \n<ul> \n <li><strong>CLI only:</strong> just install via npm/Homebrew and run <code>summarize ...</code> (no daemon needed).</li> \n <li><strong>Chrome/Firefox extension:</strong> install the CLI <strong>and</strong> run <code>summarize daemon install --token &lt;TOKEN&gt;</code> so the Side Panel can stream results and use local tools.</li> \n</ul> \n<h3>Quickstart</h3> \n<pre><code class=\"language-bash\">summarize \"https://example.com\"\n</code></pre> \n<h3>Inputs</h3> \n<p>URLs or local paths:</p> \n<pre><code class=\"language-bash\">summarize \"/path/to/file.pdf\" --model google/gemini-3-flash-preview\nsummarize \"https://example.com/report.pdf\" --model google/gemini-3-flash-preview\nsummarize \"/path/to/audio.mp3\"\nsummarize \"/path/to/video.mp4\"\n</code></pre> \n<p>Stdin (pipe content using <code>-</code>):</p> \n<pre><code class=\"language-bash\">echo \"content\" | summarize -\npbpaste | summarize -\n# binary stdin also works (PDF/image/audio/video bytes)\ncat /path/to/file.pdf | summarize -\n</code></pre> \n<p><strong>Notes:</strong></p> \n<ul> \n <li>Stdin has a 50MB size limit</li> \n <li>The <code>-</code> argument tells summarize to read from standard input</li> \n <li>Text stdin is treated as UTF-8 text (whitespace-only input is rejected as empty)</li> \n <li>Binary stdin is preserved as raw bytes and file type is auto-detected when possible</li> \n <li>Useful for piping clipboard content or command output</li> \n</ul> \n<p>YouTube (supports <code>youtube.com</code> and <code>youtu.be</code>):</p> \n<pre><code class=\"language-bash\">summarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto\n</code></pre> \n<p>Podcast RSS (transcribes latest enclosure):</p> \n<pre><code class=\"language-bash\">summarize \"https://feeds.npr.org/500005/podcast.xml\"\n</code></pre> \n<p>Apple Podcasts episode page:</p> \n<pre><code class=\"language-bash\">summarize \"https://podcasts.apple.com/us/podcast/2424-jelly-roll/id360084272?i=1000740717432\"\n</code></pre> \n<p>Spotify episode page (best-effort; may fail for exclusives):</p> \n<pre><code class=\"language-bash\">summarize \"https://open.spotify.com/episode/5auotqWAXhhKyb9ymCuBJY\"\n</code></pre> \n<h3>Output length</h3> \n<p><code>--length</code> controls how much output we ask for (guideline), not a hard cap.</p> \n<pre><code class=\"language-bash\">summarize \"https://example.com\" --length long\nsummarize \"https://example.com\" --length 20k\n</code></pre> \n<ul> \n <li>Presets: <code>short|medium|long|xl|xxl</code></li> \n <li>Character targets: <code>1500</code>, <code>20k</code>, <code>20000</code></li> \n <li>Optional hard cap: <code>--max-output-tokens &lt;count&gt;</code> (e.g. <code>2000</code>, <code>2k</code>) \n  <ul> \n   <li>Provider/model APIs still enforce their own maximum output limits.</li> \n   <li>If omitted, no max token parameter is sent (provider default).</li> \n   <li>Prefer <code>--length</code> unless you need a hard cap.</li> \n  </ul> </li> \n <li>Short content: when extracted content is shorter than the requested length, the CLI returns the content as-is. \n  <ul> \n   <li>Override with <code>--force-summary</code> to always run the LLM.</li> \n  </ul> </li> \n <li>Minimums: <code>--length</code> numeric values must be &gt;= 50 chars; <code>--max-output-tokens</code> must be &gt;= 16.</li> \n <li>Preset targets (source of truth: <code>packages/core/src/prompts/summary-lengths.ts</code>): \n  <ul> \n   <li>short: target ~900 chars (range 600-1,200)</li> \n   <li>medium: target ~1,800 chars (range 1,200-2,500)</li> \n   <li>long: target ~4,200 chars (range 2,500-6,000)</li> \n   <li>xl: target ~9,000 chars (range 6,000-14,000)</li> \n   <li>xxl: target ~17,000 chars (range 14,000-22,000)</li> \n  </ul> </li> \n</ul> \n<h3>What file types work?</h3> \n<p>Best effort and provider-dependent. These usually work well:</p> \n<ul> \n <li><code>text/*</code> and common structured text (<code>.txt</code>, <code>.md</code>, <code>.json</code>, <code>.yaml</code>, <code>.xml</code>, ...) \n  <ul> \n   <li>Text-like files are inlined into the prompt for better provider compatibility.</li> \n  </ul> </li> \n <li>PDFs: <code>application/pdf</code> (provider support varies; Google is the most reliable here)</li> \n <li>Images: <code>image/jpeg</code>, <code>image/png</code>, <code>image/webp</code>, <code>image/gif</code></li> \n <li>Audio/Video: <code>audio/*</code>, <code>video/*</code> (local audio/video files MP3/WAV/M4A/OGG/FLAC/MP4/MOV/WEBM automatically transcribed, when supported by the model)</li> \n</ul> \n<p>Notes:</p> \n<ul> \n <li>If a provider rejects a media type, the CLI fails fast with a friendly message.</li> \n <li>xAI models do not support attaching generic files (like PDFs) via the AI SDK; use Google/OpenAI/Anthropic for those.</li> \n</ul> \n<h3>Model ids</h3> \n<p>Use gateway-style ids: <code>&lt;provider&gt;/&lt;model&gt;</code>.</p> \n<p>Examples:</p> \n<ul> \n <li><code>openai/gpt-5-mini</code></li> \n <li><code>anthropic/claude-sonnet-4-5</code></li> \n <li><code>xai/grok-4-fast-non-reasoning</code></li> \n <li><code>google/gemini-3-flash-preview</code></li> \n <li><code>zai/glm-4.7</code></li> \n <li><code>openrouter/openai/gpt-5-mini</code> (force OpenRouter)</li> \n</ul> \n<p>Note: some models/providers do not support streaming or certain file media types. When that happens, the CLI prints a friendly error (or auto-disables streaming for that model when supported by the provider).</p> \n<h3>Limits</h3> \n<ul> \n <li>Text inputs over 10 MB are rejected before tokenization.</li> \n <li>Text prompts are preflighted against the model input limit (LiteLLM catalog), using a GPT tokenizer.</li> \n</ul> \n<h3>Common flags</h3> \n<pre><code class=\"language-bash\">summarize &lt;input&gt; [flags]\n</code></pre> \n<p>Use <code>summarize --help</code> or <code>summarize help</code> for the full help text.</p> \n<ul> \n <li><code>--model &lt;provider/model&gt;</code>: which model to use (defaults to <code>auto</code>)</li> \n <li><code>--model auto</code>: automatic model selection + fallback (default)</li> \n <li><code>--model &lt;name&gt;</code>: use a config-defined model (see Configuration)</li> \n <li><code>--timeout &lt;duration&gt;</code>: <code>30s</code>, <code>2m</code>, <code>5000ms</code> (default <code>2m</code>)</li> \n <li><code>--retries &lt;count&gt;</code>: LLM retry attempts on timeout (default <code>1</code>)</li> \n <li><code>--length short|medium|long|xl|xxl|s|m|l|&lt;chars&gt;</code></li> \n <li><code>--language, --lang &lt;language&gt;</code>: output language (<code>auto</code> = match source)</li> \n <li><code>--max-output-tokens &lt;count&gt;</code>: hard cap for LLM output tokens</li> \n <li><code>--cli [provider]</code>: use a CLI provider (<code>--model cli/&lt;provider&gt;</code>). Supports <code>claude</code>, <code>gemini</code>, <code>codex</code>, <code>agent</code>. If omitted, uses auto selection with CLI enabled.</li> \n <li><code>--stream auto|on|off</code>: stream LLM output (<code>auto</code> = TTY only; disabled in <code>--json</code> mode)</li> \n <li><code>--plain</code>: keep raw output (no ANSI/OSC Markdown rendering)</li> \n <li><code>--no-color</code>: disable ANSI colors</li> \n <li><code>--theme &lt;name&gt;</code>: CLI theme (<code>aurora</code>, <code>ember</code>, <code>moss</code>, <code>mono</code>)</li> \n <li><code>--format md|text</code>: website/file content format (default <code>text</code>)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code>: HTML -&gt; Markdown mode (default <code>readability</code>)</li> \n <li><code>--preprocess off|auto|always</code>: controls <code>uvx markitdown</code> usage (default <code>auto</code>) \n  <ul> \n   <li>Install <code>uvx</code>: <code>brew install uv</code> (or <a href=\"https://astral.sh/uv/\">https://astral.sh/uv/</a>)</li> \n  </ul> </li> \n <li><code>--extract</code>: print extracted content and exit (URLs only; stdin <code>-</code> is not supported) \n  <ul> \n   <li>Deprecated alias: <code>--extract-only</code></li> \n  </ul> </li> \n <li><code>--slides</code>: extract slides for YouTube/direct video URLs and render them inline in the summary narrative (auto-renders inline in supported terminals)</li> \n <li><code>--slides-ocr</code>: run OCR on extracted slides (requires <code>tesseract</code>)</li> \n <li><code>--slides-dir &lt;dir&gt;</code>: base output dir for slide images (default <code>./slides</code>)</li> \n <li><code>--slides-scene-threshold &lt;value&gt;</code>: scene detection threshold (0.1-1.0)</li> \n <li><code>--slides-max &lt;count&gt;</code>: maximum slides to extract (default <code>6</code>)</li> \n <li><code>--slides-min-duration &lt;seconds&gt;</code>: minimum seconds between slides</li> \n <li><code>--json</code>: machine-readable output with diagnostics, prompt, <code>metrics</code>, and optional summary</li> \n <li><code>--verbose</code>: debug/diagnostics on stderr</li> \n <li><code>--metrics off|on|detailed</code>: metrics output (default <code>on</code>)</li> \n</ul> \n<h3>Coding CLIs (Codex, Claude, Gemini, Agent)</h3> \n<p>Summarize can use common coding CLIs as local model backends:</p> \n<ul> \n <li><code>codex</code> -&gt; <code>--cli codex</code> / <code>--model cli/codex/&lt;model&gt;</code></li> \n <li><code>claude</code> -&gt; <code>--cli claude</code> / <code>--model cli/claude/&lt;model&gt;</code></li> \n <li><code>gemini</code> -&gt; <code>--cli gemini</code> / <code>--model cli/gemini/&lt;model&gt;</code></li> \n <li><code>agent</code> (Cursor Agent CLI) -&gt; <code>--cli agent</code> / <code>--model cli/agent/&lt;model&gt;</code></li> \n</ul> \n<p>Requirements:</p> \n<ul> \n <li>Binary installed and on <code>PATH</code> (or set <code>CODEX_PATH</code>, <code>CLAUDE_PATH</code>, <code>GEMINI_PATH</code>, <code>AGENT_PATH</code>)</li> \n <li>Provider authenticated (<code>codex login</code>, <code>claude auth</code>, <code>gemini</code> login flow, <code>agent login</code> or <code>CURSOR_API_KEY</code>)</li> \n</ul> \n<p>Quick smoke test:</p> \n<pre><code class=\"language-bash\">printf \"Summarize CLI smoke input.\\nOne short paragraph. Reply can be brief.\\n\" &gt;/tmp/summarize-cli-smoke.txt\n\nsummarize --cli codex --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli claude --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli gemini --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli agent --plain --timeout 2m /tmp/summarize-cli-smoke.txt\n</code></pre> \n<p>Set explicit CLI allowlist/order:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"codex\", \"claude\", \"gemini\", \"agent\"] }\n}\n</code></pre> \n<p>Configure implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": {\n    \"autoFallback\": {\n      \"enabled\": true,\n      \"onlyWhenNoApiKeys\": true,\n      \"order\": [\"claude\", \"gemini\", \"codex\", \"agent\"]\n    }\n  }\n}\n</code></pre> \n<p>More details: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\"><code>docs/cli.md</code></a></p> \n<h3>Auto model ordering</h3> \n<p><code>--model auto</code> builds candidate attempts from built-in rules (or your <code>model.rules</code> overrides). CLI attempts are prepended when:</p> \n<ul> \n <li><code>cli.enabled</code> is set (explicit allowlist/order), or</li> \n <li>implicit auto selection is active and <code>cli.autoFallback</code> is enabled.</li> \n</ul> \n<p>Default fallback behavior: only when no API keys are configured, order <code>claude, gemini, codex, agent</code>, and remember/prioritize last successful provider (<code>~/.summarize/cli-state.json</code>).</p> \n<p>Set explicit CLI attempts:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"gemini\"] }\n}\n</code></pre> \n<p>Disable implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"autoFallback\": { \"enabled\": false } }\n}\n</code></pre> \n<p>Note: explicit <code>--model auto</code> does not trigger implicit auto CLI fallback unless <code>cli.enabled</code> is set.</p> \n<h3>Website extraction (Firecrawl + Markdown)</h3> \n<p>Non-YouTube URLs go through a fetch -&gt; extract pipeline. When direct fetch/extraction is blocked or too thin, <code>--firecrawl auto</code> can fall back to Firecrawl (if configured).</p> \n<ul> \n <li><code>--firecrawl off|auto|always</code> (default <code>auto</code>)</li> \n <li><code>--extract --format md|text</code> (default <code>text</code>; if <code>--format</code> is omitted, <code>--extract</code> defaults to <code>md</code> for non-YouTube URLs)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code> (default <code>readability</code>) \n  <ul> \n   <li><code>auto</code>: use an LLM converter when configured; may fall back to <code>uvx markitdown</code></li> \n   <li><code>llm</code>: force LLM conversion (requires a configured model key)</li> \n   <li><code>off</code>: disable LLM conversion (still may return Firecrawl Markdown when configured)</li> \n  </ul> </li> \n <li>Plain-text mode: use <code>--format text</code>.</li> \n</ul> \n<h3>YouTube transcripts</h3> \n<p><code>--youtube auto</code> tries best-effort web transcript endpoints first. When captions are not available, it falls back to:</p> \n<ol> \n <li>Apify (if <code>APIFY_API_TOKEN</code> is set): uses a scraping actor (<code>faVsWy9VTSNVIhWpR</code>)</li> \n <li>yt-dlp + Whisper (if <code>yt-dlp</code> is available): downloads audio, then transcribes with local <code>whisper.cpp</code> when installed (preferred), otherwise falls back to OpenAI (<code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>)</li> \n</ol> \n<p>Environment variables for yt-dlp mode:</p> \n<ul> \n <li><code>YT_DLP_PATH</code> - optional path to yt-dlp binary (otherwise <code>yt-dlp</code> is resolved via <code>PATH</code>)</li> \n <li><code>SUMMARIZE_WHISPER_CPP_MODEL_PATH</code> - optional override for the local <code>whisper.cpp</code> model file</li> \n <li><code>SUMMARIZE_WHISPER_CPP_BINARY</code> - optional override for the local binary (default: <code>whisper-cli</code>)</li> \n <li><code>SUMMARIZE_DISABLE_LOCAL_WHISPER_CPP=1</code> - disable local whisper.cpp (force remote)</li> \n <li><code>OPENAI_API_KEY</code> - OpenAI Whisper transcription</li> \n <li><code>OPENAI_WHISPER_BASE_URL</code> - optional OpenAI-compatible Whisper endpoint override</li> \n <li><code>FAL_KEY</code> - FAL AI Whisper fallback</li> \n</ul> \n<p>Apify costs money but tends to be more reliable when captions exist.</p> \n<h3>Slide extraction (YouTube + direct video URLs)</h3> \n<p>Extract slide screenshots (scene detection via <code>ffmpeg</code>) and optional OCR:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --slides\nsummarize \"https://www.youtube.com/watch?v=...\" --slides --slides-ocr\n</code></pre> \n<p>Outputs are written under <code>./slides/&lt;sourceId&gt;/</code> (or <code>--slides-dir</code>). OCR results are included in JSON output (<code>--json</code>) and stored in <code>slides.json</code> inside the slide directory. When scene detection is too sparse, the extractor also samples at a fixed interval to improve coverage. When using <code>--slides</code>, supported terminals (kitty/iTerm/Konsole) render inline thumbnails automatically inside the summary narrative (the model inserts <code>[slide:N]</code> markers). Timestamp links are clickable when the terminal supports OSC-8 (YouTube/Vimeo/Loom/Dropbox). If inline images are unsupported, Summarize prints a note with the on-disk slide directory.</p> \n<p>Use <code>--slides --extract</code> to print the full timed transcript and insert slide images inline at matching timestamps.</p> \n<p>Format the extracted transcript as Markdown (headings + paragraphs) via an LLM:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --extract --format md --markdown-mode llm\n</code></pre> \n<h3>Media transcription (Whisper)</h3> \n<p>Local audio/video files are transcribed first, then summarized. <code>--video-mode transcript</code> forces direct media URLs (and embedded media) through Whisper first. Prefers local <code>whisper.cpp</code> when available; otherwise requires <code>OPENAI_API_KEY</code> or <code>FAL_KEY</code>.</p> \n<h3>Local ONNX transcription (Parakeet/Canary)</h3> \n<p>Summarize can use NVIDIA Parakeet/Canary ONNX models via a local CLI you provide. Auto selection (default) prefers ONNX when configured.</p> \n<ul> \n <li>Setup helper: <code>summarize transcriber setup</code></li> \n <li>Install <code>sherpa-onnx</code> from upstream binaries/build (Homebrew may not have a formula)</li> \n <li>Auto selection: set <code>SUMMARIZE_ONNX_PARAKEET_CMD</code> or <code>SUMMARIZE_ONNX_CANARY_CMD</code> (no flag needed)</li> \n <li>Force a model: <code>--transcriber parakeet|canary|whisper|auto</code></li> \n <li>Docs: <code>docs/nvidia-onnx-transcription.md</code></li> \n</ul> \n<h3>Verified podcast services (2025-12-25)</h3> \n<p>Run: <code>summarize &lt;url&gt;</code></p> \n<ul> \n <li>Apple Podcasts</li> \n <li>Spotify</li> \n <li>Amazon Music / Audible podcast pages</li> \n <li>Podbean</li> \n <li>Podchaser</li> \n <li>RSS feeds (Podcasting 2.0 transcripts when available)</li> \n <li>Embedded YouTube podcast pages (e.g. JREPodcast)</li> \n</ul> \n<p>Transcription: prefers local <code>whisper.cpp</code> when installed; otherwise uses OpenAI Whisper or FAL when keys are set.</p> \n<h3>Translation paths</h3> \n<p><code>--language/--lang</code> controls the output language of the summary (and other LLM-generated text). Default is <code>auto</code>.</p> \n<p>When the input is audio/video, the CLI needs a transcript first. The transcript comes from one of these paths:</p> \n<ol> \n <li>Existing transcript (preferred) \n  <ul> \n   <li>YouTube: uses <code>youtubei</code> / <code>captionTracks</code> when available.</li> \n   <li>Podcasts: uses Podcasting 2.0 RSS <code>&lt;podcast:transcript&gt;</code> (JSON/VTT) when the feed publishes it.</li> \n  </ul> </li> \n <li>Whisper transcription (fallback) \n  <ul> \n   <li>YouTube: falls back to yt-dlp (audio download) + Whisper transcription when configured; Apify is a last resort.</li> \n   <li>Prefers local <code>whisper.cpp</code> when installed + model available.</li> \n   <li>Otherwise uses cloud Whisper (OpenAI <code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>).</li> \n  </ul> </li> \n</ol> \n<p>For direct media URLs, use <code>--video-mode transcript</code> to force transcribe -&gt; summarize:</p> \n<pre><code class=\"language-bash\">summarize https://example.com/file.mp4 --video-mode transcript --lang en\n</code></pre> \n<h3>Configuration</h3> \n<p>Single config location:</p> \n<ul> \n <li><code>~/.summarize/config.json</code></li> \n</ul> \n<p>Supported keys today:</p> \n<pre><code class=\"language-json\">{\n  \"model\": { \"id\": \"openai/gpt-5-mini\" },\n  \"env\": { \"OPENAI_API_KEY\": \"sk-...\" },\n  \"ui\": { \"theme\": \"ember\" }\n}\n</code></pre> \n<p>Shorthand (equivalent):</p> \n<pre><code class=\"language-json\">{\n  \"model\": \"openai/gpt-5-mini\"\n}\n</code></pre> \n<p>Also supported:</p> \n<ul> \n <li><code>model: { \"mode\": \"auto\" }</code> (automatic model selection + fallback; see <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a>)</li> \n <li><code>model.rules</code> (customize candidates / ordering)</li> \n <li><code>models</code> (define presets selectable via <code>--model &lt;preset&gt;</code>)</li> \n <li><code>env</code> (generic env var defaults; process env still wins)</li> \n <li><code>apiKeys</code> (legacy shortcut, mapped to env names; prefer <code>env</code> for new configs)</li> \n <li><code>cache.media</code> (media download cache: TTL 7 days, 2048 MB cap by default; <code>--no-media-cache</code> disables)</li> \n <li><code>media.videoMode: \"auto\"|\"transcript\"|\"understand\"</code></li> \n <li><code>slides.enabled</code> / <code>slides.max</code> / <code>slides.ocr</code> / <code>slides.dir</code> (defaults for <code>--slides</code>)</li> \n <li><code>ui.theme: \"aurora\"|\"ember\"|\"moss\"|\"mono\"</code></li> \n <li><code>openai.useChatCompletions: true</code> (force OpenAI-compatible chat completions)</li> \n</ul> \n<p>Note: the config is parsed leniently (JSON5), but comments are not allowed. Unknown keys are ignored.</p> \n<p>Media cache defaults:</p> \n<pre><code class=\"language-json\">{\n  \"cache\": {\n    \"media\": { \"enabled\": true, \"ttlDays\": 7, \"maxMb\": 2048, \"verify\": \"size\" }\n  }\n}\n</code></pre> \n<p>Note: <code>--no-cache</code> bypasses summary caching only (LLM output). Extract/transcript caches still apply. Use <code>--no-media-cache</code> to skip media files.</p> \n<p>Precedence:</p> \n<ol> \n <li><code>--model</code></li> \n <li><code>SUMMARIZE_MODEL</code></li> \n <li><code>~/.summarize/config.json</code></li> \n <li>default (<code>auto</code>)</li> \n</ol> \n<p>Theme precedence:</p> \n<ol> \n <li><code>--theme</code></li> \n <li><code>SUMMARIZE_THEME</code></li> \n <li><code>~/.summarize/config.json</code> (<code>ui.theme</code>)</li> \n <li>default (<code>aurora</code>)</li> \n</ol> \n<p>Environment variable precedence:</p> \n<ol> \n <li>process env</li> \n <li><code>~/.summarize/config.json</code> (<code>env</code>)</li> \n <li><code>~/.summarize/config.json</code> (<code>apiKeys</code>, legacy)</li> \n</ol> \n<h3>Environment variables</h3> \n<p>Set the key matching your chosen <code>--model</code>:</p> \n<ul> \n <li> <p>Optional fallback defaults can be stored in config:</p> \n  <ul> \n   <li><code>~/.summarize/config.json</code> -&gt; <code>\"env\": { \"OPENAI_API_KEY\": \"sk-...\" }</code></li> \n   <li>process env always takes precedence</li> \n   <li>legacy <code>\"apiKeys\"</code> still works (mapped to env names)</li> \n  </ul> </li> \n <li> <p><code>OPENAI_API_KEY</code> (for <code>openai/...</code>)</p> </li> \n <li> <p><code>NVIDIA_API_KEY</code> (for <code>nvidia/...</code>)</p> </li> \n <li> <p><code>ANTHROPIC_API_KEY</code> (for <code>anthropic/...</code>)</p> </li> \n <li> <p><code>XAI_API_KEY</code> (for <code>xai/...</code>)</p> </li> \n <li> <p><code>Z_AI_API_KEY</code> (for <code>zai/...</code>; supports <code>ZAI_API_KEY</code> alias)</p> </li> \n <li> <p><code>GEMINI_API_KEY</code> (for <code>google/...</code>)</p> \n  <ul> \n   <li>also accepts <code>GOOGLE_GENERATIVE_AI_API_KEY</code> and <code>GOOGLE_API_KEY</code> as aliases</li> \n  </ul> </li> \n</ul> \n<p>OpenAI-compatible chat completions toggle:</p> \n<ul> \n <li><code>OPENAI_USE_CHAT_COMPLETIONS=1</code> (or set <code>openai.useChatCompletions</code> in config)</li> \n</ul> \n<p>UI theme:</p> \n<ul> \n <li><code>SUMMARIZE_THEME=aurora|ember|moss|mono</code></li> \n <li><code>SUMMARIZE_TRUECOLOR=1</code> (force 24-bit ANSI)</li> \n <li><code>SUMMARIZE_NO_TRUECOLOR=1</code> (disable 24-bit ANSI)</li> \n</ul> \n<p>OpenRouter (OpenAI-compatible):</p> \n<ul> \n <li>Set <code>OPENROUTER_API_KEY=...</code></li> \n <li>Prefer forcing OpenRouter per model id: <code>--model openrouter/&lt;author&gt;/&lt;slug&gt;</code></li> \n <li>Built-in preset: <code>--model free</code> (uses a default set of OpenRouter <code>:free</code> models)</li> \n</ul> \n<h3><code>summarize refresh-free</code></h3> \n<p>Quick start: make free the default (keep <code>auto</code> available)</p> \n<pre><code class=\"language-bash\">summarize refresh-free --set-default\nsummarize \"https://example.com\"\nsummarize \"https://example.com\" --model auto\n</code></pre> \n<p>Regenerates the <code>free</code> preset (<code>models.free</code> in <code>~/.summarize/config.json</code>) by:</p> \n<ul> \n <li>Fetching OpenRouter <code>/models</code>, filtering <code>:free</code></li> \n <li>Skipping models that look very small (&lt;27B by default) based on the model id/name</li> \n <li>Testing which ones return non-empty text (concurrency 4, timeout 10s)</li> \n <li>Picking a mix of smart-ish (bigger <code>context_length</code> / output cap) and fast models</li> \n <li>Refining timings and writing the sorted list back</li> \n</ul> \n<p>If <code>--model free</code> stops working, run:</p> \n<pre><code class=\"language-bash\">summarize refresh-free\n</code></pre> \n<p>Flags:</p> \n<ul> \n <li><code>--runs 2</code> (default): extra timing runs per selected model (total runs = 1 + runs)</li> \n <li><code>--smart 3</code> (default): how many smart-first picks (rest filled by fastest)</li> \n <li><code>--min-params 27b</code> (default): ignore models with inferred size smaller than N billion parameters</li> \n <li><code>--max-age-days 180</code> (default): ignore models older than N days (set 0 to disable)</li> \n <li><code>--set-default</code>: also sets <code>\"model\": \"free\"</code> in <code>~/.summarize/config.json</code></li> \n</ul> \n<p>Example:</p> \n<pre><code class=\"language-bash\">OPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/meta-llama/llama-3.1-8b-instruct:free\nOPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/minimax/minimax-m2.5\n</code></pre> \n<p>If your OpenRouter account enforces an allowed-provider list, make sure at least one provider is allowed for the selected model. When routing fails, <code>summarize</code> prints the exact providers to allow.</p> \n<p>Legacy: <code>OPENAI_BASE_URL=https://openrouter.ai/api/v1</code> (and either <code>OPENAI_API_KEY</code> or <code>OPENROUTER_API_KEY</code>) also works.</p> \n<p>NVIDIA API Catalog (OpenAI-compatible; free credits):</p> \n<ul> \n <li>Set <code>NVIDIA_API_KEY=...</code></li> \n <li>Optional: <code>NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1</code></li> \n <li>Credits: API Catalog trial starts with 1000 free API credits on signup (up to 5000 total via “Request More” in the API Catalog profile)</li> \n <li>Pick a model id from <code>/v1/models</code> (examples: fast <code>stepfun-ai/step-3.5-flash</code>, strong but slower <code>z-ai/glm5</code>)</li> \n</ul> \n<pre><code class=\"language-bash\">export NVIDIA_API_KEY=\"nvapi-...\"\nsummarize \"https://example.com\" --model nvidia/stepfun-ai/step-3.5-flash\n</code></pre> \n<p>Z.AI (OpenAI-compatible):</p> \n<ul> \n <li><code>Z_AI_API_KEY=...</code> (or <code>ZAI_API_KEY=...</code>)</li> \n <li>Optional base URL override: <code>Z_AI_BASE_URL=...</code></li> \n</ul> \n<p>Optional services:</p> \n<ul> \n <li><code>FIRECRAWL_API_KEY</code> (website extraction fallback)</li> \n <li><code>YT_DLP_PATH</code> (path to yt-dlp binary for audio extraction)</li> \n <li><code>FAL_KEY</code> (FAL AI API key for audio transcription via Whisper)</li> \n <li><code>APIFY_API_TOKEN</code> (YouTube transcript fallback)</li> \n</ul> \n<h3>Model limits</h3> \n<p>The CLI uses the LiteLLM model catalog for model limits (like max output tokens):</p> \n<ul> \n <li>Downloaded from: <code>https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json</code></li> \n <li>Cached at: <code>~/.summarize/cache/</code></li> \n</ul> \n<h3>Library usage (optional)</h3> \n<p>Recommended (minimal deps):</p> \n<ul> \n <li><code>@steipete/summarize-core/content</code></li> \n <li><code>@steipete/summarize-core/prompts</code></li> \n</ul> \n<p>Compatibility (pulls in CLI deps):</p> \n<ul> \n <li><code>@steipete/summarize/content</code></li> \n <li><code>@steipete/summarize/prompts</code></li> \n</ul> \n<h3>Development</h3> \n<pre><code class=\"language-bash\">pnpm install\npnpm check\n</code></pre> \n<h2>More</h2> \n<ul> \n <li>Docs index: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/README.md\">docs/README.md</a></li> \n <li>CLI providers and config: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\">docs/cli.md</a></li> \n <li>Auto model rules: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a></li> \n <li>Website extraction: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/website.md\">docs/website.md</a></li> \n <li>YouTube handling: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/youtube.md\">docs/youtube.md</a></li> \n <li>Media pipeline: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/media.md\">docs/media.md</a></li> \n <li>Config schema and precedence: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/config.md\">docs/config.md</a></li> \n</ul> \n<h2>Troubleshooting</h2> \n<ul> \n <li>\"Receiving end does not exist\": Chrome did not inject the content script yet. \n  <ul> \n   <li>Extension details -&gt; Site access -&gt; On all sites (or allow this domain)</li> \n   <li>Reload the tab once.</li> \n  </ul> </li> \n <li>\"Failed to fetch\" / daemon unreachable: \n  <ul> \n   <li><code>summarize daemon status</code></li> \n   <li>Logs: <code>~/.summarize/logs/daemon.err.log</code></li> \n  </ul> </li> \n</ul> \n<p>License: MIT</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-20T23:24:54.959603Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 19,
        "timeliness_score": 1,
        "final_score": 6.4,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}