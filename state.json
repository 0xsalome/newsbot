{
  "meta": {
    "last_updated": "2026-02-18T23:27:04.236759Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://phys.org/news/2026-02-footed-rope-squirrels-natural-reservoir.html",
        "posted_at": "2026-02-11",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260210040608.htm",
        "posted_at": "2026-02-11",
        "score": 5.5,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260211073026.htm",
        "posted_at": "2026-02-12",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-atoms-vibrate-ngstrm-scale.html",
        "posted_at": "2026-02-12",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-recycling-strategies-fungi-affect-forests.html",
        "posted_at": "2026-02-13",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260211073047.htm",
        "posted_at": "2026-02-13",
        "score": 4.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-ai-physics-complex-protein-biomedical.html",
        "posted_at": "2026-02-14",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223918.htm",
        "posted_at": "2026-02-14",
        "score": 5.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223857.htm",
        "posted_at": "2026-02-15",
        "score": 8.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215225541.htm",
        "posted_at": "2026-02-16",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-renewable-biological-catalyst-potential-wastewater.html",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "posted_at": "2026-02-17",
        "score": 5.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005717.htm",
        "posted_at": "2026-02-18",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://arxiv.org/abs/2602.09120",
        "posted_at": "2026-02-11",
        "score": 20.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-02-11",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/biodegradable-plastics-are-not-a-climate-solution-on-their-own/?utm_source=rss&utm_medium=rss&utm_campaign=biodegradable-plastics-could-reduce-the-environmental-impact-of-the-plastics-industry-but-only-if-we-throw-them-away-properly",
        "posted_at": "2026-02-11",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/",
        "posted_at": "2026-02-11",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://arxiv.org/abs/2507.02883",
        "posted_at": "2026-02-12",
        "score": 18.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-02-12",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
        "posted_at": "2026-02-12",
        "score": 5.4,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-12",
        "score": 4.8,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "posted_at": "2026-02-13",
        "score": 19.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.10625",
        "posted_at": "2026-02-13",
        "score": 17.0,
        "tags": [
          "transformation",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/",
        "posted_at": "2026-02-13",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/13/airbnb-says-a-third-of-its-customer-support-is-now-handled-by-ai-in-the-u-s-and-canada/",
        "posted_at": "2026-02-13",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-02-14",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2505.13557",
        "posted_at": "2026-02-14",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-14",
        "score": 4.8,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/",
        "posted_at": "2026-02-14",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
        "posted_at": "2026-02-15",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/",
        "posted_at": "2026-02-15",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "posted_at": "2026-02-16",
        "score": 33.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2501.05454",
        "posted_at": "2026-02-16",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-02-17",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2602.14299",
        "posted_at": "2026-02-17",
        "score": 21.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
        "posted_at": "2026-02-17",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/17/india-bids-to-attract-over-200b-in-ai-infrastructure-investment-by-2028/",
        "posted_at": "2026-02-17",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-02-18",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2510.22391",
        "posted_at": "2026-02-18",
        "score": 18.6,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": []
      },
      {
        "url": "https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-02-11",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-remembers-attending-the-beatles-first-american-concert-in-1964.html",
        "posted_at": "2026-02-11",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/the-damaged-gaza-war-cemetery-highlights-ongoing-risk-to-soldier-graves-in-conflict-zones-275536",
        "posted_at": "2026-02-12",
        "score": 6.6,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "posted_at": "2026-02-12",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "posted_at": "2026-02-13",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/vivaldis-four-seasons-performed-on-original-baroque-instruments.html",
        "posted_at": "2026-02-13",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/cats-in-medieval-manuscripts-and-paintings.html",
        "posted_at": "2026-02-14",
        "score": 3.7,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/proof-points-grade-inflation-lower-pay/",
        "posted_at": "2026-02-14",
        "score": 3.0,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 7.2,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/pocketblue/pocketblue",
        "posted_at": "2026-02-15",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://erichlof.github.io/THREE.js-PathTracing-Renderer/",
        "posted_at": "2026-02-16",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-being-a-madman-for-8-minutes.html",
        "posted_at": "2026-02-16",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/nz-is-slowly-slipping-on-the-global-corruption-index-is-is-time-for-an-anti-corruption-agency-275781",
        "posted_at": "2026-02-17",
        "score": 3.8,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://fuji.halfof8.com/",
        "posted_at": "2026-02-17",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.historytoday.com/archive/first-global-empire",
        "posted_at": "2026-02-18",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/02/why-some-people-think-in-words.html",
        "posted_at": "2026-02-18",
        "score": 3.3,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://phys.org/news/2026-02-footed-rope-squirrels-natural-reservoir.html",
        "posted_at": "2026-02-11",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260208233836.htm",
        "posted_at": "2026-02-11",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-twilight-fish-reveals-unique-hybrid.html",
        "posted_at": "2026-02-12",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "posted_at": "2026-02-12",
        "score": 5.2,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-basic-listeria-bacteria-unique-cancer.html",
        "posted_at": "2026-02-13",
        "score": 8.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260212025554.htm",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-ai-physics-complex-protein-biomedical.html",
        "posted_at": "2026-02-14",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "posted_at": "2026-02-14",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "posted_at": "2026-02-15",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-recycling-strategies-fungi-affect-forests.html",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "posted_at": "2026-02-16",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-molecular-machine-bacterial-capsules-3d.html",
        "posted_at": "2026-02-16",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-honey-bees-precisely-previously-thought.html",
        "posted_at": "2026-02-17",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "posted_at": "2026-02-17",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-02-fungus-species-genes-threatens-coffee.html",
        "posted_at": "2026-02-18",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260217005714.htm",
        "posted_at": "2026-02-18",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "posted_at": "2026-02-11",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/archaeologists-say-theyve-identified-traces-of-a-2000-year-old-love-note-still-etched-into-a-wall-in-ancient-pompeii-180988163/",
        "posted_at": "2026-02-11",
        "score": 4.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "posted_at": "2026-02-12",
        "score": 12.1,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/expansion-microscopy-has-transformed-how-we-see-the-cellular-world-20260204/",
        "posted_at": "2026-02-12",
        "score": 4.7,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/places/nevada-national-security-site",
        "posted_at": "2026-02-13",
        "score": 10.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/the-cosmic-collision-that-formed-saturns-rings-1267668/",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-02-14",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/when-galileos-cosmic-convictions-landed-him-in-court-1267592/",
        "posted_at": "2026-02-14",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "posted_at": "2026-02-15",
        "score": 12.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/are-the-mysteries-of-quantum-mechanics-beginning-to-dissolve-20260213/",
        "posted_at": "2026-02-15",
        "score": 4.1,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-02-16",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/pulsar-found-near-the-center-of-the-milky-way-could-test-einsteins-theories-1267701/",
        "posted_at": "2026-02-16",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "posted_at": "2026-02-17",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/2014/09/design-package-2014/",
        "posted_at": "2026-02-17",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-fordlandia",
        "posted_at": "2026-02-18",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/did-astronomers-finally-witness-a-black-hole-eat-a-white-dwarf-for-the-first-time-1268498/",
        "posted_at": "2026-02-18",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://www.scmp.com/news/us/politics/article/3343243/trump-faces-rare-pushback-within-his-party-over-tariffs-polls-slide?utm_source=rss_feed",
        "posted_at": "2026-02-11",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-02-11",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/rfk-jr-says-americans-need-more-protein-his-grok-powered-food-website-disagrees/",
        "posted_at": "2026-02-12",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://arstechnica.com/space/2026/02/ulas-vulcan-launcher-still-has-a-solid-rocket-booster-problem/",
        "posted_at": "2026-02-12",
        "score": 3.7,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-02-13",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/13/india-partners-with-alibaba-com-for-export-push-despite-past-china-tech-bans/",
        "posted_at": "2026-02-13",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/hong-kong/society/article/3343598/small-precious-breakthrough-paralysed-hong-kong-dancer-mo-li?utm_source=rss_feed",
        "posted_at": "2026-02-14",
        "score": 5.7,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-02-14",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/week-asia/health-environment/article/3343458/malaysia-says-no-e-waste-dumping-can-its-ban-stop-global-trade?utm_source=rss_feed",
        "posted_at": "2026-02-15",
        "score": 5.7,
        "tags": [
          "transformation",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "posted_at": "2026-02-15",
        "score": 4.8,
        "tags": [
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-02-16",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/02/16/after-all-the-hype-some-ai-experts-dont-think-openclaw-is-all-that-exciting/",
        "posted_at": "2026-02-16",
        "score": 4.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
        "posted_at": "2026-02-17",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-02-17",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-02-18",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/kidde-ring-new-smoke-alarm-2026/",
        "posted_at": "2026-02-18",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://dev.to/soumia_g_9dc322fc4404cecd/the-next-programming-language-is-a-team-of-agents-a-1-hour-crash-course-2e2k",
        "posted_at": "2026-02-11",
        "score": 11.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/delafosse_olivier_f47ff53/moffatt-v-air-canada-the-chatbot-ruling-every-enterprise-ai-leader-must-learn-from-2554",
        "posted_at": "2026-02-11",
        "score": 11.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/vishalmysore/ai-agent-for-moltbook-in-java-from-zero-to-hero-27pg",
        "posted_at": "2026-02-12",
        "score": 15.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/kovan/i-analyzed-every-open-issue-in-cpython-heres-what-i-found-5ega",
        "posted_at": "2026-02-12",
        "score": 10.1,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
        "posted_at": "2026-02-13",
        "score": 9.7,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/lawrencedcodes/staying-market-volatility-resilient-as-a-dev-in-the-ai-era-52gc",
        "posted_at": "2026-02-13",
        "score": 8.3,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/wordpress-vs-headless-cms-a-strategic-decision-framework-for-development-teams-evaluating-platform-35lh",
        "posted_at": "2026-02-14",
        "score": 13.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/disler/claude-code-hooks-mastery",
        "posted_at": "2026-02-14",
        "score": 12.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/videosdeti/add-nix-to-your-project-one-file-zero-setup-drama-4cl4",
        "posted_at": "2026-02-15",
        "score": 9.5,
        "tags": [
          "transformation",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/julcasans/redacta-elevating-video-content-with-github-copilot-cli-kc9",
        "posted_at": "2026-02-15",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/nautechsystems/nautilus_trader",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/moonshine-ai/moonshine",
        "posted_at": "2026-02-16",
        "score": 10.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/cli-driven-component-deployment-pushing-code-to-production-in-one-command-for-visual-page-builders-279o",
        "posted_at": "2026-02-17",
        "score": 10.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/ruvnet/wifi-densepose",
        "posted_at": "2026-02-17",
        "score": 8.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jasonbiondo/edge-rendering-vs-server-side-rendering-performance-trade-offs-explained-lmg",
        "posted_at": "2026-02-18",
        "score": 10.7,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/thanasistraitsis/flutter-sticky-bottom-button-beyond-the-floatingactionbutton-2i7o",
        "posted_at": "2026-02-18",
        "score": 8.9,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044002.htm",
        "title": "This new blood test could detect cancer before it shows up on scans",
        "summary": "A new light-based sensor can spot incredibly tiny amounts of cancer biomarkers in blood, raising the possibility of earlier and simpler cancer detection. The technology merges DNA nanotechnology, CRISPR, and quantum dots to generate a clear signal from just a few molecules. In lung cancer tests, it worked even in real patient serum samples. Researchers hope it could eventually power portable blood tests for cancer and other diseases.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 20:48:34 EST",
        "fetched_at": "2026-02-18T23:26:11.033537Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223918.htm",
        "title": "This breakthrough could finally unlock male birth control",
        "summary": "Scientists at Michigan State University have uncovered the molecular “switch” that powers sperm for their final, high-speed dash toward an egg. By tracking how sperm use glucose as fuel, the team discovered how dormant cells suddenly flip into overdrive, burning energy in a carefully controlled, multi-step process. A key enzyme, aldolase, helps convert sugar into the burst of power needed for fertilization, while other enzymes act like traffic controllers directing the flow of fuel.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 14 Feb 2026 10:47:27 EST",
        "fetched_at": "2026-02-18T23:26:11.033617Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260213223857.htm",
        "title": "Rocky planet discovered in outer orbit challenges planet formation theory",
        "summary": "Astronomers have uncovered a distant planetary system that flips a long-standing rule of planet formation on its head. Around the small red dwarf star LHS 1903, scientists expected to find rocky planets close in and gas giants farther out — the same pattern seen in our own Solar System and hundreds of others. And at first, that’s exactly what they saw. But new observations revealed a surprise: the outermost planet appears to be rocky, not gaseous.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 13 Feb 2026 22:38:57 EST",
        "fetched_at": "2026-02-18T23:26:11.033635Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215225541.htm",
        "title": "Scientists confirm one-dimensional electron behavior in phosphorus chains",
        "summary": "For the first time, researchers have shown that self-assembled phosphorus chains can host genuinely one-dimensional electron behavior. Using advanced imaging and spectroscopy techniques, they separated the signals from chains aligned in different directions to reveal their true nature. The findings suggest that squeezing the chains closer together could trigger a dramatic shift from semiconductor to metal. That means simply adjusting density could unlock entirely new electronic states.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 06:52:35 EST",
        "fetched_at": "2026-02-18T23:26:11.033575Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260216044003.htm",
        "title": "Lab grown human spinal cord heals after injury in major breakthrough",
        "summary": "Researchers have built a realistic human mini spinal cord in the lab and used it to simulate traumatic injury. The model reproduced key damage seen in real spinal cord injuries, including inflammation and scar formation. After treatment with fast moving “dancing molecules,” nerve fibers began growing again and scar tissue shrank. The results suggest the therapy could eventually help repair spinal cord damage.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 16 Feb 2026 07:41:25 EST",
        "fetched_at": "2026-02-18T23:26:11.033532Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://phys.org/news/2026-02-machine-central-problem-quantum-chemistry.html",
        "title": "Machine learning helps solve a central problem of quantum chemistry",
        "summary": "By applying new methods of machine learning to quantum chemistry research, Heidelberg University scientists have made significant strides in computational chemistry. They have achieved a major breakthrough toward solving a decades-old dilemma in quantum chemistry: the precise and stable calculation of molecular energies and electron densities with a so-called orbital-free approach, which uses considerably less computational power and therefore permits calculations for very large molecules.",
        "source": "phys.org",
        "published": "Wed, 18 Feb 2026 16:50:17 EST",
        "fetched_at": "2026-02-18T23:26:12.199666Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://phys.org/news/2026-02-based-material-sustainable-method-recovering.html",
        "title": "Plant-based material offers sustainable method of recovering rare earth element",
        "summary": "Despite rare earth elements' importance in manufacturing cell phones, magnets and a host of other consumer and commercial electronics, the lack of a sustainable, environmentally friendly approach to obtaining these metals has led to a global shortage, according to Amir Sheikhi, associate professor of chemical engineering at Pennsylvania State University.",
        "source": "phys.org",
        "published": "Wed, 18 Feb 2026 16:46:34 EST",
        "fetched_at": "2026-02-18T23:26:12.199716Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://phys.org/news/2026-02-power-grids-epidemics-small-patterns.html",
        "title": "From power grids to epidemics: Study shows how small patterns trigger systemic failures",
        "summary": "Why do some systems collapse suddenly after what seems like a minor disturbance? A single transmission line failure can cascade into widespread blackouts. A delayed shipment can ripple through a global supply chain, emptying store shelves far from the original disruption. A rumor spreading in a small online network can spark nationwide panic. In nature, a slight environmental shift can throw an ecosystem into chaos, and a local disease outbreak can quickly escalate into an epidemic.",
        "source": "phys.org",
        "published": "Wed, 18 Feb 2026 18:20:03 EST",
        "fetched_at": "2026-02-18T23:26:12.199577Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.5,
        "temp_score_trend": 4.5
      },
      {
        "url": "https://phys.org/news/2026-02-chemistry-powered-membrane-tiny-pores.html",
        "title": "Chemistry-powered 'breathing' membrane opens and closes tiny pores on its own",
        "summary": "Ion channels are narrow passageways that play a pivotal role in many biological processes. To model how ions move through these tight spaces, pores need to be fabricated at very small length scales. The narrowest regions of ion channels can be just a few angstroms wide, about the size of individual atoms, making reproducible and precise fabrication a major challenge in modern nanotechnology.",
        "source": "phys.org",
        "published": "Wed, 18 Feb 2026 16:40:05 EST",
        "fetched_at": "2026-02-18T23:26:12.199720Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.5,
        "temp_score_trend": 4.5
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260215084954.htm",
        "title": "AI uncovers the hidden genetic control centers driving Alzheimer’s",
        "summary": "Scientists have created the most detailed maps yet of how genes control one another inside the brains of people with Alzheimer’s disease. Using a powerful new AI-based system called SIGNET, the team uncovered cause-and-effect relationships between genes across six major brain cell types, revealing which genes are truly driving harmful changes. The most dramatic disruptions were found in excitatory neurons, where thousands of genetic interactions appear to be extensively rewired as the disease progresses.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 15 Feb 2026 09:15:19 EST",
        "fetched_at": "2026-02-18T23:26:11.033598Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          }
        ],
        "structural_score": 6,
        "timeliness_score": 4,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 5.3999999999999995,
        "temp_score_trend": 4.6
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
        "summary": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers — Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>",
        "source": "venturebeat.com",
        "published": "Thu, 22 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680093Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 13
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 41,
        "timeliness_score": 3,
        "final_score": 22.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
        "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> — Anthropic&#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors — tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> — an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety — that is, the task of securing Claude&#x27;s real-world actions — is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development — a major feature built in ten days, possibly by the company&#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 12 Jan 2026 11:30:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680123Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 40,
        "timeliness_score": 3,
        "final_score": 21.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "source": "venturebeat.com",
        "published": "Fri, 16 Jan 2026 14:01:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680112Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 39,
        "timeliness_score": 3,
        "final_score": 21.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "source": "venturebeat.com",
        "published": "Mon, 19 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680105Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 3,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680397Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "source": "venturebeat.com",
        "published": "Tue, 13 Jan 2026 13:00:00 GMT",
        "fetched_at": "2026-02-18T23:25:57.680118Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 3,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2503.15130",
        "title": "A Foundational Theory for Decentralized Sensory Learning",
        "summary": "arXiv:2503.15130v2 Announce Type: replace-cross \nAbstract: In both neuroscience and artificial intelligence, popular functional frameworks and neural network formulations operate by making use of extrinsic error measurements and global learning algorithms. Through a set of conjectures based on evolutionary insights on the origin of cellular adaptive mechanisms, we reinterpret the core meaning of sensory signals to allow the brain to be interpreted as a negative feedback control system, and show how this could lead to local learning algorithms without the need for global error correction metrics. Thereby, a sufficiently good minima in sensory activity can be the complete reward signal of the network, as well as being both necessary and sufficient for biological learning to arise. We show that this method of learning was likely already present in the earliest unicellular life forms on earth. We show evidence that the same principle holds and scales to multicellular organisms where it in addition can lead to division of labour between cells. Available evidence shows that the evolution of the nervous system likely was an adaptation to more effectively communicate intercellular signals to support such division of labour. We therefore propose that the same learning principle that evolved already in the earliest unicellular life forms, i.e. negative feedback control of externally and internally generated sensor signals, has simply been scaled up to become a fundament of the learning we see in biological brains today. We illustrate diverse biological settings, from the earliest unicellular organisms to humans, where this operational principle appears to be a plausible interpretation of the meaning of sensor signals in biology, how this relates to current neuroscientific theories and findings, and how it can be applied to solve body control.",
        "source": "export.arxiv.org",
        "published": "Wed, 18 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-18T23:25:54.193043Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2602.13351",
        "title": "A Formal Framework for the Explanation of Finite Automata Decisions",
        "summary": "arXiv:2602.13351v2 Announce Type: replace-cross \nAbstract: Finite automata (FA) are a fundamental computational abstraction that is widely used in practice for various tasks in computer science, linguistics, biology, electrical engineering, and artificial intelligence. Given an input word, an FA maps the word to a result, in the simple case \"accept\" or \"reject\", but in general to one of a finite set of results. A question that then arises is: why? Another question is: how can we modify the input word so that it is no longer accepted? One may think that the automaton itself is an adequate explanation of its behaviour, but automata can be very complex and difficult to make sense of directly. In this work, we investigate how to explain the behaviour of an FA on an input word in terms of the word's characters. In particular, we are interested in minimal explanations: what is the minimal set of input characters that explains the result, and what are the minimal changes needed to alter the result? In this paper, we propose an efficient method to determine all minimal explanations for the behaviour of an FA on a particular word. This allows us to give unbiased explanations about which input features are responsible for the result. Experiments show that our approach scales well, even when the underlying problem is challenging.",
        "source": "export.arxiv.org",
        "published": "Wed, 18 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-18T23:25:54.193260Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2602.15776",
        "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems",
        "summary": "arXiv:2602.15776v1 Announce Type: new \nAbstract: In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.",
        "source": "export.arxiv.org",
        "published": "Wed, 18 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-18T23:25:54.191890Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 5,
        "final_score": 10.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 13.8,
        "temp_score_trend": 7.2
      },
      {
        "url": "https://arxiv.org/abs/2602.15061",
        "title": "Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories",
        "summary": "arXiv:2602.15061v1 Announce Type: cross \nAbstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.",
        "source": "export.arxiv.org",
        "published": "Wed, 18 Feb 2026 00:00:00 -0500",
        "fetched_at": "2026-02-18T23:25:54.191964Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 15,
        "timeliness_score": 5,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 13.0,
        "temp_score_trend": 7.0
      }
    ],
    "education": [
      {
        "url": "https://www.openculture.com/2026/02/david-lynch-being-a-madman-for-8-minutes.html",
        "title": "David Lynch Being a Madman for a Relentless 8 Minutes and 30 Seconds",
        "summary": "Madman or visionary? A little of both? A genius? A brand? A mensch? David Lynch was all these things and more, and this fan-made video above serves as a quick reminder of the career and the consistency of the film director/artist/transcendental meditator who passed away last year. Early in the video we see one of [&#8230;]",
        "source": "www.openculture.com",
        "published": "Mon, 16 Feb 2026 09:00:19 +0000",
        "fetched_at": "2026-02-18T23:26:27.861032Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.openculture.com/2026/02/vivaldis-four-seasons-performed-on-original-baroque-instruments.html",
        "title": "Watch All of Vivaldi’s Four Seasons Performed on Original Baroque Instruments",
        "summary": "Antonio Vivaldi’s The Four Seasons&#160;reigns as one of the world’s most recognizable early 18th-century pieces, thanks to its frequent appearances in&#160;films and television commercials. Upon its debut in 1725, The Four Seasons stunned listeners by telling a story without the help of a human voice. Vivaldi drew on&#160;four existing sonnets&#160;(possibly of his own provenance), using [&#8230;]",
        "source": "www.openculture.com",
        "published": "Thu, 12 Feb 2026 09:00:20 +0000",
        "fetched_at": "2026-02-18T23:26:27.861048Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://letsencrypt.org/2026/02/18/dns-persist-01.html",
        "title": "DNS-Persist-01: A New Model for DNS-Based Challenge Validation",
        "summary": "<a href=\"https://news.ycombinator.com/item?id=47064047\">Comments</a>",
        "source": "news.ycombinator.com",
        "published": "Wed, 18 Feb 2026 18:04:13 +0000",
        "fetched_at": "2026-02-18T23:26:31.812124Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://blog.khanacademy.org/indiana-grade-9-10-ela-courses-for-districts-khan-academy/",
        "title": "A New Way to Support Grade 9–10 Literacy Across Indiana",
        "summary": "<p>How Khan Academy’s new Indiana-aligned ELA courses help districts build strong readers consistently and at scale. Key takeaways for district leaders The challenge: Supporting ... <a class=\"read-more\" href=\"https://blog.khanacademy.org/indiana-grade-9-10-ela-courses-for-districts-khan-academy/\" title=\"A New Way to Support Grade 9–10 Literacy Across Indiana\">Read more</a></p>\n<p>The post <a href=\"https://blog.khanacademy.org/indiana-grade-9-10-ela-courses-for-districts-khan-academy/\">A New Way to Support Grade 9–10 Literacy Across Indiana</a> appeared first on <a href=\"https://blog.khanacademy.org\">Khan Academy Blog</a>.</p>",
        "source": "blog.khanacademy.org",
        "published": "Thu, 22 Jan 2026 15:06:16 +0000",
        "fetched_at": "2026-02-18T23:26:26.232535Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 1,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.0999999999999996,
        "temp_score_trend": 1.9
      },
      {
        "url": "https://www.openculture.com/2026/02/ten-lost-roman-wonders.html",
        "title": "Ten Lost Roman Wonders: The World’s Longest Tunnel, Tallest Dam, Widest-Spanning Bridge & More",
        "summary": "Apart from a few bridges that still work, the infrastructural achievements of the Roman Empire exist, for us, mostly as ruins. With a little imagination, those historic sites give us a clear&#160;enough sense of the empire’s sheer might, but if we want to go deeper, we should then look into the numerous Roman constructions that [&#8230;]",
        "source": "www.openculture.com",
        "published": "Mon, 16 Feb 2026 10:00:44 +0000",
        "fetched_at": "2026-02-18T23:26:27.861027Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          }
        ],
        "structural_score": 2,
        "timeliness_score": 3,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 2.3,
        "temp_score_trend": 2.6999999999999997
      },
      {
        "url": "https://theconversation.com/i-feel-im-making-a-difference-how-blak-women-are-working-to-build-safer-workplaces-268283",
        "title": "‘I feel I’m making a difference’: how Blak women are working to build safer workplaces",
        "summary": "New research examines the barriers faced by Aboriginal and Torres Strait Islander women at work – and what they’re doing to challenge them.",
        "source": "theconversation.com",
        "published": "2026-02-18T19:10:26Z",
        "fetched_at": "2026-02-18T23:26:30.472176Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 1,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.0999999999999996,
        "temp_score_trend": 1.9
      },
      {
        "url": "https://theconversation.com/heart-shaped-locket-discovery-offers-rare-glimpse-into-henry-viii-and-katharine-of-aragons-marriage-276123",
        "title": "Heart-shaped locket discovery offers rare glimpse into Henry VIII and Katharine of Aragon’s marriage",
        "summary": "The recently discovered heart-shaped locket may offer a rare glimpse into the king’s personal affections.",
        "source": "theconversation.com",
        "published": "2026-02-18T17:01:40Z",
        "fetched_at": "2026-02-18T23:26:30.472244Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 1,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.0999999999999996,
        "temp_score_trend": 1.9
      },
      {
        "url": "https://theconversation.com/the-next-cancer-breakthrough-may-be-stopping-it-before-it-starts-275453",
        "title": "The next cancer breakthrough may be stopping it before it starts",
        "summary": "New research suggests cancer develops through detectable biological changes years before a tumour forms.",
        "source": "theconversation.com",
        "published": "2026-02-18T17:01:28Z",
        "fetched_at": "2026-02-18T23:26:30.472285Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 1,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.0999999999999996,
        "temp_score_trend": 1.9
      },
      {
        "url": "https://theconversation.com/the-bafta-film-awards-are-going-greener-but-some-climate-problems-are-hiding-off-camera-273121",
        "title": "The Bafta film awards are going greener – but some climate problems are hiding off camera",
        "summary": "If flights dominate emissions, then the biggest wins won’t come from menus or outfits.",
        "source": "theconversation.com",
        "published": "2026-02-18T13:10:56Z",
        "fetched_at": "2026-02-18T23:26:30.472384Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 1,
        "final_score": 2.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.0999999999999996,
        "temp_score_trend": 1.9
      },
      {
        "url": "https://theconversation.com/critical-mineral-mining-faces-risks-if-local-communities-arent-consulted-enough-the-case-of-lithium-in-ghana-275723",
        "title": "Critical mineral mining faces risks if local communities aren’t consulted enough: the case of lithium in Ghana",
        "summary": "The supply of critical minerals like lithium faces serious risks because of the failure of community approval.",
        "source": "theconversation.com",
        "published": "2026-02-18T15:17:51Z",
        "fetched_at": "2026-02-18T23:26:30.472309Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          }
        ],
        "structural_score": 3,
        "timeliness_score": 1,
        "final_score": 2.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 2.3999999999999995,
        "temp_score_trend": 1.5999999999999999
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012213.htm",
        "title": "A hidden Aloe vera compound takes aim at Alzheimer’s",
        "summary": "Scientists have uncovered promising clues that compounds found in Aloe vera could play a role in fighting Alzheimer’s disease. Using advanced computer modeling, researchers discovered that beta-sitosterol—a natural plant compound—strongly interacts with two key enzymes involved in memory loss and cognitive decline. The compound showed stability, strong binding, and favorable safety indicators, making it a standout candidate for future drug development.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 08 Feb 2026 07:57:41 EST",
        "fetched_at": "2026-02-18T23:26:36.337605Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003631",
        "title": "Recurrent mutations in the stress regulator Cap1 reveal a trade-off between azole resistance and oxidative stress response in <i>Candida albicans</i>",
        "summary": "<p>by Xin Zhou, Audrey Hilk, Norma V. Solis, Nancy Scott, Christopher Zajac, Scott G. Filler, Anna Selmecki</p>\n\nDrug resistance is a critical challenge in treating life-threatening fungal infections. Here, we uncover a mechanism of acquired azole resistance in <i>Candida albicans</i> through mutations in <i>CAP1</i>, encoding a conserved fungal transcription factor that mediates the oxidative stress response. We analyzed 300 clinical isolates and identified 25 distinct <i>CAP1</i> missense or nonsense mutations, with many occurring within the DNA-binding domain. We identified two nearly identical <i>CAP1</i> heterozygous nonsense mutations, one in an isolate obtained from a bloodstream infection and one in a population of cells undergoing adaptation to fluconazole <i>in vitro</i>. Both <i>CAP1</i> nonsense mutations resulted in loss of the C-terminal nuclear export signal, leading to nuclear retention of Cap1 and subsequent activation of genes associated with the oxidative stress response and drug transport. The <i>CAP1</i> C-terminal truncations conferred significant fitness advantages in the presence of fluconazole, both <i>in vitro</i> and in a murine model of candidiasis. Strikingly, we discovered a therapeutic vulnerability: azole concentrations above the minimal inhibitory concentration were fungicidal to mutants with the <i>CAP1</i> C-terminal truncation. The fungicidal effect was attributed to both elevated azole-induced reactive oxygen species and a compromised oxidative stress response in Cap1-truncated cells. Our results provide novel characterization of <i>de novo</i> <i>CAP1</i> point mutations emerging in both laboratory and clinical contexts, elucidate the mechanisms underlying Cap1-regulated stress responses, and reveal a potential therapeutic target for overcoming drug resistance in <i>C. albicans</i> infections.",
        "source": "journals.plos.org",
        "published": "2026-02-02T14:00:00Z",
        "fetched_at": "2026-02-18T23:26:37.608878Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 14,
        "timeliness_score": 1,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260207232242.htm",
        "title": "This weird deep-sea creature was named by thousands of people online",
        "summary": "A newly discovered deep-sea creature has become an unlikely Internet star. After appearing in a popular YouTube video, a rare chiton found nearly three miles beneath the ocean surface sparked a global naming effort, drawing more than 8,000 suggestions from people around the world. Scientists ultimately chose the name Ferreiraella populi, meaning “of the people,” honoring the public that helped bring it into the scientific record.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 07 Feb 2026 23:32:36 EST",
        "fetched_at": "2026-02-18T23:26:36.337596Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/02/260206012210.htm",
        "title": "This tiny molecular trick makes spider silk almost unbreakable",
        "summary": "Scientists have cracked a key mystery behind spider silk’s legendary strength and flexibility. They discovered that tiny molecular interactions act like natural glue, holding silk proteins together as they transform from liquid into incredibly tough fibers. This same process helps create silk that’s stronger than steel by weight and tougher than Kevlar.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 06 Feb 2026 01:22:10 EST",
        "fetched_at": "2026-02-18T23:26:36.337610Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://phys.org/news/2026-02-unique-path-poxviruses.html",
        "title": "A ring to transcribe them: The unique path of poxviruses",
        "summary": "A research team at the University of Würzburg has deciphered another aspect of poxviral gene activation. They have revealed a unique viral mechanism: A molecular ring anchors the viral copying machine to the DNA. Their findings are published in the journal Nature Communications.",
        "source": "phys.org",
        "published": "Wed, 18 Feb 2026 09:12:29 EST",
        "fetched_at": "2026-02-18T23:26:35.008080Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas/?utm_source=rss&utm_medium=rss&utm_campaign=researchers-have-figured-out-how-to-make-airplanes-fly-on-landfill-gas",
        "title": "Researchers have figured out how to make airplanes fly on landfill gas",
        "summary": "Specially designed efficient catalysts are at the heart of a reactor that makes sustainable aviation fuels from methane-rich gases created when waste decomposes",
        "source": "www.anthropocenemagazine.org",
        "published": "Thu, 12 Feb 2026 13:00:16 +0000",
        "fetched_at": "2026-02-18T23:26:38.915559Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "value_redefinition",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/02/could-we-cool-the-planet-by-turning-crop-waste-into-building-materials/?utm_source=rss&utm_medium=rss&utm_campaign=could-we-cool-the-planet-by-turning-crop-waste-into-building-materials",
        "title": "The remarkable climate case for turning farm waste into building materials",
        "summary": "Wheat straw and rice husks already appear in niche construction products. A new study explores the global climate effects if they went mainstream.",
        "source": "www.anthropocenemagazine.org",
        "published": "Fri, 06 Feb 2026 13:00:00 +0000",
        "fetched_at": "2026-02-18T23:26:38.915574Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003577",
        "title": "Piriform seizures mediated by the piriform-entorhino-dentate circuit induce brain-wide functional reorganization in mice",
        "summary": "<p>by Yan Tao, Yuxin Zhao, Wenqi Zhong, Jiajia Zhang, Hongyan Zhu, Xutao Zhu, Zikun Wang, Na Wang, Liqin Yang, Fuqiang Xu, Ruiqi Wu</p>\n\nSystematic identification of global epileptic reorganization and critical seizure-controlling circuits is essential for comprehending epilepsy pathophysiology and for developing network-guided targeted therapies. The piriform cortex (PC) is a recognized epileptogenic region, but how its hyperactivity reshapes whole-brain dynamics and which specific circuits mediate seizures remains unclear. Through multimodal integration of optogenetics, fMRI, electrophysiology, Ca<sup>2+</sup> imaging, neural tracing, and circuit-specific manipulation, we mapped the whole-brain dynamics following optogenetic stimulation of PC and identified the fundamental circuit governing piriform seizures. We observed pronounced generalized seizures in mice via repeated optogenetic stimulation of PC <i>Vglut1</i>+ neurons. Optogenetic kindling of PC<sup>Vglut1</sup> induced widespread blood-oxygen-level-dependent (BOLD) signal hyperactivation and resting-state functional connectivity (rsFC) alterations, notably sustained hyperactivation in the lateral entorhinal cortex (Lent) and enhanced PC-Lent rsFC. Chronic elimination of Lent neurons receiving PC projections significantly decreased the Lent-dentate gyrus (DG) rsFC. Disruption of the PC-Lent or Lent-DG circuit effectively suppressed PC-stimulation-triggered seizures and brain-wide hyperactivation. Our findings demonstrate the dominant role of the PC<sup>Vglut1</sup>-Lent<sup>glut</sup>-DG circuit in mediating piriform seizures and driving their resulting brain-wide functional reorganization, offering new insights for targeted epilepsy treatments.",
        "source": "journals.plos.org",
        "published": "2026-02-12T14:00:00Z",
        "fetched_at": "2026-02-18T23:26:37.608722Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 1,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003629",
        "title": "Microstructural profiles of the human superficial white matter and their associations to cortical geometry and connectivity",
        "summary": "<p>by Youngeun Hwang, Raul Rodriguez-Cruces, Jordan DeKraker, Donna Gift Cabalo, Ilana R. Leppert, Risavarshni Thevakumaran, Christine L. Tardif, David A. Rudko, Casey Paquola, Pierre-Louis Bazin, Andrea Bernasconi, Neda Bernasconi, Luis Concha, Alan C. Evans, Boris C. Bernhardt</p>\n\nThe superficial white matter (SWM), immediately beneath the cortical mantle, is thought to play a major role in cortico-cortical connectivity as well as large-scale brain function. Yet, this compartment remains rarely studied due to its complex organization. Our objectives were to develop and disseminate a robust computational framework to study SWM organization based on 3D histology and high-field 7T MRI. Using data from the BigBrain and Ahead 3D histology initiatives, we first interrogated variations in cell staining intensities across different cortical regions and different SWM depths. These findings were then translated to in vivo 7T quantitative myelin-sensitive MRI, including T1 relaxometry (T1 map) and magnetization transfer saturation (MTsat). As indicated by the statistical moments of the SWM intensity profiles, the first 2 mm below the cortico-subcortical boundary were characterized by high structural complexity. We quantified SWM microstructural variation using a nonlinear dimensionality reduction method and examined the relationship of the resulting microstructural gradients with indices of cortical geometry, as well as structural and functional connectivity. Our results showed correlations between SWM microstructural gradients, as well as curvature and cortico-cortical functional connectivity. Our study provides novel insights into the organization of SWM in the human brain and underscores the potential of SWM mapping to advance fundamental and applied neuroscience research.",
        "source": "journals.plos.org",
        "published": "2026-01-30T14:00:00Z",
        "fetched_at": "2026-02-18T23:26:37.608906Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 1,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003659",
        "title": "DRfold2 is a deep learning-based tool that enables efficient and accurate RNA structure prediction",
        "summary": "<p>by Yang Li, Chenjie Feng, Xi Zhang, Sho Tsukiyama, Duanyu Feng, Yang Zhang</p>\n\nRNA structures are essential for understanding their biological functions and developing RNA-targeted therapeutics. However, accurate RNA structure prediction from sequence remains a crucial challenge. We introduce DRfold2, a deep learning framework that integrates a novel pre-trained RNA Composite Language Model (RCLM) with a denoising structure module for end-to-end RNA structure prediction. Based solely on single sequence, DRfold2 achieves superior performance in both global topology and secondary structure predictions over other state-of-the-art approaches across multiple benchmark tests from diverse species. Detailed analyses reveal that the improvements primarily stem from the RCLM’s ability to capture co-evolutionary pattern and the effective denoising process, with a more than 100% increase in contact prediction precision compared to existing methods. Furthermore, DRfold2 demonstrates high complementarity with AlphaFold3, achieving statistically significant accuracy gains when integrated into our optimization framework. By uniquely combining composite language modeling, denoising-based end-to-end learning, and deep learning-guided post-optimization, DRfold2 establishes a distinct direction for advancing ab initio RNA structure prediction.",
        "source": "journals.plos.org",
        "published": "2026-02-17T14:00:00Z",
        "fetched_at": "2026-02-18T23:26:37.608671Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 1,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "title": "The Rebirth of Pennsylvania’s Infamous Burning Town",
        "summary": "<p>“There’s not much there anymore, it’s pretty much just a crossroads.”</p>\n<p>I read the posts online telling me not to bother, but I wanted to go anyway. Certainly I could feel something as we got close: the sense of desperation, of ruin and abandon. So I drove with a small group of friends deep into eastern Pennsylvania—coal country—through towns with names like Frackville, Pottsville, Ashland. Many downtowns had at least one house that had burned to ruin and been left abandoned. It was early June, but clouds covered the sky and we drove through a slight but persistent rain.</p>\n<p>We were on our way to Centralia, Pennsylvania. The Burning Town.</p>\n<p>The coal that made this valley famous accreted in layers over tens of thousands of years, organic swamp matter turning first to peat, and then compressed over millennia into billions of tons of anthracite—the densest and most pure form of coal—the stuff that made this region of Pennsylvania famous. Mines first opened here in 1856 and Centralia was incorporated as a town a decade later. Through the years bitter labor disputes broke out over exploitative treatment of the (largely Irish immigrant) miners, leading to regular outbreaks of violence. Add to that the boom and bust cycle of the coal industry—and the environmental desolation and impoverishment of the region—and you end up with a town that is deeply scarred, both literally and metaphorically.</p>\n<p>But the story that made Centralia famous began in May 1962, when officials set fire to the trash in a local landfill in an open strip-mine pit. This wasn’t the first year they’d done this, and there were firefighters stationed to ensure the blaze didn’t get out of control. After two days, the trash fire seemed to have burned itself out. But this time, for whatever reason (the actual cause was never fully determined), something went wrong. The landfill burn had lit the coal mines beneath the town.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106279/image.jpg\" width=\"auto\" /></figure>\n<p>Over the years, numerous attempts were made to put out the fire. Nothing worked. In all, federal, state, and local governments spent over $3.3 million on the blaze, which raged on, uncontrollably. Over time, residents reported that their basements were strangely hot, and in 1979, the mayor John Coddington lowered a thermometer into an underground fuel tank at the gas station he owned, only to discover that the gasoline was 172 degrees Fahrenheit. And then on Valentine’s Day, 1981, a twelve-year old boy fell into a four-foot-wide sinkhole that opened up in his grandmother’s backyard, barely rescued by his fourteen year-old cousin. A plume of lethal carbon monoxide bellowed out from the hole.</p>\n<p>Realizing that topsoil was the only thing separating the town from a massive, raging inferno, the federal government finally decided to clear the town. The United States Congress allocated money for a buyout, which nearly all of the town’s 1,000 or so residents took. By 1990, 63 people remained in the town. Two years later, governor Bob Casey invoked eminent domain and condemned all the remaining buildings. By 2021, only five homes were still left standing.</p>\n<p>I had come here expecting that we would find ruin and neglect, toxicity and destitution. I expected Centralia to be an exemplar of the <em>eerie: </em>A place where once there had been a town, place of thriving life, and instead now was only absence, an emptiness, a void.</p>\n<p>What we found instead, strangely, was beauty. Centralia, despite everything I’d been led to expect, was thriving.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106274/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>The Burning Town has come to stand in as a kind of exemplar of a post-industrial wasteland, a place where human folly reached its apex, scorching the land. All but abandoned, it became known primarily for the vents that poured smoke from the fire below, and for Graffiti Highway—a closed stretch of Route 61 covered in tags, doodles of genitalia, and declarations of love.</p>\n<p>When adapting the video game franchise <em>Silent Hill </em>for film, screenwriter Roger Avary used Centralia as a model for both the town’s backstory and its look. For years it drew curious onlookers and legend trippers, while the name “Centralia” itself became an almost byword for late capitalism: a term for that mixture of rapacious profit-seeking and thoughtless stewardship that created America’s own Chernobyl.</p>\n<p>Locals see the story a little differently, though their version borrows from similar themes. Phil, a tour guide at Pioneer Tunnel in neighboring Ashland, pointed out that while the grim toil of the mines claimed many human lives, their closure left the valley with little else to offer. He explained how the families that didn’t leave Centralia were harassed, as government forces tried to drive them off their land. Those that stayed had to go to court to defend their right to live on this abandoned land, all because they wanted to keep the mineral rights to their property. So now, people like Phil assume that the government is just waiting them out. Once they’re gone, putting out the fire will be easy enough. “They’ll take all that red hot coals, but also they’re going to get that rich anthracite coal,” he told us. “And I’m sure they’ll sell that. But are the people or the relatives going to get anything? It’s very doubtful. It’ll probably go to the federal government. Or the coal baron, maybe?”</p>\n<p>His voice, I noticed after a while, has a peculiar kind of nostalgia for the worst times in the world. Like so many others in these towns, he seems to long for a return, another chance for Pennsylvanians to throw their children back into the maw of the mine. Anything for a chance to get the coal jobs will come back. Anything in service of waking the Mountain once more.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106256/image.jpg\" width=\"auto\" /></figure>\n<p>When we finally got to Centralia, we were met not with destruction or despair, but with what seemed at first simply like nothing. The streets are still laid out, and there are still a handful of houses left, but the graffiti highway has been covered over. Any abandoned buildings have long been torn down.</p>\n<p>It’s why, if you ask around these days, folks will tell you there’s nothing to see in Centralia. “I drove through Centralia 2 weeks ago,” one local commented on a <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1cw0xqc/looking_to_visit_centralia_is_it_still_legal_to_go/\">Reddit thread</a>. “I didn’t realize till after I had already passed it. That should tell you everything you need to know.” In another thread a different local <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1ikd2rs/i_have_some_questions_regarding_traveling_through/\">commented</a>, “What is the draw? It’s just empty ground now.”</p>\n<p>But emptiness can tell its own story. Standing on the empty streets of Centralia, I thought mainly of Cal Flynn’s <em>Islands of Abandonment: Nature Rebounding in the Post-Human Landscape. </em>Flynn travels the world to places that have been forsworn by humanity: not the pristine, untouched wilderness, but places abandoned, like Chernobyl and the exclusion zone that divides the island of Cyprus between its Greek and Turkish halves. Places where, Flynn writes, “nature has been allowed to work unfettered.” Such places are often thriving with plant and animal life. Abandonment, she writes, “<em>is </em>rewilding, in a very pure sense, as humans draw back and nature reclaims what once was hers.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106273/image.jpg\" width=\"auto\" /></figure>\n<p>What Flynn makes clear is that while we tend to think of human activity on the landscape as not only damaging but <em>irreversible</em>, this may not always be the case. We believe, in our hubris, that we have the power to wreck nature for good. And while it’s true that places like the Bikini Atoll and Chernobyl will be radioactive for unimaginable human lifetimes, that doesn’t mean that other species haven’t moved in and, left unmolested by human activity, found ways to flourish.</p>\n<p>Flynn’s book catalogs a variety of ways in which nature has reclaimed places that we’ve left behind, often with surprising speed. When Estonia, for example, became independent of the Soviet Union, some 245 million square miles of collectivist farmlands were simply abandoned. They weren’t plowed over, repurposed, or re-seeded. They simply were left alone. Flora immediately went to work: soon these fields were covered in wildflowers and weeds, and then thorn bushes and brambles, and then the skinny shoots of young spruce trees. Now, thirty-five years later, Estonia is now one of the most forested countries in Europe, having nearly doubled the size of its forests by doing … nothing. Half the country is now a forest, and over 90 percent of those forests have naturally regenerated.</p>\n<p>When I say that Centralia is <em>thriving, </em>this is what I mean. It is a landscape pulsing with life, overflowing with lush greenery. The old grid of streets is still visible, and there are still a handful of houses with carefully mowed lawns sitting in defiance. But everything else is the wild and vital province of nature. Turkeyfoot, broom-sedge, and switchgrass and silky dogwood. Young white oaks and linden trees push their way through this cacophony of life. Everywhere that’s not asphalt is a riot of green in every possible shade. And all of this is possible, at least in part, because the state and federal governments have forbidden any new human settlement, giving the wild and the lush and untrammeled room to grow.</p>\n<p>Not all of this is just nature. In 2021, the Eastern Pennsylvania Coalition for Abandoned Mine Reclamation planted 250 apple trees in the hope of attracting butterflies. EPCAMR has hosted annual trash clean-ups in the town, but a few years ago turned to planting and furthering the former town’s potential as an unofficial wildlife sanctuary. “We’re trying to get that area designated as a monarch way station eventually,” Robert “Bobby” Hughes, executive director of EPCAMR said at the time. But as vital as this work is, it seems primarily that the rewilding of Centralia is simply the work of leaving it alone.</p>\n<p>Standing in what was once a small, otherwise forgettable town, I came to understand how folly, mistake, calamitous hubris, neglect, and plain stupidity—could all be weapons in an arsenal to rewild and reforest the Earth, a future waiting in places we mistakenly believe we have irredeemably scarred.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106280/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>Beyond the town itself, the thing people have come to mourn here is the Graffiti Highway, which for years was a strange destination before it was covered over in 2020. It began, as these things often do, as spontaneous tagging and defacement. But over time, more taggers added their names, their designs, their art, and their stories, until it had become a makeshift historical record of the people who live here.</p>\n<p>Over time, it had begun to encroach on the natural history that was also unfolding, spilling out beyond the asphalt and into the forest, as trees and plants started to get defaced. It became an attractive nuisance, repeated bonfires and ATV crashes straining local resources, so when coal company Pagnotti Enterprises bought the land in 2018, they chose to bury the road in dirt and erased it for good. There is now, in the words of many Redditors, no reason to go to Centralia. But the company’s decision also obliterated what some saw as a vital piece in the region’s history. Pagnotti’s<a href=\"https://www.google.com/search?q=pagnotti+enterprises&amp;oq=pagnotti+enterprises&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM4MjBqMGo3qAIAsAIA&amp;sourceid=chrome&amp;ie=UTF-8#lrd=0x89c51a61c01ed687:0x1b1a2cd6c4d6b514,1,,,,\"> reviews</a> on Google are uniformly one-star ratings alongside comments like “You ruined graffiti highway,” “ruined a landmark, nice piles of dirt, go die,” and so on.</p>\n<p>For those who contributed to the Graffiti Highway, it had marked loves and losses, honored the dead and celebrated the living, all in a hundred different colors. (Park Street in Centralia has since begun to take the place of the old Graffiti Highway, decorated with a variety of tags, but at the moment it has nowhere near the density of the original Graffiti Highway. Some monuments take time to rebuild.)</p>\n<p>Kutztown University professor Deryl Johnson has called the story of Graffiti Highway an “epilogue” to the story of Centralia itself, but I’m not sure I agree. The story of Centralia is still very much unfolding—it did not end in 1982, and it did not end in 2020. Now that the highway is gone, the tourist attraction draw of this place has waned, leaving even more space for the natural world to reclaim the land. A new chapter has begun, and there may be other chapters in the story yet to come—chapters whose shape and direction we can only guess at.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106277/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>If you think of Centralia in terms of human habitation, it’s a ghost town, a few stubborn holdouts fighting against entropy and inertia. If you think of Centralia in terms of legend tripping and ruin porn, it’s nothing at all, barely a wide spot in the road. But if you think of Centralia as an unintended nature preserve, it is absolutely bursting with life and potential and possibility.</p>\n<p>Yet still the ground burns. Just out of the grid of streets that was once the town, down Big Mine Run Road, are the vents themselves: small holes in the sides of the hills like something out of Tolkien that lead down to inferno below. These days, the smoke itself is rarely visible, but when rain filters down to the fires, it comes back out as steam. So on the rainy day of our visit, we watched as these vents let out a small, steady stream of white steam, proof of the heat somewhere beneath our feet.</p>\n<p>It was an odd sensation. The wisps seemed peaceful, laconic, almost soothing. And at the same time, it seemed as though at any moment the entire valley would explode. Somehow it felt like both of these things at once.</p>\n<p>Looking at these gentle wisps of smoke, it is difficult to picture the smoldering inferno they emerged from. A fire that has raged out of control for sixty years, unending and older than most people you know. You try and you fail every time.</p>\n<p>Which is to say, Centralia’s mine fire is a thing that should not be. I can describe to you its history, the actions of the people involved. I can describe to you what the surface looks like, the species of plants, the words etched into the tombstones at the Odd Fellows Cemetery. But the secret, raging, burning heart of the Valley remains elusive.</p>\n<p>The plumes are a subtle reminder, easy to miss, that there is a reason for this pristine, thriving wildness all around us. That the coal mines underground are a price that has to be paid, paid to an underworld god that must be forever fed.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 17:18:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618367Z",
        "tags": [
          {
            "name": "transformation",
            "score": 9
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 19,
        "timeliness_score": 3,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-edison-ford-winter-estate",
        "title": "Inside Thomas Edison’s Botanical Laboratory",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>Thomas Edison and his family had a ritual. Every winter, they would leave freezing cold New Jersey and head down to Fort Myers, Florida. Back then, Fort Myers was out there. Think swamps and mosquitoes. It was actually easier to get around by boat than over land.</p>\n<p>The Edisons would do vacation stuff: go fishing, go on boat rides, collect interesting plants. And in 1914, they invited a different branch of American inventing royalty to join them. That year, Henry Ford, of the Model T Ford, came down to Florida with his wife, Clara.</p>\n<p>Ford must have been psyched because Edison was actually his hero. They’d met briefly years before at a conference when Ford was still a low-level employee at an Edison company. Now they were meeting on something like equal terms.</p>\n<p>So to celebrate the occasion, Ford had some Model Ts shipped down to Fort Myers. Everyone went out joyriding around the swamps. The cars flooded, their campsite got soaked. Clara Ford was really afraid of snakes, and there were snakes everywhere. Henry tried to scare them away by shooting off a pistol. Needless to say, it was a trip.</p>\n<p>But soon, once the smoke from Ford’s pistol had cleared and the Model Ts had dried out, Edison and Ford would become more than just travel buddies. They were actually about to embark on an enormous inventing project, a project that would turn Edison’s Florida house into a full-fledged botanical laboratory and would become the last great obsession of Edison’s life.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. Today’s episode is brought to you in partnership with Fort Myers – Islands, Beaches and Neighborhoods. Maybe when you think of Henry Ford and Thomas Edison, you think technology, cars, light bulbs, electricity. But the success of both of their inventions depended on plants. That is why they had come to Florida: to experiment.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106299/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Plants were actually the reason Thomas Edison had fallen in love with Fort Myers in the first place. Around 30 years before that camping trip with Ford, Edison was working away in his Menlo Park lab on one of his most famous projects.</p>\n<p><strong>Karen Maxwell:</strong> Many people are under the misimpression he invented the light bulb. He actually perfected it.</p>\n<p><strong>Kelly: </strong>This is Karen Maxwell. She’s the horticulture director at the Edison and Ford Winter Estates.</p>\n<p><strong>Karen: </strong>So, at this time, there are about 20 different varieties of incandescent light bulbs, but none of them burned for very long.</p>\n<p><strong>Kelly:</strong> The problem was this teeny tiny piece inside the bulb called a filament. When electricity passes through, the filament heats up and glows and we get light. But none of these early filaments could glow long enough to make a practical light bulb.</p>\n<p>So Edison set out to change that, testing thousands and thousands of different materials. Cotton, platinum, cedar, and finally, bamboo.</p>\n<p><strong>Karen: </strong>And he had his team—I’m glad I wasn’t one of them then—they stayed up and did shifts to record how long it burned. That filament burned for 1,200 hours. And that made the incandescent light bulb a national product.</p>\n<p><strong>Kelly:</strong> Edison, already a famous inventor, was now a legend. But by the end of the project, his personal life was a mess.</p>\n<p><strong>Karen:</strong> He was 38 years old, burned out, and had lost his first wife, Mary. Three children. His doctor says, Thomas, you need to go south, take a vacation, and take a break. He ends up arriving in St. Augustine during the winter and finds that is really too cold. It didn’t meet what his doctor had prescribed. So one of his friends takes him further down the river and they end up going by the property, which is currently today what we know as the Edison and Ford Winter Estates. What does he see but stands of bamboo growing along the riverside? He bought it on the spot.</p>\n<p><strong>Kelly:</strong> Edison remarried, and soon he and his second wife, Mina, started transforming the Florida property and its stand of bamboo into their wintertime home away from home. Edison even had an old laboratory shipped down from New Jersey in case inspiration struck while he was on vacation. You know, his lab away from lab.</p>\n<p>At first, he did some experimenting with bamboo, but then in 1905, the invention of the tungsten filament for the light bulb made the bamboo one obsolete. Soon enough, though, he would have another project to focus on.</p>\n<p>After the Fords joined the Edison family vacation in 1914, it was time for Ford to invite Edison on a trip. They went to San Francisco, and Ford introduced Edison to some friends: a botanist named Luther Burbank, who was interested in plant hybridization, and the tire magnate, Harvey Firestone, of Firestone Tires. It wasn’t long before their conversation turned to rubber.</p>\n<p>And the thing was, in order to make cars, you needed tires, and in order to make tires, you needed rubber. Back then, there was no such thing as synthetic rubber. All of it came from plants. Most natural rubber was grown in Southeast Asia, in British and Dutch colonies, and that meant the British and Dutch set rubber prices. The crew became convinced that America needed its own domestic rubber supply. Edison got to work right away.</p>\n<p><strong>Karen:</strong> So he starts looking for a product that can grow quickly, produce latex. Latex is what makes rubber. Latex is a milky white substance. If you break open the stem, out comes a sticky white milky product. That is latex and that is the basis of all natural rubber.</p>\n<p>Over 17,000 plants are brought in and studied. There were botanists, volunteers, they even engaged the Union Pacific Railroad, who instructed every section chief to collect any plants growing along their extensive miles of right-of-way and forward them to Edison’s laboratory.</p>\n<p><strong>Kelly:</strong> The Florida House essentially became a latex distilling factory. Today, if you visit, you can still see a lot of these plants that Edison was experimenting on. There’s a spiny vine called crown of thorns, which looks like a cactus; a scrubby desert shrub called guayule, which is native to Mexico; and the most spectacular specimen, or at least the biggest, was the banyan tree.</p>\n<p><strong>Karen:</strong> It’s been in place for 100 years. And over the years, it’s grown extensively. We’ve had to maintain trimming so it doesn’t just eat up the buildings. The first impression people have is they’re looking at a forest of trees.</p>\n<p><strong>Kelly</strong>: Today, the tree covers nearly an entire acre of land. It’s the largest banyan tree in the continental U.S. But unfortunately for Edison, it just did not produce enough latex.</p>\n<p><strong>Karen:</strong> In 1928, he discovers, right here in his backyard, the plant that produces the most latex is goldenrod.</p>\n<p><strong>Kelly: </strong>Goldenrod is a very fast-growing weed with yellow flowers. Looks a lot like ragweed. So Edison ripped out rows and rows of his wife Mina’s citrus trees to plant goldenrod, which I’m sure she wasn’t thrilled about.</p>\n<p><strong>Karen:</strong> He mows them all down and he transforms their estate-like atmosphere to just a conglomeration of disorderly beds with markers and irrigation ditches all around, 500 plots of yellow goldenrod. And as you can imagine, that did little to kindle her enthusiasm for his work.</p>\n<p><strong>Kelly:</strong> Speaking of Mina’s view of his work, she was annoyed about the citrus trees, yes, but she was also worried about her husband’s health. Edison was in his 80s now and still keeping pretty long hours.</p>\n<p>Mina wrote, “He thinks of nothing else now. He has no time for anything else, no recreation,” and, “Everything turned to rubber in the family. We talked rubber, thought rubber, dreamed rubber.”</p>\n<p>There was also some tension between her and Henry Ford. For one thing, Ford had bought the house right next door. That’s why the museum today is known as the Edison and Ford Estates. And another thing: Ford had convinced Edison to let him dismantle his Florida lab and ship it up to Michigan. Because Ford wanted to start a museum dedicated to American innovation, and he said he simply needed his hero’s lab. Mina was not too happy about this. Though, with the help of Ford and Firestone, Edison did end up building a brand new botanical lab.</p>\n<p>Still, by the end of the 1920s, Edison’s health got worse. He came down with pneumonia and by the fall of 1931 was bedridden in New Jersey. At one point on his deathbed, as he was slipping in and out of consciousness, someone came in with a package sent from the Florida house.</p>\n<p>Inside was a small piece of rubber made from Edison’s goldenrod plants. According to biographer Michele Albion, he had a moment of lucidity, and then sunk into a coma. Just a few days later, he died on October 18th, 1931. The Edison family kept the botanical research lab going until 1934, when it was transferred over to the Department of Agriculture.</p>\n<p><strong>Karen:</strong> But it turned out his vision of the importance became true because when World War II came about, Japan captured Malaysia, Singapore, and most of the Pacific Rim rubber plantations.</p>\n<p><strong>Kelly: </strong>During the war, there were serious rubber shortages in the U.S. The government rationed gasoline and lowered speed limits just to make tires last longer.</p>\n<p><strong>Karen:</strong> But it was shortly after that that synthetic rubber ended the goldenrod destiny. That was in 1944. And It was pretty much what Tungsten did for his carbonized bamboo filament, the synthetic rubber did to his goldenrod rubber research. But he was right. I mean, he kept people going in the right direction. Without that foundation, we probably wouldn’t have been here today.</p>\n<p><strong>Kelly: </strong>Today, the Ford and Edison Winter Estates are combined into one big museum property. You can spend hours wandering around the grounds and seeing many of the plants that we talked about in this episode. The bamboo, the goldenrod, the banyan tree, and of course, the botanical laboratory itself.</p>\n<p><strong>Karen: </strong>It’s a 21-acre paradise of discovery for people that enjoy gardens and enjoy the different textures, the structures, the colors. There’s something blooming every single day. Many, many things.</p>\n<p><strong>Kelly:</strong> In our episode description, we will post a link to more info about visiting the Edison and Ford winter estates. And if you enjoyed today’s show, check out another episode of ours called <a href=\"https://www.atlasobscura.com/articles/podcast-fordlandia\">Fordlandia</a>. It’s all about Henry Ford’s very unsuccessful attempt to start an industrial rubber town in Brazil.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. This episode was produced by Amanda McGowan. The production team for this episode includes Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Jerome Campbell, Amanda McGowan, Alexa Lim, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 28 Jan 2026 17:15:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618347Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/idaho-sun-valley-fascinating-places",
        "title": "Atlas Obscura’s Guide to Sun Valley, Idaho’s Most Fascinating Places",
        "summary": "<p>From top to bottom, Sun Valley is full of surprises. Only in this fascinating pocket of central Idaho can you experience an annual heritage festival that parades thousands of sheep from the mountains to Main Street by day, then discover some of the darkest night skies in the world for mind-blowing star gazing.</p>\n<p>In between, you’ll relax in a botanical garden’s meditative nook, and visit the gravesite of one of the world’s most notable writers and explore a moon-like national park full of caves and lava flows. Enjoy this guide to 10 wonderful ways to start your Sun Valley adventure.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">The Roundhouse</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106296/image.jpg\" width=\"auto\" /></figure>\n<p>The Roundhouse, a staple of Sun Valley Resort since 1939, elevates any dining experience—literally. Located 7,700 feet above sea level on Bald Mountain, the restaurant has been a featured fine dining spot since 1939, and is open seasonally, December through March. The octagonal restaurant, featuring 46 windows, is only accessible only by gondola, and the sweeping views of the entire valley make the views as impressive as the menu. Inside oozes with a ski chalet-style, cozy ambiance, especially the four-sided fireplace. A popular starter, the Fondue For Two, comes with artisan bread, Granny Smith apples, grapes, and gherkins. You can also add specialty meats and vegetables for an extra charge. A Wagyu burger, lobster rolls, scallops, and elk Swedish meatballs all make the menu here.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Central Idaho Dark Sky Reserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106289/image.jpg\" width=\"auto\" /></figure>\n<p>Grab your tent and experience the awe-inspiring wonder of Central Idaho’s starry, night sky in the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/the-dark-skies-of-sun-valley-id/\">Central Idaho Dark Sky Reserve</a>. One of the last remaining areas of this level of nighttime natural darkness in the world, the reserve encompasses just under 1,500 miles of public lands inside the Sawtooth National Forest. Certified by the International Dark Sky Association in 2017, and given its highest “gold tier” status, the reserve features an ultra-dark core, plus dark periphery that helps protect the central dark area. Meteor showers, lunar eclipses, spring equinox and the summer solstice are just a few of the many public viewing events held at the reserve annually. The protected wilderness areas under these dark skies are also home to a stunning array of wildlife, including bears, wolverines, elk, wolves, and sandhill cranes.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Trailing of the Sheep</strong> <strong>Festival</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106286/image.jpg\" width=\"auto\" /></figure>\n<p>Each fall, a woolly throng of sheep, roughly 1,200 in all, parade down the main street of Ketchum, Idaho, for the <a href=\"https://visitsunvalley.com/events/annual-trailing-of-the-sheep-festival/\">Trailing of the Sheep Festival</a>. The treasured annual event commemorates the time-honored migration of sheep from Idaho’s high mountain summer pastures to the warmer, grazing and lambing grounds found farther south. For five days, the community celebrates the history, culture, and traditions of the region’s longstanding sheep ranchers, which include Basques, Peruvians, and Scots. Signature events include lamb-centered culinary classes, woolmaking workshops, a heritage fair, and national sheepdog trials. The 2026 festival is October 7-11.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Craters of the Moon National Monument and Preserve</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106287/image.jpg\" width=\"auto\" /></figure>\n<p>A trip to Central Idaho’s Snake River Plain is just about as close to the moon as most of us will ever get. Aptly described as “a weird and scenic landscape” by President Calvin Coolidge when he established the 750,000-acre federally protected site in 1924, the <a href=\"https://www.atlasobscura.com/places/craters-of-the-moon-national-monument-and-preserve\">Craters of the Moon National Monument and Preserve</a> features a vast, lunar-like landscape of lava flows, cinder cones, and sagebrush. The unique environment was created thousands of years ago by a series of major eruptions along the 52-mile stretch of deep cracks in the Earth’s crust called the Great Rift. For generations, the park has garnered attention and profound fascination, and the wild terrain even served as a training ground for Apollo astronauts in the 1960s. Today, explorers enjoy discovering the park’s many lava tube caves and trails, and viewing the impressive overlooks while driving along the 7-mile Loop Road. Nature lovers and photographers also flock to the park for its surprising diversity of birds and other wildlife, plus it’s a designated dark sky park.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>Sun Valley Museum of Art</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106293/image.jpg\" width=\"auto\" /></figure>\n<p>In downtown Ketchum, the <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> is just one of the many ways to explore the rich culture of the region—off the slopes. Now an integral part of Sun Valley’s arts and culture community, this free museum opened in 1971 and has grown to feature works from greats like Andy Warhol to important pieces from local and regional artists. Equal parts museum and educational hub, the center also features interesting lecture series, live music, films, and hands-on art classes and workshops throughout the year. The exhibit, \"Hidden Gems: Idaho Collects,\" brings art held in private collections in the region into public view through February 28, 2026. The exhibit aims to illuminate the region's community through the art they make and collect</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\">Pioneer Saloon</h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106285/image.jpg\" width=\"auto\" /></figure>\n<p>One part time capsule, one part fine dining, the Pioneer Saloon is a beloved go-to for Ketchum locals and visitors alike. Located on Main Street, and affectionately called “the Pio,” the <a href=\"https://visitsunvalley.com/dining-shopping/the-pioneer-saloon/\">Pioneer Saloon</a> opened in the 1940s as a casino, despite gambling being outlawed in Idaho. Originally called the Commercial Club, the gambling hub closed its doors after just a few years, and the American Legion turned it into a meeting hall. For a short time, the facility also served as a dry goods store until, in 1950, a man named Whitey Hirschman, turned it back into a casino. Containing decades of local lore and history, the saloon won a 2025 James Beard America's Classics Award. Today, the menu consists of hearty steaks, prime rib, ribs, and seafood, including Idaho trout. Order the signature “Jim Spud,” and you’ll get a hot baked potato with teriyaki beef, cheese, and other toppings. There’s even a “Hemingway Margarita” that pays homage to the famed author whose final resting place is in Sun Valley. Amid the rustic décor inside, you’ll find antiques and artifacts, including Hemingway’s hunting rifle, Western posters and artwork, a Native American canoe and arrowheads, and more.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ernest Hemingway’s Grave</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106288/image.jpg\" width=\"auto\" /></figure>\n<p>Despite Ernest Hemingway’s flamboyant, hard-living nature, the <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">famed writer’s final resting place</a> is a simple slab in a Sun Valley cemetery. Known for his heavy drinking, hunting, and womanizing lifestyle, Hemingway lived all over, from Spain and Cuba to Florida, penning works like, “The Sun Also Rises,” “For Whom the Bell Tolls,” and the Pulitzer Prize-awarded “The Old Man and the Sea.” He visited central Idaho many times before moving to the area prior to his death in 1961. Placed alongside his wife, Mary, under two towering spruce trees, the grave is a modest rectangular marker including just the writer’s name and dates of birth and death. In addition to the expected flowers, fans also pay respects by leaving behind booze bottles, coins, matches, and pens.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Sawtooth Botanical Garden</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106297/image.jpg\" width=\"auto\" /></figure>\n<p>For a serene escape, head to the <a href=\"https://visitsunvalley.com/services/sawtooth-botanical-garden\">Sawtooth Botanical Garden</a> in Ketchum. Located on five acres, the garden, which is also an educational non profit, centers on five major display gardens that represent the varied biomes in central Idaho. One must-see feature is the colorful Tibetan prayer wheel in the Garden of Infinite Compassion. It’s the only such wheel commissioned and blessed by the Dalai Lama in North America and the only one powered by flowing water. The 1,100-pound wheel is said to symbolize peace, healing and the dissemination prayers when turned.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Wood River Museum of History &amp; Culture</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106283/image.jpg\" width=\"auto\" /></figure>\n<p>This free cultural museum in downtown Ketchum celebrates the rich and varied history of central Idaho, from its native people and immigrants to the iconic Bald Mountain and its effect on the local landscape. One exhibit at the <a href=\"https://visitsunvalley.com/to-do/wood-river-museum-of-history-and-culture/\">Wood River Museum</a>, “A Writer in the New Country: Hemingway in 1939,” highlights Ernest Hemingway’s first trip to Sun Valley, a place that was dear to the writer up until his death in 1961. Sheep shears, a telegraph key, and vintage skis are all part of the interactive Cabinet of Wonders, which houses important regional artifacts. At the museum’s entrance, another exhibit honors the Shoshone-Bannock native peoples, who first inhabited central Idaho.</p>\n<h2 class=\"article-subheading-pre-rd\" style=\"text-align: left;\"><strong>Ore Wagon Museum</strong></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106298/image.jpg\" width=\"auto\" /></figure>\n<p>This <a href=\"https://visitsunvalley.com/events/ore-wagon-museum/\">history museum in Ketchum</a> highlights the importance of ore wagons during the region’s rich mining boom of the 1880s. These sturdy wagons, donated to the museum by the Lewis family, whose Fast Freight Line was integral in transporting silver ore from remote mines to in-town railheads, are reportedly the only of their kind in existence. In honor of its mining roots, the city hosts a heritage festival, Wagon Days, every Labor Day weekend. The beloved event features live music, food vendors, cultural presentations, and culminates with the Big Hitch, a parade of these historic, non-motorized vehicles that served as the backbone of the region’s economy before the development of the railroads.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 26 Jan 2026 14:00:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618357Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618372Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/pedro-rodriguez-kissimmee",
        "title": "Pedro Rodriguez Is on a Quest for Freshness",
        "summary": "<p>When Pedro Rodriguez is in his Kissimmee, Florida restaurant, Sajoma Latin Fusion, he makes sure to check in on the kitchen. And when he does, there’s a rule that all of his cooks must follow.</p>\n<p>“I better not catch you with anything that’s artificial,” he says. Sajoma’s sancocho, for example, is made from scratch, not with bouillon, which many cooks use to build flavor quickly.</p>\n<p>The approach has paid off. Sajoma has developed an avid following in Central Florida for its approach to Latin cuisine, rooted in good ingredients and creative cooking. Pedro, gregarious and perceptive with a quick smile and a salt and pepper beard, is proud of his brainchild. He’s a grocery supplier by trade; the restaurant business is relatively new for him.</p>\n<p>Sajoma is Pedro’s most personal project yet, the capstone of a lifelong obsession with good food and good produce. And it all started on his family’s farm.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106304/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Feeding Off the Land</h3>\n<p>Until the age of 12, Pedro grew up in the town of San Jose de las Matas in the Dominican Republic. The municipality is known for its natural beauty and mineral water. “It’s almost like one of the greenest towns there,” he says. Sajoma, as the town is called for short, boasts dramatic hills, lush vegetation, and rolling rivers.</p>\n<p>And even in a beautiful town, Pedro lived a particularly idyllic life. His family owned a 120-acre farm with animals like cows, chickens, and goats, and crops including rice, beans, coffee, and yams. “We pretty much used to feed off the land,” he says. Beef was one of the only basic foodstuffs that he recalls leaving their property to obtain.</p>\n<p>The family home sat on the top of a hill. From there, Pedro could see a 360-degree view of mountains, greenery, and livestock grazing in the meadow. After school, he would hang around the house and play with the animals on their property.</p>\n<p>The men who worked for his family would hunt for crabs in caves. Pedro would go with them on their hunts, but he would watch from the side, apprehensive, as they stuck their bare hands into the darkness for huge, snapping crabs. He enjoyed the result, though: a dish called locrio where stewed crab meat releases its flavors into brown rice.</p>\n<p>Pedro grew up loving food, and it’s easy to see why. His mother was—and still is—a great cook who can turn any ingredient into a special meal. And she had the pick of ingredients in their family home. Milk from their own cows, yams dug up from their own soil. Pedro remembers his mother cooking cerdo guisado, or stewed pork, with onions and cubanelle peppers; and pasta with cooked green bananas.</p>\n<p>“The food was, like, unexplainably good, because everything was natural,” Pedro says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106305/image.jpg\" width=\"auto\" /></figure>\n<p>Twenty years ago in New York City, Pedro met his wife, Marisol, who was born in the U.S. to Dominican parents. When they were dating, she cooked him a meal that was, somehow, even better than his mother’s cooking. Pedro went home and told his mother; she was thrilled that her son had found a worthy match. And Marisol shares her in-laws’ dedication to natural cooking. “She does not use anything artificial,” Pedro says. “She’s very big on that.” That means no bouillon, and no pre-made seasonings, like the dried adobo mix that supermarkets sell.</p>\n<p>With Sajoma, Pedro’s goal was to let good ingredients sing without any additives. Customers have taken notice. Pedro says that when he walks the floor of the restaurant, diners tell him, “I literally feel like I’m eating this at home.”</p>\n<p>He believes this is testament to the power of simple cooking with no shortcuts. “Sometimes people think that you could force flavor. You don’t force flavor,” Pedro insists. With natural ingredients, “Flavor is very easy to accomplish.”</p>\n<h3 class=\"article-second-subheading-pre-rd\">From the Dominican Republic to the World</h3>\n<p>If the Rodriguez family farm was Pedro’s first culinary education, the multicultural restaurants of New York were his second. When Pedro was 12, his parents moved to New York and sent Pedro, his brother, and his sister to the city of Santiago to live with his grandparents. When Pedro was 14, his parents brought their children to the Big Apple.</p>\n<p>One might think moving from verdant island to concrete jungle would be difficult. For Pedro, it wasn’t.</p>\n<p>He received a warm welcome from his extended family, most of whom had settled in New York by the time he and his siblings got there. His first summer in New York, relatives toured him and his siblings around to the city’s parks and botanic garden. He loved the communal culture of 1980s Brooklyn, where he would wile away the day outdoors, playing ball on the streets and hanging out with his cousins. When Pedro’s mother offered to send him back to the Dominican Republic the following winter, he declined.</p>\n<p>Chief among these new experiences were the city’s food offerings. A family member blew Pedro’s mind when he took him for his first glazed donut. “I was like, ‘Holy shit!’” He remembers. “Where has this been all my life?”</p>\n<p>Pedro had a similar reaction to his first Chinese meal. Before he learned to speak English, his cousin took him to a restaurant where the staff spoke fluent Spanish with customers before calling out orders to the kitchen in Chinese. Pedro and his cousin bought fried rice with a half chicken and tostones, or fried plantains, and ate it outside on one of their stoops. “I fell in love with that,” he says.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106306/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">Starting Small and Expanding Slowly</h3>\n<p>The excited, food-loving child is very much alive in 53-year-old Pedro. He describes with equal relish his recent meal at a Peruvian restaurant as well as the locrio he ate on his family’s farm growing up. But food is also his business. In addition to Sajoma Latin Fusion in Kissimmee, Pedro owns four restaurants in New York and runs a fleet of trucks that he says supply most of New York City’s independent grocers. When asked about his secret to success in business, he uses a distinctly Dominican analogy: “I compare it to baseball players.”</p>\n<p>Many baseball players grow up playing on poorly kept fields. A ball might hit a rock, and smack you in the face. “It’s harder when you’re in the minor leagues,” he says. But, “You got to make sure that you could do that. Because once you go to the majors, the field is perfect now.”</p>\n<p>The message: “Start small,” he says, master your craft, and expand slowly.</p>\n<p>For Pedro, starting small meant working at his uncle’s grocery stores in Far Rockaway, Queens during high school. On Saturdays, he traveled with him to produce markets to stock the store. When Pedro graduated high school, he decided that he would rather spend the next few years growing a business. “What do I know at the time and what do I like at the time? Produce,” he says.</p>\n<p>So Pedro bought a van, and started delivering groceries to supermarkets, drawing on the connections he had built while working for his uncle. Soon, he bought a large truck, then two trucks. Today, he runs a fleet of 20 trucks.</p>\n<p>The road has not been easy. His equivalent of errant baseballs that threaten to hit you in the face were snowstorms that he had to fight through to deliver groceries. For years, he worked 18-hour shifts, rain, shine or snow. “I’d come home and eat, sleep for three or four hours, and go right back out there,” he remembers. He has since stepped back from physically driving trucks and delivering produce, but still helms the business.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106307/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\">A Foothold in Florida</h3>\n<p>Over the years, many family members of Pedro’s have moved to Kissimmee. A friend told him about an open lot, wondering whether Pedro would be interested in opening a restaurant there. When Pedro saw the place, disparate threads of his life knit together: his childhood spent eating fresh produce on a Dominican farm; his exposure to cuisines from every corner of the world in New York; the New York hustle that had become his way of being.</p>\n<p>“Oh my god, this is perfect,” he remembers thinking after laying eyes on the space. He wanted to build a restaurant that combined fresh ingredients, Latin American cuisine, international influences, and New York service. And he would name it “Sajoma,” after the town that started his journey.</p>\n<p>After a period of renovation and menu-tweaking, Pedro opened Sajoma Latin Fusion in August of 2022. The restaurant’s interior is sleek and spacious, with an outdoor patio and plush couches. The team makes sure the produce is fresh, hand-picking it themselves from local independent supermarkets rather than large suppliers. Sajoma’s menu dances between Latin America—especially the Caribbean—and other parts of the world, like Europe, Asia, and North America. Their tuna tartare comes on a bed of guacamole and corn chips; their burger is topped with sweet plantains; and their sancocho is made from scratch with no additives.</p>\n<p>A pair of elderly Puerto Rican ladies recently visited the restaurant and made a point of telling Pedro how much they appreciated the sancocho. “We’ve had something like this at a house,” they told him. But “we have never tried anything like this at a restaurant.” They would spread the word to their family, they said.</p>\n<p>The word, it seems, has already gotten out. The restaurant has a loyal and growing following, and it becomes a party on weekends, when DJs and bands play salsa, bachata, merengue, and more.</p>\n<p>Much of Pedro’s work has been helping the team emulate the type of prompt, attentive service that one finds at a restaurant in New York. Achieving that has taken a lot of repetition, but they’ve pulled it off. “I’m just so proud, you know?” he says.</p>\n<p>Pedro says he approaches restaurant ownership as an eater, not a cook. He is actually not much of a chef, having been blessed with great cooking in his mother’s and wife’s kitchens, and in restaurants around the world.</p>\n<p>He constantly tries new restaurants, and he acts as the president of a group of around 40 New York supermarket industry professionals that call themselves the “Friday club” because they meet up at restaurants for food and wine every Friday. It’s easy to see why he would be named president: He knows good food and has the gift of gab.</p>\n<p>Pedro’s love of conversation and a good time is part of what draws him to the restaurant business, and when he is not checking on the kitchen at Sajoma, he is walking the floor, entertaining guests. He knows what it is to work hard all week and turn to a restaurant to provide delicious food and a space to connect with friends.</p>\n<p>“I don’t have to know how to cook,” in order to run a good restaurant, he says. “I have to know how to eat.”</p>",
        "source": "www.atlasobscura.com",
        "published": "Fri, 30 Jan 2026 13:15:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618342Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "title": "Tiquira",
        "summary": "<p><img alt=\"\" height=\"200\" src=\"https://img.atlasobscura.com/AVz4e7Gut8Wj5dEAKjG4GdVeQ-Naog6rw3iXhMFXb0k/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy9mMjk5/MWM1Mi05NDFkLTRk/ODYtYjMxZC0xZTU1/OTI0ZjI2M2Q3MDUx/Mzk4NTM2MTc1YzZh/ZDhfRFNDMDk5MTUu/SlBH.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Indigenous Brazilians have fermented alcoholic beverages from the cassava root for thousands of years. These beer-like beverages go by names like </span><em><span style=\"font-weight: 400;\">cauim</span></em><span style=\"font-weight: 400;\">, </span><em><span style=\"font-weight: 400;\">caxiri</span></em><span style=\"font-weight: 400;\">, and </span><em><span style=\"font-weight: 400;\">tarubá</span></em><span style=\"font-weight: 400;\">. Fermentation is an important step in cassava processing—the raw root has chemicals that can turn into cyanide in the human body. Native peoples found that a bit of human saliva and some naturally occurring yeast could eliminate these toxins and improve the nutritious value of the tuber. When the technology of distillation arrived to the Munim River region (now in Maranhão), locals who already drank lightly alcoholic cassava beverages began to distill them. </span><em><span style=\"font-weight: 400;\">Tiquira</span></em><span style=\"font-weight: 400;\"> was born. </span></p>\n<p><span style=\"font-weight: 400;\">The name <em>tiquira</em> is likely derived from the Tupi word </span><em><span style=\"font-weight: 400;\">tykyre </span></em><span style=\"font-weight: 400;\">meaning \"to drip.\" But it is a curiosity that the spirit has flourished in only one Brazilian state, Maranhão. Margot Stinglwagner, founder of </span><a href=\"https://www.guaajatiquira.com/en/index.html\"><span style=\"font-weight: 400;\">Guaaja Tiquira</span></a><span style=\"font-weight: 400;\">, the first modern brand to produce the spirit starting in 2016, says “It’s a spirit that is also unknown in Brazil. A few people have heard about tiquira—but usually only people who have gone to Maranhão once.” Accordingly, the state moved to declare the spirit as a piece of Cultural and Intangible Heritage </span><a href=\"https://www.al.ma.leg.br/noticias/48515\"><span style=\"font-weight: 400;\">in September 2023</span></a><span style=\"font-weight: 400;\">. </span></p>\n<p><span style=\"font-weight: 400;\">Part of the reason that tiquira has remained so isolated is that cachaça, Brazil’s rum, is far easier to produce. Because the rum comes from sugarcane, the sugar for fermentation is already there. “With cassava, you don’t have sugar,” Stinglwagner explains. “You must first transform the carbohydrates into sugar and then you can ferment and distill it.” To achieve this end, Guaaja Tiquira uses food enzymes instead of the traditional human saliva. Guaaja also differs from other distillers because they use full cassava roots where most tiquira moonshiners rely on processed </span><em><span style=\"font-weight: 400;\">farinha de mandioca</span></em><span style=\"font-weight: 400;\">, or cassava flour. </span></p>\n<p><span style=\"font-weight: 400;\">“The majority of people produce it illegally,” laughs Stinglwagner. “The state does nothing about it.” Outside of the urban center, tiquira is invariably a homemade product. Generally, tiquira makers don’t separate the \"heads\" (the first drops of liquor from a distillation, which contain harsher alcohols including toxic methanol and other pungent and volatile flavor compounds) from the \"tails\" (the final liquid produced from distillation, which has a low alcohol content and can have unwelcome bitter flavors), meaning the spirit is stronger and may contain more toxins and impurities. Some even macerate marijuana into the combined spirit to produce the doubly-illicit <em>tiquiconha</em>.</span></p>\n<p><span style=\"font-weight: 400;\">Maranhenses believe that you cannot get wet or bathe after drinking tiquira, lest you become faint or dizzy. Zelinda Machado de Castro e Lima, one of the great chroniclers of folk culture in Maranhão, has recorded other traditions surrounding the drink. Firstly, it is typical to pierce a cashew with a toothpick and soak it in a glass of tiquira for several hours. It is then sucked as a sort of boozy lollipop. She also writes about the belief that those drinking coffee should avoid tiquira, while locals say that fishermen on the coast used the liquor to sanitize wounds incurred on the job. </span></p>\n<p><span style=\"font-weight: 400;\">Finally, there is the curious question of the color of tiquira. In the tourist markets of São Luís, the spirit is always blushing a translucent violet. “They say that the color of tiquira is from tangerine leaves, but we tried to do it and the color from the leaves is not stable,” says Stinglwagner. “It is also not a strong color. The norms and laws for tiquira prohibit the addition of the leaves.” The violet color may be artificial (perhaps from food dyes), but some tiquiras do have a citrusy flavor. </span></p>\n<p><span style=\"font-weight: 400;\">Tiquira today is still largely relegated to the world of moonshining, but with the government’s recognition of the spirit and new legitimate ventures like that of Guaaja Tiquira, Brazil could be seeing more of the cassava liquor outside of its home in Maranhão. </span></p>\n<p><span style=\"font-weight: 400;\">“All the people say to me, ‘What is this new spirit?,’” says Stinglwagner. “I say, ‘It’s not a new spirit, it’s the oldest spirit from Brazil.’”</span></p>\n<p><strong>Know Before You Go</strong></p>\n<p>Tiquira is widely available in the downtown markets of São Luís, Maranhão. Both the local Mercado Central and touristic Mercado das Tulhas have many vendors selling tiquira. The commercial brand, Guaaja Tiquira, is also available in São Luís at Empório Fribal, in addition to Copacabana Palace and Fairmont Hotel in Rio de Janeiro, and Mocotó Bar e Restaurante in São Paulo. </p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 03 Apr 2024 19:17:00 -0400",
        "fetched_at": "2026-02-18T23:26:46.618391Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 9.299999999999999,
        "temp_score_trend": 5.699999999999999
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "title": "Inside America’s First Destination Ski Town",
        "summary": "<p>In the heart of Idaho, about 150 miles east of Boise, the steep slopes of Bald Mountain tower over a sun-kissed valley. For roughly a century, visitors have flocked to Sun Valley from all over the country for its premiere skiing and snowboarding. But behind these sought-after slopes, there’s an impressive history and one-of-a-kind cultural experiences that make it a unique destination.</p>\n<p>Hollywood’s most celebrated stars have traveled to the valley for decades, yet Sun Valley has managed to maintain a laid-back local life and spirit even amid such A-list appeal. That rare blend of low-pretension modernity—coupled with nonstop flights from eight major metropolitan areas, including Chicago, Seattle, and Los Angeles—make Sun Valley a low-stress, culture-packed getaway.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106264/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">A History of Innovation</h2>\n<p>Long before the glistening snow and sun-soaked days helped launch Sun Valley into a skier's dreamland, a sparkle of another sort caught national attention: silver. In the 1870s, the first discoveries of the precious metal attracted prospectors from across the nation.</p>\n<p>An anchor of the region, the <a href=\"https://visitsunvalley.com/lodging/sun-valley-lodge/\">Sun Valley Resort</a>, with slopes that cater to beginners and seasoned veterans in equal measure, has hosted some of the most iconic stars of the Golden Age of Hollywood.</p>\n<p>But it was born in part out of necessity: The Great Depression hit the railroad business hard in the region. In 1936, Averell Harriman, the chairman of the Union Pacific Railroad at the time, had the idea to boost traffic on its lines by building an exclusive European-style destination ski resort. At the time there were virtually no U.S. ski areas that had upscale lodging and dining right at the slopes.</p>\n<p>To add to the must-see appeal, the resort unveiled the first-ever chairlift on nearby Proctor Mountain. The brainchild of James Curran, an engineer with the railroad, its inspiration came from a surprising place: bananas. While traveling in tropical regions, Curran had seen bananas hooked in bunches and hauled to the dock by pulley systems. Why not try the same with people?</p>\n<p>That December, “Life Magazine” featured the new technology, which helped position the resort as a go-to getaway. The lift, which moved skiers 20 feet off the ground for more than 3,500 feet with a 1,150-foot gain in elevation, opened up the sport to people who might not have otherwise had the stamina for the activity.</p>\n<p>Cinema’s elite, including Marilyn Monroe, Ingrid Bergman, Frank Sinatra and Clark Gable, stayed at the resort, and Ernest Hemingway, whose <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">burial site</a> is also in Sun Valley, finished “For Whom the Bell Tolls” in suite 206 of the Sun Valley lodge. More recently, the region has also attracted business elites and tech giants like Microsoft founder Bill Gates and Apple CEO Tim Cook.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106260/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Laid-Back Local Vibe</h2>\n<p>Today in Sun Valley Village, the walkable heart of the resort, that glamorous essence is anchored by an affable vibe and crowd-pleasing activities. The 1937 opera house now serves as a movie theater, which features films by snow and skiboard filmmaker Warren Miller, among other classics. Ice skating enthusiasts may want to check out the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/get-to-know-every-ice-rink-in-the-wood-river-valley/\">Sun Valley ice rink</a>, a known hangout for Olympic athletes as they prepare for the popular Sun Valley on Ice shows. And additional dining, shopping, and entertainment options abound in nearby Ketchum, located less than two miles down the road (which also has its own free outdoor ice rink, open from late December until mid-February).</p>\n<p>Dining in Sun Valley can be as cosmopolitan or low-key as your tastes crave. For a rustic, homestyle pick, <a href=\"https://www.kneadery.com\">The Kneadery</a> in North Ketchum serves up hearty breakfast and lunch dishes and has been a local go-to since 1974. Owners Dillon and Heather Witmer have cultivated an impressive collection of Western art and artifacts for decades, and diners will spot a canoe hanging from the dining room ceiling, while a taxidermied grizzly bear and mounted antlers on wood-paneled walls add to the cozy, lodge-like feel.</p>\n<p>For a contemporary option be sure to check out Cookbook, which offers flavor-packed bites ranging from grilled Idaho trout to house-made pesto and inventive pizzas. The restaurant, which was originally located in a 1932 church but has since moved to a larger location, serves up plenty of vegetarian options as well, and is commended by guests for its great service and family friendly atmosphere.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106259/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Vibrant Off-Slope Culture</h2>\n<p>Even if you never hit the slopes, Sun Valley is full of high-quality, even quirky, cultural experiences all year long. The <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> in Ketchum is a regional hub for contemporary and local art, formed in 1971. Each year, the museum hosts resident artists and features exhibitions and events featuring visual arts, film, music, and more.</p>\n<p>When the Wood River Valley is blanketed in snow, the region is also host to the <a href=\"https://sunvalleyfilmfestival.org\">Sun Valley Film Festival</a>, an annual, five-day event that has featured legendary filmmakers and Hollywood’s best, including Clint Eastwood, Jodie Foster, and Woody Harrelson, since 2011. Screenings, cocktail and coffee chats, and big-ticket parties honor the greatest names in film and introduce emerging artists. Monthly movies and educational programming are also offered year-round.</p>\n<p>Each January, respected culinary masters and rising food stars emerge at the <a href=\"https://visitsunvalley.com/events/sun-valley-food-wine-celebration-2/\">Sun Valley Food &amp; Wine Celebration</a>. The Sun Valley Culinary Institute hosts this popular, five-day event, featuring James Beard Award winners, champions from the Food Network “Chopped” reality show, exclusive chef dinners, cooking classes, and spirited Après Ski events.</p>\n<p>The Sun Valley Pavilion buzzes in summer with sound at the <a href=\"https://www.svmusicfestival.org\">​​Sun Valley Music Festival</a>, a month-long event that offers world-class musicians performing in a relaxed outdoor venue.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106265/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Spirited Character</h2>\n<p>Sun Valley residents take pride in their rich heritage, cause for memorable celebrations. As the trees in downtown Ketchum begin to morph from green to fiery orange and red, over a thousand sheep amble along Main Street for the <a href=\"https://www.atlasobscura.com/articles/podcast-trailing-of-the-sheep\">Trailing of the Sheep Festival</a>. Each fall, Sun Valley honors the annual sheep migration from the summer’s high mountain pastures to the warmer grazing and lambing regions in the south, an event known historically as “trailing.” The festival is packed with wool-making classes, culinary lessons, live music and folklore, and more.</p>\n<p>For Labor Day, Sun Valley residents celebrate another part of their heritage at <a href=\"https://www.wagondays.com\">Wagon Days</a>. Founded in 1958, the tradition honors the history and mining heritage of the region, including one of the weekend’s most anticipated events: the Big Hitch Parade, which showcases antique buggies, carriages, carts, and more parading through downtown Ketchum.</p>\n<p>Whether you’re an avid skier or just want to soak in sunny days as you experience a culturally rich pocket of American history, surprises await in Sun Valley.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 06 Jan 2026 16:23:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618382Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618386Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/sean-sherman-turtle-island-cookbook",
        "title": "On 'Turtle Island,' Indigenous Food Is Not the Past—It’s the Future",
        "summary": "<div>\n<p><em>Join Gastro Obscura's Sam O'Brien each week for Kitchen Dispatch as she tests new recipes and explores wondrous foods from her home kitchen. <a href=\"https://www.atlasobscura.com/newsletters/gastro-obscura\">Subscribe to get it in the Gastro newsletter</a>.</em></p>\n</div>\n<p>One of my favorite parts of researching <em>The Gastro Obscura Cookbook</em> is talking to leaders in the food world about the recipes that matter most to them. When it comes to Indigenous food of North America, few experts rival <a href=\"https://seansherman.com/\">Sean Sherman</a>. An Oglala Lakota chef raised on the Pine Ridge Reservation of South Dakota, Sherman has devoted his career to studying and promoting Indigenous cuisine.</p>\n<p>From his <a href=\"https://www.atlasobscura.com/users/hogarth/lists/minneapolis\">Minneapolis</a> restaurant, <a href=\"https://www.atlasobscura.com/places/owamni\">Owamni</a>—which focuses on native ingredients and eschews post-colonial additions like dairy, wheat flour, sugar, and pork—to his first cookbook, <a href=\"https://seansherman.com/books/\"><em>The Sioux Chef’s Indigenous Kitchen</em></a>, Sherman has made it his mission to showcase the bounty of Indigenous foodways.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106267/image.jpg\" width=\"auto\" /></figure>\n<p>But his latest project is probably his most ambitious: <a href=\"https://www.penguinrandomhouse.com/books/712577/turtle-island-by-sean-sherman-with-kate-nelson-and-kristin-donnelly/\"><em>Turtle Island</em></a>, a cookbook covering the cuisines of Indigenous communities across North America (known as “Turtle Island” to many Indigenous tribes). From Maya turkey <em>pibil</em> of the Yucatán Peninsula to Yurok hot-smoked salmon of Northern California, Sherman’s book covers an impressive swath of Indigenous culinary diversity.</p>\n<p>I recently spoke with Sherman about his new book, his mission, and the recipe that he believes best embodies Indigeneity. Here’s an excerpt of our conversation.</p>\n<p><strong>Sam O’Brien</strong>: I’d like to start by talking about <em>Turtle Island</em>, which is impressively ambitious in its scope. You’re tackling all these different regions and communities. Can you talk about the process of making it?</p>\n<p><strong>Sean Sherman:</strong> The vision was to showcase all this Indigenous diversity that’s still very much alive, erasing these colonial construct borders and looking at this tapestry of diversity. I wanted to create something that wasn’t out there for people as a resource because a book like this didn’t really exist.</p>\n<p>It felt like a continuation of my work because <em>The Sioux Chef’s Indigenous Kitchen</em> was a much smaller project. But that book was really just laying out the initial philosophy of how I was going about approaching Indigenous foods in today’s world and restructuring things, removing fry bread, removing all colonial ingredients like dairy and wheat flour, cane sugar, and beef, pork, and chicken, and just focusing on how you identify and cook what’s regional and Indigenous, and still paying homage to a lot of the tribes and their traditions.</p>\n<p>So with this book, I wanted to go a little bit bigger, and I wanted to see the connection of Indigenous peoples everywhere, whether you’re Indigenous in Southern Mexico or Northern Alaska or the middle of the United States.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106268/image.jpg\" width=\"auto\" /></figure>\n<p><strong>SO:</strong> Speaking of that vast diversity, did you learn anything in terms of how the food you grew up eating compares to other communities around North America?</p>\n<p><strong>SS:</strong> I didn't grow up with a lot of Indigenous foods, like many people in tribal communities. We grew up in segregated communities as reservation systems. A lot of us grew up with commodity foods from the government, with canned vegetables, meats, and fruits, and empty white carbs like powdered milk and sugar. It's created health epidemics in tribal communities.</p>\n<p>A lot of this work about food sovereignty is bringing an understanding of our own foods back to us. We can work on rebuilding our food systems, not be reliant on government food programs that have made us really sick, and bring a lot of pride and connection back to our ancestors.</p>\n<p>But envisioning this future means not being stuck in the past and making a couple of recipes or just adopting fry bread, but looking at so much more. Most of the recipes [in the book] were built with a future in mind because we weren’t trying to recreate the past. There’s a handful of traditional recipes in the book, but most of them are just interpretations of what we can do moving forward. To me, this is a futurist book of just looking at what would happen if we included the Indigenous perspective on our food systems and we could really showcase so much vast diversity in the regionality of our foods everywhere.</p>\n<p><strong>SO:</strong> Speaking of commodity foods and colonial ingredients, in <em>Turtle</em> <em>Island</em>, it’s striking to see the contrast between how you talk about your experience eating the commodity foods that were forced on you and how you talk about eating Indigenous foods at community gatherings. It’s so vivid reading about foods like wóžapi [a berry sauce] and tȟaníǧa [a bison or beef intestine soup]. How often were you able to eat foods like that growing up?</p>\n<p><strong>SS:</strong> We had wóžapi a few times a year. It was typically special, like holidays or birthdays. We would harvest the chokecherries as kids in the summer, and then my grandmother would make big batches of it, and we’d use it here and there. We also had a handful of foods like the tȟaníǧa, the intestine soup, like the thíŋpsiŋla [also known as “prairie turnips”].</p>\n<p>So there were a handful of recipes that survived. I didn’t have to go far back into history because this was just my grandparents’ generation that was the first generation stripped away from all their stuff. Because my grandparents were born at the beginning of the century, they grew up speaking Lakota first, but they’re one of the first generations to be pushed through boarding schools and cut their hair, learn Christianity, and just be stripped away with what it meant to be Lakota.</p>\n<p>But a lot of Lakota culture has been very strong and survived. We still have a lot of music. Our language is strong. Our stories are strong. But food was missing. So this work was really just trying to figure out why it was missing and what can we do to bring it back.</p>\n<p><strong>SO:</strong> I know it’s hard to pick one, but are there any recipes from <em>Turtle Island</em>, <em>The Sioux Chef,</em> or your restaurant that you think especially embody the story you’re trying to share with the world?</p>\n<p><strong>SS:</strong> I feel like different readers, especially if you’re from Indigenous backgrounds, will connect with different recipes from different regions. But for me, there’s a recipe called pápa waháŋpi, and it’s a dried bison soup. It’s a really traditional-style recipe, but to me, it tasted so much like home. You have the thíŋpsiŋla, the prairie turnips, from the Great Plains and the Dakotas, and a simple mushroom broth and the dried bison. It was just a really simple soup, but it had so much character to me, and it really spoke to home. It just connected to my soul.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106270/image.jpg\" width=\"auto\" /></figure>\n<p><strong>SO:</strong> I’d love to make it. I know where I live, in Philadelphia, it might be hard to track down an ingredient like prairie turnip. Is it okay to make substitutions?</p>\n<p><strong>SS:</strong> Yes. And we offered some substitutions in the book of what people can do to at least try to mimic it. But some of these will be very special, and that’s just the way it was designed. When we wrote this book, the publisher knew that not everybody was going to be able to make every recipe. We don’t have to have instant access to everything because you’re not going to find thíŋpsiŋla in the market. You’re not going to find javelina [wild boar] at your local Whole Foods, and you’re probably not going to find seal meat at Target. Some of these recipes are special; you might need to be in the right region at the right time with the right group of people to experience them.</p>\n<p><strong>SO:</strong> I get that. In some ways, the book is a reference that’s telling a story, not just being like, <em>Oh, you have to make this specific recipe</em>. It’s educational in a very beautiful way.</p>\n<p><strong>SS:</strong> Yeah. That’s what it was meant to be, to use the power of the language of food to talk about some really important things. And some of these are difficult histories. Some things we don’t learn because we grew up in America. We don’t learn about American history, except through an obscured colonial viewpoint at best. And so there’s so much to talk about everywhere, and there’s so much connection that Indigenous peoples have that they’ve had to go through. And so food is a really great way to be able to convey a lot of that knowledge.</p>\n<p class=\"p1\"><em>This interview has been edited and condensed for clarity.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Sun, 11 Jan 2026 09:20:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618377Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.9,
        "temp_score_trend": 5.1
      },
      {
        "url": "https://www.atlasobscura.com/articles/visiting-every-museum-in-new-york-city-a-q-a-with-jane-august",
        "title": "Visiting every museum in New York City",
        "summary": "<p>Jane August has made it her mission to visit every museum in New York City and five years in, she’s still discovering new ones. What began as a pandemic-era way to leave the house has turned into a sprawling, spreadsheet-powered project that’s connected her to hidden institutions, museum professionals, and a growing community of fellow culture lovers. Known as \"the museum girl\" among her fans, August documents her explorations across multiple <a href=\"https://www.janeaugust.co/every-museum-in-nyc\" rel=\"noopener noreferrer\" target=\"_blank\">social channels,</a> where she has amassed thousands of followers, and has even launched a <a href=\"https://podcasts.apple.com/us/podcast/the-next-stop-is-with-jane-august/id1740787173\" rel=\"noopener noreferrer\" target=\"_blank\">podcast.</a></p>\n<p>Atlas Obscura Executive Editor Emma Patti spoke with August about how the quest began, what’s surprised her most, and how to explore New York like a museum insider.</p>\n<p><strong>Atlas Obscura: </strong>How did this quest to visit every museum in New York City even begin?</p>\n<p><strong>Jane August:</strong> I was furloughed during the pandemic. I work in live music, bars, and venues, and suddenly all of that stopped. In the fall of 2020, some friends and I went to the Brooklyn Museum, because museums were really the only cultural spaces that had reopened.</p>\n<p>By that winter, I was like, I need to leave my house. I need to do <em>something</em> this year. All the things I usually did—shows, parties, places where people gather—weren’t options. Museums were one of the only places you could go alone and still feel like you were doing something meaningful.</p>\n<p>I thought, “There can’t be that many museums. Maybe I’ll visit them all and be done in a year or two.” That was five years ago.</p>\n<p><strong>AO:</strong> Were you surprised by how long it’s taken?</p>\n<p><strong>August:</strong> Completely. I originally thought there were maybe 150 or 160 museums in the city. I’m at about 150 visited now, so I <em>should</em> be done.</p>\n<p>But museums keep appearing. Some come out of the woodwork and say, “We don’t really post online—we’re kind of a secret museum.” Others reopen, or I’m still trying to figure out if they even exist. I’m emailing board members and stalking LinkedIn trying to confirm whether a place is real or permanently closed. The spreadsheet keeps growing.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106345/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> When you started, did you imagine this would turn into such a public project? </p>\n<p><strong>August:</strong> Not at all. Like everyone else in 2020, I was playing around on TikTok. I realized people liked New York City content, and I thought maybe some people would be interested in this project.</p>\n<p>I didn’t expect it to become my identity. I didn’t expect to be introduced as “the museum girl,” or for museum-going to become part of my brand. That part really surprised me.</p>\n<p><strong>AO:</strong> Do you visit museums outside New York the same way?</p>\n<p><strong>August:</strong> Not on this scale. When I travel, I go to museums I <em>want</em> to see. I don’t feel obligated. That’s actually when I enjoy museums the most—when I’m not thinking about how I’ll document it or explain it to other people.</p>\n<p><strong>AO:</strong> After visiting so many museums, do you have favorites?</p>\n<p><strong>August:</strong> Picking favorites is hard when you’ve been to so many. But the ones I return to a lot include Poster House—it wasn’t even on my radar at first, and now I take everyone there.</p>\n<p>I love the Museum of the City of New York and New-York Historical Society. I realized early on that I like history museums more than art museums. I just love learning things.</p>\n<p>The Museum of the Moving Image is a favorite, especially for film and TV. I also love the Nicholas Roerich Museum, the Transit Museum, the Red Hook Pinball Museum, and the Brooklyn Seltzer Museum.</p>\n<p>And then there are the big ones—the Guggenheim, the Whitney—where I now sometimes get to experience them when they’re empty or after hours. That still feels surreal.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106341/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Have any museums totally surprised you?</p>\n<p><strong>August:</strong> Definitely. The Maritime Industry Museum at Fort Schuyler was a big one. There were no photos online, and it took me over two hours to get there. I thought, “If this is one small room, I’m going to be devastated.”</p>\n<p>But it was huge. We got lost inside. It’s in a fort and covers every nautical thing you can imagine. My parents work in the maritime industry, so it was especially meaningful.</p>\n<p>I was also surprised by the New York Sign Museum, which is inside an operating sign shop, and by the Salvador Mundi Museum in Brooklyn. That one really made me think about what <em>counts</em> as a museum—it has a gift shop, a café, rotating exhibits, and events, just scaled way down. It’s almost conceptual art about museums themselves.</p>\n<p><strong>AO:</strong> How do you keep track of all this?</p>\n<p><strong>August:</strong> I have a very intense spreadsheet. I studied stage management in college, so spreadsheets are my love language.</p>\n<p>It tracks every museum, when it’s open, the neighborhood, whether I’ve contacted them, when I visited, who I went with, whether I’ve posted the video yet. Some entries are marked in red because they’re still a mystery: “Do they exist? Find out.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106342/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Do people send you tips now?</p>\n<p><strong>August:</strong> All the time. That’s how a lot of this has grown. Museum founders DM me, followers tell me about new openings, and organizations reach out when they start doing exhibitions.</p>\n<p>Sometimes I also just find museums by dragging around Google Maps. I’ll be walking to work and realize, “Wait—that’s a museum I didn’t know existed.” Then it goes on the list.</p>\n<p><strong>AO:</strong> Has this connected you to the museum world in unexpected ways?</p>\n<p><strong>August:</strong> Absolutely. I’ve met so many people in museum marketing, social media, and public engagement, and they all seem to move between institutions. Suddenly I’m being invited to places because I know someone from somewhere else.</p>\n<p>A lot of these people also have their own art practices or side projects, and I love being able to highlight that through my platform or my podcast.</p>\n<p><strong>AO:</strong> Speaking of which—how did your podcast come about?</p>\n<p><strong>August:</strong> I had a radio show in college, and I missed interviewing people. Through this museum project, I kept meeting fascinating people, but I only had a short window to tell their stories.</p>\n<p>The podcast lets me expand beyond museums. I’ve had theater people, musicians, authors—people whose stories don’t fit neatly into one niche.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106344/image.jpg\" width=\"auto\" /></figure>\n<p><strong>AO:</strong> Any tips for visiting museums?</p>\n<p><strong>August:</strong> I go in completely blind. I don’t research much beforehand, and I like being surprised. I wander.</p>\n<p>My one consistent rule is: always go to the gift shop. I buy a postcard at every museum. I send one to my mom, and whoever I go with has to send one to me. If I go alone, I’ll mail one to myself.</p>\n<p>Postcards are my way of documenting what I’ve seen. I have a giant box full of them.</p>\n<p><strong>AO:</strong> If someone had one day to explore museums in a single New York neighborhood, where should they go?</p>\n<p><strong>August:</strong> Prospect Park and Crown Heights are great—you’ve got the Brooklyn Museum, the Botanic Garden, and Lefferts Historic House.</p>\n<p>The Lower East Side is another favorite. You can do the Tenement Museum, the International Center of Photography, and the new Automatic Photo Booth Museum, plus a bunch of smaller institutions nearby.</p>\n<p>Lower Manhattan is underrated for museums, especially National Park Service sites—and you can get Junior Ranger badges at any age, which I love.</p>\n<p>And Staten Island’s Snug Harbor is basically a museum campus with multiple institutions in one beautiful area.</p>\n<p>Honestly, museums are everywhere in New York. Even after five years, I’m still finding new ones.</p>\n<hr style=\"border: 1px solid black;\" />\n<p>Jane also appeared on the Atlas Obscura podcast. Listen to her episode here.</p>\n<p></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 10 Feb 2026 08:00:00 -0500",
        "fetched_at": "2026-02-18T23:26:46.618332Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-02-18T23:25:26.027504Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-02-18T23:25:26.027946Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-02-18T23:25:26.027172Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-02-18T23:25:26.029301Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-02-18T23:25:26.028536Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-02-18T23:25:26.029628Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-02-18T23:25:26.029752Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-02-18T23:25:26.033948Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/27/huawei-vivo-and-oppo-help-establish-first-global-fast-charging-standard-under-itu/",
        "title": "Huawei, vivo, and OPPO help establish first global fast-charging standard under ITU",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/charger-marcus-urbenz-4xMAiJZPQXI-unsplash.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>The International Telecommunication Union (ITU) has approved and released L.1004, a universal fast-charging standard for mobile terminals co-authored by China’s CAICT with Huawei, vivo, and OPPO. The standard enables cross-brand and cross-device fast charging and is intended to reduce charger duplication and electronic waste. [TechNode reporting]",
        "source": "technode.com",
        "published": "Mon, 27 Oct 2025 10:51:44 +0000",
        "fetched_at": "2026-02-18T23:25:26.028038Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/01/15/dji-launches-dji-flip-a-foldable-drone-with-hand-launch-and-ai-features/",
        "title": "DJI launches DJI Flip, a foldable drone with hand launch and AI features",
        "summary": "<figure><img alt=\"DJI currently accounts for over half of all commercial drone sales in the US.\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"510\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/01/DJI-Flip.png?fit=1024%2C510&amp;ssl=1\" width=\"1024\" /></figure>Chinese drone-maker DJI on Tuesday launched the DJI Flip, a foldable drone equipped with a 1/1.3-inch image sensor capable of shooting 4K/60fps HDR videos. Weighing under 249 grams, the foldable model features a protective cover, 31-minute flight time, AI smart tracking, and hand-launch capability without a remote. Why it matters: The DJI Flip combines portability, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 15 Jan 2025 09:27:53 +0000",
        "fetched_at": "2026-02-18T23:25:26.035759Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
        "title": "danielmiessler/Personal_AI_Infrastructure",
        "summary": "<p>Agentic AI Infrastructure for magnifying HUMAN capabilities.</p><hr /><div align=\"center\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"PAI Logo\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-logo-v7.png\" width=\"300\" /> \n  \n <br /> \n <br /> \n <h1>Personal AI Infrastructure</h1> \n <p><a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure\"><img alt=\"Typing SVG\" src=\"https://readme-typing-svg.demolab.com?font=Fira+Code&amp;weight=500&amp;size=24&amp;pause=1000&amp;color=60A5FA&amp;center=true&amp;vCenter=true&amp;width=600&amp;lines=Everyone+needs+access+to+the+best+AI.;AI+should+magnify+everyone.;Your+personal+AI+stack.\" /></a></p> \n <br /> \n <!-- Social Proof --> \n <p><img alt=\"Stars\" src=\"https://img.shields.io/github/stars/danielmiessler/Personal_AI_Infrastructure?style=social\" /> <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/danielmiessler/Personal_AI_Infrastructure?style=social\" /> <img alt=\"Watchers\" src=\"https://img.shields.io/github/watchers/danielmiessler/Personal_AI_Infrastructure?style=social\" /></p> \n <!-- Project Health --> \n <p><img alt=\"Release\" src=\"https://img.shields.io/github/v/release/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=8B5CF6\" /> <img alt=\"Last Commit\" src=\"https://img.shields.io/github/last-commit/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=git&amp;color=22C55E\" /> <img alt=\"Open Issues\" src=\"https://img.shields.io/github/issues/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=F97316\" /> <img alt=\"Open PRs\" src=\"https://img.shields.io/github/issues-pr/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;color=EC4899\" /> <img alt=\"License\" src=\"https://img.shields.io/github/license/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;color=60A5FA\" /></p> \n <!-- Metrics --> \n <p><img alt=\"Discussions\" src=\"https://img.shields.io/github/discussions/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=github&amp;label=Discussions&amp;color=EAB308\" /> <img alt=\"Commit Activity\" src=\"https://img.shields.io/github/commit-activity/m/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=git&amp;label=Commits%2Fmo&amp;color=F59E0B\" /> <img alt=\"Repo Size\" src=\"https://img.shields.io/github/repo-size/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=database&amp;label=Repo%20Size&amp;color=D97706\" /></p> \n <!-- Content --> \n <p><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-installation\"><img alt=\"Get Started\" src=\"https://img.shields.io/badge/%F0%9F%9A%80_Get_Started-Install-22C55E?style=flat\" /></a> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/\"><img alt=\"Release v3.0\" src=\"https://img.shields.io/badge/%F0%9F%93%A6_Release-v3.0-8B5CF6?style=flat\" /></a> <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/graphs/contributors\"><img alt=\"Contributors\" src=\"https://img.shields.io/github/contributors/danielmiessler/Personal_AI_Infrastructure?style=flat&amp;logo=githubsponsors&amp;logoColor=white&amp;label=Contributors&amp;color=EC4899\" /></a></p> \n <!-- Tech Stack --> \n <p><a href=\"https://claude.ai\"><img alt=\"Built with Claude\" src=\"https://img.shields.io/badge/Built_with-Claude-D4A574?style=flat&amp;logo=anthropic&amp;logoColor=white\" /></a> <a href=\"https://www.typescriptlang.org/\"><img alt=\"TypeScript\" src=\"https://img.shields.io/badge/TypeScript-3178C6?style=flat&amp;logo=typescript&amp;logoColor=white\" /></a> <a href=\"https://bun.sh\"><img alt=\"Bun\" src=\"https://img.shields.io/badge/Bun-000000?style=flat&amp;logo=bun&amp;logoColor=white\" /></a> <a href=\"https://danielmiessler.com/upgrade\"><img alt=\"UL Community\" src=\"https://img.shields.io/badge/UL_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white\" /></a></p> \n <br /> \n <p><strong>Overview:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-purpose-of-this-project\">Purpose</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#what-is-pai\">What is PAI?</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#new-to-this-start-here\">New to AI?</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-pai-principles\">Principles</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#pai-primitives\">Primitives</a></p> \n <p><strong>Get Started:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-installation\">Installation</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/\">Releases</a></p> \n <p><strong>Resources:</strong> <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-faq\">FAQ</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-roadmap\">Roadmap</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-community\">Community</a> · <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-contributing\">Contributing</a></p> \n <br /> \n <p><a href=\"https://youtu.be/Le0DLrn7ta0\"><img alt=\"PAI Overview Video\" src=\"https://img.youtube.com/vi/Le0DLrn7ta0/maxresdefault.jpg\" /></a></p> \n <p><strong><a href=\"https://youtu.be/Le0DLrn7ta0\">Watch the full PAI walkthrough</a></strong> | <strong><a href=\"https://danielmiessler.com/blog/real-internet-of-things\">Read: The Real Internet of Things</a></strong></p> \n <hr /> \n</div> \n<blockquote> \n <p>[!IMPORTANT] <strong>PAI v3.0.0 Released</strong> — The Algorithm Matures: Constraint Extraction, Build Drift Prevention, Persistent PRDs, and Parallel Loop Execution.</p> \n <p><strong><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/README.md\">Release notes →</a></strong> | <strong><a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/releases/tag/v3.0.0\">GitHub Release →</a></strong></p> \n</blockquote> \n<div align=\"center\"> \n <h1>AI should magnify everyone—not just the top 1%.</h1> \n</div> \n<h2>The Purpose of This Project</h2> \n<p><strong>PAI exists to solve what I believe is the <a href=\"https://danielmiessler.com/telos\">P0 problem</a> in the world:</strong></p> \n<h3>Only a tiny fraction of humanity's creative potential is activated on Earth.</h3> \n<p>Most people don't believe they have valuable contributions to make. They think there are \"special\" people—and they aren't one of them. They've never asked who they are, what they're about, and have never articulated or written it down. This makes them catastrophically vulnerable to AI displacement. Without activation, there is no high-agency.</p> \n<p>So our goal with PAI is to activate people.</p> \n<p><strong>PAI's mission is twofold:</strong></p> \n<ol> \n <li><strong>Activate as many people as possible</strong> — Help people identify, articulate, and pursue their own purpose in life through AI-augmented self-discovery</li> \n <li><strong>Make the best AI available in the world accessible to everyone</strong> — Ensure this quality of AI infrastructure isn't reserved for just the rich or technical elite.</li> \n</ol> \n<p>That's why this is an open-source project instead of private.</p> \n<hr /> \n<h2>New to This? Start Here</h2> \n<p>You've probably used ChatGPT or Claude. Type a question, get an answer. Simple.</p> \n<p>You can think of AI systems as <strong>three levels</strong>:</p> \n<p align=\"center\"> <img alt=\"The AI Evolution - From chatbots to your personal AI system\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-eli5-diagram.png\" width=\"800\" /> </p> \n<h3>Chatbots</h3> \n<p>ChatGPT, Claude, Gemini—you ask something, it answers, and then it forgets everything. Next conversation starts fresh. No memory of you, your preferences, or what you talked about yesterday.</p> \n<p><strong>The pattern:</strong> Ask → Answer → Forget</p> \n<h3>Agentic Platforms</h3> \n<p>Tools like Claude Code. The AI can actually <em>do</em> things—write code, browse the web, edit files, run commands.</p> \n<p><strong>The pattern:</strong> Ask → Use tools → Get result</p> \n<p>More capable, but it still doesn't know <em>you</em>—your goals, your preferences, your history.</p> \n<h3>PAI (Personal AI Infrastructure)</h3> \n<p>Now your DA <strong>learns and improves</strong>:</p> \n<ul> \n <li><strong>Captures every signal</strong> — Ratings, sentiment, verification outcomes</li> \n <li><strong>Learns from mistakes</strong> — Failures get analyzed and fixed</li> \n <li><strong>Gets better over time</strong> — Success patterns get reinforced</li> \n <li><strong>Upgrades itself</strong> — Skills, workflows, even the core behavior evolves</li> \n</ul> \n<p>Plus it knows:</p> \n<ul> \n <li><strong>Your goals</strong> — What you're working toward</li> \n <li><strong>Your preferences</strong> — How you like things done</li> \n <li><strong>Your history</strong> — Past decisions and learnings</li> \n</ul> \n<p><strong>The pattern:</strong> Observe → Think → Plan → Execute → Verify → <strong>Learn</strong> → Improve</p> \n<p>The key difference: <strong>PAI learns from feedback</strong>. Every interaction makes it better at helping <em>you</em> specifically.</p> \n<hr /> \n<h2>What is PAI?</h2> \n<p>PAI is a Personalized AI Platform designed to magnify your capabilities.</p> \n<p>It's designed for humans most of all, but can be used by teams, companies, or Federations of Planets desiring to be better versions of themselves.</p> \n<p>The scale of the entity doesn't matter: It's a system for understanding, articulating, and realizing its principal's goals using a full-featured Agentic AI Platform.</p> \n<h3>Who is PAI for?</h3> \n<p><strong>Everyone, full stop.</strong> It's the anti-gatekeeping AI project.</p> \n<ul> \n <li><strong>Small business owners</strong> who aren't technical but want AI to handle invoicing, scheduling, customer follow-ups, and marketing</li> \n <li><strong>Companies</strong> who want to understand their data, optimize operations, and make better decisions</li> \n <li><strong>Managers</strong> who want to run their teams more effectively—tracking projects, preparing for reviews, and communicating clearly</li> \n <li><strong>Artists and creatives</strong> who want to find local events, galleries, and opportunities to showcase their work</li> \n <li><strong>Everyday people</strong> who want to improve their lives—better fitness routines, stronger social connections, personal finance, or just getting organized</li> \n <li><strong>Developers</strong> using AI coding assistants who want persistent memory and custom workflows</li> \n <li><strong>Power users</strong> who want their AI to know their goals, preferences, and context</li> \n <li><strong>Teams</strong> building shared AI infrastructure with consistent capabilities</li> \n <li><strong>Experimenters</strong> interested in AI system design and personal AI patterns</li> \n</ul> \n<h3>What makes PAI different?</h3> \n<p>The first thing people ask is:</p> \n<blockquote> \n <p>How is this different from Claude Code, or any of the other agentic systems?</p> \n</blockquote> \n<p>Most agentic systems are built around tools with the user being an afterthought. They are also mostly task-based instead of being goal-based using all the context available to them. PAI is the opposite.</p> \n<p><strong>Three core differentiators:</strong></p> \n<ol> \n <li> <p><strong>Goal Orientation</strong> — PAI's primary focus is on the human running it and what they're trying to do in the world, not the tech. This is built into how the system executes all tasks.</p> </li> \n <li> <p><strong>Pursuit of Optimal Output</strong> — The system's outer loop and everything it does is trying to produce the exact right output given the current situation and all the contexts around it.</p> </li> \n <li> <p><strong>Continuous Learning</strong> — The system constantly captures signals about what was done, what changes were made, what outputs were produced for each request, and then how you liked or disliked the results.</p> </li> \n</ol> \n<hr /> \n<h2>The PAI Principles</h2> \n<p>These principles guide how PAI systems are designed and built. <strong><a href=\"https://danielmiessler.com/blog/personal-ai-infrastructure\">Full breakdown →</a></strong></p> \n<table> \n <thead> \n  <tr> \n   <th>#</th> \n   <th>Principle</th> \n   <th>Summary</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>1</td> \n   <td><strong>User Centricity</strong></td> \n   <td>PAI is built around you, not tooling. Your goals, preferences, and context come first—the infrastructure exists to serve them.</td> \n  </tr> \n  <tr> \n   <td>2</td> \n   <td><strong>The Foundational Algorithm</strong></td> \n   <td>The scientific method as a universal problem-solving loop: Observe → Think → Plan → Build → Execute → Verify → Learn. Define the ideal state, iterate until you reach it.</td> \n  </tr> \n  <tr> \n   <td>3</td> \n   <td><strong>Clear Thinking First</strong></td> \n   <td>Good prompts come from clear thinking. Clarify the problem before writing the prompt.</td> \n  </tr> \n  <tr> \n   <td>4</td> \n   <td><strong>Scaffolding &gt; Model</strong></td> \n   <td>System architecture matters more than which model you use.</td> \n  </tr> \n  <tr> \n   <td>5</td> \n   <td><strong>Deterministic Infrastructure</strong></td> \n   <td>AI is probabilistic; your infrastructure shouldn't be. Use templates and patterns.</td> \n  </tr> \n  <tr> \n   <td>6</td> \n   <td><strong>Code Before Prompts</strong></td> \n   <td>If you can solve it with a bash script, don't use AI.</td> \n  </tr> \n  <tr> \n   <td>7</td> \n   <td><strong>Spec / Test / Evals First</strong></td> \n   <td>Write specifications and tests before building. Measure if the system works.</td> \n  </tr> \n  <tr> \n   <td>8</td> \n   <td><strong>UNIX Philosophy</strong></td> \n   <td>Do one thing well. Make tools composable. Use text interfaces.</td> \n  </tr> \n  <tr> \n   <td>9</td> \n   <td><strong>ENG / SRE Principles</strong></td> \n   <td>Treat AI infrastructure like production software: version control, automation, monitoring.</td> \n  </tr> \n  <tr> \n   <td>10</td> \n   <td><strong>CLI as Interface</strong></td> \n   <td>Command-line interfaces are faster, more scriptable, and more reliable than GUIs.</td> \n  </tr> \n  <tr> \n   <td>11</td> \n   <td><strong>Goal → Code → CLI → Prompts → Agents</strong></td> \n   <td>The decision hierarchy: clarify goal, then code, then CLI, then prompts, then agents.</td> \n  </tr> \n  <tr> \n   <td>12</td> \n   <td><strong>Skill Management</strong></td> \n   <td>Modular capabilities that route intelligently based on context.</td> \n  </tr> \n  <tr> \n   <td>13</td> \n   <td><strong>Memory System</strong></td> \n   <td>Everything worth knowing gets captured. History feeds future context.</td> \n  </tr> \n  <tr> \n   <td>14</td> \n   <td><strong>Agent Personalities</strong></td> \n   <td>Different work needs different approaches. Specialized agents with unique voices.</td> \n  </tr> \n  <tr> \n   <td>15</td> \n   <td><strong>Science as Meta-Loop</strong></td> \n   <td>Hypothesis → Experiment → Measure → Iterate.</td> \n  </tr> \n  <tr> \n   <td>16</td> \n   <td><strong>Permission to Fail</strong></td> \n   <td>Explicit permission to say \"I don't know\" prevents hallucinations.</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>PAI Primitives</h2> \n<p>While the Principles describe the <em>philosophy</em> of PAI, the Primitives are the <em>architecture</em>—the core systems that make everything work.</p> \n<p align=\"center\"> <img alt=\"PAI Primitives - A system that knows you, not a tool harness\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-unique-components-diagram.png\" width=\"800\" /> </p> \n<p>These primitives work together to create the experience of working with a system that understands and knows you—as opposed to a tool harness that just executes commands.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Assistant vs Agent-Based Interaction\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-1-assistant-vs-agent.png\" width=\"700\" /> </p> \n<h3>Assistant vs. Agent-Based AI Interaction</h3> \n<p>PAI treats AI as a <a href=\"https://danielmiessler.com/blog/personal-ai-maturity-model\">persistent assistant, friend, coach, and mentor</a> rather than a stateless agent that runs tasks. An assistant knows your goals, remembers your preferences, and improves over time. An agent executes commands and forgets.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"TELOS - Deep Goal Understanding\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-telos.png\" width=\"700\" /> </p> \n<h3>TELOS (Deep Goal Understanding)</h3> \n<p>10 files that capture who you are: MISSION.md, GOALS.md, PROJECTS.md, BELIEFS.md, MODELS.md, STRATEGIES.md, NARRATIVES.md, LEARNED.md, CHALLENGES.md, IDEAS.md. Your DA knows what you're working toward because it's all documented.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"User/System Separation\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-user-system-separation.png\" width=\"700\" /> </p> \n<h3>User/System Separation</h3> \n<p>Your customizations live in USER/. PAI infrastructure lives in SYSTEM/. When PAI upgrades, your files are untouched. Portable identity, upgrade-safe.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Granular Customization\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-primitive-customization.png\" width=\"700\" /> </p> \n<h3>Granular Customization</h3> \n<p>Six layers of customization: Identity (name, voice, personality), Preferences (tech stack, tools), Workflows (how skills execute), Skills (what capabilities exist), Hooks (how events are handled), and Memory (what gets captured). Start with defaults, customize when needed.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Skill System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-2-skill-system.png\" width=\"700\" /> </p> \n<h3>Skill System</h3> \n<p>Highly focused on consistent results. It has a structure that puts <em>deterministic outcomes first</em> by going from CODE -&gt; CLI-BASED-TOOL -&gt; PROMPT -&gt; SKILL instead of a haphazard structure.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Memory System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-3-memory-system.png\" width=\"700\" /> </p> \n<h3>Memory System</h3> \n<p>Focused on continuous learning. Every interaction generates signals—ratings, sentiment, successes, failures—that feed back into improving the system. Three-tier architecture (hot/warm/cold) with phase-based learning directories.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Hook System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-6-hook-system.png\" width=\"700\" /> </p> \n<h3>Hook System</h3> \n<p>Responds to lifecycle events—session start, tool use, task completion, and more. 8 event types enable voice notifications, automatic context loading, session capture, security validation, and observability.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Security System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-5-security-system.png\" width=\"700\" /> </p> \n<h3>Security System</h3> \n<p>Defines system and user-level security policies by default. You don't have to run with <code>--dangerously-skip-permissions</code> to have an uninterrupted experience. PAI's security hooks validate commands before execution, blocking dangerous operations while allowing normal workflows to proceed smoothly.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"AI-Based Installation\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-4-ai-installation.png\" width=\"700\" /> </p> \n<h3>AI-Based Installation</h3> \n<p>The GUI installer handles everything—prerequisites, configuration, and setup. No manual configuration, no guessing.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Notification System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-8-notification-system.png\" width=\"700\" /> </p> \n<h3>Notification System</h3> \n<p>Keeps you informed without being intrusive. Push notifications via ntfy for mobile alerts, Discord integration for team updates, and duration-aware routing that escalates for long-running tasks. Fire-and-forget design means notifications never block your workflow.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Voice System\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-9-voice-system.png\" width=\"700\" /> </p> \n<h3>Voice System</h3> \n<p>Powered by ElevenLabs TTS. Hear task completions, session summaries, and important updates spoken aloud. Prosody enhancement makes speech sound natural. Your AI has a voice.</p> \n<hr /> \n<p align=\"center\"> <img alt=\"Terminal-Based UI\" src=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/images/pai-component-7-terminal-ui.png\" width=\"700\" /> </p> \n<h3>Terminal-Based UI</h3> \n<p>Rich tab titles and pane management. Dynamic status lines show learning signals, context usage, and current task state. Your terminal is a command center.</p> \n<hr /> \n<h2>🚀 Installation</h2> \n<blockquote> \n <p>[!CAUTION] <strong>Project in Active Development</strong> — PAI is evolving rapidly. Expect breaking changes, restructuring, and frequent updates. We are working on stable and development branches, but currently it's all combined.</p> \n</blockquote> \n<pre><code class=\"language-bash\"># Clone the repo\ngit clone https://github.com/danielmiessler/Personal_AI_Infrastructure.git\ncd Personal_AI_Infrastructure/Releases/v3.0\n\n# Copy the release and run the installer\ncp -r .claude ~/ &amp;&amp; cd ~/.claude &amp;&amp; bash PAI-Install/install.sh\n</code></pre> \n<p><strong>The installer will:</strong></p> \n<ul> \n <li>Detect your system and install prerequisites (Bun, Git, Claude Code)</li> \n <li>Ask for your name, AI assistant name, and timezone</li> \n <li>Clone/configure the PAI repository into <code>~/.claude/</code></li> \n <li>Set up voice features with ElevenLabs (optional)</li> \n <li>Configure your shell alias and verify the installation</li> \n</ul> \n<p><strong>After installation:</strong> Run <code>source ~/.zshrc &amp;&amp; pai</code> to launch PAI.</p> \n<hr /> \n<h2>❓ FAQ</h2> \n<h3>How is PAI different from just using Claude Code?</h3> \n<p>PAI is built natively on Claude Code and designed to stay that way. We chose Claude Code because its hook system, context management, and agentic architecture are the best foundation available for personal AI infrastructure.</p> \n<p>PAI isn't a replacement for Claude Code — it's the layer on top that makes Claude Code <em>yours</em>:</p> \n<ul> \n <li><strong>Persistent memory</strong> — Your DA remembers past sessions, decisions, and learnings</li> \n <li><strong>Custom skills</strong> — Specialized capabilities for the things you do most</li> \n <li><strong>Your context</strong> — Goals, contacts, preferences—all available without re-explaining</li> \n <li><strong>Intelligent routing</strong> — Say \"research this\" and the right workflow triggers automatically</li> \n <li><strong>Self-improvement</strong> — The system modifies itself based on what it learns</li> \n</ul> \n<p>Think of it this way: Claude Code is the engine. PAI is everything else that makes it <em>your</em> car.</p> \n<h3>What's the difference between PAI and Claude Code's built-in features?</h3> \n<p>Claude Code provides powerful primitives — hooks, slash commands, MCP servers, context files. These are individual building blocks.</p> \n<p>PAI is the complete system built on those primitives. It connects everything together: your goals inform your skills, your skills generate memory, your memory improves future responses. PAI turns Claude Code's building blocks into a coherent personal AI platform.</p> \n<h3>Is PAI only for Claude Code?</h3> \n<p>PAI is Claude Code native. We believe Claude Code's hook system, context management, and agentic capabilities make it the best platform for personal AI infrastructure, and PAI is designed to take full advantage of those features.</p> \n<p>That said, PAI's concepts (skills, memory, algorithms) are universal, and the code is TypeScript, Python, and Bash — so community members are welcome to adapt it for other platforms.</p> \n<h3>How is this different from fabric?</h3> \n<p><a href=\"https://github.com/danielmiessler/fabric\">Fabric</a> is a collection of AI prompts (patterns) for specific tasks. It's focused on <em>what to ask AI</em>.</p> \n<p>PAI is infrastructure for <em>how your DA operates</em>—memory, skills, routing, context, self-improvement. They're complementary. Many PAI users integrate Fabric patterns into their skills.</p> \n<h3>What if I break something?</h3> \n<p>Recovery is straightforward:</p> \n<ul> \n <li><strong>Git-backed</strong> — Version control everything, roll back when needed</li> \n <li><strong>History is preserved</strong> — Your DA's memory survives mistakes</li> \n <li><strong>DA can fix it</strong> — Your DA helped build it, it can help repair it</li> \n <li><strong>Re-install</strong> — Run the installer again to reset to a clean state</li> \n</ul> \n<hr /> \n<h2>🎯 Roadmap</h2> \n<table> \n <thead> \n  <tr> \n   <th>Feature</th> \n   <th>Description</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Local Model Support</strong></td> \n   <td>Run PAI with local models (Ollama, llama.cpp) for privacy and cost control</td> \n  </tr> \n  <tr> \n   <td><strong>Granular Model Routing</strong></td> \n   <td>Route different tasks to different models based on complexity</td> \n  </tr> \n  <tr> \n   <td><strong>Remote Access</strong></td> \n   <td>Access your PAI from anywhere—mobile, web, other devices</td> \n  </tr> \n  <tr> \n   <td><strong>Outbound Phone Calling</strong></td> \n   <td>Voice capabilities for outbound calls</td> \n  </tr> \n  <tr> \n   <td><strong>External Notifications</strong></td> \n   <td>Robust notification system for Email, Discord, Telegram, Slack</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>🌐 Community</h2> \n<p><strong>GitHub Discussions:</strong> <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/discussions\">Join the conversation</a></p> \n<p><strong>UL Community Discord:</strong> PAI is discussed in the <a href=\"https://danielmiessler.com/upgrade\">Unsupervised Learning community</a> along with other AI projects</p> \n<p><strong>Twitter/X:</strong> <a href=\"https://twitter.com/danielmiessler\">@danielmiessler</a></p> \n<p><strong>Blog:</strong> <a href=\"https://danielmiessler.com\">danielmiessler.com</a></p> \n<h3>Star History</h3> \n<a href=\"https://star-history.com/#danielmiessler/Personal_AI_Infrastructure&amp;Date\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=danielmiessler/Personal_AI_Infrastructure&amp;type=Date\" /> \n  </a> \n<hr /> \n<h2>🤝 Contributing</h2> \n<p>We welcome contributions! See our <a href=\"https://github.com/danielmiessler/Personal_AI_Infrastructure/issues\">GitHub Issues</a> for open tasks.</p> \n<ol> \n <li><strong>Fork the repository</strong></li> \n <li><strong>Make your changes</strong> — Bug fixes, new skills, documentation improvements</li> \n <li><strong>Test thoroughly</strong> — Install in a fresh system to verify</li> \n <li><strong>Submit a PR</strong> with examples and testing evidence</li> \n</ol> \n<hr /> \n<h2>📜 License</h2> \n<p>MIT License - see <a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE\">LICENSE</a> for details.</p> \n<hr /> \n<h2>🙏 Credits</h2> \n<p><strong>Anthropic and the Claude Code team</strong> — First and foremost. You are moving AI further and faster than anyone right now. Claude Code is the foundation that makes all of this possible.</p> \n<p><strong><a href=\"https://www.youtube.com/@indydevdan\">IndyDevDan</a></strong> — For great videos on meta-prompting and custom agents that have inspired parts of PAI.</p> \n<h3>Contributors</h3> \n<p><strong><a href=\"https://github.com/fayerman-source\">fayerman-source</a></strong> — Google Cloud TTS provider integration and Linux audio support for the voice system.</p> \n<p><strong>Matt Espinoza</strong> — Extensive testing, ideas, and feedback for the PAI 2.3 release, plus roadmap contributions.</p> \n<hr /> \n<h2>💜 Support This Project</h2> \n<div align=\"center\"> \n <p><a href=\"https://github.com/sponsors/danielmiessler\"><img alt=\"Sponsor\" src=\"https://img.shields.io/badge/Sponsor-❤️-EA4AAA?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white\" /></a></p> \n <p><strong>PAI is free and open-source forever. If you find it valuable, you can <a href=\"https://github.com/sponsors/danielmiessler\">sponsor the project</a>.</strong></p> \n</div> \n<hr /> \n<h2>📚 Related Reading</h2> \n<ul> \n <li><a href=\"https://danielmiessler.com/blog/real-internet-of-things\">The Real Internet of Things</a> — The vision behind PAI</li> \n <li><a href=\"https://danielmiessler.com/blog/ai-predictable-path-7-components-2024\">AI's Predictable Path: 7 Components</a> — Visual walkthrough of where AI is heading</li> \n <li><a href=\"https://danielmiessler.com/blog/personal-ai-infrastructure\">Building a Personal AI Infrastructure</a> — Full PAI walkthrough with examples</li> \n</ul> \n<hr /> \n<details> \n <strong>📜 Update History</strong> \n <br /> \n <p><strong>v3.0.0 (2026-02-15) — The Algorithm Matures</strong></p> \n <ul> \n  <li>Algorithm v1.4.0 with constraint extraction and build drift prevention</li> \n  <li>Persistent PRDs and parallel loop execution</li> \n  <li>Full installer with GUI wizard</li> \n  <li>10 new skills, agent teams/swarm, voice personality system</li> \n  <li>38 skills, 20 hooks, 162 workflows</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v3.0/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.5.0 (2026-01-30) — Think Deeper, Execute Faster</strong></p> \n <ul> \n  <li>Two-Pass Capability Selection: Hook hints validated against ISC in THINK phase</li> \n  <li>Thinking Tools with Justify-Exclusion: Opt-OUT, not opt-IN for Council, RedTeam, FirstPrinciples, etc.</li> \n  <li>Parallel-by-Default Execution: Independent tasks run concurrently via parallel agent spawning</li> \n  <li>28 skills, 17 hooks, 356 workflows</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.5/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.4.0 (2026-01-23) — The Algorithm</strong></p> \n <ul> \n  <li>Universal problem-solving system with ISC (Ideal State Criteria) tracking</li> \n  <li>29 skills, 15 hooks, 331 workflows</li> \n  <li>Euphoric Surprise as the outcome metric</li> \n  <li>Enhanced security with AllowList enforcement</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.4/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.3.0 (2026-01-15) — Full Releases Return</strong></p> \n <ul> \n  <li>Complete <code>.claude/</code> directory releases with continuous learning</li> \n  <li>Explicit and implicit rating capture</li> \n  <li>Enhanced hook system with 14 production hooks</li> \n  <li>Status line with learning signal display</li> \n  <li><a href=\"https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Releases/v2.3/README.md\">Release Notes</a></li> \n </ul> \n <p><strong>v2.1.1 (2026-01-09) — MEMORY System Migration</strong></p> \n <ul> \n  <li>History system merged into core as MEMORY System</li> \n </ul> \n <p><strong>v2.1.0 (2025-12-31) — Modular Architecture</strong></p> \n <ul> \n  <li>Source code in real files instead of embedded markdown</li> \n </ul> \n <p><strong>v2.0.0 (2025-12-28) — PAI v2 Launch</strong></p> \n <ul> \n  <li>Modular architecture with independent skills</li> \n  <li>Claude Code native design</li> \n </ul> \n</details> \n<hr /> \n<div align=\"center\"> \n <p><strong>Built with ❤️ by <a href=\"https://danielmiessler.com\">Daniel Miessler</a> and the PAI community</strong></p> \n <p><em>Augment yourself.</em></p> \n</div>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:38.373563Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 30,
        "timeliness_score": 1,
        "final_score": 15.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/summarize",
        "title": "steipete/summarize",
        "summary": "<p>Point at any URL/YouTube/Podcast or file. Get the gist. CLI and Chrome Extension.</p><hr /><h1>Summarize 📝 — Chrome Side Panel + CLI</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=Summarize%F0%9F%93%9D&amp;subheader=Chrome+Side+Panel+%2B+CLI&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast summaries from URLs, files, and media. Works in the terminal, a Chrome Side Panel and Firefox Sidebar.</p> \n<p><strong>0.11.0 preview (unreleased):</strong> this README reflects the upcoming release.</p> \n<h2>0.11.0 preview highlights (most interesting first)</h2> \n<ul> \n <li>Chrome Side Panel <strong>chat</strong> (streaming agent + history) inside the sidebar.</li> \n <li><strong>YouTube slides</strong>: screenshots + OCR + transcript cards, timestamped seek, OCR/Transcript toggle.</li> \n <li>Media-aware summaries: auto‑detect video/audio vs page content.</li> \n <li>Streaming Markdown + metrics + cache‑aware status.</li> \n <li>CLI supports URLs, files, podcasts, YouTube, audio/video, PDFs.</li> \n</ul> \n<h2>Feature overview</h2> \n<ul> \n <li>URLs, files, and media: web pages, PDFs, images, audio/video, YouTube, podcasts, RSS.</li> \n <li>Slide extraction for video sources (YouTube/direct media) with OCR + timestamped cards.</li> \n <li>Transcript-first media flow: published transcripts when available, Whisper fallback when not.</li> \n <li>Streaming output with Markdown rendering, metrics, and cache-aware status.</li> \n <li>Local, paid, and free models: OpenAI‑compatible local endpoints, paid providers, plus an OpenRouter free preset.</li> \n <li>Output modes: Markdown/text, JSON diagnostics, extract-only, metrics, timing, and cost estimates.</li> \n <li>Smart default: if content is shorter than the requested length, we return it as-is (use <code>--force-summary</code> to override).</li> \n</ul> \n<h2>Get the extension (recommended)</h2> \n<p><img alt=\"Summarize extension screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-extension.png\" /></p> \n<p>One‑click summarizer for the current tab. Chrome Side Panel + Firefox Sidebar + local daemon for streaming Markdown.</p> \n<p><strong>Chrome Web Store:</strong> <a href=\"https://chromewebstore.google.com/detail/summarize/cejgnmmhbbpdmjnfppjdfkocebngehfg\">Summarize Side Panel</a></p> \n<p>YouTube slide screenshots (from the browser):</p> \n<p><img alt=\"Summarize YouTube slide screenshots\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/youtube-slides.png\" /></p> \n<h3>Beginner quickstart (extension)</h3> \n<ol> \n <li>Install the CLI (choose one): \n  <ul> \n   <li><strong>npm</strong> (cross‑platform): <code>npm i -g @steipete/summarize</code></li> \n   <li><strong>Homebrew</strong> (macOS arm64): <code>brew install steipete/tap/summarize</code></li> \n  </ul> </li> \n <li>Install the extension (Chrome Web Store link above) and open the Side Panel.</li> \n <li>The panel shows a token + install command. Run it in Terminal: \n  <ul> \n   <li><code>summarize daemon install --token &lt;TOKEN&gt;</code></li> \n  </ul> </li> \n</ol> \n<p>Why a daemon/service?</p> \n<ul> \n <li>The extension can’t run heavy extraction inside the browser. It talks to a local background service on <code>127.0.0.1</code> for fast streaming and media tools (yt‑dlp, ffmpeg, OCR, transcription).</li> \n <li>The service autostarts (launchd/systemd/Scheduled Task) so the Side Panel is always ready.</li> \n</ul> \n<p>If you only want the <strong>CLI</strong>, you can skip the daemon install entirely.</p> \n<p>Notes:</p> \n<ul> \n <li>Summarization only runs when the Side Panel is open.</li> \n <li>Auto mode summarizes on navigation (incl. SPAs); otherwise use the button.</li> \n <li>Daemon is localhost-only and requires a shared token.</li> \n <li>Autostart: macOS (launchd), Linux (systemd user), Windows (Scheduled Task).</li> \n <li>Tip: configure <code>free</code> via <code>summarize refresh-free</code> (needs <code>OPENROUTER_API_KEY</code>). Add <code>--set-default</code> to set model=<code>free</code>.</li> \n</ul> \n<p>More:</p> \n<ul> \n <li>Step-by-step install: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/README.md\">apps/chrome-extension/README.md</a></li> \n <li>Architecture + troubleshooting: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/chrome-extension.md\">docs/chrome-extension.md</a></li> \n <li>Firefox compatibility notes: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/docs/firefox.md\">apps/chrome-extension/docs/firefox.md</a></li> \n</ul> \n<h3>Slides (extension)</h3> \n<ul> \n <li>Select <strong>Video + Slides</strong> in the Summarize picker.</li> \n <li>Slides render at the top; expand to full‑width cards with timestamps.</li> \n <li>Click a slide to seek the video; toggle <strong>Transcript/OCR</strong> when OCR is significant.</li> \n <li>Requirements: <code>yt-dlp</code> + <code>ffmpeg</code> for extraction; <code>tesseract</code> for OCR. Missing tools show an in‑panel notice.</li> \n</ul> \n<h3>Advanced (unpacked / dev)</h3> \n<ol> \n <li>Build + load the extension (unpacked): \n  <ul> \n   <li>Chrome: <code>pnpm -C apps/chrome-extension build</code> \n    <ul> \n     <li><code>chrome://extensions</code> → Developer mode → Load unpacked</li> \n     <li>Pick: <code>apps/chrome-extension/.output/chrome-mv3</code></li> \n    </ul> </li> \n   <li>Firefox: <code>pnpm -C apps/chrome-extension build:firefox</code> \n    <ul> \n     <li><code>about:debugging#/runtime/this-firefox</code> → Load Temporary Add-on</li> \n     <li>Pick: <code>apps/chrome-extension/.output/firefox-mv3/manifest.json</code></li> \n    </ul> </li> \n  </ul> </li> \n <li>Open Side Panel/Sidebar → copy token.</li> \n <li>Install daemon in dev mode: \n  <ul> \n   <li><code>pnpm summarize daemon install --token &lt;TOKEN&gt; --dev</code></li> \n  </ul> </li> \n</ol> \n<h2>CLI</h2> \n<p><img alt=\"Summarize CLI screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-cli.png\" /></p> \n<h3>Install</h3> \n<p>Requires Node 22+.</p> \n<ul> \n <li>npx (no install):</li> \n</ul> \n<pre><code class=\"language-bash\">npx -y @steipete/summarize \"https://example.com\"\n</code></pre> \n<ul> \n <li>npm (global):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i -g @steipete/summarize\n</code></pre> \n<ul> \n <li>npm (library / minimal deps):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i @steipete/summarize-core\n</code></pre> \n<pre><code class=\"language-ts\">import { createLinkPreviewClient } from \"@steipete/summarize-core/content\";\n</code></pre> \n<ul> \n <li>Homebrew (custom tap):</li> \n</ul> \n<pre><code class=\"language-bash\">brew install steipete/tap/summarize\n</code></pre> \n<p>Apple Silicon only (arm64).</p> \n<h3>CLI vs extension</h3> \n<ul> \n <li><strong>CLI only:</strong> just install via npm/Homebrew and run <code>summarize ...</code> (no daemon needed).</li> \n <li><strong>Chrome/Firefox extension:</strong> install the CLI <strong>and</strong> run <code>summarize daemon install --token &lt;TOKEN&gt;</code> so the Side Panel can stream results and use local tools.</li> \n</ul> \n<h3>Quickstart</h3> \n<pre><code class=\"language-bash\">summarize \"https://example.com\"\n</code></pre> \n<h3>Inputs</h3> \n<p>URLs or local paths:</p> \n<pre><code class=\"language-bash\">summarize \"/path/to/file.pdf\" --model google/gemini-3-flash-preview\nsummarize \"https://example.com/report.pdf\" --model google/gemini-3-flash-preview\nsummarize \"/path/to/audio.mp3\"\nsummarize \"/path/to/video.mp4\"\n</code></pre> \n<p>Stdin (pipe content using <code>-</code>):</p> \n<pre><code class=\"language-bash\">echo \"content\" | summarize -\npbpaste | summarize -\n# binary stdin also works (PDF/image/audio/video bytes)\ncat /path/to/file.pdf | summarize -\n</code></pre> \n<p><strong>Notes:</strong></p> \n<ul> \n <li>Stdin has a 50MB size limit</li> \n <li>The <code>-</code> argument tells summarize to read from standard input</li> \n <li>Text stdin is treated as UTF-8 text (whitespace-only input is rejected as empty)</li> \n <li>Binary stdin is preserved as raw bytes and file type is auto-detected when possible</li> \n <li>Useful for piping clipboard content or command output</li> \n</ul> \n<p>YouTube (supports <code>youtube.com</code> and <code>youtu.be</code>):</p> \n<pre><code class=\"language-bash\">summarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto\n</code></pre> \n<p>Podcast RSS (transcribes latest enclosure):</p> \n<pre><code class=\"language-bash\">summarize \"https://feeds.npr.org/500005/podcast.xml\"\n</code></pre> \n<p>Apple Podcasts episode page:</p> \n<pre><code class=\"language-bash\">summarize \"https://podcasts.apple.com/us/podcast/2424-jelly-roll/id360084272?i=1000740717432\"\n</code></pre> \n<p>Spotify episode page (best-effort; may fail for exclusives):</p> \n<pre><code class=\"language-bash\">summarize \"https://open.spotify.com/episode/5auotqWAXhhKyb9ymCuBJY\"\n</code></pre> \n<h3>Output length</h3> \n<p><code>--length</code> controls how much output we ask for (guideline), not a hard cap.</p> \n<pre><code class=\"language-bash\">summarize \"https://example.com\" --length long\nsummarize \"https://example.com\" --length 20k\n</code></pre> \n<ul> \n <li>Presets: <code>short|medium|long|xl|xxl</code></li> \n <li>Character targets: <code>1500</code>, <code>20k</code>, <code>20000</code></li> \n <li>Optional hard cap: <code>--max-output-tokens &lt;count&gt;</code> (e.g. <code>2000</code>, <code>2k</code>) \n  <ul> \n   <li>Provider/model APIs still enforce their own maximum output limits.</li> \n   <li>If omitted, no max token parameter is sent (provider default).</li> \n   <li>Prefer <code>--length</code> unless you need a hard cap.</li> \n  </ul> </li> \n <li>Short content: when extracted content is shorter than the requested length, the CLI returns the content as-is. \n  <ul> \n   <li>Override with <code>--force-summary</code> to always run the LLM.</li> \n  </ul> </li> \n <li>Minimums: <code>--length</code> numeric values must be &gt;= 50 chars; <code>--max-output-tokens</code> must be &gt;= 16.</li> \n <li>Preset targets (source of truth: <code>packages/core/src/prompts/summary-lengths.ts</code>): \n  <ul> \n   <li>short: target ~900 chars (range 600-1,200)</li> \n   <li>medium: target ~1,800 chars (range 1,200-2,500)</li> \n   <li>long: target ~4,200 chars (range 2,500-6,000)</li> \n   <li>xl: target ~9,000 chars (range 6,000-14,000)</li> \n   <li>xxl: target ~17,000 chars (range 14,000-22,000)</li> \n  </ul> </li> \n</ul> \n<h3>What file types work?</h3> \n<p>Best effort and provider-dependent. These usually work well:</p> \n<ul> \n <li><code>text/*</code> and common structured text (<code>.txt</code>, <code>.md</code>, <code>.json</code>, <code>.yaml</code>, <code>.xml</code>, ...) \n  <ul> \n   <li>Text-like files are inlined into the prompt for better provider compatibility.</li> \n  </ul> </li> \n <li>PDFs: <code>application/pdf</code> (provider support varies; Google is the most reliable here)</li> \n <li>Images: <code>image/jpeg</code>, <code>image/png</code>, <code>image/webp</code>, <code>image/gif</code></li> \n <li>Audio/Video: <code>audio/*</code>, <code>video/*</code> (local audio/video files MP3/WAV/M4A/OGG/FLAC/MP4/MOV/WEBM automatically transcribed, when supported by the model)</li> \n</ul> \n<p>Notes:</p> \n<ul> \n <li>If a provider rejects a media type, the CLI fails fast with a friendly message.</li> \n <li>xAI models do not support attaching generic files (like PDFs) via the AI SDK; use Google/OpenAI/Anthropic for those.</li> \n</ul> \n<h3>Model ids</h3> \n<p>Use gateway-style ids: <code>&lt;provider&gt;/&lt;model&gt;</code>.</p> \n<p>Examples:</p> \n<ul> \n <li><code>openai/gpt-5-mini</code></li> \n <li><code>anthropic/claude-sonnet-4-5</code></li> \n <li><code>xai/grok-4-fast-non-reasoning</code></li> \n <li><code>google/gemini-3-flash-preview</code></li> \n <li><code>zai/glm-4.7</code></li> \n <li><code>openrouter/openai/gpt-5-mini</code> (force OpenRouter)</li> \n</ul> \n<p>Note: some models/providers do not support streaming or certain file media types. When that happens, the CLI prints a friendly error (or auto-disables streaming for that model when supported by the provider).</p> \n<h3>Limits</h3> \n<ul> \n <li>Text inputs over 10 MB are rejected before tokenization.</li> \n <li>Text prompts are preflighted against the model input limit (LiteLLM catalog), using a GPT tokenizer.</li> \n</ul> \n<h3>Common flags</h3> \n<pre><code class=\"language-bash\">summarize &lt;input&gt; [flags]\n</code></pre> \n<p>Use <code>summarize --help</code> or <code>summarize help</code> for the full help text.</p> \n<ul> \n <li><code>--model &lt;provider/model&gt;</code>: which model to use (defaults to <code>auto</code>)</li> \n <li><code>--model auto</code>: automatic model selection + fallback (default)</li> \n <li><code>--model &lt;name&gt;</code>: use a config-defined model (see Configuration)</li> \n <li><code>--timeout &lt;duration&gt;</code>: <code>30s</code>, <code>2m</code>, <code>5000ms</code> (default <code>2m</code>)</li> \n <li><code>--retries &lt;count&gt;</code>: LLM retry attempts on timeout (default <code>1</code>)</li> \n <li><code>--length short|medium|long|xl|xxl|s|m|l|&lt;chars&gt;</code></li> \n <li><code>--language, --lang &lt;language&gt;</code>: output language (<code>auto</code> = match source)</li> \n <li><code>--max-output-tokens &lt;count&gt;</code>: hard cap for LLM output tokens</li> \n <li><code>--cli [provider]</code>: use a CLI provider (<code>--model cli/&lt;provider&gt;</code>). Supports <code>claude</code>, <code>gemini</code>, <code>codex</code>, <code>agent</code>. If omitted, uses auto selection with CLI enabled.</li> \n <li><code>--stream auto|on|off</code>: stream LLM output (<code>auto</code> = TTY only; disabled in <code>--json</code> mode)</li> \n <li><code>--plain</code>: keep raw output (no ANSI/OSC Markdown rendering)</li> \n <li><code>--no-color</code>: disable ANSI colors</li> \n <li><code>--theme &lt;name&gt;</code>: CLI theme (<code>aurora</code>, <code>ember</code>, <code>moss</code>, <code>mono</code>)</li> \n <li><code>--format md|text</code>: website/file content format (default <code>text</code>)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code>: HTML -&gt; Markdown mode (default <code>readability</code>)</li> \n <li><code>--preprocess off|auto|always</code>: controls <code>uvx markitdown</code> usage (default <code>auto</code>) \n  <ul> \n   <li>Install <code>uvx</code>: <code>brew install uv</code> (or <a href=\"https://astral.sh/uv/\">https://astral.sh/uv/</a>)</li> \n  </ul> </li> \n <li><code>--extract</code>: print extracted content and exit (URLs only; stdin <code>-</code> is not supported) \n  <ul> \n   <li>Deprecated alias: <code>--extract-only</code></li> \n  </ul> </li> \n <li><code>--slides</code>: extract slides for YouTube/direct video URLs and render them inline in the summary narrative (auto-renders inline in supported terminals)</li> \n <li><code>--slides-ocr</code>: run OCR on extracted slides (requires <code>tesseract</code>)</li> \n <li><code>--slides-dir &lt;dir&gt;</code>: base output dir for slide images (default <code>./slides</code>)</li> \n <li><code>--slides-scene-threshold &lt;value&gt;</code>: scene detection threshold (0.1-1.0)</li> \n <li><code>--slides-max &lt;count&gt;</code>: maximum slides to extract (default <code>6</code>)</li> \n <li><code>--slides-min-duration &lt;seconds&gt;</code>: minimum seconds between slides</li> \n <li><code>--json</code>: machine-readable output with diagnostics, prompt, <code>metrics</code>, and optional summary</li> \n <li><code>--verbose</code>: debug/diagnostics on stderr</li> \n <li><code>--metrics off|on|detailed</code>: metrics output (default <code>on</code>)</li> \n</ul> \n<h3>Coding CLIs (Codex, Claude, Gemini, Agent)</h3> \n<p>Summarize can use common coding CLIs as local model backends:</p> \n<ul> \n <li><code>codex</code> -&gt; <code>--cli codex</code> / <code>--model cli/codex/&lt;model&gt;</code></li> \n <li><code>claude</code> -&gt; <code>--cli claude</code> / <code>--model cli/claude/&lt;model&gt;</code></li> \n <li><code>gemini</code> -&gt; <code>--cli gemini</code> / <code>--model cli/gemini/&lt;model&gt;</code></li> \n <li><code>agent</code> (Cursor Agent CLI) -&gt; <code>--cli agent</code> / <code>--model cli/agent/&lt;model&gt;</code></li> \n</ul> \n<p>Requirements:</p> \n<ul> \n <li>Binary installed and on <code>PATH</code> (or set <code>CODEX_PATH</code>, <code>CLAUDE_PATH</code>, <code>GEMINI_PATH</code>, <code>AGENT_PATH</code>)</li> \n <li>Provider authenticated (<code>codex login</code>, <code>claude auth</code>, <code>gemini</code> login flow, <code>agent login</code> or <code>CURSOR_API_KEY</code>)</li> \n</ul> \n<p>Quick smoke test:</p> \n<pre><code class=\"language-bash\">printf \"Summarize CLI smoke input.\\nOne short paragraph. Reply can be brief.\\n\" &gt;/tmp/summarize-cli-smoke.txt\n\nsummarize --cli codex --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli claude --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli gemini --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli agent --plain --timeout 2m /tmp/summarize-cli-smoke.txt\n</code></pre> \n<p>Set explicit CLI allowlist/order:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"codex\", \"claude\", \"gemini\", \"agent\"] }\n}\n</code></pre> \n<p>Configure implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": {\n    \"autoFallback\": {\n      \"enabled\": true,\n      \"onlyWhenNoApiKeys\": true,\n      \"order\": [\"claude\", \"gemini\", \"codex\", \"agent\"]\n    }\n  }\n}\n</code></pre> \n<p>More details: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\"><code>docs/cli.md</code></a></p> \n<h3>Auto model ordering</h3> \n<p><code>--model auto</code> builds candidate attempts from built-in rules (or your <code>model.rules</code> overrides). CLI attempts are prepended when:</p> \n<ul> \n <li><code>cli.enabled</code> is set (explicit allowlist/order), or</li> \n <li>implicit auto selection is active and <code>cli.autoFallback</code> is enabled.</li> \n</ul> \n<p>Default fallback behavior: only when no API keys are configured, order <code>claude, gemini, codex, agent</code>, and remember/prioritize last successful provider (<code>~/.summarize/cli-state.json</code>).</p> \n<p>Set explicit CLI attempts:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"gemini\"] }\n}\n</code></pre> \n<p>Disable implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"autoFallback\": { \"enabled\": false } }\n}\n</code></pre> \n<p>Note: explicit <code>--model auto</code> does not trigger implicit auto CLI fallback unless <code>cli.enabled</code> is set.</p> \n<h3>Website extraction (Firecrawl + Markdown)</h3> \n<p>Non-YouTube URLs go through a fetch -&gt; extract pipeline. When direct fetch/extraction is blocked or too thin, <code>--firecrawl auto</code> can fall back to Firecrawl (if configured).</p> \n<ul> \n <li><code>--firecrawl off|auto|always</code> (default <code>auto</code>)</li> \n <li><code>--extract --format md|text</code> (default <code>text</code>; if <code>--format</code> is omitted, <code>--extract</code> defaults to <code>md</code> for non-YouTube URLs)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code> (default <code>readability</code>) \n  <ul> \n   <li><code>auto</code>: use an LLM converter when configured; may fall back to <code>uvx markitdown</code></li> \n   <li><code>llm</code>: force LLM conversion (requires a configured model key)</li> \n   <li><code>off</code>: disable LLM conversion (still may return Firecrawl Markdown when configured)</li> \n  </ul> </li> \n <li>Plain-text mode: use <code>--format text</code>.</li> \n</ul> \n<h3>YouTube transcripts</h3> \n<p><code>--youtube auto</code> tries best-effort web transcript endpoints first. When captions are not available, it falls back to:</p> \n<ol> \n <li>Apify (if <code>APIFY_API_TOKEN</code> is set): uses a scraping actor (<code>faVsWy9VTSNVIhWpR</code>)</li> \n <li>yt-dlp + Whisper (if <code>yt-dlp</code> is available): downloads audio, then transcribes with local <code>whisper.cpp</code> when installed (preferred), otherwise falls back to OpenAI (<code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>)</li> \n</ol> \n<p>Environment variables for yt-dlp mode:</p> \n<ul> \n <li><code>YT_DLP_PATH</code> - optional path to yt-dlp binary (otherwise <code>yt-dlp</code> is resolved via <code>PATH</code>)</li> \n <li><code>SUMMARIZE_WHISPER_CPP_MODEL_PATH</code> - optional override for the local <code>whisper.cpp</code> model file</li> \n <li><code>SUMMARIZE_WHISPER_CPP_BINARY</code> - optional override for the local binary (default: <code>whisper-cli</code>)</li> \n <li><code>SUMMARIZE_DISABLE_LOCAL_WHISPER_CPP=1</code> - disable local whisper.cpp (force remote)</li> \n <li><code>OPENAI_API_KEY</code> - OpenAI Whisper transcription</li> \n <li><code>OPENAI_WHISPER_BASE_URL</code> - optional OpenAI-compatible Whisper endpoint override</li> \n <li><code>FAL_KEY</code> - FAL AI Whisper fallback</li> \n</ul> \n<p>Apify costs money but tends to be more reliable when captions exist.</p> \n<h3>Slide extraction (YouTube + direct video URLs)</h3> \n<p>Extract slide screenshots (scene detection via <code>ffmpeg</code>) and optional OCR:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --slides\nsummarize \"https://www.youtube.com/watch?v=...\" --slides --slides-ocr\n</code></pre> \n<p>Outputs are written under <code>./slides/&lt;sourceId&gt;/</code> (or <code>--slides-dir</code>). OCR results are included in JSON output (<code>--json</code>) and stored in <code>slides.json</code> inside the slide directory. When scene detection is too sparse, the extractor also samples at a fixed interval to improve coverage. When using <code>--slides</code>, supported terminals (kitty/iTerm/Konsole) render inline thumbnails automatically inside the summary narrative (the model inserts <code>[slide:N]</code> markers). Timestamp links are clickable when the terminal supports OSC-8 (YouTube/Vimeo/Loom/Dropbox). If inline images are unsupported, Summarize prints a note with the on-disk slide directory.</p> \n<p>Use <code>--slides --extract</code> to print the full timed transcript and insert slide images inline at matching timestamps.</p> \n<p>Format the extracted transcript as Markdown (headings + paragraphs) via an LLM:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --extract --format md --markdown-mode llm\n</code></pre> \n<h3>Media transcription (Whisper)</h3> \n<p>Local audio/video files are transcribed first, then summarized. <code>--video-mode transcript</code> forces direct media URLs (and embedded media) through Whisper first. Prefers local <code>whisper.cpp</code> when available; otherwise requires <code>OPENAI_API_KEY</code> or <code>FAL_KEY</code>.</p> \n<h3>Local ONNX transcription (Parakeet/Canary)</h3> \n<p>Summarize can use NVIDIA Parakeet/Canary ONNX models via a local CLI you provide. Auto selection (default) prefers ONNX when configured.</p> \n<ul> \n <li>Setup helper: <code>summarize transcriber setup</code></li> \n <li>Install <code>sherpa-onnx</code> from upstream binaries/build (Homebrew may not have a formula)</li> \n <li>Auto selection: set <code>SUMMARIZE_ONNX_PARAKEET_CMD</code> or <code>SUMMARIZE_ONNX_CANARY_CMD</code> (no flag needed)</li> \n <li>Force a model: <code>--transcriber parakeet|canary|whisper|auto</code></li> \n <li>Docs: <code>docs/nvidia-onnx-transcription.md</code></li> \n</ul> \n<h3>Verified podcast services (2025-12-25)</h3> \n<p>Run: <code>summarize &lt;url&gt;</code></p> \n<ul> \n <li>Apple Podcasts</li> \n <li>Spotify</li> \n <li>Amazon Music / Audible podcast pages</li> \n <li>Podbean</li> \n <li>Podchaser</li> \n <li>RSS feeds (Podcasting 2.0 transcripts when available)</li> \n <li>Embedded YouTube podcast pages (e.g. JREPodcast)</li> \n</ul> \n<p>Transcription: prefers local <code>whisper.cpp</code> when installed; otherwise uses OpenAI Whisper or FAL when keys are set.</p> \n<h3>Translation paths</h3> \n<p><code>--language/--lang</code> controls the output language of the summary (and other LLM-generated text). Default is <code>auto</code>.</p> \n<p>When the input is audio/video, the CLI needs a transcript first. The transcript comes from one of these paths:</p> \n<ol> \n <li>Existing transcript (preferred) \n  <ul> \n   <li>YouTube: uses <code>youtubei</code> / <code>captionTracks</code> when available.</li> \n   <li>Podcasts: uses Podcasting 2.0 RSS <code>&lt;podcast:transcript&gt;</code> (JSON/VTT) when the feed publishes it.</li> \n  </ul> </li> \n <li>Whisper transcription (fallback) \n  <ul> \n   <li>YouTube: falls back to yt-dlp (audio download) + Whisper transcription when configured; Apify is a last resort.</li> \n   <li>Prefers local <code>whisper.cpp</code> when installed + model available.</li> \n   <li>Otherwise uses cloud Whisper (OpenAI <code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>).</li> \n  </ul> </li> \n</ol> \n<p>For direct media URLs, use <code>--video-mode transcript</code> to force transcribe -&gt; summarize:</p> \n<pre><code class=\"language-bash\">summarize https://example.com/file.mp4 --video-mode transcript --lang en\n</code></pre> \n<h3>Configuration</h3> \n<p>Single config location:</p> \n<ul> \n <li><code>~/.summarize/config.json</code></li> \n</ul> \n<p>Supported keys today:</p> \n<pre><code class=\"language-json\">{\n  \"model\": { \"id\": \"openai/gpt-5-mini\" },\n  \"env\": { \"OPENAI_API_KEY\": \"sk-...\" },\n  \"ui\": { \"theme\": \"ember\" }\n}\n</code></pre> \n<p>Shorthand (equivalent):</p> \n<pre><code class=\"language-json\">{\n  \"model\": \"openai/gpt-5-mini\"\n}\n</code></pre> \n<p>Also supported:</p> \n<ul> \n <li><code>model: { \"mode\": \"auto\" }</code> (automatic model selection + fallback; see <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a>)</li> \n <li><code>model.rules</code> (customize candidates / ordering)</li> \n <li><code>models</code> (define presets selectable via <code>--model &lt;preset&gt;</code>)</li> \n <li><code>env</code> (generic env var defaults; process env still wins)</li> \n <li><code>apiKeys</code> (legacy shortcut, mapped to env names; prefer <code>env</code> for new configs)</li> \n <li><code>cache.media</code> (media download cache: TTL 7 days, 2048 MB cap by default; <code>--no-media-cache</code> disables)</li> \n <li><code>media.videoMode: \"auto\"|\"transcript\"|\"understand\"</code></li> \n <li><code>slides.enabled</code> / <code>slides.max</code> / <code>slides.ocr</code> / <code>slides.dir</code> (defaults for <code>--slides</code>)</li> \n <li><code>ui.theme: \"aurora\"|\"ember\"|\"moss\"|\"mono\"</code></li> \n <li><code>openai.useChatCompletions: true</code> (force OpenAI-compatible chat completions)</li> \n</ul> \n<p>Note: the config is parsed leniently (JSON5), but comments are not allowed. Unknown keys are ignored.</p> \n<p>Media cache defaults:</p> \n<pre><code class=\"language-json\">{\n  \"cache\": {\n    \"media\": { \"enabled\": true, \"ttlDays\": 7, \"maxMb\": 2048, \"verify\": \"size\" }\n  }\n}\n</code></pre> \n<p>Note: <code>--no-cache</code> bypasses summary caching only (LLM output). Extract/transcript caches still apply. Use <code>--no-media-cache</code> to skip media files.</p> \n<p>Precedence:</p> \n<ol> \n <li><code>--model</code></li> \n <li><code>SUMMARIZE_MODEL</code></li> \n <li><code>~/.summarize/config.json</code></li> \n <li>default (<code>auto</code>)</li> \n</ol> \n<p>Theme precedence:</p> \n<ol> \n <li><code>--theme</code></li> \n <li><code>SUMMARIZE_THEME</code></li> \n <li><code>~/.summarize/config.json</code> (<code>ui.theme</code>)</li> \n <li>default (<code>aurora</code>)</li> \n</ol> \n<p>Environment variable precedence:</p> \n<ol> \n <li>process env</li> \n <li><code>~/.summarize/config.json</code> (<code>env</code>)</li> \n <li><code>~/.summarize/config.json</code> (<code>apiKeys</code>, legacy)</li> \n</ol> \n<h3>Environment variables</h3> \n<p>Set the key matching your chosen <code>--model</code>:</p> \n<ul> \n <li> <p>Optional fallback defaults can be stored in config:</p> \n  <ul> \n   <li><code>~/.summarize/config.json</code> -&gt; <code>\"env\": { \"OPENAI_API_KEY\": \"sk-...\" }</code></li> \n   <li>process env always takes precedence</li> \n   <li>legacy <code>\"apiKeys\"</code> still works (mapped to env names)</li> \n  </ul> </li> \n <li> <p><code>OPENAI_API_KEY</code> (for <code>openai/...</code>)</p> </li> \n <li> <p><code>NVIDIA_API_KEY</code> (for <code>nvidia/...</code>)</p> </li> \n <li> <p><code>ANTHROPIC_API_KEY</code> (for <code>anthropic/...</code>)</p> </li> \n <li> <p><code>XAI_API_KEY</code> (for <code>xai/...</code>)</p> </li> \n <li> <p><code>Z_AI_API_KEY</code> (for <code>zai/...</code>; supports <code>ZAI_API_KEY</code> alias)</p> </li> \n <li> <p><code>GEMINI_API_KEY</code> (for <code>google/...</code>)</p> \n  <ul> \n   <li>also accepts <code>GOOGLE_GENERATIVE_AI_API_KEY</code> and <code>GOOGLE_API_KEY</code> as aliases</li> \n  </ul> </li> \n</ul> \n<p>OpenAI-compatible chat completions toggle:</p> \n<ul> \n <li><code>OPENAI_USE_CHAT_COMPLETIONS=1</code> (or set <code>openai.useChatCompletions</code> in config)</li> \n</ul> \n<p>UI theme:</p> \n<ul> \n <li><code>SUMMARIZE_THEME=aurora|ember|moss|mono</code></li> \n <li><code>SUMMARIZE_TRUECOLOR=1</code> (force 24-bit ANSI)</li> \n <li><code>SUMMARIZE_NO_TRUECOLOR=1</code> (disable 24-bit ANSI)</li> \n</ul> \n<p>OpenRouter (OpenAI-compatible):</p> \n<ul> \n <li>Set <code>OPENROUTER_API_KEY=...</code></li> \n <li>Prefer forcing OpenRouter per model id: <code>--model openrouter/&lt;author&gt;/&lt;slug&gt;</code></li> \n <li>Built-in preset: <code>--model free</code> (uses a default set of OpenRouter <code>:free</code> models)</li> \n</ul> \n<h3><code>summarize refresh-free</code></h3> \n<p>Quick start: make free the default (keep <code>auto</code> available)</p> \n<pre><code class=\"language-bash\">summarize refresh-free --set-default\nsummarize \"https://example.com\"\nsummarize \"https://example.com\" --model auto\n</code></pre> \n<p>Regenerates the <code>free</code> preset (<code>models.free</code> in <code>~/.summarize/config.json</code>) by:</p> \n<ul> \n <li>Fetching OpenRouter <code>/models</code>, filtering <code>:free</code></li> \n <li>Skipping models that look very small (&lt;27B by default) based on the model id/name</li> \n <li>Testing which ones return non-empty text (concurrency 4, timeout 10s)</li> \n <li>Picking a mix of smart-ish (bigger <code>context_length</code> / output cap) and fast models</li> \n <li>Refining timings and writing the sorted list back</li> \n</ul> \n<p>If <code>--model free</code> stops working, run:</p> \n<pre><code class=\"language-bash\">summarize refresh-free\n</code></pre> \n<p>Flags:</p> \n<ul> \n <li><code>--runs 2</code> (default): extra timing runs per selected model (total runs = 1 + runs)</li> \n <li><code>--smart 3</code> (default): how many smart-first picks (rest filled by fastest)</li> \n <li><code>--min-params 27b</code> (default): ignore models with inferred size smaller than N billion parameters</li> \n <li><code>--max-age-days 180</code> (default): ignore models older than N days (set 0 to disable)</li> \n <li><code>--set-default</code>: also sets <code>\"model\": \"free\"</code> in <code>~/.summarize/config.json</code></li> \n</ul> \n<p>Example:</p> \n<pre><code class=\"language-bash\">OPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/meta-llama/llama-3.1-8b-instruct:free\nOPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/minimax/minimax-m2.5\n</code></pre> \n<p>If your OpenRouter account enforces an allowed-provider list, make sure at least one provider is allowed for the selected model. When routing fails, <code>summarize</code> prints the exact providers to allow.</p> \n<p>Legacy: <code>OPENAI_BASE_URL=https://openrouter.ai/api/v1</code> (and either <code>OPENAI_API_KEY</code> or <code>OPENROUTER_API_KEY</code>) also works.</p> \n<p>NVIDIA API Catalog (OpenAI-compatible; free credits):</p> \n<ul> \n <li>Set <code>NVIDIA_API_KEY=...</code></li> \n <li>Optional: <code>NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1</code></li> \n <li>Credits: API Catalog trial starts with 1000 free API credits on signup (up to 5000 total via “Request More” in the API Catalog profile)</li> \n <li>Pick a model id from <code>/v1/models</code> (examples: fast <code>stepfun-ai/step-3.5-flash</code>, strong but slower <code>z-ai/glm5</code>)</li> \n</ul> \n<pre><code class=\"language-bash\">export NVIDIA_API_KEY=\"nvapi-...\"\nsummarize \"https://example.com\" --model nvidia/stepfun-ai/step-3.5-flash\n</code></pre> \n<p>Z.AI (OpenAI-compatible):</p> \n<ul> \n <li><code>Z_AI_API_KEY=...</code> (or <code>ZAI_API_KEY=...</code>)</li> \n <li>Optional base URL override: <code>Z_AI_BASE_URL=...</code></li> \n</ul> \n<p>Optional services:</p> \n<ul> \n <li><code>FIRECRAWL_API_KEY</code> (website extraction fallback)</li> \n <li><code>YT_DLP_PATH</code> (path to yt-dlp binary for audio extraction)</li> \n <li><code>FAL_KEY</code> (FAL AI API key for audio transcription via Whisper)</li> \n <li><code>APIFY_API_TOKEN</code> (YouTube transcript fallback)</li> \n</ul> \n<h3>Model limits</h3> \n<p>The CLI uses the LiteLLM model catalog for model limits (like max output tokens):</p> \n<ul> \n <li>Downloaded from: <code>https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json</code></li> \n <li>Cached at: <code>~/.summarize/cache/</code></li> \n</ul> \n<h3>Library usage (optional)</h3> \n<p>Recommended (minimal deps):</p> \n<ul> \n <li><code>@steipete/summarize-core/content</code></li> \n <li><code>@steipete/summarize-core/prompts</code></li> \n</ul> \n<p>Compatibility (pulls in CLI deps):</p> \n<ul> \n <li><code>@steipete/summarize/content</code></li> \n <li><code>@steipete/summarize/prompts</code></li> \n</ul> \n<h3>Development</h3> \n<pre><code class=\"language-bash\">pnpm install\npnpm check\n</code></pre> \n<h2>More</h2> \n<ul> \n <li>Docs index: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/README.md\">docs/README.md</a></li> \n <li>CLI providers and config: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\">docs/cli.md</a></li> \n <li>Auto model rules: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a></li> \n <li>Website extraction: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/website.md\">docs/website.md</a></li> \n <li>YouTube handling: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/youtube.md\">docs/youtube.md</a></li> \n <li>Media pipeline: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/media.md\">docs/media.md</a></li> \n <li>Config schema and precedence: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/config.md\">docs/config.md</a></li> \n</ul> \n<h2>Troubleshooting</h2> \n<ul> \n <li>\"Receiving end does not exist\": Chrome did not inject the content script yet. \n  <ul> \n   <li>Extension details -&gt; Site access -&gt; On all sites (or allow this domain)</li> \n   <li>Reload the tab once.</li> \n  </ul> </li> \n <li>\"Failed to fetch\" / daemon unreachable: \n  <ul> \n   <li><code>summarize daemon status</code></li> \n   <li>Logs: <code>~/.summarize/logs/daemon.err.log</code></li> \n  </ul> </li> \n</ul> \n<p>License: MIT</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:38.373542Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 19,
        "timeliness_score": 1,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/resizer/i-built-a-privacy-first-image-resizer-that-runs-entirely-in-your-browser-5dnp",
        "title": "I Built a Privacy-First Image Resizer That Runs Entirely in Your Browser",
        "summary": "<p>How I created <a href=\"https://dev.tourl\">resiz.site</a> - a free batch image resizer with 100% client-side processing. No uploads, no servers, your images never leave your device.</p>\n\n<p>I Built a Privacy-First Image Resizer That Runs Entirely in Your Browser<br />\nLet me tell you a story about frustration, privacy concerns, and building something better.</p>\n\n<p>The Problem That Started It All<br />\nLast month, I needed to resize about 50 product images for an e-commerce project. Simple task, right? I opened my go-to online image resizer, uploaded the files, and... waited. And waited. Then I started thinking:</p>\n\n<p>\"Where exactly are my images going? Who has access to them? Are they being stored somewhere?\"</p>\n\n<p>As developers, we've become numb to the \"upload your files\" paradigm. But think about it—why should resizing an image require uploading your personal photos, client assets, or proprietary graphics to someone else's server?</p>\n\n<p>That night, I started building resiz.site .</p>\n\n<p>The Core Philosophy: Your Images, Your Device<br />\nThe fundamental question I asked myself was:</p>\n\n<p>\"Does image resizing actually need a server?\"</p>\n\n<p>The answer was a resounding no. Modern browsers have powerful APIs that can handle image processing entirely on the client side:</p>\n\n<p>Canvas API for pixel manipulation<br />\nFile API for reading local files<br />\nBlob API for generating output files<br />\nWeb Workers for non-blocking processing<br />\nHere's the beautiful part: your images literally never leave your computer. They're processed in your browser's memory and never touch any server, anywhere.</p>\n\n<p>What I Built<br />\nresiz.site is a free, privacy-first batch image resizer with these core features:</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fuad384ha8bj5gbaizdcg.png\"><img alt=\" \" height=\"832\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fuad384ha8bj5gbaizdcg.png\" width=\"800\" /></a><br />\n🖼️ Batch Processing<br />\nUpload up to 50 images at once and resize them all in a single operation. Perfect for e-commerce stores, photographers, and content creators dealing with multiple assets.</p>\n\n<p>🔒 100% Client-Side Processing<br />\nEverything happens in your browser. No uploads, no cloud processing, no storage. Your images stay on your device—period.</p>\n\n<p>⚡ Three Resize Modes<br />\nDimensions Mode - Set exact width and height in pixels<br />\nScale Mode - Resize by percentage (e.g., reduce to 50%)<br />\nFile Size Mode - Target a specific file size (great for web optimization)<br />\n🎛️ Flexible Options<br />\nAspect ratio lock - Prevent distortion<br />\nFit modes - Contain, cover, or fill<br />\nFormat conversion - Output as JPG, PNG, or WebP<br />\nQuality control - Adjust compression levels<br />\n📱 Responsive Design<br />\nWorks on desktop and mobile. No app to install—just open in any modern browser.</p>\n\n<p>Preserving EXIF data orientation<br />\nMaintaining color profiles<br />\nHandling transparent PNGs correctly<br />\nProcessing multiple files with Web Workers to avoid UI blocking<br />\nWhy This Matters for Privacy<br />\nIn an era of data breaches and privacy concerns, every piece of data we share online adds to our digital footprint. Image files can contain:</p>\n\n<p>EXIF metadata with GPS coordinates<br />\nTimestamps of when photos were taken<br />\nDevice information and camera settings<br />\nPersonal content in screenshots and photos<br />\nTraditional online image tools require uploading these files to external servers. Even with privacy policies, you're trusting a third party with potentially sensitive information.</p>\n\n<p>resiz.site eliminates this trust requirement entirely. Your images are processed locally and never transmitted anywhere.</p>\n\n<p>Real-World Use Cases<br />\nSince launching, I've heard from users with diverse needs:</p>\n\n<p>E-commerce Store Owners: \"I resize hundreds of product images monthly. Now I don't worry about my inventory photos leaking.\"</p>\n\n<p>Photographers: \"Client proofs often contain sensitive family moments. Privacy-first processing gives me peace of mind.\"</p>\n\n<p>Web Developers: \"I use it daily for optimizing images before deployment. The batch feature saves hours.\"</p>\n\n<p>Content Creators: \"Social media platforms have different size requirements. Scale mode makes this a breeze.\"</p>\n\n<p>Technical Advantages<br />\nBeyond privacy, there are practical benefits to client-side processing:</p>\n\n<p>Feature<br />\nServer-Based<br />\nClient-Side (resiz.site)<br />\nProcessing Speed    Upload + Process + Download time    Process only<br />\nServer Costs    Ongoing hosting expenses    Zero server costs<br />\nBandwidth Usage 2x file size (upload + download)    Zero network transfer<br />\nFile Size Limits    Often restricted    Browser memory only<br />\nOffline Access  No  Works offline after load<br />\nPrivacy Data leaves your device 100% local</p>\n\n<p>Performance Optimization Tips<br />\nTo get the best results from <a href=\"https://dev.tourl\">resiz.site</a> :</p>\n\n<p>Use WebP format for web images - smaller files with excellent quality<br />\nBatch similar images - process images of the same type together for efficiency<br />\nChoose the right fit mode:<br />\nContain for thumbnails (maintains aspect ratio)<br />\nCover for hero images (fills frame, may crop)<br />\nFill for exact dimensions (may distort)<br />\nWhat's Next<br />\nI'm continuously improving resiz.site based on user feedback. On the roadmap:</p>\n\n<p>🔄 Image cropping tool<br />\n🎨 Basic filters and adjustments<br />\n📐 Preset sizes for social media platforms<br />\n🌐 Offline PWA support<br />\nTry It Yourself<br />\nHead over to resiz.site and give it a spin. No signup required, no limits, no tracking. Just a straightforward tool that does one thing well—resizing your images privately.</p>\n\n<p>Your images deserve privacy. Your workflow deserves simplicity.</p>\n\n<p>Feedback Welcome<br />\nAs a developer, I'd love to hear your thoughts:</p>\n\n<p>What features would make this more useful for your workflow?<br />\nAny edge cases I should handle better?<br />\nSuggestions for the UI/UX?<br />\nDrop a comment below or reach out through the contact page .</p>\n\n<p>If you found this useful, consider bookmarking resiz.site for your next image optimization task. It's free, private, and always will be.`</p>",
        "source": "dev.to",
        "published": "Wed, 18 Feb 2026 23:15:35 +0000",
        "fetched_at": "2026-02-18T23:25:42.462370Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 2,
        "final_score": 8.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/gogcli",
        "title": "steipete/gogcli",
        "summary": "<p>Google Suite CLI: Gmail, GCal, GDrive, GContacts.</p><hr /><h1>🧭 gogcli — Google in your terminal.</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=gogcli%F0%9F%A7%AD&amp;subheader=Google+in+your+terminal&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast, script-friendly CLI for Gmail, Calendar, Chat, Classroom, Drive, Docs, Slides, Sheets, Forms, Apps Script, Contacts, Tasks, People, Groups (Workspace), and Keep (Workspace-only). JSON-first output, multiple accounts, and least-privilege auth built in.</p> \n<h2>Features</h2> \n<ul> \n <li><strong>Gmail</strong> - search threads and messages, send emails, view attachments, manage labels/drafts/filters/delegation/vacation settings, history, and watch (Pub/Sub push)</li> \n <li><strong>Email tracking</strong> - track opens for <code>gog gmail send --track</code> with a small Cloudflare Worker backend</li> \n <li><strong>Calendar</strong> - list/create/update events, detect conflicts, manage invitations, check free/busy status, team calendars, propose new times, focus/OOO/working-location events, recurrence + reminders</li> \n <li><strong>Classroom</strong> - manage courses, roster, coursework/materials, submissions, announcements, topics, invitations, guardians, profiles</li> \n <li><strong>Chat</strong> - list/find/create spaces, list messages/threads (filter by thread/unread), send messages and DMs (Workspace-only)</li> \n <li><strong>Drive</strong> - list/search/upload/download files, manage permissions/comments, organize folders, list shared drives</li> \n <li><strong>Contacts</strong> - search/create/update contacts, access Workspace directory/other contacts</li> \n <li><strong>Tasks</strong> - manage tasklists and tasks: get/create/add/update/done/undo/delete/clear, repeat schedules</li> \n <li><strong>Sheets</strong> - read/write/update spreadsheets, insert rows/cols, format cells, read notes, create new sheets (and export via Drive)</li> \n <li><strong>Forms</strong> - create/get forms and inspect responses</li> \n <li><strong>Apps Script</strong> - create/get projects, inspect content, and run functions</li> \n <li><strong>Docs/Slides</strong> - export to PDF/DOCX/PPTX via Drive (plus create/copy, docs-to-text)</li> \n <li><strong>People</strong> - access profile information</li> \n <li><strong>Keep (Workspace only)</strong> - list/get/search notes and download attachments (service account + domain-wide delegation)</li> \n <li><strong>Groups</strong> - list groups you belong to, view group members (Google Workspace)</li> \n <li><strong>Local time</strong> - quick local/UTC time display for scripts and agents</li> \n <li><strong>Multiple accounts</strong> - manage multiple Google accounts simultaneously (with aliases)</li> \n <li><strong>Command allowlist</strong> - restrict top-level commands for sandboxed/agent runs</li> \n <li><strong>Secure credential storage</strong> using OS keyring or encrypted on-disk keyring (configurable)</li> \n <li><strong>Auto-refreshing tokens</strong> - authenticate once, use indefinitely</li> \n <li><strong>Least-privilege auth</strong> - <code>--readonly</code> and <code>--drive-scope</code> to request fewer scopes</li> \n <li><strong>Workspace service accounts</strong> - domain-wide delegation auth (preferred when configured)</li> \n <li><strong>Parseable output</strong> - JSON mode for scripting and automation (Calendar adds day-of-week fields)</li> \n</ul> \n<h2>Installation</h2> \n<h3>Homebrew</h3> \n<pre><code class=\"language-bash\">brew install steipete/tap/gogcli\n</code></pre> \n<h3>Arch User Repository</h3> \n<pre><code class=\"language-bash\">yay -S gogcli\n</code></pre> \n<h3>Build from Source</h3> \n<pre><code class=\"language-bash\">git clone https://github.com/steipete/gogcli.git\ncd gogcli\nmake\n</code></pre> \n<p>Run:</p> \n<pre><code class=\"language-bash\">./bin/gog --help\n</code></pre> \n<p>Help:</p> \n<ul> \n <li><code>gog --help</code> shows top-level command groups.</li> \n <li>Drill down with <code>gog &lt;group&gt; --help</code> (and deeper subcommands).</li> \n <li>For the full expanded command list: <code>GOG_HELP=full gog --help</code>.</li> \n <li>Make shortcut: <code>make gog -- --help</code> (or <code>make gog -- gmail --help</code>).</li> \n <li><code>make gog-help</code> shows CLI help (note: <code>make gog --help</code> is Make’s own help; use <code>--</code>).</li> \n <li>Version: <code>gog --version</code> or <code>gog version</code>.</li> \n</ul> \n<h2>Quick Start</h2> \n<h3>1. Get OAuth2 Credentials</h3> \n<p>Before adding an account, create OAuth2 credentials from Google Cloud Console:</p> \n<ol> \n <li>Open the Google Cloud Console credentials page: <a href=\"https://console.cloud.google.com/apis/credentials\">https://console.cloud.google.com/apis/credentials</a></li> \n <li>Create a project: <a href=\"https://console.cloud.google.com/projectcreate\">https://console.cloud.google.com/projectcreate</a></li> \n <li>Enable the APIs you need: \n  <ul> \n   <li>Gmail API: <a href=\"https://console.cloud.google.com/apis/api/gmail.googleapis.com\">https://console.cloud.google.com/apis/api/gmail.googleapis.com</a></li> \n   <li>Google Calendar API: <a href=\"https://console.cloud.google.com/apis/api/calendar-json.googleapis.com\">https://console.cloud.google.com/apis/api/calendar-json.googleapis.com</a></li> \n   <li>Google Chat API: <a href=\"https://console.cloud.google.com/apis/api/chat.googleapis.com\">https://console.cloud.google.com/apis/api/chat.googleapis.com</a></li> \n   <li>Google Drive API: <a href=\"https://console.cloud.google.com/apis/api/drive.googleapis.com\">https://console.cloud.google.com/apis/api/drive.googleapis.com</a></li> \n   <li>Google Classroom API: <a href=\"https://console.cloud.google.com/apis/api/classroom.googleapis.com\">https://console.cloud.google.com/apis/api/classroom.googleapis.com</a></li> \n   <li>People API (Contacts): <a href=\"https://console.cloud.google.com/apis/api/people.googleapis.com\">https://console.cloud.google.com/apis/api/people.googleapis.com</a></li> \n   <li>Google Tasks API: <a href=\"https://console.cloud.google.com/apis/api/tasks.googleapis.com\">https://console.cloud.google.com/apis/api/tasks.googleapis.com</a></li> \n   <li>Google Sheets API: <a href=\"https://console.cloud.google.com/apis/api/sheets.googleapis.com\">https://console.cloud.google.com/apis/api/sheets.googleapis.com</a></li> \n   <li>Google Forms API: <a href=\"https://console.cloud.google.com/apis/api/forms.googleapis.com\">https://console.cloud.google.com/apis/api/forms.googleapis.com</a></li> \n   <li>Apps Script API: <a href=\"https://console.cloud.google.com/apis/api/script.googleapis.com\">https://console.cloud.google.com/apis/api/script.googleapis.com</a></li> \n   <li>Cloud Identity API (Groups): <a href=\"https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com\">https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com</a></li> \n  </ul> </li> \n <li>Configure OAuth consent screen: <a href=\"https://console.cloud.google.com/auth/branding\">https://console.cloud.google.com/auth/branding</a></li> \n <li>If your app is in \"Testing\", add test users: <a href=\"https://console.cloud.google.com/auth/audience\">https://console.cloud.google.com/auth/audience</a></li> \n <li>Create OAuth client: \n  <ul> \n   <li>Go to <a href=\"https://console.cloud.google.com/auth/clients\">https://console.cloud.google.com/auth/clients</a></li> \n   <li>Click \"Create Client\"</li> \n   <li>Application type: \"Desktop app\"</li> \n   <li>Download the JSON file (usually named <code>client_secret_....apps.googleusercontent.com.json</code>)</li> \n  </ul> </li> \n</ol> \n<h3>2. Store Credentials</h3> \n<pre><code class=\"language-bash\">gog auth credentials ~/Downloads/client_secret_....json\n</code></pre> \n<p>For multiple OAuth clients/projects:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work-client.json\ngog auth credentials list\n</code></pre> \n<h3>3. Authorize Your Account</h3> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com\n</code></pre> \n<p>This will open a browser window for OAuth authorization. The refresh token is stored securely in your system keychain.</p> \n<p>Headless / remote server flows (no browser on the server):</p> \n<p>Manual interactive flow (recommended):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services user --manual\n</code></pre> \n<ul> \n <li>The CLI prints an auth URL. Open it in a local browser.</li> \n <li>After approval, copy the full loopback redirect URL from the browser address bar.</li> \n <li>Paste that URL back into the terminal when prompted.</li> \n</ul> \n<p>Split remote flow (<code>--remote</code>, useful for two-step/scripted handoff):</p> \n<pre><code class=\"language-bash\"># Step 1: print auth URL (open it locally in a browser)\ngog auth add you@gmail.com --services user --remote --step 1\n\n# Step 2: paste the full redirect URL from your browser address bar\ngog auth add you@gmail.com --services user --remote --step 2 --auth-url 'http://127.0.0.1:&lt;port&gt;/oauth2/callback?code=...&amp;state=...'\n</code></pre> \n<ul> \n <li>The <code>state</code> is cached on disk for a short time (about 10 minutes). If it expires, rerun step 1.</li> \n <li>Remote step 2 requires a redirect URL that includes <code>state</code> (state check mandatory).</li> \n</ul> \n<h3>4. Test Authentication</h3> \n<pre><code class=\"language-bash\">export GOG_ACCOUNT=you@gmail.com\ngog gmail labels list\n</code></pre> \n<h2>Authentication &amp; Secrets</h2> \n<h3>Accounts and tokens</h3> \n<p><code>gog</code> stores your OAuth refresh tokens in a “keyring” backend. Default is <code>auto</code> (best available backend for your OS/environment).</p> \n<p>Before you can run <code>gog auth add</code>, you must store OAuth client credentials once via <code>gog auth credentials &lt;credentials.json&gt;</code> (download a Desktop app OAuth client JSON from the Cloud Console). For multiple clients, use <code>gog --client &lt;name&gt; auth credentials ...</code>; tokens are isolated per client.</p> \n<p>List accounts:</p> \n<pre><code class=\"language-bash\">gog auth list\n</code></pre> \n<p>Verify tokens are usable (helps spot revoked/expired tokens):</p> \n<pre><code class=\"language-bash\">gog auth list --check\n</code></pre> \n<p>Accounts can be authorized either via OAuth refresh tokens or Workspace service accounts (domain-wide delegation). If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see <code>gog auth list</code>).</p> \n<p>Show current auth state/services for the active account:</p> \n<pre><code class=\"language-bash\">gog auth status\n</code></pre> \n<h3>Multiple OAuth clients</h3> \n<p>Use <code>--client</code> (or <code>GOG_CLIENT</code>) to select a named OAuth client:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work.json\ngog --client work auth add you@company.com\n</code></pre> \n<p>Optional domain mapping for auto-selection:</p> \n<pre><code class=\"language-bash\">gog --client work auth credentials ~/Downloads/work.json --domain example.com\n</code></pre> \n<p>How it works:</p> \n<ul> \n <li>Default client is <code>default</code> (stored in <code>credentials.json</code>).</li> \n <li>Named clients are stored as <code>credentials-&lt;client&gt;.json</code>.</li> \n <li>Tokens are isolated per client (<code>token:&lt;client&gt;:&lt;email&gt;</code>); defaults are per client too.</li> \n</ul> \n<p>Client selection order (when <code>--client</code> is not set):</p> \n<ol> \n <li><code>--client</code> / <code>GOG_CLIENT</code></li> \n <li><code>account_clients</code> config (email -&gt; client)</li> \n <li><code>client_domains</code> config (domain -&gt; client)</li> \n <li>Credentials file named after the email domain (<code>credentials-example.com.json</code>)</li> \n <li><code>default</code></li> \n</ol> \n<p>Config example (JSON5):</p> \n<pre><code class=\"language-json5\">{\n  account_clients: { \"you@company.com\": \"work\" },\n  client_domains: { \"example.com\": \"work\" },\n}\n</code></pre> \n<p>List stored credentials:</p> \n<pre><code class=\"language-bash\">gog auth credentials list\n</code></pre> \n<p>See <code>docs/auth-clients.md</code> for the full client selection and mapping rules.</p> \n<h3>Keyring backend: Keychain vs encrypted file</h3> \n<p>Backends:</p> \n<ul> \n <li><code>auto</code> (default): picks the best backend for the platform.</li> \n <li><code>keychain</code>: macOS Keychain (recommended on macOS; avoids password management).</li> \n <li><code>file</code>: encrypted on-disk keyring (requires a password).</li> \n</ul> \n<p>Set backend via command (writes <code>keyring_backend</code> into <code>config.json</code>):</p> \n<pre><code class=\"language-bash\">gog auth keyring file\ngog auth keyring keychain\ngog auth keyring auto\n</code></pre> \n<p>Show current backend + source (env/config/default) and config path:</p> \n<pre><code class=\"language-bash\">gog auth keyring\n</code></pre> \n<p>Non-interactive runs (CI/ssh): file backend requires <code>GOG_KEYRING_PASSWORD</code>.</p> \n<pre><code class=\"language-bash\">export GOG_KEYRING_PASSWORD='...'\ngog --no-input auth status\n</code></pre> \n<p>Force backend via env (overrides config):</p> \n<pre><code class=\"language-bash\">export GOG_KEYRING_BACKEND=file\n</code></pre> \n<p>Precedence: <code>GOG_KEYRING_BACKEND</code> env var overrides <code>config.json</code>.</p> \n<h2>Configuration</h2> \n<h3>Account Selection</h3> \n<p>Specify the account using either a flag or environment variable:</p> \n<pre><code class=\"language-bash\"># Via flag\ngog gmail search 'newer_than:7d' --account you@gmail.com\n\n# Via alias\ngog auth alias set work work@company.com\ngog gmail search 'newer_than:7d' --account work\n\n# Via environment\nexport GOG_ACCOUNT=you@gmail.com\ngog gmail search 'newer_than:7d'\n\n# Auto-select (default account or the single stored token)\ngog gmail labels list --account auto\n</code></pre> \n<p>List configured accounts:</p> \n<pre><code class=\"language-bash\">gog auth list\n</code></pre> \n<h3>Output</h3> \n<ul> \n <li>Default: human-friendly tables on stdout.</li> \n <li><code>--plain</code>: stable TSV on stdout (tabs preserved; best for piping to tools that expect <code>\\t</code>).</li> \n <li><code>--json</code>: JSON on stdout (best for scripting).</li> \n <li>Human-facing hints/progress go to stderr.</li> \n <li>Colors are enabled only in rich TTY output and are disabled automatically for <code>--json</code> and <code>--plain</code>.</li> \n</ul> \n<h3>Service Scopes</h3> \n<p>By default, <code>gog auth add</code> requests access to the <strong>user</strong> services (see <code>gog auth services</code> for the current list and scopes).</p> \n<p>To request fewer scopes:</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive,calendar\n</code></pre> \n<p>To request read-only scopes (write operations will fail with 403 insufficient scopes):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive,calendar --readonly\n</code></pre> \n<p>To control Drive’s scope (default: <code>full</code>):</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services drive --drive-scope full\ngog auth add you@gmail.com --services drive --drive-scope readonly\ngog auth add you@gmail.com --services drive --drive-scope file\n</code></pre> \n<p>Notes:</p> \n<ul> \n <li><code>--drive-scope readonly</code> is enough for listing/downloading/exporting via Drive (write operations will 403).</li> \n <li><code>--drive-scope file</code> is write-capable (limited to files created/opened by this app) and can’t be combined with <code>--readonly</code>.</li> \n</ul> \n<p>If you need to add services later and Google doesn't return a refresh token, re-run with <code>--force-consent</code>:</p> \n<pre><code class=\"language-bash\">gog auth add you@gmail.com --services user --force-consent\n# Or add just Sheets\ngog auth add you@gmail.com --services sheets --force-consent\n</code></pre> \n<p><code>--services all</code> is accepted as an alias for <code>user</code> for backwards compatibility.</p> \n<p>Docs commands are implemented via the Drive API, and <code>docs</code> requests both Drive and Docs API scopes.</p> \n<p>Service scope matrix (auto-generated; run <code>go run scripts/gen-auth-services-md.go</code>):</p> \n<!-- auth-services:start --> \n<table> \n <thead> \n  <tr> \n   <th>Service</th> \n   <th>User</th> \n   <th>APIs</th> \n   <th>Scopes</th> \n   <th>Notes</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>gmail</td> \n   <td>yes</td> \n   <td>Gmail API</td> \n   <td><code>https://www.googleapis.com/auth/gmail.modify</code><br /><code>https://www.googleapis.com/auth/gmail.settings.basic</code><br /><code>https://www.googleapis.com/auth/gmail.settings.sharing</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>calendar</td> \n   <td>yes</td> \n   <td>Calendar API</td> \n   <td><code>https://www.googleapis.com/auth/calendar</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>chat</td> \n   <td>yes</td> \n   <td>Chat API</td> \n   <td><code>https://www.googleapis.com/auth/chat.spaces</code><br /><code>https://www.googleapis.com/auth/chat.messages</code><br /><code>https://www.googleapis.com/auth/chat.memberships</code><br /><code>https://www.googleapis.com/auth/chat.users.readstate.readonly</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>classroom</td> \n   <td>yes</td> \n   <td>Classroom API</td> \n   <td><code>https://www.googleapis.com/auth/classroom.courses</code><br /><code>https://www.googleapis.com/auth/classroom.rosters</code><br /><code>https://www.googleapis.com/auth/classroom.coursework.students</code><br /><code>https://www.googleapis.com/auth/classroom.coursework.me</code><br /><code>https://www.googleapis.com/auth/classroom.courseworkmaterials</code><br /><code>https://www.googleapis.com/auth/classroom.announcements</code><br /><code>https://www.googleapis.com/auth/classroom.topics</code><br /><code>https://www.googleapis.com/auth/classroom.guardianlinks.students</code><br /><code>https://www.googleapis.com/auth/classroom.profile.emails</code><br /><code>https://www.googleapis.com/auth/classroom.profile.photos</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>drive</td> \n   <td>yes</td> \n   <td>Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>docs</td> \n   <td>yes</td> \n   <td>Docs API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/documents</code></td> \n   <td>Export/copy/create via Drive</td> \n  </tr> \n  <tr> \n   <td>slides</td> \n   <td>yes</td> \n   <td>Slides API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/presentations</code></td> \n   <td>Create/edit presentations</td> \n  </tr> \n  <tr> \n   <td>contacts</td> \n   <td>yes</td> \n   <td>People API</td> \n   <td><code>https://www.googleapis.com/auth/contacts</code><br /><code>https://www.googleapis.com/auth/contacts.other.readonly</code><br /><code>https://www.googleapis.com/auth/directory.readonly</code></td> \n   <td>Contacts + other contacts + directory</td> \n  </tr> \n  <tr> \n   <td>tasks</td> \n   <td>yes</td> \n   <td>Tasks API</td> \n   <td><code>https://www.googleapis.com/auth/tasks</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>sheets</td> \n   <td>yes</td> \n   <td>Sheets API, Drive API</td> \n   <td><code>https://www.googleapis.com/auth/drive</code><br /><code>https://www.googleapis.com/auth/spreadsheets</code></td> \n   <td>Export via Drive</td> \n  </tr> \n  <tr> \n   <td>people</td> \n   <td>yes</td> \n   <td>People API</td> \n   <td><code>profile</code></td> \n   <td>OIDC profile scope</td> \n  </tr> \n  <tr> \n   <td>forms</td> \n   <td>yes</td> \n   <td>Forms API</td> \n   <td><code>https://www.googleapis.com/auth/forms.body</code><br /><code>https://www.googleapis.com/auth/forms.responses.readonly</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>appscript</td> \n   <td>yes</td> \n   <td>Apps Script API</td> \n   <td><code>https://www.googleapis.com/auth/script.projects</code><br /><code>https://www.googleapis.com/auth/script.deployments</code><br /><code>https://www.googleapis.com/auth/script.processes</code></td> \n   <td></td> \n  </tr> \n  <tr> \n   <td>groups</td> \n   <td>no</td> \n   <td>Cloud Identity API</td> \n   <td><code>https://www.googleapis.com/auth/cloud-identity.groups.readonly</code></td> \n   <td>Workspace only</td> \n  </tr> \n  <tr> \n   <td>keep</td> \n   <td>no</td> \n   <td>Keep API</td> \n   <td><code>https://www.googleapis.com/auth/keep.readonly</code></td> \n   <td>Workspace only; service account (domain-wide delegation)</td> \n  </tr> \n </tbody> \n</table> \n<!-- auth-services:end --> \n<h3>Service Accounts (Workspace only)</h3> \n<p>A service account is a non-human Google identity that belongs to a Google Cloud project. In Google Workspace, a service account can impersonate a user via <strong>domain-wide delegation</strong> (admin-controlled) and access APIs like Gmail/Calendar/Drive as that user.</p> \n<p>In <code>gog</code>, service accounts are an <strong>optional auth method</strong> that can be configured per account email. If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see <code>gog auth list</code>).</p> \n<h4>1) Create a Service Account (Google Cloud)</h4> \n<ol> \n <li>Create (or pick) a Google Cloud project.</li> \n <li>Enable the APIs you’ll use (e.g. Gmail, Calendar, Drive, Sheets, Docs, People, Tasks, Cloud Identity).</li> \n <li>Go to <strong>IAM &amp; Admin → Service Accounts</strong> and create a service account.</li> \n <li>In the service account details, enable <strong>Domain-wide delegation</strong>.</li> \n <li>Create a key (<strong>Keys → Add key → Create new key → JSON</strong>) and download the JSON key file.</li> \n</ol> \n<h4>2) Allowlist scopes (Google Workspace Admin Console)</h4> \n<p>Domain-wide delegation is enforced by Workspace admin settings.</p> \n<ol> \n <li>Open <strong>Admin console → Security → API controls → Domain-wide delegation</strong>.</li> \n <li>Add a new API client: \n  <ul> \n   <li>Client ID: use the service account’s “Client ID” from Google Cloud.</li> \n   <li>OAuth scopes: comma-separated list of scopes you want to allow (copy from <code>gog auth services</code> and/or your <code>gog auth add --services ...</code> usage).</li> \n  </ul> </li> \n</ol> \n<p>If a scope is missing from the allowlist, service-account token minting can fail (or API calls will 403 with insufficient permissions).</p> \n<h4>3) Configure <code>gog</code> to use the service account</h4> \n<p>Store the key for the user you want to impersonate:</p> \n<pre><code class=\"language-bash\">gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json\n</code></pre> \n<p>Verify <code>gog</code> is preferring the service account for that account:</p> \n<pre><code class=\"language-bash\">gog --account you@yourdomain.com auth status\ngog auth list\n</code></pre> \n<h3>Google Keep (Workspace only)</h3> \n<p>Keep requires Workspace + domain-wide delegation. You can configure it via the generic service-account command above (recommended), or the legacy Keep helper:</p> \n<pre><code class=\"language-bash\">gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json\ngog keep list --account you@yourdomain.com\ngog keep get &lt;noteId&gt; --account you@yourdomain.com\n</code></pre> \n<h3>Environment Variables</h3> \n<ul> \n <li><code>GOG_ACCOUNT</code> - Default account email or alias to use (avoids repeating <code>--account</code>; otherwise uses keyring default or a single stored token)</li> \n <li><code>GOG_CLIENT</code> - OAuth client name (selects stored credentials + token bucket)</li> \n <li><code>GOG_JSON</code> - Default JSON output</li> \n <li><code>GOG_PLAIN</code> - Default plain output</li> \n <li><code>GOG_COLOR</code> - Color mode: <code>auto</code> (default), <code>always</code>, or <code>never</code></li> \n <li><code>GOG_TIMEZONE</code> - Default output timezone for Calendar/Gmail (IANA name, <code>UTC</code>, or <code>local</code>)</li> \n <li><code>GOG_ENABLE_COMMANDS</code> - Comma-separated allowlist of top-level commands (e.g., <code>calendar,tasks</code>)</li> \n</ul> \n<h3>Config File (JSON5)</h3> \n<p>Find the actual config path in <code>gog --help</code> or <code>gog auth keyring</code>.</p> \n<p>Typical paths:</p> \n<ul> \n <li>macOS: <code>~/Library/Application Support/gogcli/config.json</code></li> \n <li>Linux: <code>~/.config/gogcli/config.json</code> (or <code>$XDG_CONFIG_HOME/gogcli/config.json</code>)</li> \n <li>Windows: <code>%AppData%\\\\gogcli\\\\config.json</code></li> \n</ul> \n<p>Example (JSON5 supports comments and trailing commas):</p> \n<pre><code class=\"language-json5\">{\n  // Avoid macOS Keychain prompts\n  keyring_backend: \"file\",\n  // Default output timezone for Calendar/Gmail (IANA, UTC, or local)\n  default_timezone: \"UTC\",\n  // Optional account aliases\n  account_aliases: {\n    work: \"work@company.com\",\n    personal: \"me@gmail.com\",\n  },\n  // Optional per-account OAuth client selection\n  account_clients: {\n    \"work@company.com\": \"work\",\n  },\n  // Optional domain -&gt; client mapping\n  client_domains: {\n    \"example.com\": \"work\",\n  },\n}\n</code></pre> \n<h3>Config Commands</h3> \n<pre><code class=\"language-bash\">gog config path\ngog config list\ngog config keys\ngog config get default_timezone\ngog config set default_timezone UTC\ngog config unset default_timezone\n</code></pre> \n<h3>Account Aliases</h3> \n<pre><code class=\"language-bash\">gog auth alias set work work@company.com\ngog auth alias list\ngog auth alias unset work\n</code></pre> \n<p>Aliases work anywhere you pass <code>--account</code> or <code>GOG_ACCOUNT</code> (reserved: <code>auto</code>, <code>default</code>).</p> \n<h3>Command Allowlist (Sandboxing)</h3> \n<pre><code class=\"language-bash\"># Only allow calendar + tasks commands for an agent\ngog --enable-commands calendar,tasks calendar events --today\n\n# Same via env\nexport GOG_ENABLE_COMMANDS=calendar,tasks\ngog tasks list &lt;tasklistId&gt;\n</code></pre> \n<h2>Security</h2> \n<h3>Credential Storage</h3> \n<p>OAuth credentials are stored securely in your system's keychain:</p> \n<ul> \n <li><strong>macOS</strong>: Keychain Access</li> \n <li><strong>Linux</strong>: Secret Service (GNOME Keyring, KWallet)</li> \n <li><strong>Windows</strong>: Credential Manager</li> \n</ul> \n<p>The CLI uses <a href=\"https://github.com/99designs/keyring\">github.com/99designs/keyring</a> for secure storage.</p> \n<p>If no OS keychain backend is available (e.g., Linux/WSL/container), keyring can fall back to an encrypted on-disk store and may prompt for a password; for non-interactive runs set <code>GOG_KEYRING_PASSWORD</code>.</p> \n<h3>Keychain Prompts (macOS)</h3> \n<p>macOS Keychain may prompt more than you’d expect when the “app identity” keeps changing (different binary path, <code>go run</code> temp builds, rebuilding to new <code>./bin/gog</code>, multiple copies). Keychain treats those as different apps, so it asks again.</p> \n<p>Options:</p> \n<ul> \n <li><strong>Default (recommended):</strong> keep using Keychain (secure) and run a stable <code>gog</code> binary path to reduce repeat prompts.</li> \n <li><strong>Force Keychain:</strong> <code>GOG_KEYRING_BACKEND=keychain</code> (disables any file-backend fallback).</li> \n <li><strong>Avoid Keychain prompts entirely:</strong> <code>GOG_KEYRING_BACKEND=file</code> (stores encrypted entries on disk under your config dir). \n  <ul> \n   <li>To avoid password prompts too (CI/non-interactive): set <code>GOG_KEYRING_PASSWORD=...</code> (tradeoff: secret in env).</li> \n  </ul> </li> \n</ul> \n<h3>Best Practices</h3> \n<ul> \n <li><strong>Never commit OAuth client credentials</strong> to version control</li> \n <li>Store client credentials outside your project directory</li> \n <li>Use different OAuth clients for development and production</li> \n <li>Re-authorize with <code>--force-consent</code> if you suspect token compromise</li> \n <li>Remove unused accounts with <code>gog auth remove &lt;email&gt;</code></li> \n</ul> \n<h3>OAuth Client IDs in Open Source</h3> \n<p>Some open source Google CLIs ship a pre-configured OAuth client ID/secret copied from other desktop apps to avoid OAuth consent verification, testing-user limits, or quota issues. This makes the consent screen/security emails show the other app’s name and can stop working at any time.</p> \n<p><code>gogcli</code> does not do this. Supported auth:</p> \n<ul> \n <li>Your own OAuth Desktop client JSON via <code>gog auth credentials ...</code> + <code>gog auth add ...</code></li> \n <li>Google Workspace service accounts with domain-wide delegation (Workspace only)</li> \n</ul> \n<h2>Commands</h2> \n<p>Flag aliases:</p> \n<ul> \n <li><code>--out</code> also accepts <code>--output</code>.</li> \n <li><code>--out-dir</code> also accepts <code>--output-dir</code> (Gmail thread attachment downloads).</li> \n</ul> \n<h3>Authentication</h3> \n<pre><code class=\"language-bash\">gog auth credentials &lt;path&gt;           # Store OAuth client credentials\ngog auth credentials list             # List stored OAuth client credentials\ngog --client work auth credentials &lt;path&gt;  # Store named OAuth client credentials\ngog auth add &lt;email&gt;                  # Authorize and store refresh token\ngog auth service-account set &lt;email&gt; --key &lt;path&gt;  # Configure service account impersonation (Workspace only)\ngog auth service-account status &lt;email&gt;            # Show service account status\ngog auth service-account unset &lt;email&gt;             # Remove service account\ngog auth keep &lt;email&gt; --key &lt;path&gt;                 # Legacy alias (Keep)\ngog auth keyring [backend]            # Show/set keyring backend (auto|keychain|file)\ngog auth status                       # Show current auth state/services\ngog auth services                     # List available services and OAuth scopes\ngog auth list                         # List stored accounts\ngog auth list --check                 # Validate stored refresh tokens\ngog auth remove &lt;email&gt;               # Remove a stored refresh token\ngog auth manage                       # Open accounts manager in browser\ngog auth tokens                       # Manage stored refresh tokens\n</code></pre> \n<h3>Keep (Workspace only)</h3> \n<pre><code class=\"language-bash\">gog keep list --account you@yourdomain.com\ngog keep get &lt;noteId&gt; --account you@yourdomain.com\ngog keep search &lt;query&gt; --account you@yourdomain.com\ngog keep attachment &lt;attachmentName&gt; --account you@yourdomain.com --out ./attachment.bin\n</code></pre> \n<h3>Gmail</h3> \n<pre><code class=\"language-bash\"># Search and read\ngog gmail search 'newer_than:7d' --max 10\ngog gmail thread get &lt;threadId&gt;\ngog gmail thread get &lt;threadId&gt; --download              # Download attachments to current dir\ngog gmail thread get &lt;threadId&gt; --download --out-dir ./attachments\ngog gmail get &lt;messageId&gt;\ngog gmail get &lt;messageId&gt; --format metadata\ngog gmail attachment &lt;messageId&gt; &lt;attachmentId&gt;\ngog gmail attachment &lt;messageId&gt; &lt;attachmentId&gt; --out ./attachment.bin\ngog gmail url &lt;threadId&gt;              # Print Gmail web URL\ngog gmail thread modify &lt;threadId&gt; --add STARRED --remove INBOX\n\n# Send and compose\ngog gmail send --to a@b.com --subject \"Hi\" --body \"Plain fallback\"\ngog gmail send --to a@b.com --subject \"Hi\" --body-file ./message.txt\ngog gmail send --to a@b.com --subject \"Hi\" --body-file -   # Read body from stdin\ngog gmail send --to a@b.com --subject \"Hi\" --body \"Plain fallback\" --body-html \"&lt;p&gt;Hello&lt;/p&gt;\"\n# Reply + include quoted original message (auto-generates HTML quote unless you pass --body-html)\ngog gmail send --reply-to-message-id &lt;messageId&gt; --quote --to a@b.com --subject \"Re: Hi\" --body \"My reply\"\ngog gmail drafts list\ngog gmail drafts create --subject \"Draft\" --body \"Body\"\ngog gmail drafts create --to a@b.com --subject \"Draft\" --body \"Body\"\ngog gmail drafts update &lt;draftId&gt; --subject \"Draft\" --body \"Body\"\ngog gmail drafts update &lt;draftId&gt; --to a@b.com --subject \"Draft\" --body \"Body\"\ngog gmail drafts send &lt;draftId&gt;\n\n# Labels\ngog gmail labels list\ngog gmail labels get INBOX --json  # Includes message counts\ngog gmail labels create \"My Label\"\ngog gmail labels modify &lt;threadId&gt; --add STARRED --remove INBOX\ngog gmail labels delete &lt;labelIdOrName&gt;  # Deletes user label (guards system labels; confirm)\n\n# Batch operations\ngog gmail batch delete &lt;messageId&gt; &lt;messageId&gt;\ngog gmail batch modify &lt;messageId&gt; &lt;messageId&gt; --add STARRED --remove INBOX\n\n# Filters\ngog gmail filters list\ngog gmail filters create --from 'noreply@example.com' --add-label 'Notifications'\ngog gmail filters delete &lt;filterId&gt;\n\n# Settings\ngog gmail autoforward get\ngog gmail autoforward enable --email forward@example.com\ngog gmail autoforward disable\ngog gmail forwarding list\ngog gmail forwarding add --email forward@example.com\ngog gmail sendas list\ngog gmail sendas create --email alias@example.com\ngog gmail vacation get\ngog gmail vacation enable --subject \"Out of office\" --message \"...\"\ngog gmail vacation disable\n\n# Delegation (G Suite/Workspace)\ngog gmail delegates list\ngog gmail delegates add --email delegate@example.com\ngog gmail delegates remove --email delegate@example.com\n\n# Watch (Pub/Sub push)\ngog gmail watch start --topic projects/&lt;p&gt;/topics/&lt;t&gt; --label INBOX\ngog gmail watch serve --bind 127.0.0.1 --token &lt;shared&gt; --hook-url http://127.0.0.1:18789/hooks/agent\ngog gmail watch serve --bind 0.0.0.0 --verify-oidc --oidc-email &lt;svc@...&gt; --hook-url &lt;url&gt;\ngog gmail watch serve --bind 127.0.0.1 --token &lt;shared&gt; --exclude-labels SPAM,TRASH --hook-url http://127.0.0.1:18789/hooks/agent\ngog gmail history --since &lt;historyId&gt;\n</code></pre> \n<p>Gmail watch (Pub/Sub push):</p> \n<ul> \n <li>Create Pub/Sub topic + push subscription (OIDC preferred; shared token ok for dev).</li> \n <li>Full flow + payload details: <code>docs/watch.md</code>.</li> \n <li><code>watch serve --exclude-labels</code> defaults to <code>SPAM,TRASH</code>; IDs are case-sensitive.</li> \n</ul> \n<h3>Email Tracking</h3> \n<p>Track when recipients open your emails:</p> \n<pre><code class=\"language-bash\"># Set up local tracking config (per-account; generates keys; follow printed deploy steps)\ngog gmail track setup --worker-url https://gog-email-tracker.&lt;acct&gt;.workers.dev\n\n# Send with tracking\ngog gmail send --to recipient@example.com --subject \"Hello\" --body-html \"&lt;p&gt;Hi!&lt;/p&gt;\" --track\n\n# Check opens\ngog gmail track opens &lt;tracking_id&gt;\ngog gmail track opens --to recipient@example.com\n\n# View status\ngog gmail track status\n</code></pre> \n<p>Docs: <code>docs/email-tracking.md</code> (setup/deploy) + <code>docs/email-tracking-worker.md</code> (internals).</p> \n<p><strong>Notes:</strong> <code>--track</code> requires exactly 1 recipient (no cc/bcc) and an HTML body (<code>--body-html</code> or <code>--quote</code>). Use <code>--track-split</code> to send per-recipient messages with individual tracking ids. The tracking worker stores IP/user-agent + coarse geo by default.</p> \n<h3>Calendar</h3> \n<pre><code class=\"language-bash\"># Calendars\ngog calendar calendars\ngog calendar acl &lt;calendarId&gt;         # List access control rules\ngog calendar colors                   # List available event/calendar colors\ngog calendar time --timezone America/New_York\ngog calendar users                    # List workspace users (use email as calendar ID)\n\n# Events (with timezone-aware time flags)\ngog calendar events &lt;calendarId&gt; --today                    # Today's events\ngog calendar events &lt;calendarId&gt; --tomorrow                 # Tomorrow's events\ngog calendar events &lt;calendarId&gt; --week                     # This week (Mon-Sun by default; use --week-start)\ngog calendar events &lt;calendarId&gt; --days 3                   # Next 3 days\ngog calendar events &lt;calendarId&gt; --from today --to friday   # Relative dates\ngog calendar events &lt;calendarId&gt; --from today --to friday --weekday   # Include weekday columns\ngog calendar events &lt;calendarId&gt; --from 2025-01-01T00:00:00Z --to 2025-01-08T00:00:00Z\ngog calendar events --all             # Fetch events from all calendars\ngog calendar events --calendars 1,3   # Fetch events from calendar indices (see gog calendar calendars)\ngog calendar events --cal Work --cal Personal  # Fetch events from calendars by name/ID\ngog calendar event &lt;calendarId&gt; &lt;eventId&gt;\ngog calendar get &lt;calendarId&gt; &lt;eventId&gt;                     # Alias for event\ngog calendar search \"meeting\" --today\ngog calendar search \"meeting\" --tomorrow\ngog calendar search \"meeting\" --days 365\ngog calendar search \"meeting\" --from 2025-01-01T00:00:00Z --to 2025-01-31T00:00:00Z --max 50\n\n# Search defaults to 30 days ago through 90 days ahead unless you set --from/--to/--today/--week/--days.\n# Tip: set GOG_CALENDAR_WEEKDAY=1 to default --weekday for calendar events output.\n\n# JSON event output includes timezone and localized times (useful for agents).\ngog calendar get &lt;calendarId&gt; &lt;eventId&gt; --json\n# {\n#   \"event\": {\n#     \"id\": \"...\",\n#     \"summary\": \"...\",\n#     \"startDayOfWeek\": \"Friday\",\n#     \"endDayOfWeek\": \"Friday\",\n#     \"timezone\": \"America/Los_Angeles\",\n#     \"eventTimezone\": \"America/New_York\",\n#     \"startLocal\": \"2026-01-23T20:45:00-08:00\",\n#     \"endLocal\": \"2026-01-23T22:45:00-08:00\",\n#     \"start\": { \"dateTime\": \"2026-01-23T23:45:00-05:00\" },\n#     \"end\": { \"dateTime\": \"2026-01-24T01:45:00-05:00\" }\n#   }\n# }\n\n# Team calendars (requires Cloud Identity API for Google Workspace)\ngog calendar team &lt;group-email&gt; --today           # Show team's events for today\ngog calendar team &lt;group-email&gt; --week            # Show team's events for the week (use --week-start)\ngog calendar team &lt;group-email&gt; --freebusy        # Show only busy/free blocks (faster)\ngog calendar team &lt;group-email&gt; --query \"standup\" # Filter by event title\n\n# Create and update\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Meeting\" \\\n  --from 2025-01-15T10:00:00Z \\\n  --to 2025-01-15T11:00:00Z\n\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Team Sync\" \\\n  --from 2025-01-15T14:00:00Z \\\n  --to 2025-01-15T15:00:00Z \\\n  --attendees \"alice@example.com,bob@example.com\" \\\n  --location \"Zoom\"\n\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --summary \"Updated Meeting\" \\\n  --from 2025-01-15T11:00:00Z \\\n  --to 2025-01-15T12:00:00Z\n\n# Send notifications when creating/updating\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Team Sync\" \\\n  --from 2025-01-15T14:00:00Z \\\n  --to 2025-01-15T15:00:00Z \\\n  --send-updates all\n\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --send-updates externalOnly\n\n# Default: no attendee notifications unless you pass --send-updates.\ngog calendar delete &lt;calendarId&gt; &lt;eventId&gt; \\\n  --send-updates all --force\n\n# Recurrence + reminders\ngog calendar create &lt;calendarId&gt; \\\n  --summary \"Payment\" \\\n  --from 2025-02-11T09:00:00-03:00 \\\n  --to 2025-02-11T09:15:00-03:00 \\\n  --rrule \"RRULE:FREQ=MONTHLY;BYMONTHDAY=11\" \\\n  --reminder \"email:3d\" \\\n  --reminder \"popup:30m\"\n\n# Special event types via --event-type (focus-time/out-of-office/working-location)\ngog calendar create primary \\\n  --event-type focus-time \\\n  --from 2025-01-15T13:00:00Z \\\n  --to 2025-01-15T14:00:00Z\n\ngog calendar create primary \\\n  --event-type out-of-office \\\n  --from 2025-01-20 \\\n  --to 2025-01-21 \\\n  --all-day\n\ngog calendar create primary \\\n  --event-type working-location \\\n  --working-location-type office \\\n  --working-office-label \"HQ\" \\\n  --from 2025-01-22 \\\n  --to 2025-01-23\n\n# Dedicated shortcuts (same event types, more opinionated defaults)\ngog calendar focus-time --from 2025-01-15T13:00:00Z --to 2025-01-15T14:00:00Z\ngog calendar out-of-office --from 2025-01-20 --to 2025-01-21 --all-day\ngog calendar working-location --type office --office-label \"HQ\" --from 2025-01-22 --to 2025-01-23\n# Add attendees without replacing existing attendees/RSVP state\ngog calendar update &lt;calendarId&gt; &lt;eventId&gt; \\\n  --add-attendee \"alice@example.com,bob@example.com\"\n\ngog calendar delete &lt;calendarId&gt; &lt;eventId&gt;\n\n# Invitations\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status accepted\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status declined\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status tentative\ngog calendar respond &lt;calendarId&gt; &lt;eventId&gt; --status declined --send-updates externalOnly\n\n# Propose a new time (browser-only flow; API limitation)\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt;\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt; --open\ngog calendar propose-time &lt;calendarId&gt; &lt;eventId&gt; --decline --comment \"Can we do 5pm?\"\n\n# Availability\ngog calendar freebusy --calendars \"primary,work@example.com\" \\\n  --from 2025-01-15T00:00:00Z \\\n  --to 2025-01-16T00:00:00Z\n\ngog calendar conflicts --calendars \"primary,work@example.com\" \\\n  --today                             # Today's conflicts\n</code></pre> \n<h3>Time</h3> \n<pre><code class=\"language-bash\">gog time now\ngog time now --timezone UTC\n</code></pre> \n<h3>Drive</h3> \n<pre><code class=\"language-bash\"># List and search\ngog drive ls --max 20\ngog drive ls --parent &lt;folderId&gt; --max 20\ngog drive ls --no-all-drives            # Only list from \"My Drive\"\ngog drive search \"invoice\" --max 20\ngog drive search \"invoice\" --no-all-drives\ngog drive search \"mimeType = 'application/pdf'\" --raw-query\ngog drive get &lt;fileId&gt;                # Get file metadata\ngog drive url &lt;fileId&gt;                # Print Drive web URL\ngog drive copy &lt;fileId&gt; \"Copy Name\"\n\n# Upload and download\ngog drive upload ./path/to/file --parent &lt;folderId&gt;\ngog drive upload ./path/to/file --replace &lt;fileId&gt;  # Replace file content in-place (preserves shared link)\ngog drive upload ./report.docx --convert\ngog drive upload ./chart.png --convert-to sheet\ngog drive upload ./report.docx --convert --name report.docx\ngog drive download &lt;fileId&gt; --out ./downloaded.bin\ngog drive download &lt;fileId&gt; --format pdf --out ./exported.pdf     # Google Workspace files only\ngog drive download &lt;fileId&gt; --format docx --out ./doc.docx\ngog drive download &lt;fileId&gt; --format pptx --out ./slides.pptx\n\n# Organize\ngog drive mkdir \"New Folder\"\ngog drive mkdir \"New Folder\" --parent &lt;parentFolderId&gt;\ngog drive rename &lt;fileId&gt; \"New Name\"\ngog drive move &lt;fileId&gt; --parent &lt;destinationFolderId&gt;\ngog drive delete &lt;fileId&gt;             # Move to trash\ngog drive delete &lt;fileId&gt; --permanent # Permanently delete\n\n# Permissions\ngog drive permissions &lt;fileId&gt;\ngog drive share &lt;fileId&gt; --to user --email user@example.com --role reader\ngog drive share &lt;fileId&gt; --to user --email user@example.com --role writer\ngog drive share &lt;fileId&gt; --to domain --domain example.com --role reader\ngog drive unshare &lt;fileId&gt; --permission-id &lt;permissionId&gt;\n\n# Shared drives (Team Drives)\ngog drive drives --max 100\n</code></pre> \n<h3>Docs / Slides / Sheets</h3> \n<pre><code class=\"language-bash\"># Docs\ngog docs info &lt;docId&gt;\ngog docs cat &lt;docId&gt; --max-bytes 10000\ngog docs create \"My Doc\"\ngog docs create \"My Doc\" --file ./doc.md            # Import markdown\ngog docs copy &lt;docId&gt; \"My Doc Copy\"\ngog docs export &lt;docId&gt; --format pdf --out ./doc.pdf\ngog docs list-tabs &lt;docId&gt;\ngog docs cat &lt;docId&gt; --tab \"Notes\"\ngog docs cat &lt;docId&gt; --all-tabs\ngog docs update &lt;docId&gt; --format markdown --content-file ./doc.md\ngog docs write &lt;docId&gt; --replace --markdown --file ./doc.md\ngog docs find-replace &lt;docId&gt; \"old\" \"new\"\n\n# Slides\ngog slides info &lt;presentationId&gt;\ngog slides create \"My Deck\"\ngog slides create-from-markdown \"My Deck\" --content-file ./slides.md\ngog slides copy &lt;presentationId&gt; \"My Deck Copy\"\ngog slides export &lt;presentationId&gt; --format pdf --out ./deck.pdf\ngog slides list-slides &lt;presentationId&gt;\ngog slides add-slide &lt;presentationId&gt; ./slide.png --notes \"Speaker notes\"\ngog slides update-notes &lt;presentationId&gt; &lt;slideId&gt; --notes \"Updated notes\"\ngog slides replace-slide &lt;presentationId&gt; &lt;slideId&gt; ./new-slide.png --notes \"New notes\"\n\n# Sheets\ngog sheets copy &lt;spreadsheetId&gt; \"My Sheet Copy\"\ngog sheets export &lt;spreadsheetId&gt; --format pdf --out ./sheet.pdf\ngog sheets format &lt;spreadsheetId&gt; 'Sheet1!A1:B2' --format-json '{\"textFormat\":{\"bold\":true}}' --format-fields 'userEnteredFormat.textFormat.bold'\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" rows 2 --count 3\ngog sheets notes &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n</code></pre> \n<h3>Contacts</h3> \n<pre><code class=\"language-bash\"># Personal contacts\ngog contacts list --max 50\ngog contacts search \"Ada\" --max 50\ngog contacts get people/&lt;resourceName&gt;\ngog contacts get user@example.com     # Get by email\n\n# Other contacts (people you've interacted with)\ngog contacts other list --max 50\ngog contacts other search \"John\" --max 50\n\n# Create and update\ngog contacts create \\\n  --given \"John\" \\\n  --family \"Doe\" \\\n  --email \"john@example.com\" \\\n  --phone \"+1234567890\"\n\ngog contacts update people/&lt;resourceName&gt; \\\n  --given \"Jane\" \\\n  --email \"jane@example.com\" \\\n  --birthday \"1990-05-12\" \\\n  --notes \"Met at WWDC\"\n\n# Update via JSON (see docs/contacts-json-update.md)\ngog contacts get people/&lt;resourceName&gt; --json | \\\n  jq '(.contact.urls //= []) | (.contact.urls += [{\"value\":\"obsidian://open?vault=notes&amp;file=People/John%20Doe\",\"type\":\"profile\"}])' | \\\n  gog contacts update people/&lt;resourceName&gt; --from-file -\n\ngog contacts delete people/&lt;resourceName&gt;\n\n# Workspace directory (requires Google Workspace)\ngog contacts directory list --max 50\ngog contacts directory search \"Jane\" --max 50\n</code></pre> \n<h3>Tasks</h3> \n<pre><code class=\"language-bash\"># Task lists\ngog tasks lists --max 50\ngog tasks lists create &lt;title&gt;\n\n# Tasks in a list\ngog tasks list &lt;tasklistId&gt; --max 50\ngog tasks get &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks add &lt;tasklistId&gt; --title \"Task title\"\ngog tasks add &lt;tasklistId&gt; --title \"Weekly sync\" --due 2025-02-01 --repeat weekly --repeat-count 4\ngog tasks add &lt;tasklistId&gt; --title \"Daily standup\" --due 2025-02-01 --repeat daily --repeat-until 2025-02-05\ngog tasks update &lt;tasklistId&gt; &lt;taskId&gt; --title \"New title\"\ngog tasks done &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks undo &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks delete &lt;tasklistId&gt; &lt;taskId&gt;\ngog tasks clear &lt;tasklistId&gt;\n\n# Note: Google Tasks treats due dates as date-only; time components may be ignored.\n# See docs/dates.md for all supported date/time input formats across commands.\n</code></pre> \n<h3>Sheets</h3> \n<pre><code class=\"language-bash\"># Read\ngog sheets metadata &lt;spreadsheetId&gt;\ngog sheets get &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Export (via Drive)\ngog sheets export &lt;spreadsheetId&gt; --format pdf --out ./sheet.pdf\ngog sheets export &lt;spreadsheetId&gt; --format xlsx --out ./sheet.xlsx\n\n# Write\ngog sheets update &lt;spreadsheetId&gt; 'A1' 'val1|val2,val3|val4'\ngog sheets update &lt;spreadsheetId&gt; 'A1' --values-json '[[\"a\",\"b\"],[\"c\",\"d\"]]'\ngog sheets update &lt;spreadsheetId&gt; 'Sheet1!A1:C1' 'new|row|data' --copy-validation-from 'Sheet1!A2:C2'\ngog sheets append &lt;spreadsheetId&gt; 'Sheet1!A:C' 'new|row|data'\ngog sheets append &lt;spreadsheetId&gt; 'Sheet1!A:C' 'new|row|data' --copy-validation-from 'Sheet1!A2:C2'\ngog sheets clear &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Format\ngog sheets format &lt;spreadsheetId&gt; 'Sheet1!A1:B2' --format-json '{\"textFormat\":{\"bold\":true}}' --format-fields 'userEnteredFormat.textFormat.bold'\n\n# Insert rows/cols\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" rows 2 --count 3\ngog sheets insert &lt;spreadsheetId&gt; \"Sheet1\" cols 3 --after\n\n# Notes\ngog sheets notes &lt;spreadsheetId&gt; 'Sheet1!A1:B10'\n\n# Create\ngog sheets create \"My New Spreadsheet\" --sheets \"Sheet1,Sheet2\"\n</code></pre> \n<h3>Forms</h3> \n<pre><code class=\"language-bash\"># Forms\ngog forms get &lt;formId&gt;\ngog forms create --title \"Weekly Check-in\" --description \"Friday async update\"\n\n# Responses\ngog forms responses list &lt;formId&gt; --max 20\ngog forms responses get &lt;formId&gt; &lt;responseId&gt;\n</code></pre> \n<h3>Apps Script</h3> \n<pre><code class=\"language-bash\"># Projects\ngog appscript get &lt;scriptId&gt;\ngog appscript content &lt;scriptId&gt;\ngog appscript create --title \"Automation Helpers\"\ngog appscript create --title \"Bound Script\" --parent-id &lt;driveFileId&gt;\n\n# Execute functions\ngog appscript run &lt;scriptId&gt; myFunction --params '[\"arg1\", 123, true]'\ngog appscript run &lt;scriptId&gt; myFunction --dev-mode\n</code></pre> \n<h3>People</h3> \n<pre><code class=\"language-bash\"># Profile\ngog people me\ngog people get people/&lt;userId&gt;\n\n# Search the Workspace directory\ngog people search \"Ada Lovelace\" --max 5\n\n# Relations (defaults to people/me)\ngog people relations\ngog people relations people/&lt;userId&gt; --type manager\n</code></pre> \n<h3>Chat</h3> \n<pre><code class=\"language-bash\"># Spaces\ngog chat spaces list\ngog chat spaces find \"Engineering\"\ngog chat spaces create \"Engineering\" --member alice@company.com --member bob@company.com\n\n# Messages\ngog chat messages list spaces/&lt;spaceId&gt; --max 5\ngog chat messages list spaces/&lt;spaceId&gt; --thread &lt;threadId&gt;\ngog chat messages list spaces/&lt;spaceId&gt; --unread\ngog chat messages send spaces/&lt;spaceId&gt; --text \"Build complete!\" --thread spaces/&lt;spaceId&gt;/threads/&lt;threadId&gt;\n\n# Threads\ngog chat threads list spaces/&lt;spaceId&gt;\n\n# Direct messages\ngog chat dm space user@company.com\ngog chat dm send user@company.com --text \"ping\"\n</code></pre> \n<p>Note: Chat commands require a Google Workspace account (consumer @gmail.com accounts are not supported).</p> \n<h3>Groups (Google Workspace)</h3> \n<pre><code class=\"language-bash\"># List groups you belong to\ngog groups list\n\n# List members of a group\ngog groups members engineering@company.com\n</code></pre> \n<p>Note: Groups commands require the Cloud Identity API and the <code>cloud-identity.groups.readonly</code> scope. If you get a permissions error, re-authenticate:</p> \n<pre><code class=\"language-bash\">gog auth add your@email.com --services groups --force-consent\n</code></pre> \n<h3>Classroom (Google Workspace for Education)</h3> \n<pre><code class=\"language-bash\"># Courses\ngog classroom courses list\ngog classroom courses list --role teacher\ngog classroom courses get &lt;courseId&gt;\ngog classroom courses create --name \"Math 101\"\ngog classroom courses update &lt;courseId&gt; --name \"Math 102\"\ngog classroom courses archive &lt;courseId&gt;\ngog classroom courses unarchive &lt;courseId&gt;\ngog classroom courses url &lt;courseId&gt;\n\n# Roster\ngog classroom roster &lt;courseId&gt;\ngog classroom roster &lt;courseId&gt; --students\ngog classroom students add &lt;courseId&gt; &lt;userId&gt;\ngog classroom teachers add &lt;courseId&gt; &lt;userId&gt;\n\n# Coursework\ngog classroom coursework list &lt;courseId&gt;\ngog classroom coursework get &lt;courseId&gt; &lt;courseworkId&gt;\ngog classroom coursework create &lt;courseId&gt; --title \"Homework 1\" --type ASSIGNMENT --state PUBLISHED\ngog classroom coursework update &lt;courseId&gt; &lt;courseworkId&gt; --title \"Updated\"\ngog classroom coursework assignees &lt;courseId&gt; &lt;courseworkId&gt; --mode INDIVIDUAL_STUDENTS --add-student &lt;studentId&gt;\n\n# Materials\ngog classroom materials list &lt;courseId&gt;\ngog classroom materials create &lt;courseId&gt; --title \"Syllabus\" --state PUBLISHED\n\n# Submissions\ngog classroom submissions list &lt;courseId&gt; &lt;courseworkId&gt;\ngog classroom submissions get &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions grade &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt; --grade 85\ngog classroom submissions return &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions turn-in &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\ngog classroom submissions reclaim &lt;courseId&gt; &lt;courseworkId&gt; &lt;submissionId&gt;\n\n# Announcements\ngog classroom announcements list &lt;courseId&gt;\ngog classroom announcements create &lt;courseId&gt; --text \"Welcome!\"\ngog classroom announcements update &lt;courseId&gt; &lt;announcementId&gt; --text \"Updated\"\ngog classroom announcements assignees &lt;courseId&gt; &lt;announcementId&gt; --mode INDIVIDUAL_STUDENTS --add-student &lt;studentId&gt;\n\n# Topics\ngog classroom topics list &lt;courseId&gt;\ngog classroom topics create &lt;courseId&gt; --name \"Unit 1\"\ngog classroom topics update &lt;courseId&gt; &lt;topicId&gt; --name \"Unit 2\"\n\n# Invitations\ngog classroom invitations list\ngog classroom invitations create &lt;courseId&gt; &lt;userId&gt; --role student\ngog classroom invitations accept &lt;invitationId&gt;\n\n# Guardians\ngog classroom guardians list &lt;studentId&gt;\ngog classroom guardians get &lt;studentId&gt; &lt;guardianId&gt;\ngog classroom guardians delete &lt;studentId&gt; &lt;guardianId&gt;\n\n# Guardian invitations\ngog classroom guardian-invitations list &lt;studentId&gt;\ngog classroom guardian-invitations create &lt;studentId&gt; --email parent@example.com\n\n# Profiles\ngog classroom profile get\ngog classroom profile get &lt;userId&gt;\n</code></pre> \n<p>Note: Classroom commands require a Google Workspace for Education account. Personal Google accounts have limited Classroom functionality.</p> \n<h3>Docs</h3> \n<pre><code class=\"language-bash\"># Export (via Drive)\ngog docs export &lt;docId&gt; --format pdf --out ./doc.pdf\ngog docs export &lt;docId&gt; --format docx --out ./doc.docx\ngog docs export &lt;docId&gt; --format txt --out ./doc.txt\n</code></pre> \n<h3>Slides</h3> \n<pre><code class=\"language-bash\"># Export (via Drive)\ngog slides export &lt;presentationId&gt; --format pptx --out ./deck.pptx\ngog slides export &lt;presentationId&gt; --format pdf --out ./deck.pdf\n</code></pre> \n<h2>Output Formats</h2> \n<h3>Text</h3> \n<p>Human-readable output with colors (default):</p> \n<pre><code class=\"language-bash\">$ gog gmail search 'newer_than:7d' --max 3\nTHREAD_ID           SUBJECT                           FROM                  DATE\n18f1a2b3c4d5e6f7    Meeting notes                     alice@example.com     2025-01-10\n17e1d2c3b4a5f6e7    Invoice #12345                    billing@vendor.com    2025-01-09\n16d1c2b3a4e5f6d7    Project update                    bob@example.com       2025-01-08\n</code></pre> \n<p>Message-level search (one row per email; add <code>--include-body</code> to fetch/decode bodies):</p> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 3\nID                  THREAD             SUBJECT                           FROM                  DATE\n18f1a2b3c4d5e6f7    9e8d7c6b5a4f3e2d    Meeting notes                     alice@example.com     2025-01-10\n17e1d2c3b4a5f6e7    9e8d7c6b5a4f3e2d    Invoice #12345                    billing@vendor.com    2025-01-09\n16d1c2b3a4e5f6d7    7f6e5d4c3b2a1908    Project update                    bob@example.com       2025-01-08\n</code></pre> \n<h3>JSON</h3> \n<p>Machine-readable output for scripting and automation:</p> \n<pre><code class=\"language-bash\">$ gog gmail search 'newer_than:7d' --max 3 --json\n{\n  \"threads\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"snippet\": \"Meeting notes from today...\",\n      \"messages\": [...]\n    },\n    ...\n  ]\n}\n</code></pre> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 3 --json\n{\n  \"messages\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"threadId\": \"9e8d7c6b5a4f3e2d\",\n      \"subject\": \"Meeting notes\",\n      \"from\": \"alice@example.com\",\n      \"date\": \"2025-01-10\"\n    },\n    ...\n  ]\n}\n</code></pre> \n<pre><code class=\"language-bash\">$ gog gmail messages search 'newer_than:7d' --max 1 --include-body --json\n{\n  \"messages\": [\n    {\n      \"id\": \"18f1a2b3c4d5e6f7\",\n      \"threadId\": \"9e8d7c6b5a4f3e2d\",\n      \"subject\": \"Meeting notes\",\n      \"from\": \"alice@example.com\",\n      \"date\": \"2025-01-10\",\n      \"body\": \"Hi team — meeting notes...\"\n    }\n  ]\n}\n</code></pre> \n<p>Data goes to stdout, errors and progress to stderr for clean piping:</p> \n<pre><code class=\"language-bash\">gog --json drive ls --max 5 | jq '.files[] | select(.mimeType==\"application/pdf\")'\n</code></pre> \n<p>Useful pattern:</p> \n<ul> \n <li><code>gog --json ... | jq .</code></li> \n</ul> \n<p>Calendar JSON convenience fields:</p> \n<ul> \n <li><code>startDayOfWeek</code> / <code>endDayOfWeek</code> on event payloads (derived from start/end).</li> \n</ul> \n<h2>Examples</h2> \n<h3>Search recent emails and download attachments</h3> \n<pre><code class=\"language-bash\"># Search for emails from the last week\ngog gmail search 'newer_than:7d has:attachment' --max 10\n\n# Get thread details and download attachments\ngog gmail thread get &lt;threadId&gt; --download\n</code></pre> \n<h3>Modify labels on a thread</h3> \n<pre><code class=\"language-bash\"># Archive and star a thread\ngog gmail thread modify &lt;threadId&gt; --remove INBOX --add STARRED\n</code></pre> \n<h3>Create a calendar event with attendees</h3> \n<pre><code class=\"language-bash\"># Find a free time slot\ngog calendar freebusy --calendars \"primary\" \\\n  --from 2025-01-15T00:00:00Z \\\n  --to 2025-01-16T00:00:00Z\n\n# Create the meeting\ngog calendar create primary \\\n  --summary \"Team Standup\" \\\n  --from 2025-01-15T10:00:00Z \\\n  --to 2025-01-15T10:30:00Z \\\n  --attendees \"alice@example.com,bob@example.com\"\n</code></pre> \n<h3>Find and download files from Drive</h3> \n<pre><code class=\"language-bash\"># Search for PDFs\ngog drive search \"invoice filetype:pdf\" --max 20 --json | \\\n  jq -r '.files[] | .id' | \\\n  while read fileId; do\n    gog drive download \"$fileId\"\n  done\n</code></pre> \n<h3>Manage multiple accounts</h3> \n<pre><code class=\"language-bash\"># Check personal Gmail\ngog gmail search 'is:unread' --account personal@gmail.com\n\n# Check work Gmail\ngog gmail search 'is:unread' --account work@company.com\n\n# Or set default\nexport GOG_ACCOUNT=work@company.com\ngog gmail search 'is:unread'\n</code></pre> \n<h3>Update a Google Sheet from a CSV</h3> \n<pre><code class=\"language-bash\"># Convert CSV to pipe-delimited format and update sheet\ncat data.csv | tr ',' '|' | \\\n  gog sheets update &lt;spreadsheetId&gt; 'Sheet1!A1'\n</code></pre> \n<h3>Export Sheets / Docs / Slides</h3> \n<pre><code class=\"language-bash\"># Sheets\ngog sheets export &lt;spreadsheetId&gt; --format pdf\n\n# Docs\ngog docs export &lt;docId&gt; --format docx\n\n# Slides\ngog slides export &lt;presentationId&gt; --format pptx\n</code></pre> \n<h3>Batch process Gmail threads</h3> \n<pre><code class=\"language-bash\"># Mark all emails from a sender as read\ngog --json gmail search 'from:noreply@example.com' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --remove UNREAD\n\n# Archive old emails\ngog --json gmail search 'older_than:1y' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --remove INBOX\n\n# Label important emails\ngog --json gmail search 'from:boss@example.com' --max 200 | \\\n  jq -r '.threads[].id' | \\\n  xargs -n 50 gog gmail labels modify --add IMPORTANT\n</code></pre> \n<h2>Advanced Features</h2> \n<h3>Verbose Mode</h3> \n<p>Enable verbose logging for troubleshooting:</p> \n<pre><code class=\"language-bash\">gog --verbose gmail search 'newer_than:7d'\n# Shows API requests and responses\n</code></pre> \n<h2>Global Flags</h2> \n<p>All commands support these flags:</p> \n<ul> \n <li><code>--account &lt;email|alias|auto&gt;</code> - Account to use (overrides GOG_ACCOUNT)</li> \n <li><code>--enable-commands &lt;csv&gt;</code> - Allowlist top-level commands (e.g., <code>calendar,tasks</code>)</li> \n <li><code>--json</code> - Output JSON to stdout (best for scripting)</li> \n <li><code>--plain</code> - Output stable, parseable text to stdout (TSV; no colors)</li> \n <li><code>--color &lt;mode&gt;</code> - Color mode: <code>auto</code>, <code>always</code>, or <code>never</code> (default: auto)</li> \n <li><code>--force</code> - Skip confirmations for destructive commands</li> \n <li><code>--no-input</code> - Never prompt; fail instead (useful for CI)</li> \n <li><code>--verbose</code> - Enable verbose logging</li> \n <li><code>--help</code> - Show help for any command</li> \n</ul> \n<h2>Shell Completions</h2> \n<p>Generate shell completions for your preferred shell:</p> \n<h3>Bash</h3> \n<pre><code class=\"language-bash\"># macOS (with Homebrew)\ngog completion bash &gt; $(brew --prefix)/etc/bash_completion.d/gog\n\n# Linux\ngog completion bash &gt; /etc/bash_completion.d/gog\n\n# Or load directly in your current session\nsource &lt;(gog completion bash)\n</code></pre> \n<h3>Zsh</h3> \n<pre><code class=\"language-zsh\"># Generate completion file\ngog completion zsh &gt; \"${fpath[1]}/_gog\"\n\n# Or add to .zshrc for automatic loading\necho 'eval \"$(gog completion zsh)\"' &gt;&gt; ~/.zshrc\n\n# Enable completions if not already enabled\necho \"autoload -U compinit; compinit\" &gt;&gt; ~/.zshrc\n</code></pre> \n<h3>Fish</h3> \n<pre><code class=\"language-fish\">gog completion fish &gt; ~/.config/fish/completions/gog.fish\n</code></pre> \n<h3>PowerShell</h3> \n<pre><code class=\"language-powershell\"># Load for current session\ngog completion powershell | Out-String | Invoke-Expression\n\n# Or add to profile for all sessions\ngog completion powershell &gt;&gt; $PROFILE\n</code></pre> \n<p>After installing completions, start a new shell session for changes to take effect.</p> \n<h2>Development</h2> \n<p>After cloning, install tools:</p> \n<pre><code class=\"language-bash\">make tools\n</code></pre> \n<p>Pinned tools (installed into <code>.tools/</code>):</p> \n<ul> \n <li>Format: <code>make fmt</code> (goimports + gofumpt)</li> \n <li>Lint: <code>make lint</code> (golangci-lint)</li> \n <li>Test: <code>make test</code></li> \n</ul> \n<p>CI runs format checks, tests, and lint on push/PR.</p> \n<h3>Integration Tests (Live Google APIs)</h3> \n<p>Opt-in tests that hit real Google APIs using your stored <code>gog</code> credentials/tokens.</p> \n<pre><code class=\"language-bash\"># Optional: override which account to use\nexport GOG_IT_ACCOUNT=you@gmail.com\nexport GOG_CLIENT=work\ngo test -tags=integration ./...\n</code></pre> \n<p>Tip: if you want to avoid macOS Keychain prompts during these runs, set <code>GOG_KEYRING_BACKEND=file</code> and <code>GOG_KEYRING_PASSWORD=...</code> (uses encrypted on-disk keyring).</p> \n<h3>Live Test Script (CLI)</h3> \n<p>Fast end-to-end smoke checks against live APIs:</p> \n<pre><code class=\"language-bash\">scripts/live-test.sh --fast\nscripts/live-test.sh --account you@gmail.com --skip groups,keep,calendar-enterprise\nscripts/live-test.sh --client work --account you@company.com\n</code></pre> \n<p>Script toggles:</p> \n<ul> \n <li><code>--auth all,groups</code> to re-auth before running</li> \n <li><code>--client &lt;name&gt;</code> to select OAuth client credentials</li> \n <li><code>--strict</code> to fail on optional features (groups/keep/enterprise)</li> \n <li><code>--allow-nontest</code> to override the test-account guardrail</li> \n</ul> \n<p>Go test wrapper (opt-in):</p> \n<pre><code class=\"language-bash\">GOG_LIVE=1 go test -tags=integration ./internal/integration -run Live\n</code></pre> \n<p>Optional env:</p> \n<ul> \n <li><code>GOG_LIVE_FAST=1</code></li> \n <li><code>GOG_LIVE_SKIP=groups,keep</code></li> \n <li><code>GOG_LIVE_AUTH=all,groups</code></li> \n <li><code>GOG_LIVE_ALLOW_NONTEST=1</code></li> \n <li><code>GOG_LIVE_EMAIL_TEST=steipete+gogtest@gmail.com</code></li> \n <li><code>GOG_LIVE_GROUP_EMAIL=group@domain</code></li> \n <li><code>GOG_LIVE_CLASSROOM_COURSE=&lt;courseId&gt;</code></li> \n <li><code>GOG_LIVE_CLASSROOM_CREATE=1</code></li> \n <li><code>GOG_LIVE_CLASSROOM_ALLOW_STATE=1</code></li> \n <li><code>GOG_LIVE_TRACK=1</code></li> \n <li><code>GOG_LIVE_GMAIL_BATCH_DELETE=1</code></li> \n <li><code>GOG_LIVE_GMAIL_FILTERS=1</code></li> \n <li><code>GOG_LIVE_GMAIL_WATCH_TOPIC=projects/.../topics/...</code></li> \n <li><code>GOG_LIVE_CALENDAR_RESPOND=1</code></li> \n <li><code>GOG_LIVE_CALENDAR_RECURRENCE=1</code></li> \n <li><code>GOG_KEEP_SERVICE_ACCOUNT=/path/to/service-account.json</code></li> \n <li><code>GOG_KEEP_IMPERSONATE=user@workspace-domain</code></li> \n</ul> \n<h3>Make Shortcut</h3> \n<p>Build and run:</p> \n<pre><code class=\"language-bash\">make gog auth add you@gmail.com\n</code></pre> \n<p>For clean stdout when scripting:</p> \n<ul> \n <li>Use <code>--</code> when the first arg is a flag: <code>make gog -- --json gmail search \"from:me\" | jq .</code></li> \n</ul> \n<h2>License</h2> \n<p>MIT</p> \n<h2>Links</h2> \n<ul> \n <li><a href=\"https://github.com/steipete/gogcli\">GitHub Repository</a></li> \n <li><a href=\"https://developers.google.com/gmail/api\">Gmail API Documentation</a></li> \n <li><a href=\"https://developers.google.com/calendar\">Google Calendar API Documentation</a></li> \n <li><a href=\"https://developers.google.com/drive\">Google Drive API Documentation</a></li> \n <li><a href=\"https://developers.google.com/people\">Google People API Documentation</a></li> \n <li><a href=\"https://developers.google.com/tasks\">Google Tasks API Documentation</a></li> \n <li><a href=\"https://developers.google.com/sheets\">Google Sheets API Documentation</a></li> \n <li><a href=\"https://cloud.google.com/identity/docs/reference/rest\">Cloud Identity API Documentation</a></li> \n</ul> \n<h2>Credits</h2> \n<p>This project is inspired by Mario Zechner's original CLIs:</p> \n<ul> \n <li><a href=\"https://github.com/badlogic/gmcli\">gmcli</a></li> \n <li><a href=\"https://github.com/badlogic/gccli\">gccli</a></li> \n <li><a href=\"https://github.com/badlogic/gdcli\">gdcli</a></li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:38.373547Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 16,
        "timeliness_score": 1,
        "final_score": 8.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/SynkraAI/aios-core",
        "title": "SynkraAI/aios-core",
        "summary": "<p>Synkra AIOS: AI-Orchestrated System for Full Stack Development - Core Framework v4.0</p><hr /><h1>Synkra AIOS: Framework Universal de Agentes IA 🚀</h1> \n<p><a href=\"https://www.npmjs.com/package/aios-core\"><img alt=\"Versão NPM\" src=\"https://img.shields.io/npm/v/aios-core.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\"><img alt=\"Licença: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true\" /></a> <a href=\"https://nodejs.org/\"><img alt=\"Versão Node.js\" src=\"https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true\" /></a> <a href=\"https://github.com/SynkraAI/aios-core/actions/workflows/ci.yml\"><img alt=\"CI\" src=\"https://github.com/SynkraAI/aios-core/actions/workflows/ci.yml/badge.svg?sanitize=true\" /></a> <a href=\"https://codecov.io/gh/SynkraAI/aios-core\"><img alt=\"codecov\" src=\"https://codecov.io/gh/SynkraAI/aios-core/branch/main/graph/badge.svg?sanitize=true\" /></a> <a href=\"https://synkra.ai\"><img alt=\"Documentação\" src=\"https://img.shields.io/badge/docs-dispon%C3%ADvel-orange.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\"><img alt=\"Open Source\" src=\"https://img.shields.io/badge/Open%20Source-Yes-success.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\"><img alt=\"Contributions Welcome\" src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CODE_OF_CONDUCT.md\"><img alt=\"Code of Conduct\" src=\"https://img.shields.io/badge/code%20of%20conduct-Contributor%20Covenant-blue.svg?sanitize=true\" /></a></p> \n<p>Framework de Desenvolvimento Auto-Modificável Alimentado por IA. Fundado em Desenvolvimento Ágil Dirigido por Agentes, oferecendo capacidades revolucionárias para desenvolvimento dirigido por IA e muito mais. Transforme qualquer domínio com expertise especializada de IA: desenvolvimento de software, entretenimento, escrita criativa, estratégia de negócios, bem-estar pessoal e muito mais.</p> \n<h2>Comece Aqui (10 Min)</h2> \n<p>Se é sua primeira vez no AIOS, siga este caminho linear:</p> \n<ol> \n <li>Instale em um projeto novo ou existente:</li> \n</ol> \n<pre><code class=\"language-bash\"># novo projeto\nnpx aios-core init meu-projeto\n\n# projeto existente\ncd seu-projeto\nnpx aios-core install\n</code></pre> \n<ol start=\"2\"> \n <li>Escolha sua IDE/CLI e o caminho de ativação:</li> \n</ol> \n<ul> \n <li>Claude Code: <code>/agent-name</code></li> \n <li>Gemini CLI: <code>/aios-menu</code> → <code>/aios-&lt;agent&gt;</code></li> \n <li>Codex CLI: <code>/skills</code> → <code>aios-&lt;agent-id&gt;</code></li> \n <li>Cursor/Copilot/AntiGravity: siga os limites e workarounds em <code>docs/ide-integration.md</code></li> \n</ul> \n<ol start=\"3\"> \n <li>Ative 1 agente e confirme o greeting.</li> \n <li>Rode 1 comando inicial (<code>*help</code> ou equivalente) para validar first-value.</li> \n</ol> \n<p>Definição de first-value (binária): ativação de agente + greeting válido + comando inicial com output útil em &lt;= 10 minutos.</p> \n<h2>Compatibilidade de Hooks por IDE (Realidade AIOS 4.2)</h2> \n<p>Muitos recursos avançados do AIOS dependem de eventos de ciclo de vida (hooks). A tabela abaixo mostra a paridade real entre IDEs/plataformas:</p> \n<table> \n <thead> \n  <tr> \n   <th>IDE/CLI</th> \n   <th>Paridade de Hooks vs Claude</th> \n   <th>Impacto Prático</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Claude Code</td> \n   <td>Completa (referência)</td> \n   <td>Automação máxima de contexto, guardrails e auditoria</td> \n  </tr> \n  <tr> \n   <td>Gemini CLI</td> \n   <td>Alta (eventos nativos)</td> \n   <td>Cobertura forte de automações pre/post tool e sessão</td> \n  </tr> \n  <tr> \n   <td>Codex CLI</td> \n   <td>Parcial/limitada</td> \n   <td>Parte das automações depende de <code>AGENTS.md</code>, <code>/skills</code>, MCP e fluxo operacional</td> \n  </tr> \n  <tr> \n   <td>Cursor</td> \n   <td>Sem lifecycle hooks equivalentes</td> \n   <td>Menor automação de pre/post tool; foco em regras, MCP e fluxo do agente</td> \n  </tr> \n  <tr> \n   <td>GitHub Copilot</td> \n   <td>Sem lifecycle hooks equivalentes</td> \n   <td>Menor automação de sessão/tooling; foco em instruções de repositório + MCP no VS Code</td> \n  </tr> \n  <tr> \n   <td>AntiGravity</td> \n   <td>Workflow-based (não hook-based)</td> \n   <td>Integração por workflows, não por eventos de hook equivalentes ao Claude</td> \n  </tr> \n </tbody> \n</table> \n<p>Impactos e mitigação detalhados: <code>docs/ide-integration.md</code>.</p> \n<h2>Acknowledgments &amp; Attribution</h2> \n<p>Synkra AIOS was originally derived from the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">BMad Method</a>, created by <a href=\"https://github.com/bmadcode\">Brian Madison</a> (BMad Code, LLC). We gratefully acknowledge the BMad Method for providing the foundation from which this project began.</p> \n<p><strong>Important:</strong> This project is <strong>NOT affiliated with, endorsed by, or sanctioned by</strong> the BMad Method or BMad Code, LLC. Contributors appearing in the git history from the original BMad Method repository do not imply active participation in or endorsement of Synkra AIOS.</p> \n<p>Since its origin, AIOS has evolved significantly with its own architecture, terminology, and features (v4.x+), and does not depend on BMad for current operation. The BMad Method remains an excellent framework in its own right — please visit the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">official BMad Method repository</a> to learn more.</p> \n<p>BMad, BMad Method, and BMad Core are trademarks of BMad Code, LLC. See <a href=\"https://github.com/bmad-code-org/BMAD-METHOD/raw/main/TRADEMARK.md\">TRADEMARK.md</a> for usage guidelines.</p> \n<h2>Visão Geral</h2> \n<h3>Premissa Arquitetural: CLI First</h3> \n<p>O Synkra AIOS segue uma hierarquia clara de prioridades:</p> \n<pre><code>CLI First → Observability Second → UI Third\n</code></pre> \n<table> \n <thead> \n  <tr> \n   <th>Camada</th> \n   <th>Prioridade</th> \n   <th>Foco</th> \n   <th>Exemplos</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>CLI</strong></td> \n   <td>Máxima</td> \n   <td>Onde a inteligência vive. Toda execução, decisões e automação acontecem aqui.</td> \n   <td>Agentes (<code>@dev</code>, <code>@qa</code>), workflows, comandos</td> \n  </tr> \n  <tr> \n   <td><strong>Observability</strong></td> \n   <td>Secundária</td> \n   <td>Observar e monitorar o que acontece no CLI em tempo real.</td> \n   <td>Dashboard SSE, logs, métricas, timeline</td> \n  </tr> \n  <tr> \n   <td><strong>UI</strong></td> \n   <td>Terciária</td> \n   <td>Gestão pontual e visualizações quando necessário.</td> \n   <td>Kanban, settings, story management</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Princípios derivados:</strong></p> \n<ul> \n <li>A CLI é a fonte da verdade - dashboards apenas observam</li> \n <li>Funcionalidades novas devem funcionar 100% via CLI antes de ter UI</li> \n <li>A UI nunca deve ser requisito para operação do sistema</li> \n <li>Observabilidade serve para entender o que o CLI está fazendo, não para controlá-lo</li> \n</ul> \n<hr /> \n<p><strong>As Duas Inovações Chave do Synkra AIOS:</strong></p> \n<p><strong>1. Planejamento Agêntico:</strong> Agentes dedicados (analyst, pm, architect) colaboram com você para criar documentos de PRD e Arquitetura detalhados e consistentes. Através de engenharia avançada de prompts e refinamento com human-in-the-loop, estes agentes de planejamento produzem especificações abrangentes que vão muito além da geração genérica de tarefas de IA.</p> \n<p><strong>2. Desenvolvimento Contextualizado por Engenharia:</strong> O agente sm (Scrum Master) então transforma estes planos detalhados em histórias de desenvolvimento hiperdetalhadas que contêm tudo que o agente dev precisa - contexto completo, detalhes de implementação e orientação arquitetural incorporada diretamente nos arquivos de histórias.</p> \n<p>Esta abordagem de duas fases elimina tanto a <strong>inconsistência de planejamento</strong> quanto a <strong>perda de contexto</strong> - os maiores problemas no desenvolvimento assistido por IA. Seu agente dev abre um arquivo de história com compreensão completa do que construir, como construir e por quê.</p> \n<p><strong>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Veja o fluxo de trabalho completo no Guia do Usuário</a></strong> - Fase de planejamento, ciclo de desenvolvimento e todos os papéis dos agentes</p> \n<h2>Pré-requisitos</h2> \n<ul> \n <li>Node.js &gt;=18.0.0 (v20+ recomendado)</li> \n <li>npm &gt;=9.0.0</li> \n <li>GitHub CLI (opcional, necessário para colaboração em equipe)</li> \n</ul> \n<blockquote> \n <p><strong>Problemas de instalação?</strong> Consulte o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/installation-troubleshooting.md\">Guia de Troubleshooting</a></p> \n</blockquote> \n<p><strong>Guias específicos por plataforma:</strong></p> \n<ul> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/macos.md\">Guia de Instalação para macOS</a></li> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/windows.md\">Guia de Instalação para Windows</a></li> \n <li>📖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/installation/linux.md\">Guia de Instalação para Linux</a></li> \n</ul> \n<p><strong>Documentação multilíngue disponível:</strong> <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/installation/\">Português</a> | <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/es/installation/\">Español</a></p> \n<h2>Navegação Rápida</h2> \n<h3>Entendendo o Fluxo de Trabalho AIOS</h3> \n<p><strong>Antes de mergulhar, revise estes diagramas críticos de fluxo de trabalho que explicam como o AIOS funciona:</strong></p> \n<ol> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md#the-planning-workflow-web-ui\">Fluxo de Planejamento (Interface Web)</a></strong> - Como criar documentos de PRD e Arquitetura</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md#the-core-development-cycle-ide\">Ciclo Principal de Desenvolvimento (IDE)</a></strong> - Como os agentes sm, dev e qa colaboram através de arquivos de histórias</li> \n</ol> \n<blockquote> \n <p>⚠️ <strong>Estes diagramas explicam 90% da confusão sobre o fluxo Synkra AIOS Agentic Agile</strong> - Entender a criação de PRD+Arquitetura e o fluxo de trabalho sm/dev/qa e como os agentes passam notas através de arquivos de histórias é essencial - e também explica por que isto NÃO é taskmaster ou apenas um simples executor de tarefas!</p> \n</blockquote> \n<h3>O que você gostaria de fazer?</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#in%C3%ADcio-r%C3%A1pido\">Instalar e Construir software com Equipe Ágil Full Stack de IA</a></strong> → Instruções de Início Rápido</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Aprender como usar o AIOS</a></strong> → Guia completo do usuário e passo a passo</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#agentes-dispon%C3%ADveis\">Ver agentes IA disponíveis</a></strong> → Papéis especializados para sua equipe</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#-al%C3%A9m-do-desenvolvimento-de-software---squads\">Explorar usos não técnicos</a></strong> → Escrita criativa, negócios, bem-estar, educação</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#criando-seu-pr%C3%B3prio-squad\">Criar meus próprios agentes IA</a></strong> → Construir agentes para seu domínio</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-overview.md\">Navegar Squads prontos</a></strong> → Veja como criar e usar equipes de agentes IA</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ARCHITECTURE-INDEX.md\">Entender a arquitetura</a></strong> → Mergulho técnico profundo</li> \n <li><strong><a href=\"https://github.com/SynkraAI/aios-core/issues\">Reportar problemas</a></strong> → Bug reports e feature requests</li> \n</ul> \n<h2>Importante: Mantenha Sua Instalação AIOS Atualizada</h2> \n<p><strong>Mantenha-se atualizado sem esforço!</strong> Para atualizar sua instalação AIOS existente:</p> \n<pre><code class=\"language-bash\">npx aios-core@latest install\n</code></pre> \n<p>Isto vai:</p> \n<ul> \n <li>✅ Detectar automaticamente sua instalação existente</li> \n <li>✅ Atualizar apenas os arquivos que mudaram</li> \n <li>✅ Criar arquivos de backup <code>.bak</code> para quaisquer modificações customizadas</li> \n <li>✅ Preservar suas configurações específicas do projeto</li> \n</ul> \n<p>Isto facilita beneficiar-se das últimas melhorias, correções de bugs e novos agentes sem perder suas customizações!</p> \n<h2>Início Rápido</h2> \n<h3>🚀 Instalação via NPX (Recomendado)</h3> \n<p><strong>Instale o Synkra AIOS com um único comando:</strong></p> \n<pre><code class=\"language-bash\"># Criar um novo projeto com assistente interativo moderno\nnpx aios-core init meu-projeto\n\n# Ou instalar em projeto existente\ncd seu-projeto\nnpx aios-core install\n\n# Ou usar uma versão específica\nnpx aios-core@latest init meu-projeto\n</code></pre> \n<h3>✨ Assistente de Instalação Moderno</h3> \n<p>O Synkra AIOS agora inclui uma experiência de instalação interativa de última geração, inspirada em ferramentas modernas como Vite e Next.js:</p> \n<p><strong>Recursos do Instalador Interativo:</strong></p> \n<ul> \n <li>🎨 <strong>Interface Moderna</strong>: Prompts coloridos e visuais com @clack/prompts</li> \n <li>✅ <strong>Validação em Tempo Real</strong>: Feedback instantâneo sobre entradas inválidas</li> \n <li>🔄 <strong>Indicadores de Progresso</strong>: Spinners para operações longas (cópia de arquivos, instalação de deps)</li> \n <li>📦 <strong>Seleção Multi-Componente</strong>: Escolha quais componentes instalar com interface intuitiva</li> \n <li>⚙️ <strong>Escolha de Gerenciador de Pacotes</strong>: Selecione entre npm, yarn ou pnpm</li> \n <li>⌨️ <strong>Suporte a Cancelamento</strong>: Ctrl+C ou ESC para sair graciosamente a qualquer momento</li> \n <li>📊 <strong>Resumo de Instalação</strong>: Visualize todas as configurações antes de prosseguir</li> \n <li>⏱️ <strong>Rastreamento de Duração</strong>: Veja quanto tempo levou a instalação</li> \n</ul> \n<p><strong>O instalador oferece:</strong></p> \n<ul> \n <li>✅ Download da versão mais recente do NPM</li> \n <li>✅ Assistente de instalação interativo moderno</li> \n <li>✅ Configuração automática do IDE (Codex CLI, Cursor ou Claude Code)</li> \n <li>✅ Configuração de todos os agentes e fluxos de trabalho AIOS</li> \n <li>✅ Criação dos arquivos de configuração necessários</li> \n <li>✅ Inicialização do sistema de meta-agentes</li> \n <li>✅ Verificações de saúde do sistema</li> \n <li>✅ <strong>Suporte Cross-Platform</strong>: Testado em Windows, macOS e Linux</li> \n</ul> \n<blockquote> \n <p><strong>É isso!</strong> Sem clonar, sem configuração manual - apenas um comando e você está pronto para começar com uma experiência de instalação moderna e profissional.</p> \n</blockquote> \n<p><strong>Pré-requisitos</strong>: <a href=\"https://nodejs.org\">Node.js</a> v18+ necessário (v20+ recomendado) | <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/installation-troubleshooting.md\">Troubleshooting</a></p> \n<h3>Atualizando uma Instalação Existente</h3> \n<p>Se você já tem o AIOS instalado:</p> \n<pre><code class=\"language-bash\">npx aios-core@latest install\n# O instalador detectará sua instalação existente e a atualizará\n</code></pre> \n<h3>Configure Seu IDE para Desenvolvimento AIOS</h3> \n<p>O Synkra AIOS inclui regras pré-configuradas para IDE para melhorar sua experiência de desenvolvimento:</p> \n<h4>Para Cursor:</h4> \n<ol> \n <li>Abra as configurações do Cursor</li> \n <li>Navegue até <strong>User Rules</strong></li> \n <li>Copie o conteúdo de <code>.cursor/global-rules.md</code></li> \n <li>Cole na seção de regras e salve</li> \n</ol> \n<h4>Para Claude Code:</h4> \n<ul> \n <li>✅ Já configurado! O arquivo <code>.claude/CLAUDE.md</code> é carregado automaticamente</li> \n <li>Sync dedicado de agentes: <code>npm run sync:ide:claude</code></li> \n <li>Validacao dedicada: <code>npm run validate:claude-sync &amp;&amp; npm run validate:claude-integration</code></li> \n</ul> \n<h4>Para Codex CLI:</h4> \n<ul> \n <li>✅ Integração de primeira classe no AIOS 4.2 (pipeline de ativação e greeting compartilhado)</li> \n <li>✅ Já configurado! O arquivo <code>AGENTS.md</code> na raiz é carregado automaticamente</li> \n <li>Opcional: sincronize agentes auxiliares com <code>npm run sync:ide:codex</code></li> \n <li>Recomendado neste repositório: gerar e versionar skills locais com <code>npm run sync:skills:codex</code></li> \n <li>Use <code>npm run sync:skills:codex:global</code> apenas fora deste projeto (para evitar duplicidade no <code>/skills</code>)</li> \n <li>Validacao dedicada: <code>npm run validate:codex-sync &amp;&amp; npm run validate:codex-integration</code></li> \n <li>Guardrails de skills/paths: <code>npm run validate:codex-skills &amp;&amp; npm run validate:paths</code></li> \n</ul> \n<h4>Para Gemini CLI:</h4> \n<ul> \n <li>✅ Regras e agentes sincronizaveis com <code>npm run sync:ide:gemini</code></li> \n <li>Arquivos gerados em <code>.gemini/rules.md</code>, <code>.gemini/rules/AIOS/agents/</code> e <code>.gemini/commands/*.toml</code></li> \n <li>✅ Hooks e settings locais no fluxo de instalacao (<code>.gemini/hooks/</code> + <code>.gemini/settings.json</code>)</li> \n <li>✅ Ativacao rapida por slash commands (<code>/aios-menu</code>, <code>/aios-dev</code>, <code>/aios-architect</code>, etc.)</li> \n <li>Validacao dedicada: <code>npm run validate:gemini-sync &amp;&amp; npm run validate:gemini-integration</code></li> \n <li>Paridade multi-IDE em um comando: <code>npm run validate:parity</code></li> \n</ul> \n<p>Estas regras fornecem:</p> \n<ul> \n <li>🤖 Reconhecimento e integração de comandos de agentes</li> \n <li>📋 Fluxo de trabalho de desenvolvimento dirigido por histórias</li> \n <li>✅ Rastreamento automático de checkboxes</li> \n <li>🧪 Padrões de teste e validação</li> \n <li>📝 Padrões de código específicos do AIOS</li> \n</ul> \n<h3>Início Mais Rápido com Interface Web (2 minutos)</h3> \n<ol> \n <li><strong>Instale o AIOS</strong>: Execute <code>npx aios-core init meu-projeto</code></li> \n <li><strong>Configure seu IDE</strong>: Siga as instruções de configuração para Codex CLI, Cursor ou Claude Code</li> \n <li><strong>Comece a Planejar</strong>: Ative um agente como <code>@analyst</code> para começar a criar seu briefing</li> \n <li><strong>Use comandos AIOS</strong>: Digite <code>*help</code> para ver comandos disponíveis</li> \n <li><strong>Siga o fluxo</strong>: Veja o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Guia do usuário</a> para mais detalhes</li> \n</ol> \n<h3>Referência de Comandos CLI</h3> \n<p>O Synkra AIOS oferece uma CLI moderna e cross-platform com comandos intuitivos:</p> \n<pre><code class=\"language-bash\"># Gerenciamento de Projeto (com assistente interativo)\nnpx aios-core init &lt;nome-projeto&gt; [opções]\n  --force              Forçar criação em diretório não vazio\n  --skip-install       Pular instalação de dependências npm\n  --template &lt;nome&gt;    Usar template específico (default, minimal, enterprise)\n\n# Instalação e Configuração (com prompts modernos)\nnpx aios-core install [opções]\n  --force              Sobrescrever configuração existente\n  --quiet              Saída mínima durante instalação\n  --dry-run            Simular instalação sem modificar arquivos\n\n# Comandos do Sistema\nnpx aios-core --version   Exibir versão instalada\nnpx aios-core --help      Exibir ajuda detalhada\nnpx aios-core info        Exibir informações do sistema\nnpx aios-core doctor      Executar diagnósticos do sistema\nnpx aios-core doctor --fix Corrigir problemas detectados automaticamente\n\n# Manutenção\nnpx aios-core update      Atualizar para versão mais recente\nnpx aios-core uninstall   Remover Synkra AIOS\n</code></pre> \n<p><strong>Recursos da CLI:</strong></p> \n<ul> \n <li>✅ <strong>Help System Abrangente</strong>: <code>--help</code> em qualquer comando mostra documentação detalhada</li> \n <li>✅ <strong>Validação de Entrada</strong>: Feedback imediato sobre parâmetros inválidos</li> \n <li>✅ <strong>Mensagens Coloridas</strong>: Erros em vermelho, sucessos em verde, avisos em amarelo</li> \n <li>✅ <strong>Cross-Platform</strong>: Funciona perfeitamente em Windows, macOS e Linux</li> \n <li>✅ <strong>Suporte a Dry-Run</strong>: Teste instalações sem modificar arquivos</li> \n</ul> \n<h3>💡 Exemplos de Uso</h3> \n<h4>Instalação Interativa Completa</h4> \n<pre><code class=\"language-bash\">$ npx aios-core install\n\n🚀 Synkra AIOS Installation\n\n◆ What is your project name?\n│  my-awesome-project\n│\n◇ Which directory should we use?\n│  ./my-awesome-project\n│\n◆ Choose components to install:\n│  ● Core Framework (Required)\n│  ● Agent System (Required)\n│  ● Squads (optional)\n│  ○ Example Projects (optional)\n│\n◇ Select package manager:\n│  ● npm\n│  ○ yarn\n│  ○ pnpm\n│\n◆ Initialize Git repository?\n│  Yes\n│\n◆ Install dependencies?\n│  Yes\n│\n▸ Creating project directory...\n▸ Copying framework files...\n▸ Initializing Git repository...\n▸ Installing dependencies (this may take a minute)...\n▸ Configuring environment...\n▸ Running post-installation setup...\n\n✔ Installation completed successfully! (34.2s)\n\nNext steps:\n  cd my-awesome-project\n  aios-core doctor     # Verify installation\n  aios-core --help     # See available commands\n</code></pre> \n<h4>Instalação Silenciosa (CI/CD)</h4> \n<pre><code class=\"language-bash\"># Instalação automatizada sem prompts\n$ npx aios-core install --quiet --force\n✔ Synkra AIOS installed successfully\n</code></pre> \n<h4>Simulação de Instalação (Dry-Run)</h4> \n<pre><code class=\"language-bash\"># Testar instalação sem modificar arquivos\n$ npx aios-core install --dry-run\n\n[DRY RUN] Would create: ./my-project/\n[DRY RUN] Would copy: .aios-core/ (45 files)\n[DRY RUN] Would initialize: Git repository\n[DRY RUN] Would install: npm dependencies\n✔ Dry run completed - no files were modified\n</code></pre> \n<h4>Diagnóstico do Sistema</h4> \n<pre><code class=\"language-bash\">$ npx aios-core doctor\n\n🏥 AIOS System Diagnostics\n\n✔ Node.js version: v20.10.0 (meets requirement: &gt;=18.0.0)\n✔ npm version: 10.2.3\n✔ Git installed: version 2.43.0\n✔ GitHub CLI: gh 2.40.1\n✔ Synkra AIOS: v4.2.11\n\nConfiguration:\n✔ .aios-core/ directory exists\n✔ Agent files: 11 found\n✔ Workflow files: 8 found\n✔ Templates: 15 found\n\nDependencies:\n✔ @clack/prompts: ^0.7.0\n✔ commander: ^12.0.0\n✔ execa: ^9.0.0\n✔ fs-extra: ^11.0.0\n✔ picocolors: ^1.0.0\n\n✅ All checks passed! Your installation is healthy.\n</code></pre> \n<h4>Obter Ajuda</h4> \n<pre><code class=\"language-bash\">$ npx aios-core --help\n\nUsage: aios-core [options] [command]\n\nSynkra AIOS: AI-Orchestrated System for Full Stack Development\n\nOptions:\n  -V, --version                output the version number\n  -h, --help                   display help for command\n\nCommands:\n  init &lt;project-name&gt;          Create new AIOS project with interactive wizard\n  install [options]            Install AIOS in current directory\n  info                         Display system information\n  doctor [options]             Run system diagnostics and health checks\n  help [command]               display help for command\n\nRun 'aios-core &lt;command&gt; --help' for detailed information about each command.\n</code></pre> \n<h3>Alternativa: Clonar e Construir</h3> \n<p>Para contribuidores ou usuários avançados que queiram modificar o código fonte:</p> \n<pre><code class=\"language-bash\"># Clonar o repositório\ngit clone https://github.com/SynkraAI/aios-core.git\ncd aios-core\n\n# Instalar dependências\nnpm install\n\n# Executar o instalador\nnpm run install:aios\n</code></pre> \n<h3>Configuração Rápida para Equipe</h3> \n<p>Para membros da equipe ingressando no projeto:</p> \n<pre><code class=\"language-bash\"># Instalar AIOS no projeto\nnpx aios-core@latest install\n\n# Isto vai:\n# 1. Detectar instalação existente (se houver)\n# 2. Instalar/atualizar framework AIOS\n# 3. Configurar agentes e workflows\n</code></pre> \n<h2>🌟 Além do Desenvolvimento de Software - Squads</h2> \n<p>O framework de linguagem natural do AIOS funciona em QUALQUER domínio. Os Squads fornecem agentes IA especializados para escrita criativa, estratégia de negócios, saúde e bem-estar, educação e muito mais. Além disso, os Squads podem expandir o núcleo do Synkra AIOS com funcionalidade específica que não é genérica para todos os casos. <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Veja o Guia de Squads</a> e aprenda a criar os seus próprios!</p> \n<h2>Agentes Disponíveis</h2> \n<p>O Synkra AIOS vem com 11 agentes especializados:</p> \n<h3>Agentes Meta</h3> \n<ul> \n <li><strong>aios-master</strong> - Agente mestre de orquestração (inclui capacidades de desenvolvimento de framework)</li> \n <li><strong>aios-orchestrator</strong> - Orquestrador de fluxo de trabalho e coordenação de equipe</li> \n</ul> \n<h3>Agentes de Planejamento (Interface Web)</h3> \n<ul> \n <li><strong>analyst</strong> - Especialista em análise de negócios e criação de PRD</li> \n <li><strong>pm</strong> (Product Manager) - Gerente de produto e priorização</li> \n <li><strong>architect</strong> - Arquiteto de sistema e design técnico</li> \n <li><strong>ux-expert</strong> - Design de experiência do usuário e usabilidade</li> \n</ul> \n<h3>Agentes de Desenvolvimento (IDE)</h3> \n<ul> \n <li><strong>sm</strong> (Scrum Master) - Gerenciamento de sprint e criação de histórias</li> \n <li><strong>dev</strong> - Desenvolvedor e implementação</li> \n <li><strong>qa</strong> - Garantia de qualidade e testes</li> \n <li><strong>po</strong> (Product Owner) - Gerenciamento de backlog e histórias</li> \n</ul> \n<h2>Documentação e Recursos</h2> \n<h3>Guias Essenciais</h3> \n<ul> \n <li>📖 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/user-guide.md\">Guia do Usuário</a></strong> - Passo a passo completo desde a concepção até a conclusão do projeto</li> \n <li>🏗️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ARCHITECTURE-INDEX.md\">Arquitetura Principal</a></strong> - Mergulho técnico profundo e design do sistema</li> \n <li>🚀 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a></strong> - Estenda o AIOS para qualquer domínio além do desenvolvimento de software</li> \n</ul> \n<h3>Documentação Adicional</h3> \n<ul> \n <li>🤖 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a></strong> - Crie e publique equipes de agentes IA</li> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/getting-started.md\">Primeiros Passos</a></strong> - Tutorial passo a passo para iniciantes</li> \n <li>🔧 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/troubleshooting.md\">Solução de Problemas</a></strong> - Soluções para problemas comuns</li> \n <li>🎯 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/GUIDING-PRINCIPLES.md\">Princípios Orientadores</a></strong> - Filosofia e melhores práticas do AIOS</li> \n <li>🏛️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ARCHITECTURE-INDEX.md\">Visão Geral da Arquitetura</a></strong> - Visão detalhada da arquitetura do sistema</li> \n <li>⚙️ <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/performance-tuning-guide.md\">Guia de Ajuste de Performance</a></strong> - Otimize seu fluxo de trabalho AIOS</li> \n <li>🔒 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/security-best-practices.md\">Melhores Práticas de Segurança</a></strong> - Segurança e proteção de dados</li> \n <li>🔄 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/migration-guide.md\">Guia de Migração</a></strong> - Migração de versões anteriores</li> \n <li>📦 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/versioning-and-releases.md\">Versionamento e Releases</a></strong> - Política de versões</li> \n</ul> \n<h2>🤖 AIOS Autonomous Development Engine (ADE)</h2> \n<p>O Synkra AIOS introduz o <strong>Autonomous Development Engine (ADE)</strong> - um sistema completo para desenvolvimento autônomo que transforma requisitos em código funcional.</p> \n<h3>🎯 O Que é o ADE?</h3> \n<p>O ADE é um conjunto de <strong>7 Epics</strong> que habilitam execução autônoma de desenvolvimento:</p> \n<table> \n <thead> \n  <tr> \n   <th>Epic</th> \n   <th>Nome</th> \n   <th>Descrição</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>1</strong></td> \n   <td>Worktree Manager</td> \n   <td>Isolamento de branches via Git worktrees</td> \n  </tr> \n  <tr> \n   <td><strong>2</strong></td> \n   <td>Migration V2→V3</td> \n   <td>Migração para formato autoClaude V3</td> \n  </tr> \n  <tr> \n   <td><strong>3</strong></td> \n   <td>Spec Pipeline</td> \n   <td>Transforma requisitos em specs executáveis</td> \n  </tr> \n  <tr> \n   <td><strong>4</strong></td> \n   <td>Execution Engine</td> \n   <td>Executa specs com 13 steps + self-critique</td> \n  </tr> \n  <tr> \n   <td><strong>5</strong></td> \n   <td>Recovery System</td> \n   <td>Recuperação automática de falhas</td> \n  </tr> \n  <tr> \n   <td><strong>6</strong></td> \n   <td>QA Evolution</td> \n   <td>Review estruturado em 10 fases</td> \n  </tr> \n  <tr> \n   <td><strong>7</strong></td> \n   <td>Memory Layer</td> \n   <td>Memória persistente de padrões e insights</td> \n  </tr> \n </tbody> \n</table> \n<h3>🔄 Fluxo Principal</h3> \n<pre><code>User Request → Spec Pipeline → Execution Engine → QA Review → Working Code\n                                      ↓\n                              Recovery System\n                                      ↓\n                               Memory Layer\n</code></pre> \n<h3>⚡ Quick Start ADE</h3> \n<pre><code class=\"language-bash\"># 1. Criar spec a partir de requisito\n@pm *gather-requirements\n@architect *assess-complexity\n@analyst *research-deps\n@pm *write-spec\n@qa *critique-spec\n\n# 2. Executar spec aprovada\n@architect *create-plan\n@architect *create-context\n@dev *execute-subtask 1.1\n\n# 3. QA Review\n@qa *review-build STORY-42\n</code></pre> \n<h3>📖 Documentação ADE</h3> \n<ul> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/ade-guide.md\">Guia Completo do ADE</a></strong> - Tutorial passo a passo</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-AGENT-CHANGES.md\">Alterações nos Agentes</a></strong> - Comandos e capabilities por agente</li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC1-HANDOFF.md\">Epic 1 - Worktree Manager</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC2-HANDOFF.md\">Epic 2 - Migration V2→V3</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC3-HANDOFF.md\">Epic 3 - Spec Pipeline</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC4-HANDOFF.md\">Epic 4 - Execution Engine</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC5-HANDOFF.md\">Epic 5 - Recovery System</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC6-HANDOFF.md\">Epic 6 - QA Evolution</a></strong></li> \n <li><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/architecture/ADE-EPIC7-HANDOFF.md\">Epic 7 - Memory Layer</a></strong></li> \n</ul> \n<h3>🆕 Novos Comandos por Agente</h3> \n<p><strong>@devops:</strong></p> \n<ul> \n <li><code>*create-worktree</code>, <code>*list-worktrees</code>, <code>*merge-worktree</code>, <code>*cleanup-worktrees</code></li> \n <li><code>*inventory-assets</code>, <code>*analyze-paths</code>, <code>*migrate-agent</code>, <code>*migrate-batch</code></li> \n</ul> \n<p><strong>@pm:</strong></p> \n<ul> \n <li><code>*gather-requirements</code>, <code>*write-spec</code></li> \n</ul> \n<p><strong>@architect:</strong></p> \n<ul> \n <li><code>*assess-complexity</code>, <code>*create-plan</code>, <code>*create-context</code>, <code>*map-codebase</code></li> \n</ul> \n<p><strong>@analyst:</strong></p> \n<ul> \n <li><code>*research-deps</code>, <code>*extract-patterns</code></li> \n</ul> \n<p><strong>@qa:</strong></p> \n<ul> \n <li><code>*critique-spec</code>, <code>*review-build</code>, <code>*request-fix</code>, <code>*verify-fix</code></li> \n</ul> \n<p><strong>@dev:</strong></p> \n<ul> \n <li><code>*execute-subtask</code>, <code>*track-attempt</code>, <code>*rollback</code>, <code>*capture-insights</code>, <code>*list-gotchas</code>, <code>*apply-qa-fix</code></li> \n</ul> \n<h2>Criando Seu Próprio Squad</h2> \n<p>Squads permitem estender o AIOS para qualquer domínio. Estrutura básica:</p> \n<pre><code>squads/seu-squad/\n├── config.yaml           # Configuração do squad\n├── agents/              # Agentes especializados\n├── tasks/               # Fluxos de trabalho de tarefas\n├── templates/           # Templates de documentos\n├── checklists/          # Checklists de validação\n├── data/                # Base de conhecimento\n├── README.md            # Documentação do squad\n└── user-guide.md        # Guia do usuário\n</code></pre> \n<p>Veja o <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a> para instruções detalhadas.</p> \n<h2>Squads Disponíveis</h2> \n<p>Squads são equipes modulares de agentes IA. Veja a <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-overview.md\">Visão Geral de Squads</a> para mais informações.</p> \n<h3>Squads Externos</h3> \n<ul> \n <li><strong><a href=\"https://github.com/SynkraAI/aios-hybrid-ops-pedro-valerio\">hybrid-ops</a></strong> - Operações híbridas humano-agente (repositório separado)</li> \n</ul> \n<h2>AIOS Pro</h2> \n<p>O <strong>AIOS Pro</strong> (<code>@aios-fullstack/pro</code>) é o módulo premium do Synkra AIOS, oferecendo funcionalidades avançadas para equipes e projetos de maior escala.</p> \n<blockquote> \n <p><strong>Disponibilidade restrita:</strong> O AIOS Pro está disponível exclusivamente para membros do <strong>AIOS Cohort Advanced</strong>. <a href=\"https://synkra.ai\">Saiba mais sobre o programa</a>.</p> \n</blockquote> \n<h3>Instalação</h3> \n<pre><code class=\"language-bash\">npm install @aios-fullstack/pro\n</code></pre> \n<h3>Features Premium</h3> \n<ul> \n <li><strong>Squads Avançados</strong> - Squads especializados com capacidades expandidas</li> \n <li><strong>Memory Layer</strong> - Memória persistente de padrões e insights entre sessões</li> \n <li><strong>Métricas &amp; Analytics</strong> - Dashboard de produtividade e métricas de desenvolvimento</li> \n <li><strong>Integrações Enterprise</strong> - Conectores para Jira, Linear, Notion e mais</li> \n <li><strong>Configuração em Camadas</strong> - Sistema de configuração L1-L4 com herança</li> \n <li><strong>Licenciamento</strong> - Gerenciamento de licença via <code>aios pro activate --key &lt;KEY&gt;</code></li> \n</ul> \n<p>Para mais informações, execute <code>npx aios-core pro --help</code> após a instalação.</p> \n<h2>Suporte</h2> \n<ul> \n <li>🐛 <a href=\"https://github.com/SynkraAI/aios-core/issues\">Rastreador de Issues</a> - Bug reports e feature requests</li> \n <li>💡 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/FEATURE_PROCESS.md\">Processo de Features</a> - Como propor novas funcionalidades</li> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">Como Contribuir</a></li> \n <li>🗺️ <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/roadmap.md\">Roadmap</a> - Veja o que estamos construindo</li> \n <li>🤖 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/guides/squads-guide.md\">Guia de Squads</a> - Crie equipes de agentes IA</li> \n</ul> \n<h2>Git Workflow e Validação</h2> \n<p>O Synkra AIOS implementa um sistema de validação de múltiplas camadas para garantir qualidade do código e consistência:</p> \n<h3>🛡️ Defense in Depth - 3 Camadas de Validação</h3> \n<p><strong>Camada 1: Pre-commit (Local - Rápida)</strong></p> \n<ul> \n <li>✅ ESLint - Qualidade de código</li> \n <li>✅ TypeScript - Verificação de tipos</li> \n <li>⚡ Performance: &lt;5s</li> \n <li>💾 Cache habilitado</li> \n</ul> \n<p><strong>Camada 2: Pre-push (Local - Validação de Stories)</strong></p> \n<ul> \n <li>✅ Validação de checkboxes de histórias</li> \n <li>✅ Consistência de status</li> \n <li>✅ Seções obrigatórias</li> \n</ul> \n<p><strong>Camada 3: CI/CD (Cloud - Obrigatório para merge)</strong></p> \n<ul> \n <li>✅ Todos os testes</li> \n <li>✅ Cobertura de testes (80% mínimo)</li> \n <li>✅ Validações completas</li> \n <li>✅ GitHub Actions</li> \n</ul> \n<h3>📖 Documentação Detalhada</h3> \n<ul> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/git-workflow-guide.md\">Guia Completo de Git Workflow</a></strong> - Guia detalhado do fluxo de trabalho</li> \n <li>📋 <strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">CONTRIBUTING.md</a></strong> - Guia de contribuição</li> \n</ul> \n<h3>Comandos Disponíveis</h3> \n<pre><code class=\"language-bash\"># Validações locais\nnpm run lint           # ESLint\nnpm run typecheck      # TypeScript\nnpm test              # Testes\nnpm run test:coverage # Testes com cobertura\n\n# Validador AIOS\nnode .aios-core/utils/aios-validator.js pre-commit   # Validação pre-commit\nnode .aios-core/utils/aios-validator.js pre-push     # Validação pre-push\nnode .aios-core/utils/aios-validator.js stories      # Validar todas stories\n</code></pre> \n<h3>Branch Protection</h3> \n<p>Configure proteção da branch master com:</p> \n<pre><code class=\"language-bash\">node scripts/setup-branch-protection.js\n</code></pre> \n<p>Requer:</p> \n<ul> \n <li>GitHub CLI (gh) instalado e autenticado</li> \n <li>Acesso de admin ao repositório</li> \n</ul> \n<h2>Contribuindo</h2> \n<p><strong>Estamos empolgados com contribuições e acolhemos suas ideias, melhorias e Squads!</strong> 🎉</p> \n<p>Para contribuir:</p> \n<ol> \n <li>Fork o repositório</li> \n <li>Crie uma branch para sua feature (<code>git checkout -b feature/MinhaNovaFeature</code>)</li> \n <li>Commit suas mudanças (<code>git commit -m 'feat: Adicionar nova feature'</code>)</li> \n <li>Push para a branch (<code>git push origin feature/MinhaNovaFeature</code>)</li> \n <li>Abra um Pull Request</li> \n</ol> \n<p>Veja também:</p> \n<ul> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/how-to-contribute-with-pull-requests.md\">Como Contribuir com Pull Requests</a></li> \n <li>📋 <a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/git-workflow-guide.md\">Guia de Git Workflow</a></li> \n</ul> \n<h2>📄 Legal</h2> \n<table> \n <thead> \n  <tr> \n   <th>Documento</th> \n   <th>English</th> \n   <th>Português</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Licença</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/LICENSE\">MIT License</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Modelo de Licença</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/license-clarification.md\">Core vs Pro</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Privacidade</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/privacy.md\">Privacy Policy</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Termos de Uso</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/legal/terms.md\">Terms of Use</a></td> \n   <td>-</td> \n  </tr> \n  <tr> \n   <td><strong>Código de Conduta</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CODE_OF_CONDUCT.md\">Code of Conduct</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/code-of-conduct.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Contribuição</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CONTRIBUTING.md\">Contributing</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/contributing.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Segurança</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/security.md\">Security</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/security.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Comunidade</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/community.md\">Community</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/community.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Roadmap</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/roadmap.md\">Roadmap</a></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/docs/pt/roadmap.md\">PT-BR</a></td> \n  </tr> \n  <tr> \n   <td><strong>Changelog</strong></td> \n   <td><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/CHANGELOG.md\">Version History</a></td> \n   <td>-</td> \n  </tr> \n </tbody> \n</table> \n<h2>Reconhecimentos</h2> \n<p>This project was originally derived from the <a href=\"https://github.com/bmad-code-org/BMAD-METHOD\">BMad Method</a> by <a href=\"https://github.com/bmadcode\">Brian Madison</a>. We thank Brian and all BMad Method contributors for the original work that made this project possible.</p> \n<p><strong>Note:</strong> Some contributors shown in the GitHub contributors graph are inherited from the original BMad Method git history and do not represent active participation in or endorsement of Synkra AIOS.</p> \n<p><a href=\"https://github.com/SynkraAI/aios-core/graphs/contributors\"><img alt=\"Contributors\" src=\"https://contrib.rocks/image?repo=SynkraAI/aios-core\" /></a></p> \n<p><sub>Construído com ❤️ para a comunidade de desenvolvimento assistido por IA</sub></p> \n<hr /> \n<p><strong><a href=\"https://raw.githubusercontent.com/SynkraAI/aios-core/main/#synkra-aios-framework-universal-de-agentes-ia-\">⬆ Voltar ao topo</a></strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:37.109775Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 5
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 8.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/hsnrique/how-we-built-an-ai-deep-research-engine-and-the-seo-strategy-behind-it-4bk",
        "title": "How We Built an AI Deep Research Engine — And the SEO Strategy Behind It",
        "summary": "<p>If you've ever spent hours digging through Google results, opening 30+ tabs, cross-referencing sources, and trying to synthesize everything into a coherent answer — you know how painful deep research is.</p>\n\n<p>That's the problem we set out to solve with <a href=\"https://neiro.it\" rel=\"noopener noreferrer\">Neiro</a>.</p>\n\n<h2>\n  \n  \n  What is Neiro?\n</h2>\n\n<p>Neiro is an AI-powered deep research engine. You ask a complex question — the kind that Google can't answer in a single snippet — and Neiro goes to work.</p>\n\n<p>It doesn't just search. It <strong>researches</strong>. It scans thousands of live web sources, reads them, cross-references data points, and delivers a structured intelligence dossier with full citations.</p>\n\n<h3>\n  \n  \n  Who is it for?\n</h3>\n\n<ul>\n<li>VC analysts doing due diligence on startups</li>\n<li>Strategy teams running competitive intelligence</li>\n<li>Researchers conducting literature reviews</li>\n<li>Product managers sizing markets</li>\n<li>Anyone who needs answers that require more than a quick search</li>\n</ul>\n\n<h2>\n  \n  \n  The Technical Challenge\n</h2>\n\n<p>Building a research engine is fundamentally different from building a chatbot. Here's why:</p>\n\n<h3>\n  \n  \n  1. Breadth of Sources\n</h3>\n\n<p>A chatbot responds from training data. A search engine returns 10 links. Neiro needs to actively crawl and process thousands of sources per query — in real time. This means the system needs to be highly parallelized, with intelligent source selection to avoid noise.</p>\n\n<h3>\n  \n  \n  2. Zero Hallucinations\n</h3>\n\n<p>When you're producing research that professionals rely on for million-dollar decisions, you can't afford hallucinations. Every data point in a Neiro dossier needs to be traceable to its original source. This is a hard constraint that shapes the entire architecture.</p>\n\n<h3>\n  \n  \n  3. Structured Output\n</h3>\n\n<p>Raw text isn't useful for research. Neiro produces structured dossiers with:</p>\n\n<ul>\n<li>Executive summaries</li>\n<li>Data tables</li>\n<li>Source citations</li>\n<li>Risk assessments</li>\n<li>Competitive matrices</li>\n</ul>\n\n<p>This requires a fundamentally different output pipeline than a typical LLM chat interface.</p>\n\n<h2>\n  \n  \n  Our SEO Strategy (The Fun Part for Devs)\n</h2>\n\n<p>As a startup, we can't just build a great product and hope people find it. We needed a comprehensive organic growth strategy. Here's what we implemented:</p>\n\n<h3>\n  \n  \n  Dynamic Sitemap\n</h3>\n\n<p>Our blog content is published automatically. A static sitemap.xml wouldn't cut it — it would go stale immediately.</p>\n\n<p>We built a dynamic sitemap endpoint on our Express backend that queries the database for all published posts and generates the XML on-the-fly.<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight typescript\"><code><span class=\"nx\">app</span><span class=\"p\">.</span><span class=\"nf\">get</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">/sitemap.xml</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"k\">async </span><span class=\"p\">(</span><span class=\"nx\">req</span><span class=\"p\">,</span> <span class=\"nx\">res</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">posts</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nf\">query</span><span class=\"p\">(</span>\n    <span class=\"dl\">\"</span><span class=\"s2\">SELECT slug, updated_at FROM blog_posts WHERE status = 'published'</span><span class=\"dl\">\"</span>\n  <span class=\"p\">);</span>\n\n  <span class=\"kd\">const</span> <span class=\"nx\">urls</span> <span class=\"o\">=</span> <span class=\"nx\">posts</span><span class=\"p\">.</span><span class=\"nx\">rows</span><span class=\"p\">.</span><span class=\"nf\">map</span><span class=\"p\">(</span><span class=\"nx\">p</span> <span class=\"o\">=&gt;</span> <span class=\"s2\">`\n    &lt;url&gt;\n      &lt;loc&gt;https://yoursite.com/blog/</span><span class=\"p\">${</span><span class=\"nx\">p</span><span class=\"p\">.</span><span class=\"nx\">slug</span><span class=\"p\">}</span><span class=\"s2\">&lt;/loc&gt;\n      &lt;lastmod&gt;</span><span class=\"p\">${</span><span class=\"k\">new</span> <span class=\"nc\">Date</span><span class=\"p\">(</span><span class=\"nx\">p</span><span class=\"p\">.</span><span class=\"nx\">updated_at</span><span class=\"p\">).</span><span class=\"nf\">toISOString</span><span class=\"p\">().</span><span class=\"nf\">split</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">T</span><span class=\"dl\">'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]}</span><span class=\"s2\">&lt;/lastmod&gt;\n    &lt;/url&gt;\n  `</span><span class=\"p\">).</span><span class=\"nf\">join</span><span class=\"p\">(</span><span class=\"dl\">''</span><span class=\"p\">);</span>\n\n  <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nf\">type</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">application/xml</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nf\">send</span><span class=\"p\">(</span><span class=\"s2\">`&lt;?xml version=\"1.0\"?&gt;\n    &lt;urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"&gt;\n      </span><span class=\"p\">${</span><span class=\"nx\">urls</span><span class=\"p\">}</span><span class=\"s2\">\n    &lt;/urlset&gt;`</span><span class=\"p\">);</span>\n<span class=\"p\">});</span>\n</code></pre>\n\n</div>\n\n\n\n<p>Since our frontend is a Vite SPA on Vercel, we use Vercel rewrites to proxy /sitemap.xml to this backend endpoint.</p>\n\n<h3>\n  \n  \n  RSS Feed for Syndication\n</h3>\n\n<p>We added an RSS 2.0 feed endpoint that enables automatic syndication to platforms like Feedly, dev.to, and Google News.</p>\n\n<h3>\n  \n  \n  AI Discoverability with <code>llms.txt</code>\n</h3>\n\n<p>This is a newer concept — a file at /llms.txt that tells AI models (ChatGPT, Perplexity, Claude) about your product. Think of it as robots.txt for AI.<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code># Neiro — AI Deep Research Engine\n\n&gt; Neiro is an AI-powered deep research platform that \n&gt; synthesizes knowledge from 10,000+ real-time sources \n&gt; into verified intelligence dossiers.\n\n## What Neiro Does\n- Deep research on any topic\n- Verified citations for every claim\n- Structured dossiers, not chat responses\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  Dynamic OG Tags with Edge Middleware\n</h3>\n\n<p>SPAs have a classic problem: social media crawlers can't read client-rendered meta tags. When someone shares a blog post on LinkedIn or Twitter, the preview shows generic site info instead of the post's actual title and image.</p>\n\n<p>Our solution: Vercel Edge Middleware.<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight typescript\"><code><span class=\"k\">export</span> <span class=\"k\">default</span> <span class=\"k\">async</span> <span class=\"kd\">function</span> <span class=\"nf\">middleware</span><span class=\"p\">(</span><span class=\"nx\">request</span><span class=\"p\">:</span> <span class=\"nx\">Request</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">ua</span> <span class=\"o\">=</span> <span class=\"nx\">request</span><span class=\"p\">.</span><span class=\"nx\">headers</span><span class=\"p\">.</span><span class=\"nf\">get</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">user-agent</span><span class=\"dl\">'</span><span class=\"p\">)</span> <span class=\"o\">||</span> <span class=\"dl\">''</span><span class=\"p\">;</span>\n\n  <span class=\"k\">if </span><span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">CRAWLERS</span><span class=\"p\">.</span><span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"nx\">ua</span><span class=\"p\">))</span> <span class=\"k\">return</span> <span class=\"nf\">next</span><span class=\"p\">();</span>\n\n  <span class=\"kd\">const</span> <span class=\"nx\">post</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"nf\">fetch</span><span class=\"p\">(</span><span class=\"s2\">`</span><span class=\"p\">${</span><span class=\"nx\">API</span><span class=\"p\">}</span><span class=\"s2\">/blog/post/</span><span class=\"p\">${</span><span class=\"nx\">slug</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">);</span>\n  <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"nc\">Response</span><span class=\"p\">(</span><span class=\"nf\">generateOgHtml</span><span class=\"p\">(</span><span class=\"nx\">post</span><span class=\"p\">),</span> <span class=\"p\">{</span>\n    <span class=\"na\">headers</span><span class=\"p\">:</span> <span class=\"p\">{</span> <span class=\"dl\">'</span><span class=\"s1\">Content-Type</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">text/html</span><span class=\"dl\">'</span> <span class=\"p\">}</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p>Crawlers get pre-rendered HTML with correct meta tags. Real users get the normal SPA experience. Best of both worlds.</p>\n\n<h3>\n  \n  \n  IndexNow for Instant Indexing\n</h3>\n\n<p>Instead of waiting for search engines to discover new content, we proactively notify them using the IndexNow protocol:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight typescript\"><code><span class=\"k\">async</span> <span class=\"kd\">function</span> <span class=\"nf\">pingIndexNow</span><span class=\"p\">(</span><span class=\"nx\">postUrl</span><span class=\"p\">:</span> <span class=\"kr\">string</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"k\">await</span> <span class=\"nf\">fetch</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">https://api.indexnow.org/IndexNow</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"p\">{</span>\n    <span class=\"na\">method</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">POST</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n    <span class=\"na\">headers</span><span class=\"p\">:</span> <span class=\"p\">{</span> <span class=\"dl\">'</span><span class=\"s1\">Content-Type</span><span class=\"dl\">'</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">application/json</span><span class=\"dl\">'</span> <span class=\"p\">},</span>\n    <span class=\"na\">body</span><span class=\"p\">:</span> <span class=\"nx\">JSON</span><span class=\"p\">.</span><span class=\"nf\">stringify</span><span class=\"p\">({</span>\n      <span class=\"na\">host</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">yoursite.com</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n      <span class=\"na\">key</span><span class=\"p\">:</span> <span class=\"nx\">process</span><span class=\"p\">.</span><span class=\"nx\">env</span><span class=\"p\">.</span><span class=\"nx\">INDEXNOW_KEY</span><span class=\"p\">,</span>\n      <span class=\"na\">urlList</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"nx\">postUrl</span><span class=\"p\">]</span>\n    <span class=\"p\">})</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p>This fires automatically every time a new blog post is published. Bing, Yandex, and other supporting engines pick it up within minutes.</p>\n\n<h3>\n  \n  \n  Programmatic SEO Pages\n</h3>\n\n<p>We created landing pages targeting high-intent keywords:</p>\n\n<ul>\n<li>Use case pages: /use-cases/ai-due-diligence, /use-cases/market-research, etc.</li>\n<li>Comparison pages: /compare/neiro-vs-perplexity, /compare/neiro-vs-chatgpt, etc.</li>\n</ul>\n\n<p>Each page has unique content, FAQ structured data (for Google rich snippets), breadcrumb schema, and proper OG tags. These are data-driven — a single React component renders different content based on a data file, making it easy to add new pages.</p>\n\n<h2>\n  \n  \n  Results So Far\n</h2>\n\n<p>We're early, but the infrastructure is solid:</p>\n\n<ul>\n<li>✅ All blog posts indexed within hours of publishing</li>\n<li>✅ Correct social previews when shared on LinkedIn/Twitter</li>\n<li>✅ AI models (ChatGPT, Claude) can discover and reference Neiro</li>\n<li>✅ Growing organic traffic from long-tail keywords</li>\n<li>✅ RSS feed enables automatic cross-posting</li>\n</ul>\n\n<h2>\n  \n  \n  Try It\n</h2>\n\n<p>If you're curious about what AI deep research looks like in practice, <a href=\"https://neiro.it\" rel=\"noopener noreferrer\">try Neiro for free</a> — 3 researches, no credit card.<br />\nI'd love to hear your feedback, especially from anyone working on similar problems in the AI/search space.</p>\n\n\n\n\n<p>What SEO strategies are you using for your side projects? Drop them in the comments — always looking to learn from the community.</p>",
        "source": "dev.to",
        "published": "Wed, 18 Feb 2026 23:01:23 +0000",
        "fetched_at": "2026-02-18T23:25:42.462407Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 2,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/KeygraphHQ/shannon",
        "title": "KeygraphHQ/shannon",
        "summary": "<p>Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p><hr /><blockquote> \n <p>[!NOTE] <strong><a href=\"https://github.com/KeygraphHQ/shannon/tree/main/xben-benchmark-results/README.md\">Shannon Lite achieves a 96.15% success rate on a hint-free, source-aware XBOW benchmark. →</a></strong></p> \n</blockquote> \n<div align=\"center\"> \n <p><a href=\"https://trendshift.io/repositories/15604\" target=\"_blank\"><img alt=\"KeygraphHQ%2Fshannon | Trendshift\" height=\"55\" src=\"https://trendshift.io/api/badge/repositories/15604\" style=\"width: 250px; height: 55px;\" width=\"250\" /></a></p> \n <img alt=\"Shannon Screen\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-screen.png?v=2\" width=\"100%\" /> \n <h1>Shannon is your fully autonomous AI pentester.</h1> \n <p>Shannon’s job is simple: break your web app before anyone else does. <br /> The Red Team to your vibe-coding Blue team. <br /> Every Claude (coder) deserves their Shannon.</p> \n <hr /> \n <p><a href=\"https://keygraph.io\">Website</a> • <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></p> \n <hr /> \n</div> \n<h2>🎯 What is Shannon?</h2> \n<p>Shannon is an AI pentester that delivers actual exploits, not just alerts.</p> \n<p>Shannon's goal is to break your web app before someone else does. It autonomously hunts for attack vectors in your code, then uses its built-in browser to execute real exploits, such as injection attacks, and auth bypass, to prove the vulnerability is actually exploitable.</p> \n<p><strong>What Problem Does Shannon Solve?</strong></p> \n<p>Thanks to tools like Claude Code and Cursor, your team ships code non-stop. But your penetration test? That happens once a year. This creates a <em>massive</em> security gap. For the other 364 days, you could be unknowingly shipping vulnerabilities to production.</p> \n<p>Shannon closes this gap by acting as your on-demand whitebox pentester. It doesn't just find potential issues. It executes real exploits, providing concrete proof of vulnerabilities. This lets you ship with confidence, knowing every build can be secured.</p> \n<blockquote> \n <p>[!NOTE] <strong>From Autonomous Pentesting to Automated Compliance</strong></p> \n <p>Shannon is a core component of the <strong>Keygraph Security and Compliance Platform</strong>.</p> \n <p>While Shannon automates the critical task of penetration testing for your application, our broader platform automates your entire compliance journey—from evidence collection to audit readiness. We're building the \"Rippling for Cybersecurity,\" a single platform to manage your security posture and streamline compliance frameworks like SOC 2 and HIPAA.</p> \n <p>➡️ <strong><a href=\"https://keygraph.io\">Learn more about the Keygraph Platform</a></strong></p> \n</blockquote> \n<h2>🎬 See Shannon in Action</h2> \n<p><strong>Real Results</strong>: Shannon discovered 20+ critical vulnerabilities in OWASP Juice Shop, including complete auth bypass and database exfiltration. <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">See full report →</a></p> \n<p><img alt=\"Demo\" src=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/assets/shannon-action.gif\" /></p> \n<h2>✨ Features</h2> \n<ul> \n <li><strong>Fully Autonomous Operation</strong>: Launch the pentest with a single command. The AI handles everything from advanced 2FA/TOTP logins (including sign in with Google) and browser navigation to the final report with zero intervention.</li> \n <li><strong>Pentester-Grade Reports with Reproducible Exploits</strong>: Delivers a final report focused on proven, exploitable findings, complete with copy-and-paste Proof-of-Concepts to eliminate false positives and provide actionable results.</li> \n <li><strong>Critical OWASP Vulnerability Coverage</strong>: Currently identifies and validates the following critical vulnerabilities: Injection, XSS, SSRF, and Broken Authentication/Authorization, with more types in development.</li> \n <li><strong>Code-Aware Dynamic Testing</strong>: Analyzes your source code to intelligently guide its attack strategy, then performs live, browser and command line based exploits on the running application to confirm real-world risk.</li> \n <li><strong>Powered by Integrated Security Tools</strong>: Enhances its discovery phase by leveraging leading reconnaissance and testing tools—including <strong>Nmap, Subfinder, WhatWeb, and Schemathesis</strong>—for deep analysis of the target environment.</li> \n <li><strong>Parallel Processing for Faster Results</strong>: Get your report faster. The system parallelizes the most time-intensive phases, running analysis and exploitation for all vulnerability types concurrently.</li> \n</ul> \n<h2>📦 Product Line</h2> \n<p>Shannon is available in two editions:</p> \n<table> \n <thead> \n  <tr> \n   <th>Edition</th> \n   <th>License</th> \n   <th>Best For</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>Shannon Lite</strong></td> \n   <td>AGPL-3.0</td> \n   <td>Security teams, independent researchers, testing your own applications</td> \n  </tr> \n  <tr> \n   <td><strong>Shannon Pro</strong></td> \n   <td>Commercial</td> \n   <td>Enterprises requiring advanced features, CI/CD integration, and dedicated support</td> \n  </tr> \n </tbody> \n</table> \n<blockquote> \n <p><strong>This repository contains Shannon Lite,</strong> which utilizes our core autonomous AI pentesting framework. <strong>Shannon Pro</strong> enhances this foundation with an advanced, LLM-powered data flow analysis engine (inspired by the <a href=\"https://arxiv.org/abs/2402.10754\">LLMDFA paper</a>) for enterprise-grade code analysis and deeper vulnerability detection.</p> \n</blockquote> \n<blockquote> \n <p>[!IMPORTANT] <strong>White-box only.</strong> Shannon Lite is designed for <strong>white-box (source-available)</strong> application security testing.<br /> It expects access to your application's source code and repository layout.</p> \n</blockquote> \n<p><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">See feature comparison</a></p> \n<h2>📑 Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-what-is-shannon\">What is Shannon?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-see-shannon-in-action\">See Shannon in Action</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-features\">Features</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-product-line\">Product Line</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-setup--usage-instructions\">Setup &amp; Usage Instructions</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#prerequisites\">Prerequisites</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#quick-start\">Quick Start</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#monitoring-progress\">Monitoring Progress</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#stopping-shannon\">Stopping Shannon</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#usage-examples\">Usage Examples</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#workspaces-and-resuming\">Workspaces and Resuming</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#configuration-optional\">Configuration (Optional)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#output-and-results\">Output and Results</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-sample-reports\">Sample Reports</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-architecture\">Architecture</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-coverage-and-roadmap\">Coverage and Roadmap</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#%EF%B8%8F-disclaimers\">Disclaimers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-license\">License</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-community--support\">Community &amp; Support</a></li> \n <li><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#-get-in-touch\">Get in Touch</a></li> \n</ul> \n<hr /> \n<h2>🚀 Setup &amp; Usage Instructions</h2> \n<h3>Prerequisites</h3> \n<ul> \n <li><strong>Docker</strong> - Container runtime (<a href=\"https://docs.docker.com/get-docker/\">Install Docker</a>)</li> \n <li><strong>AI Provider Credentials</strong> (choose one): \n  <ul> \n   <li><strong>Anthropic API key</strong> (recommended) - Get from <a href=\"https://console.anthropic.com\">Anthropic Console</a></li> \n   <li><strong>Claude Code OAuth token</strong></li> \n   <li><strong>[EXPERIMENTAL - UNSUPPORTED] Alternative providers via Router Mode</strong> - OpenAI or Google Gemini via OpenRouter (see <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#experimental---unsupported-router-mode-alternative-providers\">Router Mode</a>)</li> \n  </ul> </li> \n</ul> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># 1. Clone Shannon\ngit clone https://github.com/KeygraphHQ/shannon.git\ncd shannon\n\n# 2. Configure credentials (choose one method)\n\n# Option A: Export environment variables\nexport ANTHROPIC_API_KEY=\"your-api-key\"              # or CLAUDE_CODE_OAUTH_TOKEN\nexport CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000           # recommended\n\n# Option B: Create a .env file\ncat &gt; .env &lt;&lt; 'EOF'\nANTHROPIC_API_KEY=your-api-key\nCLAUDE_CODE_MAX_OUTPUT_TOKENS=64000\nEOF\n\n# 3. Run a pentest\n./shannon start URL=https://your-app.com REPO=your-repo\n</code></pre> \n<p>Shannon will build the containers, start the workflow, and return a workflow ID. The pentest runs in the background.</p> \n<h3>Monitoring Progress</h3> \n<pre><code class=\"language-bash\"># View real-time worker logs\n./shannon logs\n\n# Query a specific workflow's progress\n./shannon query ID=shannon-1234567890\n\n# Open the Temporal Web UI for detailed monitoring\nopen http://localhost:8233\n</code></pre> \n<h3>Stopping Shannon</h3> \n<pre><code class=\"language-bash\"># Stop all containers (preserves workflow data)\n./shannon stop\n\n# Full cleanup (removes all data)\n./shannon stop CLEAN=true\n</code></pre> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># Basic pentest\n./shannon start URL=https://example.com REPO=repo-name\n\n# With a configuration file\n./shannon start URL=https://example.com REPO=repo-name CONFIG=./configs/my-config.yaml\n\n# Custom output directory\n./shannon start URL=https://example.com REPO=repo-name OUTPUT=./my-reports\n\n# Named workspace\n./shannon start URL=https://example.com REPO=repo-name WORKSPACE=q1-audit\n\n# List all workspaces\n./shannon workspaces\n</code></pre> \n<h3>Workspaces and Resuming</h3> \n<p>Shannon supports <strong>workspaces</strong> that allow you to resume interrupted or failed runs without re-running completed agents.</p> \n<p><strong>How it works:</strong></p> \n<ul> \n <li>Every run creates a workspace in <code>audit-logs/</code> (auto-named by default, e.g. <code>example-com_shannon-1771007534808</code>)</li> \n <li>Use <code>WORKSPACE=&lt;name&gt;</code> to give your run a custom name for easier reference</li> \n <li>To resume any run, pass its workspace name via <code>WORKSPACE=</code> — Shannon detects which agents completed successfully and picks up where it left off</li> \n <li>Each agent's progress is checkpointed via git commits, so resumed runs start from a clean, validated state</li> \n</ul> \n<pre><code class=\"language-bash\"># Start with a named workspace\n./shannon start URL=https://example.com REPO=repo-name WORKSPACE=my-audit\n\n# Resume the same workspace (skips completed agents)\n./shannon start URL=https://example.com REPO=repo-name WORKSPACE=my-audit\n\n# Resume an auto-named workspace from a previous run\n./shannon start URL=https://example.com REPO=repo-name WORKSPACE=example-com_shannon-1771007534808\n\n# List all workspaces and their status\n./shannon workspaces\n</code></pre> \n<blockquote> \n <p>[!NOTE] The <code>URL</code> must match the original workspace URL when resuming. Shannon will reject mismatched URLs to prevent cross-target contamination.</p> \n</blockquote> \n<h3>Prepare Your Repository</h3> \n<p>Shannon expects target repositories to be placed under the <code>./repos/</code> directory at the project root. The <code>REPO</code> flag refers to a folder name inside <code>./repos/</code>. Copy the repository you want to scan into <code>./repos/</code>, or clone it directly there:</p> \n<pre><code class=\"language-bash\">git clone https://github.com/your-org/your-repo.git ./repos/your-repo\n</code></pre> \n<p><strong>For monorepos:</strong></p> \n<pre><code class=\"language-bash\">git clone https://github.com/your-org/your-monorepo.git ./repos/your-monorepo\n</code></pre> \n<p><strong>For multi-repository applications</strong> (e.g., separate frontend/backend):</p> \n<pre><code class=\"language-bash\">mkdir ./repos/your-app\ncd ./repos/your-app\ngit clone https://github.com/your-org/frontend.git\ngit clone https://github.com/your-org/backend.git\ngit clone https://github.com/your-org/api.git\n</code></pre> \n<h3>Platform-Specific Instructions</h3> \n<p><strong>For Windows:</strong></p> \n<p><em>Native (Git Bash):</em></p> \n<p>Install <a href=\"https://git-scm.com/install/windows\">Git for Windows</a> and run Shannon from <strong>Git Bash</strong> with Docker Desktop installed.</p> \n<p><em>WSL2 (Recommended):</em></p> \n<p><strong>Step 1: Ensure WSL 2</strong></p> \n<pre><code class=\"language-powershell\">wsl --install\nwsl --set-default-version 2\n\n# Check installed distros\nwsl --list --verbose\n\n# If you don't have a distro, install one (Ubuntu 24.04 recommended)\nwsl --list --online\nwsl --install Ubuntu-24.04\n\n# If your distro shows VERSION 1, convert it to WSL 2:\nwsl --set-version &lt;distro-name&gt; 2\n</code></pre> \n<p>See <a href=\"https://learn.microsoft.com/en-us/windows/wsl/basic-commands\">WSL basic commands</a> for reference.</p> \n<p><strong>Step 2: Install Docker Desktop on Windows</strong> and enable <strong>WSL2 backend</strong> under <em>Settings &gt; General &gt; Use the WSL 2 based engine</em>.</p> \n<p><strong>Step 3: Clone and run Shannon inside WSL.</strong> Type <code>wsl -d &lt;distro-name&gt;</code> in PowerShell or CMD and press Enter to open a WSL terminal.</p> \n<pre><code class=\"language-bash\"># Inside WSL terminal\ngit clone https://github.com/KeygraphHQ/shannon.git\ncd shannon\ncp .env.example .env  # Edit with your API key\n./shannon start URL=https://your-app.com REPO=your-repo\n</code></pre> \n<p>To access the Temporal Web UI, run <code>ip addr</code> inside WSL to find your WSL IP address, then navigate to <code>http://&lt;wsl-ip&gt;:8233</code> in your Windows browser.</p> \n<p>Windows Defender may flag exploit code in reports as false positives; see <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/#6-windows-antivirus-false-positives\">Antivirus False Positives</a> below.</p> \n<p><strong>For Linux (Native Docker):</strong></p> \n<p>You may need to run commands with <code>sudo</code> depending on your Docker setup. If you encounter permission issues with output files, ensure your user has access to the Docker socket.</p> \n<p><strong>For macOS:</strong></p> \n<p>Works out of the box with Docker Desktop installed.</p> \n<p><strong>Testing Local Applications:</strong></p> \n<p>Docker containers cannot reach <code>localhost</code> on your host machine. Use <code>host.docker.internal</code> in place of <code>localhost</code>:</p> \n<pre><code class=\"language-bash\">./shannon start URL=http://host.docker.internal:3000 REPO=repo-name\n</code></pre> \n<h3>Configuration (Optional)</h3> \n<p>While you can run without a config file, creating one enables authenticated testing and customized analysis. Place your configuration files inside the <code>./configs/</code> directory — this folder is mounted into the Docker container automatically.</p> \n<h4>Create Configuration File</h4> \n<p>Copy and modify the example configuration:</p> \n<pre><code class=\"language-bash\">cp configs/example-config.yaml configs/my-app-config.yaml\n</code></pre> \n<h4>Basic Configuration Structure</h4> \n<pre><code class=\"language-yaml\">authentication:\n  login_type: form\n  login_url: \"https://your-app.com/login\"\n  credentials:\n    username: \"test@example.com\"\n    password: \"yourpassword\"\n    totp_secret: \"LB2E2RX7XFHSTGCK\"  # Optional for 2FA\n\n  login_flow:\n    - \"Type $username into the email field\"\n    - \"Type $password into the password field\"\n    - \"Click the 'Sign In' button\"\n\n  success_condition:\n    type: url_contains\n    value: \"/dashboard\"\n\nrules:\n  avoid:\n    - description: \"AI should avoid testing logout functionality\"\n      type: path\n      url_path: \"/logout\"\n\n  focus:\n    - description: \"AI should emphasize testing API endpoints\"\n      type: path\n      url_path: \"/api\"\n</code></pre> \n<h4>TOTP Setup for 2FA</h4> \n<p>If your application uses two-factor authentication, simply add the TOTP secret to your config file. The AI will automatically generate the required codes during testing.</p> \n<h3>[EXPERIMENTAL - UNSUPPORTED] Router Mode (Alternative Providers)</h3> \n<p>Shannon can experimentally route requests through alternative AI providers using claude-code-router. This mode is not officially supported and is intended primarily for:</p> \n<ul> \n <li><strong>Model experimentation</strong> — try Shannon with GPT-5.2 or Gemini 3–family models</li> \n</ul> \n<h4>Quick Setup</h4> \n<ol> \n <li>Add your provider API key to <code>.env</code>:</li> \n</ol> \n<pre><code class=\"language-bash\"># Choose one provider:\nOPENAI_API_KEY=sk-...\n# OR\nOPENROUTER_API_KEY=sk-or-...\n\n# Set default model:\nROUTER_DEFAULT=openai,gpt-5.2  # provider,model format\n</code></pre> \n<ol start=\"2\"> \n <li>Run with <code>ROUTER=true</code>:</li> \n</ol> \n<pre><code class=\"language-bash\">./shannon start URL=https://example.com REPO=repo-name ROUTER=true\n</code></pre> \n<h4>Experimental Models</h4> \n<table> \n <thead> \n  <tr> \n   <th>Provider</th> \n   <th>Models</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>OpenAI</td> \n   <td>gpt-5.2, gpt-5-mini</td> \n  </tr> \n  <tr> \n   <td>OpenRouter</td> \n   <td>google/gemini-3-flash-preview</td> \n  </tr> \n </tbody> \n</table> \n<h4>Disclaimer</h4> \n<p>This feature is experimental and unsupported. Output quality depends heavily on the model. Shannon is built on top of the Anthropic Agent SDK and is optimized and primarily tested with Anthropic Claude models. Alternative providers may produce inconsistent results (including failing early phases like Recon) depending on the model and routing setup.</p> \n<h3>Output and Results</h3> \n<p>All results are saved to <code>./audit-logs/{hostname}_{sessionId}/</code> by default. Use <code>--output &lt;path&gt;</code> to specify a custom directory.</p> \n<p>Output structure:</p> \n<pre><code>audit-logs/{hostname}_{sessionId}/\n├── session.json          # Metrics and session data\n├── agents/               # Per-agent execution logs\n├── prompts/              # Prompt snapshots for reproducibility\n└── deliverables/\n    └── comprehensive_security_assessment_report.md   # Final comprehensive security report\n</code></pre> \n<hr /> \n<h2>📊 Sample Reports</h2> \n<blockquote> \n <p><strong>Looking for quantitative benchmarks?</strong> <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/xben-benchmark-results/README.md\">See full benchmark methodology and results →</a></p> \n</blockquote> \n<p>See Shannon's capabilities in action with penetration test results from industry-standard vulnerable applications:</p> \n<h4>🧃 <strong>OWASP Juice Shop</strong> • <a href=\"https://github.com/juice-shop/juice-shop\">GitHub</a></h4> \n<p><em>A notoriously insecure web application maintained by OWASP, designed to test a tool's ability to uncover a wide range of modern vulnerabilities.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 20 high-impact vulnerabilities</strong> across targeted OWASP categories in a single automated run.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Achieved complete authentication bypass</strong> and exfiltrated the entire user database via Injection attack</li> \n <li><strong>Executed a full privilege escalation</strong> by creating a new administrator account through a registration workflow bypass</li> \n <li><strong>Identified and exploited systemic authorization flaws (IDOR)</strong> to access and modify any user's private data and shopping cart</li> \n <li><strong>Discovered a Server-Side Request Forgery (SSRF)</strong> vulnerability, enabling internal network reconnaissance</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-juice-shop.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🔗 <strong>c{api}tal API</strong> • <a href=\"https://github.com/Checkmarx/capital\">GitHub</a></h4> \n<p><em>An intentionally vulnerable API from Checkmarx, designed to test a tool's ability to uncover the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>nearly 15 critical and high-severity vulnerabilities</strong>, leading to full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Executed a root-level Injection attack</strong> by bypassing a denylist via command chaining in a hidden debug endpoint</li> \n <li><strong>Achieved complete authentication bypass</strong> by discovering and targeting a legacy, unpatched v1 API endpoint</li> \n <li><strong>Escalated a regular user to full administrator privileges</strong> by exploiting a Mass Assignment vulnerability in the user profile update function</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly confirming the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-capital-api.md\">View Complete Report →</a></strong></p> \n<hr /> \n<h4>🚗 <strong>OWASP crAPI</strong> • <a href=\"https://github.com/OWASP/crAPI\">GitHub</a></h4> \n<p><em>A modern, intentionally vulnerable API from OWASP, designed to benchmark a tool's effectiveness against the OWASP API Security Top 10.</em></p> \n<p><strong>Performance</strong>: Identified <strong>over 15 critical and high-severity vulnerabilities</strong>, achieving full application compromise.</p> \n<p><strong>Key Accomplishments</strong>:</p> \n<ul> \n <li><strong>Bypassed authentication using multiple advanced JWT attacks</strong>, including Algorithm Confusion, alg:none, and weak key (kid) injection</li> \n <li><strong>Achieved full database compromise via Injection attacks</strong>, exfiltrating user credentials from the PostgreSQL database</li> \n <li><strong>Executed a critical Server-Side Request Forgery (SSRF) attack</strong> that successfully forwarded internal authentication tokens to an external service</li> \n <li><strong>Demonstrated high accuracy</strong> by correctly identifying the application's robust XSS defenses, reporting zero false positives</li> \n</ul> \n<p>📄 <strong><a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/sample-reports/shannon-report-crapi.md\">View Complete Report →</a></strong></p> \n<hr /> \n<p><em>These results demonstrate Shannon's ability to move beyond simple scanning, performing deep contextual exploitation with minimal false positives and actionable proof-of-concepts.</em></p> \n<hr /> \n<h2>🏗️ Architecture</h2> \n<p>Shannon emulates a human penetration tester's methodology using a sophisticated multi-agent architecture. It combines white-box source code analysis with black-box dynamic exploitation across four distinct phases:</p> \n<pre><code>                    ┌──────────────────────┐\n                    │    Reconnaissance    │\n                    └──────────┬───────────┘\n                               │\n                               ▼\n                    ┌──────────┴───────────┐\n                    │          │           │\n                    ▼          ▼           ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │ Vuln Analysis   │ │ Vuln Analysis   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  ▼                   ▼                   ▼\n        ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐\n        │  Exploitation   │ │  Exploitation   │ │      ...        │\n        │  (Injection)    │ │     (XSS)       │ │                 │\n        └─────────┬───────┘ └─────────┬───────┘ └─────────┬───────┘\n                  │                   │                   │\n                  └─────────┬─────────┴───────────────────┘\n                            │\n                            ▼\n                    ┌──────────────────────┐\n                    │      Reporting       │\n                    └──────────────────────┘\n</code></pre> \n<h3>Architectural Overview</h3> \n<p>Shannon is engineered to emulate the methodology of a human penetration tester. It leverages Anthropic's Claude Agent SDK as its core reasoning engine, but its true strength lies in the sophisticated multi-agent architecture built around it. This architecture combines the deep context of <strong>white-box source code analysis</strong> with the real-world validation of <strong>black-box dynamic exploitation</strong>, managed by an orchestrator through four distinct phases to ensure a focus on minimal false positives and intelligent context management.</p> \n<hr /> \n<h4><strong>Phase 1: Reconnaissance</strong></h4> \n<p>The first phase builds a comprehensive map of the application's attack surface. Shannon analyzes the source code and integrates with tools like Nmap and Subfinder to understand the tech stack and infrastructure. Simultaneously, it performs live application exploration via browser automation to correlate code-level insights with real-world behavior, producing a detailed map of all entry points, API endpoints, and authentication mechanisms for the next phase.</p> \n<h4><strong>Phase 2: Vulnerability Analysis</strong></h4> \n<p>To maximize efficiency, this phase operates in parallel. Using the reconnaissance data, specialized agents for each OWASP category hunt for potential flaws in parallel. For vulnerabilities like Injection and SSRF, agents perform a structured data flow analysis, tracing user input to dangerous sinks. This phase produces a key deliverable: a list of <strong>hypothesized exploitable paths</strong> that are passed on for validation.</p> \n<h4><strong>Phase 3: Exploitation</strong></h4> \n<p>Continuing the parallel workflow to maintain speed, this phase is dedicated entirely to turning hypotheses into proof. Dedicated exploit agents receive the hypothesized paths and attempt to execute real-world attacks using browser automation, command-line tools, and custom scripts. This phase enforces a strict <strong>\"No Exploit, No Report\"</strong> policy: if a hypothesis cannot be successfully exploited to demonstrate impact, it is discarded as a false positive.</p> \n<h4><strong>Phase 4: Reporting</strong></h4> \n<p>The final phase compiles all validated findings into a professional, actionable report. An agent consolidates the reconnaissance data and the successful exploit evidence, cleaning up any noise or hallucinated artifacts. Only verified vulnerabilities are included, complete with <strong>reproducible, copy-and-paste Proof-of-Concepts</strong>, delivering a final pentest-grade report focused exclusively on proven risks.</p> \n<h2>📋 Coverage and Roadmap</h2> \n<p>For detailed information about Shannon's security testing coverage and development roadmap, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/COVERAGE.md\">Coverage and Roadmap</a> documentation.</p> \n<h2>⚠️ Disclaimers</h2> \n<h3>Important Usage Guidelines &amp; Disclaimers</h3> \n<p>Please review the following guidelines carefully before using Shannon (Lite). As a user, you are responsible for your actions and assume all liability.</p> \n<h4><strong>1. Potential for Mutative Effects &amp; Environment Selection</strong></h4> \n<p>This is not a passive scanner. The exploitation agents are designed to <strong>actively execute attacks</strong> to confirm vulnerabilities. This process can have mutative effects on the target application and its data.</p> \n<blockquote> \n <p>[!WARNING] <strong>⚠️ DO NOT run Shannon on production environments.</strong></p> \n <ul> \n  <li>It is intended exclusively for use on sandboxed, staging, or local development environments where data integrity is not a concern.</li> \n  <li>Potential mutative effects include, but are not limited to: creating new users, modifying or deleting data, compromising test accounts, and triggering unintended side effects from injection attacks.</li> \n </ul> \n</blockquote> \n<h4><strong>2. Legal &amp; Ethical Use</strong></h4> \n<p>Shannon is designed for legitimate security auditing purposes only.</p> \n<blockquote> \n <p>[!CAUTION] <strong>You must have explicit, written authorization</strong> from the owner of the target system before running Shannon.</p> \n <p>Unauthorized scanning and exploitation of systems you do not own is illegal and can be prosecuted under laws such as the Computer Fraud and Abuse Act (CFAA). Keygraph is not responsible for any misuse of Shannon.</p> \n</blockquote> \n<h4><strong>3. LLM &amp; Automation Caveats</strong></h4> \n<ul> \n <li><strong>Verification is Required</strong>: While significant engineering has gone into our \"proof-by-exploitation\" methodology to eliminate false positives, the underlying LLMs can still generate hallucinated or weakly-supported content in the final report. <strong>Human oversight is essential</strong> to validate the legitimacy and severity of all reported findings.</li> \n <li><strong>Comprehensiveness</strong>: The analysis in Shannon Lite may not be exhaustive due to the inherent limitations of LLM context windows. For a more comprehensive, graph-based analysis of your entire codebase, <strong>Shannon Pro</strong> leverages its advanced data flow analysis engine to ensure deeper and more thorough coverage.</li> \n</ul> \n<h4><strong>4. Scope of Analysis</strong></h4> \n<ul> \n <li><strong>Targeted Vulnerabilities</strong>: The current version of Shannon Lite specifically targets the following classes of <em>exploitable</em> vulnerabilities: \n  <ul> \n   <li>Broken Authentication &amp; Authorization</li> \n   <li>Injection</li> \n   <li>Cross-Site Scripting (XSS)</li> \n   <li>Server-Side Request Forgery (SSRF)</li> \n  </ul> </li> \n <li><strong>What Shannon Lite Does Not Cover</strong>: This list is not exhaustive of all potential security risks. Shannon Lite's \"proof-by-exploitation\" model means it will not report on issues it cannot actively exploit, such as vulnerable third-party libraries or insecure configurations. These types of deep static-analysis findings are a core focus of the advanced analysis engine in <strong>Shannon Pro</strong>.</li> \n</ul> \n<h4><strong>5. Cost &amp; Performance</strong></h4> \n<ul> \n <li><strong>Time</strong>: As of the current version, a full test run typically takes <strong>1 to 1.5 hours</strong> to complete.</li> \n <li><strong>Cost</strong>: Running the full test using Anthropic's Claude 4.5 Sonnet model may incur costs of approximately <strong>$50 USD</strong>. Costs vary based on model pricing and application complexity.</li> \n</ul> \n<h4><strong>6. Windows Antivirus False Positives</strong></h4> \n<p>Windows Defender may flag files in <code>xben-benchmark-results/</code> or <code>deliverables/</code> as malware. These are false positives caused by exploit code in the reports. Add an exclusion for the Shannon directory in Windows Defender, or use Docker/WSL2.</p> \n<h2>📜 License</h2> \n<p>Shannon Lite is released under the <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/LICENSE\">GNU Affero General Public License v3.0 (AGPL-3.0)</a>.</p> \n<p>Shannon is open source (AGPL v3). This license allows you to:</p> \n<ul> \n <li>Use it freely for all internal security testing.</li> \n <li>Modify the code privately for internal use without sharing your changes.</li> \n</ul> \n<p>The AGPL's sharing requirements primarily apply to organizations offering Shannon as a public or managed service (such as a SaaS platform). In those specific cases, any modifications made to the core software must be open-sourced.</p> \n<h2>👥 Community &amp; Support</h2> \n<h3>Community Resources</h3> \n<p><strong>Contributing:</strong> At this time, we’re not accepting external code contributions (PRs).<br /> Issues are welcome for bug reports and feature requests.</p> \n<ul> \n <li>🐛 <strong>Report bugs</strong> via <a href=\"https://github.com/KeygraphHQ/shannon/issues\">GitHub Issues</a></li> \n <li>💡 <strong>Suggest features</strong> in <a href=\"https://github.com/KeygraphHQ/shannon/discussions\">Discussions</a></li> \n <li>💬 <strong>Join our <a href=\"https://discord.gg/KAqzSHHpRt\">Discord</a></strong> for real-time community support</li> \n</ul> \n<h3>Stay Connected</h3> \n<ul> \n <li>🐦 <strong>Twitter</strong>: <a href=\"https://twitter.com/KeygraphHQ\">@KeygraphHQ</a></li> \n <li>💼 <strong>LinkedIn</strong>: <a href=\"https://linkedin.com/company/keygraph\">Keygraph</a></li> \n <li>🌐 <strong>Website</strong>: <a href=\"https://keygraph.io\">keygraph.io</a></li> \n</ul> \n<h2>💬 Get in Touch</h2> \n<h3>Interested in Shannon Pro?</h3> \n<p>Shannon Pro is designed for organizations serious about application security. It offers enterprise-grade features, dedicated support, and seamless CI/CD integration, all powered by our most advanced LLM-based analysis engine. Find and fix complex vulnerabilities deep in your codebase before they ever reach production.</p> \n<p>For a detailed breakdown of features, technical differences, and enterprise use cases, see our <a href=\"https://raw.githubusercontent.com/KeygraphHQ/shannon/main/SHANNON-PRO.md\">complete comparison guide</a>.</p> \n<p align=\"center\"> <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSf-cPZcWjlfBJ3TCT8AaWpf8ztsw3FaHzJE4urr55KdlQs6cQ/viewform?usp=header\" target=\"_blank\"> <img alt=\"Express Interest\" src=\"https://img.shields.io/badge/📋%20Express%20Interest%20in%20Shannon%20Pro-4285F4?style=for-the-badge&amp;logo=google&amp;logoColor=white\" /> </a> </p> \n<p><strong>Or contact us directly:</strong></p> \n<p>📧 <strong>Email</strong>: <a href=\"mailto:shannon@keygraph.io\">shannon@keygraph.io</a></p> \n<hr /> \n<p align=\"center\"> <b>Built with ❤️ by the Keygraph team</b><br /> <i>Making application security accessible to everyone</i> </p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:38.373531Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 12
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/google/langextract",
        "title": "google/langextract",
        "summary": "<p>A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</p><hr /><p align=\"center\"> <a href=\"https://github.com/google/langextract\"> <img alt=\"LangExtract Logo\" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/logo.svg?sanitize=true\" width=\"128\" /> </a> </p> \n<h1>LangExtract</h1> \n<p><a href=\"https://pypi.org/project/langextract/\"><img alt=\"PyPI version\" src=\"https://img.shields.io/pypi/v/langextract.svg?sanitize=true\" /></a> <a href=\"https://github.com/google/langextract\"><img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/google/langextract.svg?style=social&amp;label=Star\" /></a> <img alt=\"Tests\" src=\"https://github.com/google/langextract/actions/workflows/ci.yaml/badge.svg?sanitize=true\" /> <a href=\"https://doi.org/10.5281/zenodo.17015089\"><img alt=\"DOI\" src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.17015089.svg?sanitize=true\" /></a></p> \n<h2>Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#introduction\">Introduction</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#why-langextract\">Why LangExtract?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#installation\">Installation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup for Cloud Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#adding-custom-model-providers\">Adding Custom Model Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-openai-models\">Using OpenAI Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-local-llms-with-ollama\">Using Local LLMs with Ollama</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#more-examples\">More Examples</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#romeo-and-juliet-full-text-extraction\"><em>Romeo and Juliet</em> Full Text Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#medication-extraction\">Medication Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#radiology-report-structuring-radextract\">Radiology Report Structuring: RadExtract</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#community-providers\">Community Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#contributing\">Contributing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#testing\">Testing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#disclaimer\">Disclaimer</a></li> \n</ul> \n<h2>Introduction</h2> \n<p>LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.</p> \n<h2>Why LangExtract?</h2> \n<ol> \n <li><strong>Precise Source Grounding:</strong> Maps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.</li> \n <li><strong>Reliable Structured Outputs:</strong> Enforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.</li> \n <li><strong>Optimized for Long Documents:</strong> Overcomes the \"needle-in-a-haystack\" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.</li> \n <li><strong>Interactive Visualization:</strong> Instantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.</li> \n <li><strong>Flexible LLM Support:</strong> Supports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.</li> \n <li><strong>Adaptable to Any Domain:</strong> Define extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.</li> \n <li><strong>Leverages LLM World Knowledge:</strong> Utilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.</li> \n</ol> \n<h2>Quick Start</h2> \n<blockquote> \n <p><strong>Note:</strong> Using cloud-hosted models like Gemini requires an API key. See the <a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup</a> section for instructions on how to get and configure your key.</p> \n</blockquote> \n<p>Extract structured information with just a few lines of code.</p> \n<h3>1. Define Your Extraction Task</h3> \n<p>First, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.</p> \n<pre><code class=\"language-python\">import langextract as lx\nimport textwrap\n\n# 1. Define the prompt and extraction rules\nprompt = textwrap.dedent(\"\"\"\\\n    Extract characters, emotions, and relationships in order of appearance.\n    Use exact text for extractions. Do not paraphrase or overlap entities.\n    Provide meaningful attributes for each entity to add context.\"\"\")\n\n# 2. Provide a high-quality example to guide the model\nexamples = [\n    lx.data.ExampleData(\n        text=\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\",\n        extractions=[\n            lx.data.Extraction(\n                extraction_class=\"character\",\n                extraction_text=\"ROMEO\",\n                attributes={\"emotional_state\": \"wonder\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"emotion\",\n                extraction_text=\"But soft!\",\n                attributes={\"feeling\": \"gentle awe\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"relationship\",\n                extraction_text=\"Juliet is the sun\",\n                attributes={\"type\": \"metaphor\"}\n            ),\n        ]\n    )\n]\n</code></pre> \n<blockquote> \n <p><strong>Note:</strong> Examples drive model behavior. Each <code>extraction_text</code> should ideally be verbatim from the example's <code>text</code> (no paraphrasing), listed in order of appearance. LangExtract raises <code>Prompt alignment</code> warnings by default if examples don't follow this pattern—resolve these for best results.</p> \n</blockquote> \n<h3>2. Run the Extraction</h3> \n<p>Provide your input text and the prompt materials to the <code>lx.extract</code> function.</p> \n<pre><code class=\"language-python\"># The input text to be processed\ninput_text = \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n\n# Run the extraction\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n)\n</code></pre> \n<blockquote> \n <p><strong>Model Selection</strong>: <code>gemini-2.5-flash</code> is the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning, <code>gemini-2.5-pro</code> may provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the <a href=\"https://ai.google.dev/gemini-api/docs/rate-limits#tier-2\">rate-limit documentation</a> for details.</p> \n <p><strong>Model Lifecycle</strong>: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\">official model version documentation</a> to stay informed about the latest stable and legacy versions.</p> \n</blockquote> \n<h3>3. Visualize the Results</h3> \n<p>The extractions can be saved to a <code>.jsonl</code> file, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.</p> \n<pre><code class=\"language-python\"># Save the results to a JSONL file\nlx.io.save_annotated_documents([result], output_name=\"extraction_results.jsonl\", output_dir=\".\")\n\n# Generate the visualization from the file\nhtml_content = lx.visualize(\"extraction_results.jsonl\")\nwith open(\"visualization.html\", \"w\") as f:\n    if hasattr(html_content, 'data'):\n        f.write(html_content.data)  # For Jupyter/Colab\n    else:\n        f.write(html_content)\n</code></pre> \n<p>This creates an animated and interactive HTML file:</p> \n<p><img alt=\"Romeo and Juliet Basic Visualization \" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif\" /></p> \n<blockquote> \n <p><strong>Note on LLM Knowledge Utilization:</strong> This example demonstrates extractions that stay close to the text evidence - extracting \"longing\" for Lady Juliet's emotional state and identifying \"yearning\" from \"gazed longingly at the stars.\" The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding <code>\"identity\": \"Capulet family daughter\"</code> or <code>\"literary_context\": \"tragic heroine\"</code>). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.</p> \n</blockquote> \n<h3>Scaling to Longer Documents</h3> \n<p>For larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:</p> \n<pre><code class=\"language-python\"># Process Romeo &amp; Juliet directly from Project Gutenberg\nresult = lx.extract(\n    text_or_documents=\"https://www.gutenberg.org/files/1513/1513-0.txt\",\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n    extraction_passes=3,    # Improves recall through multiple passes\n    max_workers=20,         # Parallel processing for speed\n    max_char_buffer=1000    # Smaller contexts for better accuracy\n)\n</code></pre> \n<p>This approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file. <strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">See the full <em>Romeo and Juliet</em> extraction example →</a></strong> for detailed results and performance insights.</p> \n<h3>Vertex AI Batch Processing</h3> \n<p>Save costs on large-scale tasks by enabling Vertex AI Batch API: <code>language_model_params={\"vertexai\": True, \"batch\": {\"enabled\": True}}</code>.</p> \n<p>See an example of the Vertex AI Batch API usage in <a href=\"https://raw.githubusercontent.com/google/langextract/main/docs/examples/batch_api_example.md\">this example</a>.</p> \n<h2>Installation</h2> \n<h3>From PyPI</h3> \n<pre><code class=\"language-bash\">pip install langextract\n</code></pre> \n<p><em>Recommended for most users. For isolated environments, consider using a virtual environment:</em></p> \n<pre><code class=\"language-bash\">python -m venv langextract_env\nsource langextract_env/bin/activate  # On Windows: langextract_env\\Scripts\\activate\npip install langextract\n</code></pre> \n<h3>From Source</h3> \n<p>LangExtract uses modern Python packaging with <code>pyproject.toml</code> for dependency management:</p> \n<p><em>Installing with <code>-e</code> puts the package in development mode, allowing you to modify the code without reinstalling.</em></p> \n<pre><code class=\"language-bash\">git clone https://github.com/google/langextract.git\ncd langextract\n\n# For basic installation:\npip install -e .\n\n# For development (includes linting tools):\npip install -e \".[dev]\"\n\n# For testing (includes pytest):\npip install -e \".[test]\"\n</code></pre> \n<h3>Docker</h3> \n<pre><code class=\"language-bash\">docker build -t langextract .\ndocker run --rm -e LANGEXTRACT_API_KEY=\"your-api-key\" langextract python your_script.py\n</code></pre> \n<h2>API Key Setup for Cloud Models</h2> \n<p>When using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to set up an API key. On-device models don't require an API key. For developers using local LLMs, LangExtract offers built-in support for Ollama and can be extended to other third-party APIs by updating the inference endpoints.</p> \n<h3>API Key Sources</h3> \n<p>Get API keys from:</p> \n<ul> \n <li><a href=\"https://aistudio.google.com/app/apikey\">AI Studio</a> for Gemini models</li> \n <li><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview\">Vertex AI</a> for enterprise use</li> \n <li><a href=\"https://platform.openai.com/api-keys\">OpenAI Platform</a> for OpenAI models</li> \n</ul> \n<h3>Setting up API key in your environment</h3> \n<p><strong>Option 1: Environment Variable</strong></p> \n<pre><code class=\"language-bash\">export LANGEXTRACT_API_KEY=\"your-api-key-here\"\n</code></pre> \n<p><strong>Option 2: .env File (Recommended)</strong></p> \n<p>Add your API key to a <code>.env</code> file:</p> \n<pre><code class=\"language-bash\"># Add API key to .env file\ncat &gt;&gt; .env &lt;&lt; 'EOF'\nLANGEXTRACT_API_KEY=your-api-key-here\nEOF\n\n# Keep your API key secure\necho '.env' &gt;&gt; .gitignore\n</code></pre> \n<p>In your Python code:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\"\n)\n</code></pre> \n<p><strong>Option 3: Direct API Key (Not Recommended for Production)</strong></p> \n<p>You can also provide the API key directly in your code, though this is not recommended for production use:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    api_key=\"your-api-key-here\"  # Only use this for testing/development\n)\n</code></pre> \n<p><strong>Option 4: Vertex AI (Service Accounts)</strong></p> \n<p>Use <a href=\"https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform\">Vertex AI</a> for authentication with service accounts:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    language_model_params={\n        \"vertexai\": True,\n        \"project\": \"your-project-id\",\n        \"location\": \"global\"  # or regional endpoint\n    }\n)\n</code></pre> \n<h2>Adding Custom Model Providers</h2> \n<p>LangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.</p> \n<ul> \n <li>Add new model support independently of the core library</li> \n <li>Distribute your provider as a separate Python package</li> \n <li>Keep custom dependencies isolated</li> \n <li>Override or extend built-in providers via priority-based resolution</li> \n</ul> \n<p>See the detailed guide in <a href=\"https://raw.githubusercontent.com/google/langextract/main/langextract/providers/README.md\">Provider System Documentation</a> to learn how to:</p> \n<ul> \n <li>Register a provider with <code>@registry.register(...)</code></li> \n <li>Publish an entry point for discovery</li> \n <li>Optionally provide a schema with <code>get_schema_class()</code> for structured output</li> \n <li>Integrate with the factory via <code>create_model(...)</code></li> \n</ul> \n<h2>Using OpenAI Models</h2> \n<p>LangExtract supports OpenAI models (requires optional dependency: <code>pip install langextract[openai]</code>):</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gpt-4o\",  # Automatically selects OpenAI provider\n    api_key=os.environ.get('OPENAI_API_KEY'),\n    fence_output=True,\n    use_schema_constraints=False\n)\n</code></pre> \n<p>Note: OpenAI models require <code>fence_output=True</code> and <code>use_schema_constraints=False</code> because LangExtract doesn't implement schema constraints for OpenAI yet.</p> \n<h2>Using Local LLMs with Ollama</h2> \n<p>LangExtract supports local inference using Ollama, allowing you to run models without API keys:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemma2:2b\",  # Automatically selects Ollama provider\n    model_url=\"http://localhost:11434\",\n    fence_output=False,\n    use_schema_constraints=False\n)\n</code></pre> \n<p><strong>Quick setup:</strong> Install Ollama from <a href=\"https://ollama.com/\">ollama.com</a>, run <code>ollama pull gemma2:2b</code>, then <code>ollama serve</code>.</p> \n<p>For detailed installation, Docker setup, and examples, see <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/ollama/\"><code>examples/ollama/</code></a>.</p> \n<h2>More Examples</h2> \n<p>Additional examples of LangExtract in action:</p> \n<h3><em>Romeo and Juliet</em> Full Text Extraction</h3> \n<p>LangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of <em>Romeo and Juliet</em> from Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">View <em>Romeo and Juliet</em> Full Text Example →</a></strong></p> \n<h3>Medication Extraction</h3> \n<blockquote> \n <p><strong>Disclaimer:</strong> This demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.</p> \n</blockquote> \n<p>LangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/medication_examples.md\">View Medication Examples →</a></strong></p> \n<h3>Radiology Report Structuring: RadExtract</h3> \n<p>Explore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.</p> \n<p><strong><a href=\"https://huggingface.co/spaces/google/radextract\">View RadExtract Demo →</a></strong></p> \n<h2>Community Providers</h2> \n<p>Extend LangExtract with custom model providers! Check out our <a href=\"https://raw.githubusercontent.com/google/langextract/main/COMMUNITY_PROVIDERS.md\">Community Provider Plugins</a> registry to discover providers created by the community or add your own.</p> \n<p>For detailed instructions on creating a provider plugin, see the <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/custom_provider_plugin/\">Custom Provider Plugin Example</a>.</p> \n<h2>Contributing</h2> \n<p>Contributions are welcome! See <a href=\"https://github.com/google/langextract/raw/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> to get started with development, testing, and pull requests. You must sign a <a href=\"https://cla.developers.google.com/about\">Contributor License Agreement</a> before submitting patches.</p> \n<h2>Testing</h2> \n<p>To run tests locally from the source:</p> \n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/google/langextract.git\ncd langextract\n\n# Install with test dependencies\npip install -e \".[test]\"\n\n# Run all tests\npytest tests\n</code></pre> \n<p>Or reproduce the full CI matrix locally with tox:</p> \n<pre><code class=\"language-bash\">tox  # runs pylint + pytest on Python 3.10 and 3.11\n</code></pre> \n<h3>Ollama Integration Testing</h3> \n<p>If you have Ollama installed locally, you can run integration tests:</p> \n<pre><code class=\"language-bash\"># Test Ollama integration (requires Ollama running with gemma2:2b model)\ntox -e ollama-integration\n</code></pre> \n<p>This test will automatically detect if Ollama is available and run real inference tests.</p> \n<h2>Development</h2> \n<h3>Code Formatting</h3> \n<p>This project uses automated formatting tools to maintain consistent code style:</p> \n<pre><code class=\"language-bash\"># Auto-format all code\n./autoformat.sh\n\n# Or run formatters separately\nisort langextract tests --profile google --line-length 80\npyink langextract tests --config pyproject.toml\n</code></pre> \n<h3>Pre-commit Hooks</h3> \n<p>For automatic formatting checks:</p> \n<pre><code class=\"language-bash\">pre-commit install  # One-time setup\npre-commit run --all-files  # Manual run\n</code></pre> \n<h3>Linting</h3> \n<p>Run linting before submitting PRs:</p> \n<pre><code class=\"language-bash\">pylint --rcfile=.pylintrc langextract tests\n</code></pre> \n<p>See <a href=\"https://raw.githubusercontent.com/google/langextract/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for full development guidelines.</p> \n<h2>Disclaimer</h2> \n<p>This is not an officially supported Google product. If you use LangExtract in production or publications, please cite accordingly and acknowledge usage. Use is subject to the <a href=\"https://github.com/google/langextract/raw/main/LICENSE\">Apache 2.0 License</a>. For health-related applications, use of LangExtract is also subject to the <a href=\"https://developers.google.com/health-ai-developer-foundations/terms\">Health AI Developer Foundations Terms of Use</a>.</p> \n<hr /> \n<p><strong>Happy Extracting!</strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:38.373568Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/steipete/summarize",
        "title": "steipete/summarize",
        "summary": "<p>Point at any URL/YouTube/Podcast or file. Get the gist. CLI and Chrome Extension.</p><hr /><h1>Summarize 📝 — Chrome Side Panel + CLI</h1> \n<p><img alt=\"GitHub Repo Banner\" src=\"https://ghrb.waren.build/banner?header=Summarize%F0%9F%93%9D&amp;subheader=Chrome+Side+Panel+%2B+CLI&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true\" /></p> \n<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --> \n<p>Fast summaries from URLs, files, and media. Works in the terminal, a Chrome Side Panel and Firefox Sidebar.</p> \n<p><strong>0.11.0 preview (unreleased):</strong> this README reflects the upcoming release.</p> \n<h2>0.11.0 preview highlights (most interesting first)</h2> \n<ul> \n <li>Chrome Side Panel <strong>chat</strong> (streaming agent + history) inside the sidebar.</li> \n <li><strong>YouTube slides</strong>: screenshots + OCR + transcript cards, timestamped seek, OCR/Transcript toggle.</li> \n <li>Media-aware summaries: auto‑detect video/audio vs page content.</li> \n <li>Streaming Markdown + metrics + cache‑aware status.</li> \n <li>CLI supports URLs, files, podcasts, YouTube, audio/video, PDFs.</li> \n</ul> \n<h2>Feature overview</h2> \n<ul> \n <li>URLs, files, and media: web pages, PDFs, images, audio/video, YouTube, podcasts, RSS.</li> \n <li>Slide extraction for video sources (YouTube/direct media) with OCR + timestamped cards.</li> \n <li>Transcript-first media flow: published transcripts when available, Whisper fallback when not.</li> \n <li>Streaming output with Markdown rendering, metrics, and cache-aware status.</li> \n <li>Local, paid, and free models: OpenAI‑compatible local endpoints, paid providers, plus an OpenRouter free preset.</li> \n <li>Output modes: Markdown/text, JSON diagnostics, extract-only, metrics, timing, and cost estimates.</li> \n <li>Smart default: if content is shorter than the requested length, we return it as-is (use <code>--force-summary</code> to override).</li> \n</ul> \n<h2>Get the extension (recommended)</h2> \n<p><img alt=\"Summarize extension screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-extension.png\" /></p> \n<p>One‑click summarizer for the current tab. Chrome Side Panel + Firefox Sidebar + local daemon for streaming Markdown.</p> \n<p><strong>Chrome Web Store:</strong> <a href=\"https://chromewebstore.google.com/detail/summarize/cejgnmmhbbpdmjnfppjdfkocebngehfg\">Summarize Side Panel</a></p> \n<p>YouTube slide screenshots (from the browser):</p> \n<p><img alt=\"Summarize YouTube slide screenshots\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/youtube-slides.png\" /></p> \n<h3>Beginner quickstart (extension)</h3> \n<ol> \n <li>Install the CLI (choose one): \n  <ul> \n   <li><strong>npm</strong> (cross‑platform): <code>npm i -g @steipete/summarize</code></li> \n   <li><strong>Homebrew</strong> (macOS arm64): <code>brew install steipete/tap/summarize</code></li> \n  </ul> </li> \n <li>Install the extension (Chrome Web Store link above) and open the Side Panel.</li> \n <li>The panel shows a token + install command. Run it in Terminal: \n  <ul> \n   <li><code>summarize daemon install --token &lt;TOKEN&gt;</code></li> \n  </ul> </li> \n</ol> \n<p>Why a daemon/service?</p> \n<ul> \n <li>The extension can’t run heavy extraction inside the browser. It talks to a local background service on <code>127.0.0.1</code> for fast streaming and media tools (yt‑dlp, ffmpeg, OCR, transcription).</li> \n <li>The service autostarts (launchd/systemd/Scheduled Task) so the Side Panel is always ready.</li> \n</ul> \n<p>If you only want the <strong>CLI</strong>, you can skip the daemon install entirely.</p> \n<p>Notes:</p> \n<ul> \n <li>Summarization only runs when the Side Panel is open.</li> \n <li>Auto mode summarizes on navigation (incl. SPAs); otherwise use the button.</li> \n <li>Daemon is localhost-only and requires a shared token.</li> \n <li>Autostart: macOS (launchd), Linux (systemd user), Windows (Scheduled Task).</li> \n <li>Tip: configure <code>free</code> via <code>summarize refresh-free</code> (needs <code>OPENROUTER_API_KEY</code>). Add <code>--set-default</code> to set model=<code>free</code>.</li> \n</ul> \n<p>More:</p> \n<ul> \n <li>Step-by-step install: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/README.md\">apps/chrome-extension/README.md</a></li> \n <li>Architecture + troubleshooting: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/chrome-extension.md\">docs/chrome-extension.md</a></li> \n <li>Firefox compatibility notes: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/apps/chrome-extension/docs/firefox.md\">apps/chrome-extension/docs/firefox.md</a></li> \n</ul> \n<h3>Slides (extension)</h3> \n<ul> \n <li>Select <strong>Video + Slides</strong> in the Summarize picker.</li> \n <li>Slides render at the top; expand to full‑width cards with timestamps.</li> \n <li>Click a slide to seek the video; toggle <strong>Transcript/OCR</strong> when OCR is significant.</li> \n <li>Requirements: <code>yt-dlp</code> + <code>ffmpeg</code> for extraction; <code>tesseract</code> for OCR. Missing tools show an in‑panel notice.</li> \n</ul> \n<h3>Advanced (unpacked / dev)</h3> \n<ol> \n <li>Build + load the extension (unpacked): \n  <ul> \n   <li>Chrome: <code>pnpm -C apps/chrome-extension build</code> \n    <ul> \n     <li><code>chrome://extensions</code> → Developer mode → Load unpacked</li> \n     <li>Pick: <code>apps/chrome-extension/.output/chrome-mv3</code></li> \n    </ul> </li> \n   <li>Firefox: <code>pnpm -C apps/chrome-extension build:firefox</code> \n    <ul> \n     <li><code>about:debugging#/runtime/this-firefox</code> → Load Temporary Add-on</li> \n     <li>Pick: <code>apps/chrome-extension/.output/firefox-mv3/manifest.json</code></li> \n    </ul> </li> \n  </ul> </li> \n <li>Open Side Panel/Sidebar → copy token.</li> \n <li>Install daemon in dev mode: \n  <ul> \n   <li><code>pnpm summarize daemon install --token &lt;TOKEN&gt; --dev</code></li> \n  </ul> </li> \n</ol> \n<h2>CLI</h2> \n<p><img alt=\"Summarize CLI screenshot\" src=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/assets/summarize-cli.png\" /></p> \n<h3>Install</h3> \n<p>Requires Node 22+.</p> \n<ul> \n <li>npx (no install):</li> \n</ul> \n<pre><code class=\"language-bash\">npx -y @steipete/summarize \"https://example.com\"\n</code></pre> \n<ul> \n <li>npm (global):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i -g @steipete/summarize\n</code></pre> \n<ul> \n <li>npm (library / minimal deps):</li> \n</ul> \n<pre><code class=\"language-bash\">npm i @steipete/summarize-core\n</code></pre> \n<pre><code class=\"language-ts\">import { createLinkPreviewClient } from \"@steipete/summarize-core/content\";\n</code></pre> \n<ul> \n <li>Homebrew (custom tap):</li> \n</ul> \n<pre><code class=\"language-bash\">brew install steipete/tap/summarize\n</code></pre> \n<p>Apple Silicon only (arm64).</p> \n<h3>CLI vs extension</h3> \n<ul> \n <li><strong>CLI only:</strong> just install via npm/Homebrew and run <code>summarize ...</code> (no daemon needed).</li> \n <li><strong>Chrome/Firefox extension:</strong> install the CLI <strong>and</strong> run <code>summarize daemon install --token &lt;TOKEN&gt;</code> so the Side Panel can stream results and use local tools.</li> \n</ul> \n<h3>Quickstart</h3> \n<pre><code class=\"language-bash\">summarize \"https://example.com\"\n</code></pre> \n<h3>Inputs</h3> \n<p>URLs or local paths:</p> \n<pre><code class=\"language-bash\">summarize \"/path/to/file.pdf\" --model google/gemini-3-flash-preview\nsummarize \"https://example.com/report.pdf\" --model google/gemini-3-flash-preview\nsummarize \"/path/to/audio.mp3\"\nsummarize \"/path/to/video.mp4\"\n</code></pre> \n<p>Stdin (pipe content using <code>-</code>):</p> \n<pre><code class=\"language-bash\">echo \"content\" | summarize -\npbpaste | summarize -\n# binary stdin also works (PDF/image/audio/video bytes)\ncat /path/to/file.pdf | summarize -\n</code></pre> \n<p><strong>Notes:</strong></p> \n<ul> \n <li>Stdin has a 50MB size limit</li> \n <li>The <code>-</code> argument tells summarize to read from standard input</li> \n <li>Text stdin is treated as UTF-8 text (whitespace-only input is rejected as empty)</li> \n <li>Binary stdin is preserved as raw bytes and file type is auto-detected when possible</li> \n <li>Useful for piping clipboard content or command output</li> \n</ul> \n<p>YouTube (supports <code>youtube.com</code> and <code>youtu.be</code>):</p> \n<pre><code class=\"language-bash\">summarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto\n</code></pre> \n<p>Podcast RSS (transcribes latest enclosure):</p> \n<pre><code class=\"language-bash\">summarize \"https://feeds.npr.org/500005/podcast.xml\"\n</code></pre> \n<p>Apple Podcasts episode page:</p> \n<pre><code class=\"language-bash\">summarize \"https://podcasts.apple.com/us/podcast/2424-jelly-roll/id360084272?i=1000740717432\"\n</code></pre> \n<p>Spotify episode page (best-effort; may fail for exclusives):</p> \n<pre><code class=\"language-bash\">summarize \"https://open.spotify.com/episode/5auotqWAXhhKyb9ymCuBJY\"\n</code></pre> \n<h3>Output length</h3> \n<p><code>--length</code> controls how much output we ask for (guideline), not a hard cap.</p> \n<pre><code class=\"language-bash\">summarize \"https://example.com\" --length long\nsummarize \"https://example.com\" --length 20k\n</code></pre> \n<ul> \n <li>Presets: <code>short|medium|long|xl|xxl</code></li> \n <li>Character targets: <code>1500</code>, <code>20k</code>, <code>20000</code></li> \n <li>Optional hard cap: <code>--max-output-tokens &lt;count&gt;</code> (e.g. <code>2000</code>, <code>2k</code>) \n  <ul> \n   <li>Provider/model APIs still enforce their own maximum output limits.</li> \n   <li>If omitted, no max token parameter is sent (provider default).</li> \n   <li>Prefer <code>--length</code> unless you need a hard cap.</li> \n  </ul> </li> \n <li>Short content: when extracted content is shorter than the requested length, the CLI returns the content as-is. \n  <ul> \n   <li>Override with <code>--force-summary</code> to always run the LLM.</li> \n  </ul> </li> \n <li>Minimums: <code>--length</code> numeric values must be &gt;= 50 chars; <code>--max-output-tokens</code> must be &gt;= 16.</li> \n <li>Preset targets (source of truth: <code>packages/core/src/prompts/summary-lengths.ts</code>): \n  <ul> \n   <li>short: target ~900 chars (range 600-1,200)</li> \n   <li>medium: target ~1,800 chars (range 1,200-2,500)</li> \n   <li>long: target ~4,200 chars (range 2,500-6,000)</li> \n   <li>xl: target ~9,000 chars (range 6,000-14,000)</li> \n   <li>xxl: target ~17,000 chars (range 14,000-22,000)</li> \n  </ul> </li> \n</ul> \n<h3>What file types work?</h3> \n<p>Best effort and provider-dependent. These usually work well:</p> \n<ul> \n <li><code>text/*</code> and common structured text (<code>.txt</code>, <code>.md</code>, <code>.json</code>, <code>.yaml</code>, <code>.xml</code>, ...) \n  <ul> \n   <li>Text-like files are inlined into the prompt for better provider compatibility.</li> \n  </ul> </li> \n <li>PDFs: <code>application/pdf</code> (provider support varies; Google is the most reliable here)</li> \n <li>Images: <code>image/jpeg</code>, <code>image/png</code>, <code>image/webp</code>, <code>image/gif</code></li> \n <li>Audio/Video: <code>audio/*</code>, <code>video/*</code> (local audio/video files MP3/WAV/M4A/OGG/FLAC/MP4/MOV/WEBM automatically transcribed, when supported by the model)</li> \n</ul> \n<p>Notes:</p> \n<ul> \n <li>If a provider rejects a media type, the CLI fails fast with a friendly message.</li> \n <li>xAI models do not support attaching generic files (like PDFs) via the AI SDK; use Google/OpenAI/Anthropic for those.</li> \n</ul> \n<h3>Model ids</h3> \n<p>Use gateway-style ids: <code>&lt;provider&gt;/&lt;model&gt;</code>.</p> \n<p>Examples:</p> \n<ul> \n <li><code>openai/gpt-5-mini</code></li> \n <li><code>anthropic/claude-sonnet-4-5</code></li> \n <li><code>xai/grok-4-fast-non-reasoning</code></li> \n <li><code>google/gemini-3-flash-preview</code></li> \n <li><code>zai/glm-4.7</code></li> \n <li><code>openrouter/openai/gpt-5-mini</code> (force OpenRouter)</li> \n</ul> \n<p>Note: some models/providers do not support streaming or certain file media types. When that happens, the CLI prints a friendly error (or auto-disables streaming for that model when supported by the provider).</p> \n<h3>Limits</h3> \n<ul> \n <li>Text inputs over 10 MB are rejected before tokenization.</li> \n <li>Text prompts are preflighted against the model input limit (LiteLLM catalog), using a GPT tokenizer.</li> \n</ul> \n<h3>Common flags</h3> \n<pre><code class=\"language-bash\">summarize &lt;input&gt; [flags]\n</code></pre> \n<p>Use <code>summarize --help</code> or <code>summarize help</code> for the full help text.</p> \n<ul> \n <li><code>--model &lt;provider/model&gt;</code>: which model to use (defaults to <code>auto</code>)</li> \n <li><code>--model auto</code>: automatic model selection + fallback (default)</li> \n <li><code>--model &lt;name&gt;</code>: use a config-defined model (see Configuration)</li> \n <li><code>--timeout &lt;duration&gt;</code>: <code>30s</code>, <code>2m</code>, <code>5000ms</code> (default <code>2m</code>)</li> \n <li><code>--retries &lt;count&gt;</code>: LLM retry attempts on timeout (default <code>1</code>)</li> \n <li><code>--length short|medium|long|xl|xxl|s|m|l|&lt;chars&gt;</code></li> \n <li><code>--language, --lang &lt;language&gt;</code>: output language (<code>auto</code> = match source)</li> \n <li><code>--max-output-tokens &lt;count&gt;</code>: hard cap for LLM output tokens</li> \n <li><code>--cli [provider]</code>: use a CLI provider (<code>--model cli/&lt;provider&gt;</code>). Supports <code>claude</code>, <code>gemini</code>, <code>codex</code>, <code>agent</code>. If omitted, uses auto selection with CLI enabled.</li> \n <li><code>--stream auto|on|off</code>: stream LLM output (<code>auto</code> = TTY only; disabled in <code>--json</code> mode)</li> \n <li><code>--plain</code>: keep raw output (no ANSI/OSC Markdown rendering)</li> \n <li><code>--no-color</code>: disable ANSI colors</li> \n <li><code>--theme &lt;name&gt;</code>: CLI theme (<code>aurora</code>, <code>ember</code>, <code>moss</code>, <code>mono</code>)</li> \n <li><code>--format md|text</code>: website/file content format (default <code>text</code>)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code>: HTML -&gt; Markdown mode (default <code>readability</code>)</li> \n <li><code>--preprocess off|auto|always</code>: controls <code>uvx markitdown</code> usage (default <code>auto</code>) \n  <ul> \n   <li>Install <code>uvx</code>: <code>brew install uv</code> (or <a href=\"https://astral.sh/uv/\">https://astral.sh/uv/</a>)</li> \n  </ul> </li> \n <li><code>--extract</code>: print extracted content and exit (URLs only; stdin <code>-</code> is not supported) \n  <ul> \n   <li>Deprecated alias: <code>--extract-only</code></li> \n  </ul> </li> \n <li><code>--slides</code>: extract slides for YouTube/direct video URLs and render them inline in the summary narrative (auto-renders inline in supported terminals)</li> \n <li><code>--slides-ocr</code>: run OCR on extracted slides (requires <code>tesseract</code>)</li> \n <li><code>--slides-dir &lt;dir&gt;</code>: base output dir for slide images (default <code>./slides</code>)</li> \n <li><code>--slides-scene-threshold &lt;value&gt;</code>: scene detection threshold (0.1-1.0)</li> \n <li><code>--slides-max &lt;count&gt;</code>: maximum slides to extract (default <code>6</code>)</li> \n <li><code>--slides-min-duration &lt;seconds&gt;</code>: minimum seconds between slides</li> \n <li><code>--json</code>: machine-readable output with diagnostics, prompt, <code>metrics</code>, and optional summary</li> \n <li><code>--verbose</code>: debug/diagnostics on stderr</li> \n <li><code>--metrics off|on|detailed</code>: metrics output (default <code>on</code>)</li> \n</ul> \n<h3>Coding CLIs (Codex, Claude, Gemini, Agent)</h3> \n<p>Summarize can use common coding CLIs as local model backends:</p> \n<ul> \n <li><code>codex</code> -&gt; <code>--cli codex</code> / <code>--model cli/codex/&lt;model&gt;</code></li> \n <li><code>claude</code> -&gt; <code>--cli claude</code> / <code>--model cli/claude/&lt;model&gt;</code></li> \n <li><code>gemini</code> -&gt; <code>--cli gemini</code> / <code>--model cli/gemini/&lt;model&gt;</code></li> \n <li><code>agent</code> (Cursor Agent CLI) -&gt; <code>--cli agent</code> / <code>--model cli/agent/&lt;model&gt;</code></li> \n</ul> \n<p>Requirements:</p> \n<ul> \n <li>Binary installed and on <code>PATH</code> (or set <code>CODEX_PATH</code>, <code>CLAUDE_PATH</code>, <code>GEMINI_PATH</code>, <code>AGENT_PATH</code>)</li> \n <li>Provider authenticated (<code>codex login</code>, <code>claude auth</code>, <code>gemini</code> login flow, <code>agent login</code> or <code>CURSOR_API_KEY</code>)</li> \n</ul> \n<p>Quick smoke test:</p> \n<pre><code class=\"language-bash\">printf \"Summarize CLI smoke input.\\nOne short paragraph. Reply can be brief.\\n\" &gt;/tmp/summarize-cli-smoke.txt\n\nsummarize --cli codex --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli claude --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli gemini --plain --timeout 2m /tmp/summarize-cli-smoke.txt\nsummarize --cli agent --plain --timeout 2m /tmp/summarize-cli-smoke.txt\n</code></pre> \n<p>Set explicit CLI allowlist/order:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"codex\", \"claude\", \"gemini\", \"agent\"] }\n}\n</code></pre> \n<p>Configure implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": {\n    \"autoFallback\": {\n      \"enabled\": true,\n      \"onlyWhenNoApiKeys\": true,\n      \"order\": [\"claude\", \"gemini\", \"codex\", \"agent\"]\n    }\n  }\n}\n</code></pre> \n<p>More details: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\"><code>docs/cli.md</code></a></p> \n<h3>Auto model ordering</h3> \n<p><code>--model auto</code> builds candidate attempts from built-in rules (or your <code>model.rules</code> overrides). CLI attempts are prepended when:</p> \n<ul> \n <li><code>cli.enabled</code> is set (explicit allowlist/order), or</li> \n <li>implicit auto selection is active and <code>cli.autoFallback</code> is enabled.</li> \n</ul> \n<p>Default fallback behavior: only when no API keys are configured, order <code>claude, gemini, codex, agent</code>, and remember/prioritize last successful provider (<code>~/.summarize/cli-state.json</code>).</p> \n<p>Set explicit CLI attempts:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"enabled\": [\"gemini\"] }\n}\n</code></pre> \n<p>Disable implicit auto CLI fallback:</p> \n<pre><code class=\"language-json\">{\n  \"cli\": { \"autoFallback\": { \"enabled\": false } }\n}\n</code></pre> \n<p>Note: explicit <code>--model auto</code> does not trigger implicit auto CLI fallback unless <code>cli.enabled</code> is set.</p> \n<h3>Website extraction (Firecrawl + Markdown)</h3> \n<p>Non-YouTube URLs go through a fetch -&gt; extract pipeline. When direct fetch/extraction is blocked or too thin, <code>--firecrawl auto</code> can fall back to Firecrawl (if configured).</p> \n<ul> \n <li><code>--firecrawl off|auto|always</code> (default <code>auto</code>)</li> \n <li><code>--extract --format md|text</code> (default <code>text</code>; if <code>--format</code> is omitted, <code>--extract</code> defaults to <code>md</code> for non-YouTube URLs)</li> \n <li><code>--markdown-mode off|auto|llm|readability</code> (default <code>readability</code>) \n  <ul> \n   <li><code>auto</code>: use an LLM converter when configured; may fall back to <code>uvx markitdown</code></li> \n   <li><code>llm</code>: force LLM conversion (requires a configured model key)</li> \n   <li><code>off</code>: disable LLM conversion (still may return Firecrawl Markdown when configured)</li> \n  </ul> </li> \n <li>Plain-text mode: use <code>--format text</code>.</li> \n</ul> \n<h3>YouTube transcripts</h3> \n<p><code>--youtube auto</code> tries best-effort web transcript endpoints first. When captions are not available, it falls back to:</p> \n<ol> \n <li>Apify (if <code>APIFY_API_TOKEN</code> is set): uses a scraping actor (<code>faVsWy9VTSNVIhWpR</code>)</li> \n <li>yt-dlp + Whisper (if <code>yt-dlp</code> is available): downloads audio, then transcribes with local <code>whisper.cpp</code> when installed (preferred), otherwise falls back to OpenAI (<code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>)</li> \n</ol> \n<p>Environment variables for yt-dlp mode:</p> \n<ul> \n <li><code>YT_DLP_PATH</code> - optional path to yt-dlp binary (otherwise <code>yt-dlp</code> is resolved via <code>PATH</code>)</li> \n <li><code>SUMMARIZE_WHISPER_CPP_MODEL_PATH</code> - optional override for the local <code>whisper.cpp</code> model file</li> \n <li><code>SUMMARIZE_WHISPER_CPP_BINARY</code> - optional override for the local binary (default: <code>whisper-cli</code>)</li> \n <li><code>SUMMARIZE_DISABLE_LOCAL_WHISPER_CPP=1</code> - disable local whisper.cpp (force remote)</li> \n <li><code>OPENAI_API_KEY</code> - OpenAI Whisper transcription</li> \n <li><code>OPENAI_WHISPER_BASE_URL</code> - optional OpenAI-compatible Whisper endpoint override</li> \n <li><code>FAL_KEY</code> - FAL AI Whisper fallback</li> \n</ul> \n<p>Apify costs money but tends to be more reliable when captions exist.</p> \n<h3>Slide extraction (YouTube + direct video URLs)</h3> \n<p>Extract slide screenshots (scene detection via <code>ffmpeg</code>) and optional OCR:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --slides\nsummarize \"https://www.youtube.com/watch?v=...\" --slides --slides-ocr\n</code></pre> \n<p>Outputs are written under <code>./slides/&lt;sourceId&gt;/</code> (or <code>--slides-dir</code>). OCR results are included in JSON output (<code>--json</code>) and stored in <code>slides.json</code> inside the slide directory. When scene detection is too sparse, the extractor also samples at a fixed interval to improve coverage. When using <code>--slides</code>, supported terminals (kitty/iTerm/Konsole) render inline thumbnails automatically inside the summary narrative (the model inserts <code>[slide:N]</code> markers). Timestamp links are clickable when the terminal supports OSC-8 (YouTube/Vimeo/Loom/Dropbox). If inline images are unsupported, Summarize prints a note with the on-disk slide directory.</p> \n<p>Use <code>--slides --extract</code> to print the full timed transcript and insert slide images inline at matching timestamps.</p> \n<p>Format the extracted transcript as Markdown (headings + paragraphs) via an LLM:</p> \n<pre><code class=\"language-bash\">summarize \"https://www.youtube.com/watch?v=...\" --extract --format md --markdown-mode llm\n</code></pre> \n<h3>Media transcription (Whisper)</h3> \n<p>Local audio/video files are transcribed first, then summarized. <code>--video-mode transcript</code> forces direct media URLs (and embedded media) through Whisper first. Prefers local <code>whisper.cpp</code> when available; otherwise requires <code>OPENAI_API_KEY</code> or <code>FAL_KEY</code>.</p> \n<h3>Local ONNX transcription (Parakeet/Canary)</h3> \n<p>Summarize can use NVIDIA Parakeet/Canary ONNX models via a local CLI you provide. Auto selection (default) prefers ONNX when configured.</p> \n<ul> \n <li>Setup helper: <code>summarize transcriber setup</code></li> \n <li>Install <code>sherpa-onnx</code> from upstream binaries/build (Homebrew may not have a formula)</li> \n <li>Auto selection: set <code>SUMMARIZE_ONNX_PARAKEET_CMD</code> or <code>SUMMARIZE_ONNX_CANARY_CMD</code> (no flag needed)</li> \n <li>Force a model: <code>--transcriber parakeet|canary|whisper|auto</code></li> \n <li>Docs: <code>docs/nvidia-onnx-transcription.md</code></li> \n</ul> \n<h3>Verified podcast services (2025-12-25)</h3> \n<p>Run: <code>summarize &lt;url&gt;</code></p> \n<ul> \n <li>Apple Podcasts</li> \n <li>Spotify</li> \n <li>Amazon Music / Audible podcast pages</li> \n <li>Podbean</li> \n <li>Podchaser</li> \n <li>RSS feeds (Podcasting 2.0 transcripts when available)</li> \n <li>Embedded YouTube podcast pages (e.g. JREPodcast)</li> \n</ul> \n<p>Transcription: prefers local <code>whisper.cpp</code> when installed; otherwise uses OpenAI Whisper or FAL when keys are set.</p> \n<h3>Translation paths</h3> \n<p><code>--language/--lang</code> controls the output language of the summary (and other LLM-generated text). Default is <code>auto</code>.</p> \n<p>When the input is audio/video, the CLI needs a transcript first. The transcript comes from one of these paths:</p> \n<ol> \n <li>Existing transcript (preferred) \n  <ul> \n   <li>YouTube: uses <code>youtubei</code> / <code>captionTracks</code> when available.</li> \n   <li>Podcasts: uses Podcasting 2.0 RSS <code>&lt;podcast:transcript&gt;</code> (JSON/VTT) when the feed publishes it.</li> \n  </ul> </li> \n <li>Whisper transcription (fallback) \n  <ul> \n   <li>YouTube: falls back to yt-dlp (audio download) + Whisper transcription when configured; Apify is a last resort.</li> \n   <li>Prefers local <code>whisper.cpp</code> when installed + model available.</li> \n   <li>Otherwise uses cloud Whisper (OpenAI <code>OPENAI_API_KEY</code>) or FAL (<code>FAL_KEY</code>).</li> \n  </ul> </li> \n</ol> \n<p>For direct media URLs, use <code>--video-mode transcript</code> to force transcribe -&gt; summarize:</p> \n<pre><code class=\"language-bash\">summarize https://example.com/file.mp4 --video-mode transcript --lang en\n</code></pre> \n<h3>Configuration</h3> \n<p>Single config location:</p> \n<ul> \n <li><code>~/.summarize/config.json</code></li> \n</ul> \n<p>Supported keys today:</p> \n<pre><code class=\"language-json\">{\n  \"model\": { \"id\": \"openai/gpt-5-mini\" },\n  \"env\": { \"OPENAI_API_KEY\": \"sk-...\" },\n  \"ui\": { \"theme\": \"ember\" }\n}\n</code></pre> \n<p>Shorthand (equivalent):</p> \n<pre><code class=\"language-json\">{\n  \"model\": \"openai/gpt-5-mini\"\n}\n</code></pre> \n<p>Also supported:</p> \n<ul> \n <li><code>model: { \"mode\": \"auto\" }</code> (automatic model selection + fallback; see <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a>)</li> \n <li><code>model.rules</code> (customize candidates / ordering)</li> \n <li><code>models</code> (define presets selectable via <code>--model &lt;preset&gt;</code>)</li> \n <li><code>env</code> (generic env var defaults; process env still wins)</li> \n <li><code>apiKeys</code> (legacy shortcut, mapped to env names; prefer <code>env</code> for new configs)</li> \n <li><code>cache.media</code> (media download cache: TTL 7 days, 2048 MB cap by default; <code>--no-media-cache</code> disables)</li> \n <li><code>media.videoMode: \"auto\"|\"transcript\"|\"understand\"</code></li> \n <li><code>slides.enabled</code> / <code>slides.max</code> / <code>slides.ocr</code> / <code>slides.dir</code> (defaults for <code>--slides</code>)</li> \n <li><code>ui.theme: \"aurora\"|\"ember\"|\"moss\"|\"mono\"</code></li> \n <li><code>openai.useChatCompletions: true</code> (force OpenAI-compatible chat completions)</li> \n</ul> \n<p>Note: the config is parsed leniently (JSON5), but comments are not allowed. Unknown keys are ignored.</p> \n<p>Media cache defaults:</p> \n<pre><code class=\"language-json\">{\n  \"cache\": {\n    \"media\": { \"enabled\": true, \"ttlDays\": 7, \"maxMb\": 2048, \"verify\": \"size\" }\n  }\n}\n</code></pre> \n<p>Note: <code>--no-cache</code> bypasses summary caching only (LLM output). Extract/transcript caches still apply. Use <code>--no-media-cache</code> to skip media files.</p> \n<p>Precedence:</p> \n<ol> \n <li><code>--model</code></li> \n <li><code>SUMMARIZE_MODEL</code></li> \n <li><code>~/.summarize/config.json</code></li> \n <li>default (<code>auto</code>)</li> \n</ol> \n<p>Theme precedence:</p> \n<ol> \n <li><code>--theme</code></li> \n <li><code>SUMMARIZE_THEME</code></li> \n <li><code>~/.summarize/config.json</code> (<code>ui.theme</code>)</li> \n <li>default (<code>aurora</code>)</li> \n</ol> \n<p>Environment variable precedence:</p> \n<ol> \n <li>process env</li> \n <li><code>~/.summarize/config.json</code> (<code>env</code>)</li> \n <li><code>~/.summarize/config.json</code> (<code>apiKeys</code>, legacy)</li> \n</ol> \n<h3>Environment variables</h3> \n<p>Set the key matching your chosen <code>--model</code>:</p> \n<ul> \n <li> <p>Optional fallback defaults can be stored in config:</p> \n  <ul> \n   <li><code>~/.summarize/config.json</code> -&gt; <code>\"env\": { \"OPENAI_API_KEY\": \"sk-...\" }</code></li> \n   <li>process env always takes precedence</li> \n   <li>legacy <code>\"apiKeys\"</code> still works (mapped to env names)</li> \n  </ul> </li> \n <li> <p><code>OPENAI_API_KEY</code> (for <code>openai/...</code>)</p> </li> \n <li> <p><code>NVIDIA_API_KEY</code> (for <code>nvidia/...</code>)</p> </li> \n <li> <p><code>ANTHROPIC_API_KEY</code> (for <code>anthropic/...</code>)</p> </li> \n <li> <p><code>XAI_API_KEY</code> (for <code>xai/...</code>)</p> </li> \n <li> <p><code>Z_AI_API_KEY</code> (for <code>zai/...</code>; supports <code>ZAI_API_KEY</code> alias)</p> </li> \n <li> <p><code>GEMINI_API_KEY</code> (for <code>google/...</code>)</p> \n  <ul> \n   <li>also accepts <code>GOOGLE_GENERATIVE_AI_API_KEY</code> and <code>GOOGLE_API_KEY</code> as aliases</li> \n  </ul> </li> \n</ul> \n<p>OpenAI-compatible chat completions toggle:</p> \n<ul> \n <li><code>OPENAI_USE_CHAT_COMPLETIONS=1</code> (or set <code>openai.useChatCompletions</code> in config)</li> \n</ul> \n<p>UI theme:</p> \n<ul> \n <li><code>SUMMARIZE_THEME=aurora|ember|moss|mono</code></li> \n <li><code>SUMMARIZE_TRUECOLOR=1</code> (force 24-bit ANSI)</li> \n <li><code>SUMMARIZE_NO_TRUECOLOR=1</code> (disable 24-bit ANSI)</li> \n</ul> \n<p>OpenRouter (OpenAI-compatible):</p> \n<ul> \n <li>Set <code>OPENROUTER_API_KEY=...</code></li> \n <li>Prefer forcing OpenRouter per model id: <code>--model openrouter/&lt;author&gt;/&lt;slug&gt;</code></li> \n <li>Built-in preset: <code>--model free</code> (uses a default set of OpenRouter <code>:free</code> models)</li> \n</ul> \n<h3><code>summarize refresh-free</code></h3> \n<p>Quick start: make free the default (keep <code>auto</code> available)</p> \n<pre><code class=\"language-bash\">summarize refresh-free --set-default\nsummarize \"https://example.com\"\nsummarize \"https://example.com\" --model auto\n</code></pre> \n<p>Regenerates the <code>free</code> preset (<code>models.free</code> in <code>~/.summarize/config.json</code>) by:</p> \n<ul> \n <li>Fetching OpenRouter <code>/models</code>, filtering <code>:free</code></li> \n <li>Skipping models that look very small (&lt;27B by default) based on the model id/name</li> \n <li>Testing which ones return non-empty text (concurrency 4, timeout 10s)</li> \n <li>Picking a mix of smart-ish (bigger <code>context_length</code> / output cap) and fast models</li> \n <li>Refining timings and writing the sorted list back</li> \n</ul> \n<p>If <code>--model free</code> stops working, run:</p> \n<pre><code class=\"language-bash\">summarize refresh-free\n</code></pre> \n<p>Flags:</p> \n<ul> \n <li><code>--runs 2</code> (default): extra timing runs per selected model (total runs = 1 + runs)</li> \n <li><code>--smart 3</code> (default): how many smart-first picks (rest filled by fastest)</li> \n <li><code>--min-params 27b</code> (default): ignore models with inferred size smaller than N billion parameters</li> \n <li><code>--max-age-days 180</code> (default): ignore models older than N days (set 0 to disable)</li> \n <li><code>--set-default</code>: also sets <code>\"model\": \"free\"</code> in <code>~/.summarize/config.json</code></li> \n</ul> \n<p>Example:</p> \n<pre><code class=\"language-bash\">OPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/meta-llama/llama-3.1-8b-instruct:free\nOPENROUTER_API_KEY=sk-or-... summarize \"https://example.com\" --model openrouter/minimax/minimax-m2.5\n</code></pre> \n<p>If your OpenRouter account enforces an allowed-provider list, make sure at least one provider is allowed for the selected model. When routing fails, <code>summarize</code> prints the exact providers to allow.</p> \n<p>Legacy: <code>OPENAI_BASE_URL=https://openrouter.ai/api/v1</code> (and either <code>OPENAI_API_KEY</code> or <code>OPENROUTER_API_KEY</code>) also works.</p> \n<p>NVIDIA API Catalog (OpenAI-compatible; free credits):</p> \n<ul> \n <li>Set <code>NVIDIA_API_KEY=...</code></li> \n <li>Optional: <code>NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1</code></li> \n <li>Credits: API Catalog trial starts with 1000 free API credits on signup (up to 5000 total via “Request More” in the API Catalog profile)</li> \n <li>Pick a model id from <code>/v1/models</code> (examples: fast <code>stepfun-ai/step-3.5-flash</code>, strong but slower <code>z-ai/glm5</code>)</li> \n</ul> \n<pre><code class=\"language-bash\">export NVIDIA_API_KEY=\"nvapi-...\"\nsummarize \"https://example.com\" --model nvidia/stepfun-ai/step-3.5-flash\n</code></pre> \n<p>Z.AI (OpenAI-compatible):</p> \n<ul> \n <li><code>Z_AI_API_KEY=...</code> (or <code>ZAI_API_KEY=...</code>)</li> \n <li>Optional base URL override: <code>Z_AI_BASE_URL=...</code></li> \n</ul> \n<p>Optional services:</p> \n<ul> \n <li><code>FIRECRAWL_API_KEY</code> (website extraction fallback)</li> \n <li><code>YT_DLP_PATH</code> (path to yt-dlp binary for audio extraction)</li> \n <li><code>FAL_KEY</code> (FAL AI API key for audio transcription via Whisper)</li> \n <li><code>APIFY_API_TOKEN</code> (YouTube transcript fallback)</li> \n</ul> \n<h3>Model limits</h3> \n<p>The CLI uses the LiteLLM model catalog for model limits (like max output tokens):</p> \n<ul> \n <li>Downloaded from: <code>https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json</code></li> \n <li>Cached at: <code>~/.summarize/cache/</code></li> \n</ul> \n<h3>Library usage (optional)</h3> \n<p>Recommended (minimal deps):</p> \n<ul> \n <li><code>@steipete/summarize-core/content</code></li> \n <li><code>@steipete/summarize-core/prompts</code></li> \n</ul> \n<p>Compatibility (pulls in CLI deps):</p> \n<ul> \n <li><code>@steipete/summarize/content</code></li> \n <li><code>@steipete/summarize/prompts</code></li> \n</ul> \n<h3>Development</h3> \n<pre><code class=\"language-bash\">pnpm install\npnpm check\n</code></pre> \n<h2>More</h2> \n<ul> \n <li>Docs index: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/README.md\">docs/README.md</a></li> \n <li>CLI providers and config: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/cli.md\">docs/cli.md</a></li> \n <li>Auto model rules: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/model-auto.md\">docs/model-auto.md</a></li> \n <li>Website extraction: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/website.md\">docs/website.md</a></li> \n <li>YouTube handling: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/youtube.md\">docs/youtube.md</a></li> \n <li>Media pipeline: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/media.md\">docs/media.md</a></li> \n <li>Config schema and precedence: <a href=\"https://raw.githubusercontent.com/steipete/summarize/main/docs/config.md\">docs/config.md</a></li> \n</ul> \n<h2>Troubleshooting</h2> \n<ul> \n <li>\"Receiving end does not exist\": Chrome did not inject the content script yet. \n  <ul> \n   <li>Extension details -&gt; Site access -&gt; On all sites (or allow this domain)</li> \n   <li>Reload the tab once.</li> \n  </ul> </li> \n <li>\"Failed to fetch\" / daemon unreachable: \n  <ul> \n   <li><code>summarize daemon status</code></li> \n   <li>Logs: <code>~/.summarize/logs/daemon.err.log</code></li> \n  </ul> </li> \n</ul> \n<p>License: MIT</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-02-18T23:25:37.109791Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 19,
        "timeliness_score": 1,
        "final_score": 6.4,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/octasoft-ltd/moving-wsl-distributions-to-another-drive-3id4",
        "title": "Moving WSL Distributions to Another Drive",
        "summary": "<p>WSL2 distributions default to your C: drive. That's fine when you have one small Ubuntu install. It's less fine when you have five distros, each with a 20-50GB virtual disk, and your system drive is running out of space.</p>\n\n<p>The good news: you can move distributions to any drive. The less good news: there are a couple of ways to do it, and the right approach depends on your WSL version.</p>\n\n<h2>\n  \n  \n  Where Are My Distributions Stored?\n</h2>\n\n<p>Before moving anything, let's find where your distros currently live. WSL stores each distribution's virtual hard disk (VHDX) in a base path registered in the Windows Registry:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Lxss\\{GUID}\\BasePath\n</code></pre>\n\n</div>\n\n\n\n<p>Common default locations:</p>\n\n<ul>\n<li>\n<strong>Newer WSL:</strong> <code>%LOCALAPPDATA%\\wsl\\{GUID}\\</code>\n</li>\n<li>\n<strong>Store-installed distros:</strong> <code>%LOCALAPPDATA%\\Packages\\&lt;distro-package&gt;\\LocalState\\</code>\n</li>\n</ul>\n\n<p>You can check your distro sizes from PowerShell:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">Get-ChildItem</span><span class=\"w\"> </span><span class=\"nt\">-Path</span><span class=\"w\"> </span><span class=\"s2\">\"</span><span class=\"nv\">$</span><span class=\"nn\">env</span><span class=\"p\">:</span><span class=\"nv\">LOCALAPPDATA</span><span class=\"s2\">\\wsl\"</span><span class=\"w\"> </span><span class=\"nt\">-Recurse</span><span class=\"w\"> </span><span class=\"nt\">-Filter</span><span class=\"w\"> </span><span class=\"s2\">\"ext4.vhdx\"</span><span class=\"w\"> </span><span class=\"o\">|</span><span class=\"w\">\n  </span><span class=\"n\">Select-Object</span><span class=\"w\"> </span><span class=\"nx\">FullName</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">@{</span><span class=\"nx\">N</span><span class=\"o\">=</span><span class=\"s1\">'SizeGB'</span><span class=\"p\">;</span><span class=\"nx\">E</span><span class=\"o\">=</span><span class=\"p\">{[</span><span class=\"n\">math</span><span class=\"p\">]::</span><span class=\"n\">Round</span><span class=\"p\">(</span><span class=\"bp\">$_</span><span class=\"o\">.</span><span class=\"nf\">Length</span><span class=\"n\">/1GB</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nx\">2</span><span class=\"p\">)}}</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>Or list all your distributions and their WSL versions:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--list</span><span class=\"w\"> </span><span class=\"nt\">--verbose</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  Method 1: wsl --manage --move (Recommended)\n</h2>\n\n<p>The simplest way to move a distribution is WSL's built-in move command. This relocates the VHDX file and updates the registry in one step.</p>\n\n<h3>\n  \n  \n  Step 1: Stop the Distribution\n</h3>\n\n<p>The distro must be stopped before moving:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--terminate</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>Verify it's stopped:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--list</span><span class=\"w\"> </span><span class=\"nt\">--verbose</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>Look for \"Stopped\" next to your distro name.</p>\n\n<h3>\n  \n  \n  Step 2: Move It\n</h3>\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--manage</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nt\">--move</span><span class=\"w\"> </span><span class=\"s2\">\"D:\\WSL\\Ubuntu\"</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>WSL will create the destination directory if needed and move the VHDX file. This can take a while for large distros — a 50GB VHDX will take a few minutes depending on your disk speed.</p>\n\n<h3>\n  \n  \n  Step 3: Verify\n</h3>\n\n<p>Start the distro and confirm everything works:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">-d</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code><span class=\"nb\">whoami\nls</span> ~\n</code></pre>\n\n</div>\n\n\n\n<p>That's it. Your distribution is now on D: and WSL knows where to find it. All your files, installed packages, and configuration are preserved.</p>\n\n<h2>\n  \n  \n  Method 2: Export and Import\n</h2>\n\n<p>If <code>--manage --move</code> isn't available on your WSL version, or if you want to rename the distro at the same time, the export/import approach works on all WSL2 installations.</p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fowlz6meb5xbt2qr1zd16.png\"><img alt=\"moving-wsl-distributions-to-another-drive/export-import-workflow\" height=\"1442\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fowlz6meb5xbt2qr1zd16.png\" width=\"716\" /></a></p>\n\n<h3>\n  \n  \n  Step 1: Export the Distribution\n</h3>\n\n<p>You have two format options:</p>\n\n<p><strong>TAR format (default, universal):</strong><br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--export</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.tar</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p><strong>VHD format (faster, preserves disk structure):</strong><br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--export</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.vhdx</span><span class=\"w\"> </span><span class=\"nt\">--format</span><span class=\"w\"> </span><span class=\"nx\">vhd</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>The VHD format is significantly faster because it copies the VHDX file directly instead of creating a tar archive from the filesystem. For large distros, this can save considerable time.</p>\n\n<p><strong>Compressed TAR (smaller file):</strong><br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--export</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.tar.gz</span><span class=\"w\"> </span><span class=\"nt\">--format</span><span class=\"w\"> </span><span class=\"nx\">tar.gz</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  Step 2: Unregister the Old Distribution\n</h3>\n\n<p>This removes the distribution from WSL's registry and deletes the original VHDX:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--unregister</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p><strong>Warning:</strong> This deletes the original distribution data. Make sure your export completed successfully before running this. Check the file size of your export — it should be reasonable (not 0 bytes).</p>\n\n<h3>\n  \n  \n  Step 3: Import to the New Location\n</h3>\n\n<p><strong>From a TAR export:</strong><br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--import</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"s2\">\"D:\\WSL\\Ubuntu\"</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.tar</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p><strong>From a VHD export:</strong><br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--import</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"s2\">\"D:\\WSL\\Ubuntu\"</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.vhdx</span><span class=\"w\"> </span><span class=\"nt\">--vhd</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>The arguments are: <code>wsl --import &lt;name&gt; &lt;install-location&gt; &lt;file-path&gt;</code>.</p>\n\n<h3>\n  \n  \n  Step 4: Fix the Default User\n</h3>\n\n<p>When you import from a TAR archive, WSL defaults to logging in as root. You need to restore your default user. Edit <code>/etc/wsl.conf</code> inside the distro:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">-d</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nt\">-u</span><span class=\"w\"> </span><span class=\"nx\">root</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code><span class=\"nb\">cat</span> <span class=\"o\">&gt;&gt;</span> /etc/wsl.conf <span class=\"o\">&lt;&lt;</span> <span class=\"sh\">'</span><span class=\"no\">EOF</span><span class=\"sh\">'\n[user]\ndefault=yourusername\n</span><span class=\"no\">EOF\n</span><span class=\"nb\">exit</span>\n</code></pre>\n\n</div>\n\n\n\n<p>Then restart the distro for the change to take effect:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--terminate</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\">\n</span><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">-d</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\">\n</span><span class=\"n\">whoami</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>This should now show your username instead of root.</p>\n\n<p><strong>Note:</strong> If you exported as VHD format, the <code>/etc/wsl.conf</code> file is preserved as-is inside the VHDX, so your default user setting should already be correct.</p>\n\n<h3>\n  \n  \n  Step 5: Clean Up\n</h3>\n\n<p>Once everything is working, delete the backup file:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">Remove-Item</span><span class=\"w\"> </span><span class=\"nx\">D:\\Backups\\ubuntu-backup.tar</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  Method 3: Import In-Place (Advanced)\n</h2>\n\n<p>If you've already manually copied a VHDX file to a new location, you can register it directly without WSL copying it again:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--import-in-place</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"s2\">\"D:\\WSL\\Ubuntu\\ext4.vhdx\"</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>This tells WSL to use the VHDX at its current location. The file must be ext4-formatted (which all WSL2 VHDX files are). This is the fastest option if you've already moved the file yourself.</p>\n\n<h2>\n  \n  \n  Choosing the Right Method\n</h2>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Factor</th>\n<th>--manage --move</th>\n<th>Export/Import (TAR)</th>\n<th>Export/Import (VHD)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Speed</td>\n<td>Fast (direct move)</td>\n<td>Slow (tar + extract)</td>\n<td>Medium (file copy)</td>\n</tr>\n<tr>\n<td>Disk space needed</td>\n<td>Just the destination</td>\n<td>2x (export + import)</td>\n<td>2x (export + import)</td>\n</tr>\n<tr>\n<td>Preserves user settings</td>\n<td>Yes</td>\n<td>No (need to fix)</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Rename distro</td>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>WSL version required</td>\n<td>Recent WSL</td>\n<td>Any WSL2</td>\n<td>Any WSL2</td>\n</tr>\n<tr>\n<td>Complexity</td>\n<td>Low</td>\n<td>Medium</td>\n<td>Medium</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>For most people, <code>--manage --move</code> is the right choice. Use export/import when you need to rename the distro or are on an older WSL version.</p>\n\n<h2>\n  \n  \n  Installing New Distros on a Different Drive\n</h2>\n\n<p>Prevention is better than cure. When installing new distributions, you can specify the location upfront:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight powershell\"><code><span class=\"n\">wsl</span><span class=\"w\"> </span><span class=\"nt\">--install</span><span class=\"w\"> </span><span class=\"nx\">Ubuntu</span><span class=\"w\"> </span><span class=\"nt\">--location</span><span class=\"w\"> </span><span class=\"s2\">\"D:\\WSL\\Ubuntu\"</span><span class=\"w\">\n</span></code></pre>\n\n</div>\n\n\n\n<p>This puts the VHDX on D: from the start, avoiding the need to move it later.</p>\n\n<h2>\n  \n  \n  The Easy Way: WSL UI\n</h2>\n\n<p><a href=\"https://wsl-ui.octasoft.co.uk\" rel=\"noopener noreferrer\">WSL UI</a> makes moving distributions a point-and-click operation. The Move Distribution dialog:</p>\n\n<ol>\n<li>Shows the current location and disk size</li>\n<li>Lets you browse to a new location</li>\n<li>Handles stopping the distro, moving the files, and updating the registry</li>\n<li>Shows progress for large moves</li>\n</ol>\n\n<p>No command line, no worrying about which method to use, no manual registry updates. It uses WSL's native move command under the hood, so everything is preserved — your files, settings, default user, and configuration.</p>\n\n<h2>\n  \n  \n  Troubleshooting\n</h2>\n\n<p><strong>\"The operation is not supported\" when using --manage --move:</strong><br />\nYou may be on an older WSL version. Update with <code>wsl --update</code> or use the export/import method instead.</p>\n\n<p><strong>Import defaults to root user:</strong><br />\nThis is expected with TAR imports. Edit <code>/etc/wsl.conf</code> as described in Step 4 of Method 2.</p>\n\n<p><strong>\"Access is denied\" during move:</strong><br />\nMake sure no WSL processes are using the distro. Run <code>wsl --shutdown</code> to stop everything, then try again.</p>\n\n<p><strong>Distro not showing after import:</strong><br />\nCheck that the import path exists and you have write permissions. Try running PowerShell as Administrator.</p>\n\n<p><strong>Running out of space during export:</strong><br />\nExport to the destination drive directly. For example, if moving from C: to D:, export to <code>D:\\Backups\\</code> instead of a location on C:.</p>\n\n<h2>\n  \n  \n  Summary\n</h2>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Command</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>List distros</td>\n<td><code>wsl --list --verbose</code></td>\n</tr>\n<tr>\n<td>Stop a distro</td>\n<td><code>wsl --terminate &lt;distro&gt;</code></td>\n</tr>\n<tr>\n<td>Move (simple)</td>\n<td><code>wsl --manage &lt;distro&gt; --move \"D:\\WSL\\path\"</code></td>\n</tr>\n<tr>\n<td>Export (TAR)</td>\n<td><code>wsl --export &lt;distro&gt; backup.tar</code></td>\n</tr>\n<tr>\n<td>Export (VHD)</td>\n<td><code>wsl --export &lt;distro&gt; backup.vhdx --format vhd</code></td>\n</tr>\n<tr>\n<td>Unregister</td>\n<td><code>wsl --unregister &lt;distro&gt;</code></td>\n</tr>\n<tr>\n<td>Import (TAR)</td>\n<td><code>wsl --import &lt;name&gt; \"D:\\path\" backup.tar</code></td>\n</tr>\n<tr>\n<td>Import (VHD)</td>\n<td><code>wsl --import &lt;name&gt; \"D:\\path\" backup.vhdx --vhd</code></td>\n</tr>\n<tr>\n<td>Import in-place</td>\n<td><code>wsl --import-in-place &lt;name&gt; \"D:\\path\\ext4.vhdx\"</code></td>\n</tr>\n<tr>\n<td>Install on D:</td>\n<td><code>wsl --install Ubuntu --location \"D:\\WSL\\Ubuntu\"</code></td>\n</tr>\n<tr>\n<td>Fix default user</td>\n<td>Edit <code>/etc/wsl.conf</code> → <code>[user]</code> → <code>default=username</code>\n</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>Moving a distro is one of those tasks you only do once or twice, but it makes a real difference when your C: drive is filling up.</p>\n\n\n\n\n<p><em>Originally published at <a href=\"https://wsl-ui.octasoft.co.uk/blog/moving-wsl-distributions-to-another-drive\" rel=\"noopener noreferrer\">https://wsl-ui.octasoft.co.uk/blog/moving-wsl-distributions-to-another-drive</a></em></p>",
        "source": "dev.to",
        "published": "Wed, 18 Feb 2026 23:13:30 +0000",
        "fetched_at": "2026-02-18T23:25:42.462376Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 16,
        "timeliness_score": 2,
        "final_score": 6.2,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}