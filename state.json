{
  "meta": {
    "last_updated": "2026-01-19T23:18:41.235561Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260108231409.htm",
        "posted_at": "2026-01-12",
        "score": 7.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-el-nio-la-nia-synchronize.html",
        "posted_at": "2026-01-12",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112214304.htm",
        "posted_at": "2026-01-13",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-global-standard-graphene-atom-thickness.html",
        "posted_at": "2026-01-13",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-flagship-space-telescope-lunar-exploration.html",
        "posted_at": "2026-01-14",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260108190339.htm",
        "posted_at": "2026-01-14",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260114084134.htm",
        "posted_at": "2026-01-15",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-microscopy-technique-cell-natural-conditions.html",
        "posted_at": "2026-01-15",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-scientists-enigmatic-cell-devices-rna.html",
        "posted_at": "2026-01-16",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260115220608.htm",
        "posted_at": "2026-01-16",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-tightening-focus-subcellular-snapshots-combined.html",
        "posted_at": "2026-01-17",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260117053528.htm",
        "posted_at": "2026-01-17",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-albumin-abundant-blood-protein-shield.html",
        "posted_at": "2026-01-18",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "posted_at": "2026-01-18",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118233604.htm",
        "posted_at": "2026-01-19",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-vibrational-spectroscopy-technique-enables-nanoscale.html",
        "posted_at": "2026-01-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://arxiv.org/abs/2505.11274",
        "posted_at": "2026-01-12",
        "score": 14.6,
        "tags": [
          "transformation",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.reddit.com/r/MachineLearning/comments/1q893c1/d_deepseek_published_a_new_training_method_for/",
        "posted_at": "2026-01-12",
        "score": 8.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1129982/hyperscale-ai-data-centers-energy-usage-2026-breakthrough-technology/",
        "posted_at": "2026-01-12",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/09/ces-2026-everything-revealed-from-nvidias-debuts-to-amds-new-chips-to-razers-ai-oddities/",
        "posted_at": "2026-01-12",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-01-13",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.07035",
        "posted_at": "2026-01-13",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1130003/mechanistic-interpretability-ai-research-models-2026-breakthrough-technologies/",
        "posted_at": "2026-01-13",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/13/a-consumer-watchdog-issued-a-warning-about-googles-ai-agent-shopping-protocol-google-says-shes-wrong/",
        "posted_at": "2026-01-13",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-01-14",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.08224",
        "posted_at": "2026-01-14",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1130018/ai-companions-chatbots-relationships-2026-breakthrough-technology/",
        "posted_at": "2026-01-14",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/here-are-three-climate-wins-airlines-could-unlock-tomorrow-no-new-technology-required/?utm_source=rss&utm_medium=rss&utm_campaign=the-climate-impact-of-aviation-varies-widely-here-are-three-simple-strategies-to-keep-it-in-check",
        "posted_at": "2026-01-14",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2508.18025",
        "posted_at": "2026-01-15",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "posted_at": "2026-01-15",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1130027/generative-coding-ai-software-2026-breakthrough-technology/",
        "posted_at": "2026-01-15",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/15/the-ai-lab-revolving-door-spins-ever-faster/",
        "posted_at": "2026-01-15",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-01-16",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.09745",
        "posted_at": "2026-01-16",
        "score": 17.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1131193/ces-showed-me-why-chinese-tech-companies-feel-so-optimistic/",
        "posted_at": "2026-01-16",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/a-trees-bark-can-take-a-staggeringly-large-bite-out-of-climate-change/?utm_source=rss&utm_medium=rss&utm_campaign=a-trees-bark-can-take-a-staggeringly-large-bite-out-of-climate-change",
        "posted_at": "2026-01-16",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-01-17",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.09879",
        "posted_at": "2026-01-17",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
        "posted_at": "2026-01-17",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/17/musk-wants-up-to-134b-in-openai-lawsuit-despite-700b-fortune/",
        "posted_at": "2026-01-17",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-01-18",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/",
        "posted_at": "2026-01-18",
        "score": 5.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/18/moxie-marlinspike-has-a-privacy-conscious-alternative-to-chatgpt/",
        "posted_at": "2026-01-18",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://radiancefields.com/a-ap-rocky-releases-helicopter-music-video-featuring-gaussian-splatting",
        "posted_at": "2026-01-18",
        "score": 2.4,
        "tags": []
      },
      {
        "url": "https://arxiv.org/abs/2507.03585",
        "posted_at": "2026-01-19",
        "score": 20.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/19/rogue-agents-and-shadow-ai-why-vcs-are-betting-big-on-ai-security/",
        "posted_at": "2026-01-19",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1129782/ai-large-language-models-biology-alien-autopsy/",
        "posted_at": "2026-01-19",
        "score": 4.4,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/weve-overlooked-a-key-benefit-of-seaweed-farms-on-ocean-chemistry-for-the-first-time-scientists-quantify/?utm_source=rss&utm_medium=rss&utm_campaign=weve-overlooked-a-key-benefit-of-seaweed-farms-on-ocean-chemistry-for-the-first-time-scientists-quantify",
        "posted_at": "2026-01-19",
        "score": 3.2,
        "tags": []
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "posted_at": "2026-01-12",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2025/12/the-mystery-of-how-a-samurai-ended-up-in-17th-century-venice.html",
        "posted_at": "2026-01-12",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/a-cosmic-clock-in-tiny-crystals-has-revealed-the-rise-and-fall-of-australias-ancient-landscapes-271751",
        "posted_at": "2026-01-13",
        "score": 6.6,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.lanl.gov/media/publications/1663/ice-house-heats-up",
        "posted_at": "2026-01-13",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://theconversation.com/from-a-new-flagship-space-telescope-to-lunar-exploration-global-cooperation-and-competition-will-make-2026-an-exciting-year-for-space-272010",
        "posted_at": "2026-01-14",
        "score": 6.6,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "posted_at": "2026-01-14",
        "score": 3.3,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "posted_at": "2026-01-15",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/opinion-instead-of-defining-black-children-by-their-test-scores-we-should-help-them-overcome-academic-barriers-and-pursue-their-dreams/",
        "posted_at": "2026-01-15",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://hechingerreport.org/proof-points-math-vocabulary/",
        "posted_at": "2026-01-16",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "posted_at": "2026-01-16",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "posted_at": "2026-01-17",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/01/can-genius-be-taught.html",
        "posted_at": "2026-01-17",
        "score": 3.3,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-01-18",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://hechingerreport.org/schools-are-closing-across-rural-america-heres-how-a-battle-over-small-districts-is-playing-out-in-one-state/",
        "posted_at": "2026-01-18",
        "score": 2.7,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "posted_at": "2026-01-19",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/high-school-college-computer-science-lessons/",
        "posted_at": "2026-01-19",
        "score": 2.7,
        "tags": [
          "boundary_crossing"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "posted_at": "2026-01-12",
        "score": 7.5,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-fungal-mechanism-reveals-powdery-mildew.html",
        "posted_at": "2026-01-12",
        "score": 3.6,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260101160854.htm",
        "posted_at": "2026-01-13",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-sourcing-future-food-cell-bank.html",
        "posted_at": "2026-01-13",
        "score": 4.2,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251216081930.htm",
        "posted_at": "2026-01-14",
        "score": 7.5,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://therevelator.org/sea-turtle-migration/",
        "posted_at": "2026-01-14",
        "score": 4.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-cholera-virulence-sought-explanation.html",
        "posted_at": "2026-01-15",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "posted_at": "2026-01-15",
        "score": 6.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-scientists-enigmatic-cell-devices-rna.html",
        "posted_at": "2026-01-16",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "posted_at": "2026-01-16",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251226045324.htm",
        "posted_at": "2026-01-17",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-tightening-focus-subcellular-snapshots-combined.html",
        "posted_at": "2026-01-17",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260106001914.htm",
        "posted_at": "2026-01-18",
        "score": 8.2,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-albumin-abundant-blood-protein-shield.html",
        "posted_at": "2026-01-18",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-revealing-cell-nanocourier.html",
        "posted_at": "2026-01-19",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112001034.htm",
        "posted_at": "2026-01-19",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "posted_at": "2026-01-12",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/could-leonardo-da-vincis-dna-be-hiding-inside-one-of-his-renaissance-sketches-180987982/",
        "posted_at": "2026-01-12",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-01-13",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://aeon.co/essays/how-a-playful-literary-hoax-illuminates-classical-queerness?utm_source=rss-feed",
        "posted_at": "2026-01-13",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-01-14",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/the-search-for-where-consciousness-lives-in-the-brain-1261596/",
        "posted_at": "2026-01-14",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/sean-sherman-turtle-island-cookbook",
        "posted_at": "2026-01-15",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/2014/09/design-package-2014/",
        "posted_at": "2026-01-15",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "posted_at": "2026-01-16",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/why-theres-no-single-best-way-to-store-information-20260116/",
        "posted_at": "2026-01-16",
        "score": 4.1,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "posted_at": "2026-01-17",
        "score": 12.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/why-the-do-nothing-challenge-doesnt-do-much-for-you-1262005/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "posted_at": "2026-01-18",
        "score": 12.1,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/ai-weiwei-gets-artsy-fartsy-about-surveillance/",
        "posted_at": "2026-01-18",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "posted_at": "2026-01-19",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/all-nine-of-jan-van-eycks-surviving-portraits-are-coming-together-for-the-very-first-time-in-history-180988003/",
        "posted_at": "2026-01-19",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-01-12",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/fbi-agents-sworn-testimony-contradicts-claims-ices-jonathan-ross-made-under-oath/",
        "posted_at": "2026-01-12",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-01-13",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/china/diplomacy/article/3339797/us-government-approves-nvidia-h200-chip-exports-china?utm_source=rss_feed",
        "posted_at": "2026-01-13",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-01-14",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.wired.com/story/neuroscience-procrastination-brain-mechanism-task-avoidance/",
        "posted_at": "2026-01-14",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.scmp.com/news/china/diplomacy/article/3339989/south-korean-leader-lee-takes-pragmatic-approach-reset-ties-china-japan?utm_source=rss_feed",
        "posted_at": "2026-01-15",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-01-15",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://pandaily.com/china-s-fast-radio-telescope-to-be-upgraded-into-a-cosmic-super-probe-with-dozens-of-new-antennas",
        "posted_at": "2026-01-16",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-01-16",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/16/x-is-down-for-the-second-time-this-week/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.wired.com/story/livestream-welcome-to-the-chinese-century/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-01-18",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.scmp.com/news/world/europe/article/3340324/europes-far-right-eyes-run-portugals-presidential-election?utm_source=rss_feed",
        "posted_at": "2026-01-18",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/19/looking-ahead-to-2026-whats-next-for-startup-battlefield-200/",
        "posted_at": "2026-01-19",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/china/diplomacy/article/3340468/how-narrowing-china-us-gap-could-reshape-global-power-play-2035?utm_source=rss_feed",
        "posted_at": "2026-01-19",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://dev.to/kolkov/smart-coding-vs-vibe-coding-engineering-discipline-in-the-age-of-ai-5b20",
        "posted_at": "2026-01-12",
        "score": 15.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/siy/the-underlying-process-of-request-processing-1od4",
        "posted_at": "2026-01-12",
        "score": 10.1,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/cseby92/how-to-run-jest-integration-tests-in-parallel-using-isolated-sql-schemas-1bm7",
        "posted_at": "2026-01-13",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/donhadley22/a-real-world-serverless-appointment-booking-backend-on-aws-dc4",
        "posted_at": "2026-01-13",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/adam-maj/tiny-gpu",
        "posted_at": "2026-01-14",
        "score": 10.9,
        "tags": [
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/microsoft/PowerToys",
        "posted_at": "2026-01-14",
        "score": 8.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/maame-codes/top-offshore-software-development-companies-reviews-rates-33-got-the-opportunity-to-interview-9c1",
        "posted_at": "2026-01-15",
        "score": 14.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/mudler/LocalAI",
        "posted_at": "2026-01-15",
        "score": 9.7,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/gd-tech-guru/the-great-decoupling-the-data-sovereignty-correction-4m7o",
        "posted_at": "2026-01-16",
        "score": 14.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/techresolve/solved-ai-costs-skyrocketing-how-we-cut-our-spend-and-tamed-idle-gpus-4631",
        "posted_at": "2026-01-16",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jakiru5/how-i-built-my-8-bit-portfolio-with-claude-opus-45-on-antigravity-3a1j",
        "posted_at": "2026-01-17",
        "score": 8.0,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/google/langextract",
        "posted_at": "2026-01-17",
        "score": 7.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/agusrdz/from-glasses-to-code-the-personal-journey-behind-harmonia-vision-1ofc",
        "posted_at": "2026-01-18",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/fabianfrankwerner/python-vs-ruby-i-built-the-same-github-analyzer-with-both-51gj",
        "posted_at": "2026-01-18",
        "score": 7.4,
        "tags": [
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/yt-dlp/yt-dlp",
        "posted_at": "2026-01-19",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/deepak_mishra_35863517037/integrating-playwright-with-flask-resolving-the-async-conflict-2d9o",
        "posted_at": "2026-01-19",
        "score": 11.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260114084134.htm",
        "title": "Scientists question the safety of BPA-free packaging",
        "summary": "“BPA-free” food packaging may be hiding new risks. A McGill University study found that several BPA substitutes used in grocery price labels can seep into food and interfere with vital processes in human ovarian cells. Some triggered unusual fat buildup and disrupted genes linked to cell repair and growth. The results raise concerns that BPA replacements may be just as troubling as the chemical they replaced.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 15 Jan 2026 02:53:46 EST",
        "fetched_at": "2026-01-19T23:17:38.759145Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 4,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260117053528.htm",
        "title": "How scientists are turning thyme into precision medicine",
        "summary": "Thyme extract is packed with health-promoting compounds, but it is difficult to control and easy to waste. Researchers created a new technique that traps tiny amounts of the extract inside microscopic capsules, preventing evaporation and irritation. The method delivers consistent nanodoses and could eventually be used in medicines or food products. It may also work for many other natural extracts.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 17 Jan 2026 09:48:30 EST",
        "fetched_at": "2026-01-19T23:17:38.759016Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260115220608.htm",
        "title": "Stretchable OLED displays take a big leap forward",
        "summary": "A new OLED design can stretch dramatically while staying bright, solving a problem that has long limited flexible displays. The breakthrough comes from pairing a highly efficient light-emitting material with tough, transparent MXene-based electrodes. Tests showed the display kept most of its brightness even after repeated stretching. The technology could power future wearable screens and on-skin health sensors.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 15 Jan 2026 22:15:29 EST",
        "fetched_at": "2026-01-19T23:17:38.759092Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://phys.org/news/2026-01-ultrafast-spectroscopy-reveals-energy-germanium.html",
        "title": "Ultrafast spectroscopy reveals step-by-step energy flow in germanium semiconductors",
        "summary": "Whether in a smartphone or laptop, semiconductors form the basis of modern electronics and accompany us constantly in everyday life. The processes taking place inside these materials are the subject of ongoing research. When the electrons in a semiconductor material are activated using light or an electrical voltage, the excited electrons also set the atomic lattice in motion. This results in collective vibrations of the atoms, known as phonons or lattice vibrations, which interact with each other and with the electrons themselves.",
        "source": "phys.org",
        "published": "Mon, 19 Jan 2026 15:11:30 EST",
        "fetched_at": "2026-01-19T23:17:40.125260Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://phys.org/news/2026-01-atomistic-simulation-software-cp2k-enables.html",
        "title": "Atomistic simulation software CP2K enables AI models",
        "summary": "The CP2K open-source package is among the top three most widely used research software suites worldwide for simulating the behavior of atoms and molecules. Among other applications, CP2K plays an important role in generating data used to train artificial intelligence (AI)-based models that determine molecular energies and forces.",
        "source": "phys.org",
        "published": "Mon, 19 Jan 2026 14:47:22 EST",
        "fetched_at": "2026-01-19T23:17:40.125317Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260113220920.htm",
        "title": "Doctors discover the source of mysterious intoxication",
        "summary": "Some people get drunk without drinking because their gut bacteria produce alcohol from food. Researchers have now identified the microbes and biological pathways behind this rare condition, auto-brewery syndrome. Tests showed patients’ gut samples produced far more alcohol than those of healthy people. In one case, a fecal transplant led to long-lasting symptom relief.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 13 Jan 2026 23:41:15 EST",
        "fetched_at": "2026-01-19T23:17:38.759203Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          }
        ],
        "structural_score": 7,
        "timeliness_score": 4,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.1,
        "temp_score_trend": 4.9
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260116035308.htm",
        "title": "The breakthrough that makes robot faces feel less creepy",
        "summary": "Humans pay enormous attention to lips during conversation, and robots have struggled badly to keep up. A new robot developed at Columbia Engineering learned realistic lip movements by watching its own reflection and studying human videos online. This allowed it to speak and sing with synchronized facial motion, without being explicitly programmed. Researchers believe this breakthrough could help robots finally cross the uncanny valley.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 16 Jan 2026 10:28:30 EST",
        "fetched_at": "2026-01-19T23:17:38.759082Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 4,
        "final_score": 5.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 5.3999999999999995,
        "temp_score_trend": 4.6
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118233555.htm",
        "title": "How the frog meat trade helped spread a deadly fungus worldwide",
        "summary": "A deadly fungus that has wiped out hundreds of amphibian species worldwide may have started its global journey in Brazil. Genetic evidence and trade data suggest the fungus hitchhiked across the world via international frog meat markets. The findings raise urgent concerns about how wildlife trade can spread hidden biological threats.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 19 Jan 2026 06:40:08 EST",
        "fetched_at": "2026-01-19T23:17:38.758967Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 4,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.7,
        "temp_score_trend": 4.3
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118064641.htm",
        "title": "Silver just solved a major solid-state battery problem",
        "summary": "Solid-state batteries could store more energy and charge faster than today’s batteries, but they tend to crack and fail over time. Stanford researchers found that a nanoscale silver treatment can greatly strengthen the battery’s ceramic core. The silver helps seal tiny flaws and prevents lithium from causing further damage. This simple approach could help unlock next-generation batteries.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 18 Jan 2026 22:23:20 EST",
        "fetched_at": "2026-01-19T23:17:38.758997Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 4,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.7,
        "temp_score_trend": 4.3
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118064633.htm",
        "title": "The Ring Nebula is hiding a giant structure made of iron",
        "summary": "A huge bar of iron has been discovered lurking inside the iconic Ring Nebula. The structure is enormous, spanning hundreds of times the size of Pluto’s orbit and containing a Mars-sized amount of iron. It was detected using a new instrument that allowed astronomers to map the nebula in far greater detail than ever before. The origin of the iron bar is still a mystery, with one theory suggesting it could be the remains of a vaporized planet.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 18 Jan 2026 10:24:20 EST",
        "fetched_at": "2026-01-19T23:17:38.759006Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 4,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.7,
        "temp_score_trend": 4.3
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
        "summary": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> — Anthropic&#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors — tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> — an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety — that is, the task of securing Claude&#x27;s real-world actions — is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development — a major feature built in ten days, possibly by the company&#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 12 Jan 2026 11:30:00 GMT",
        "fetched_at": "2026-01-19T23:17:25.199137Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 40,
        "timeliness_score": 3,
        "final_score": 21.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "source": "venturebeat.com",
        "published": "Fri, 16 Jan 2026 14:01:00 GMT",
        "fetched_at": "2026-01-19T23:17:25.199119Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 39,
        "timeliness_score": 3,
        "final_score": 21.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "source": "venturebeat.com",
        "published": "Wed, 07 Jan 2026 20:00:00 GMT",
        "fetched_at": "2026-01-19T23:17:25.199142Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 3,
        "final_score": 17.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.04521",
        "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation",
        "summary": "arXiv:2601.04521v2 Announce Type: replace-cross \nAbstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.",
        "source": "export.arxiv.org",
        "published": "Mon, 19 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-19T23:17:21.706832Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 22,
        "timeliness_score": 5,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 18.6,
        "temp_score_trend": 8.4
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-01-19T23:17:25.199147Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.04521",
        "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation",
        "summary": "arXiv:2601.04521v2 Announce Type: replace \nAbstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.",
        "source": "export.arxiv.org",
        "published": "Mon, 19 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-19T23:17:22.860957Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 20,
        "timeliness_score": 5,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "source": "venturebeat.com",
        "published": "Tue, 13 Jan 2026 13:00:00 GMT",
        "fetched_at": "2026-01-19T23:17:25.199131Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 3,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.11258",
        "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation",
        "summary": "arXiv:2601.11258v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.",
        "source": "export.arxiv.org",
        "published": "Mon, 19 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-19T23:17:21.706183Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2601.09105",
        "title": "AviationLMM: A Large Multimodal Foundation Model for Civil Aviation",
        "summary": "arXiv:2601.09105v2 Announce Type: replace \nAbstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.",
        "source": "export.arxiv.org",
        "published": "Mon, 19 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-19T23:17:21.706562Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 15.4,
        "temp_score_trend": 7.6
      },
      {
        "url": "https://arxiv.org/abs/2601.11258",
        "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation",
        "summary": "arXiv:2601.11258v1 Announce Type: new \nAbstract: Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.",
        "source": "export.arxiv.org",
        "published": "Mon, 19 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-19T23:17:22.860367Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 18,
        "timeliness_score": 5,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "title": "How one California school came together to pack 20,000 meals for the holidays",
        "summary": "At an Elk Grove high school in Sacramento County, students worked a night in the cafeteria to combat global food insecurity.",
        "source": "edsource.org",
        "published": "Mon, 08 Dec 2025 08:03:00 +0000",
        "fetched_at": "2026-01-19T23:18:03.361010Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "title": "Fresno Unified error skews state teacher data, analysis shows",
        "summary": "A mistake made by a staff member deflated claims that the state added 3,000 new teachers to its ranks between 2020 and 2024.",
        "source": "edsource.org",
        "published": "Tue, 19 Aug 2025 19:26:35 +0000",
        "fetched_at": "2026-01-19T23:18:03.362149Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 2
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://hechingerreport.org/proof-points-math-vocabulary/",
        "title": "Talk nerdy to me: Teachers who use math vocabulary help students do better in math",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"684\" src=\"https://i0.wp.com/hechingerreport.org/wp-content/uploads/2026/01/proof-math-vocab-010226-scaled.jpg?fit=1024%2C684&amp;ssl=1\" width=\"1024\" /></figure>\n<p>Students, parents and school principals all instinctively know that some teachers are better than others. Education researchers have spent decades trying — with mixed success — to calculate exactly how much better. What remains far more elusive is why. A new study suggests that one surprisingly simple difference between stronger and weaker math teachers may [&#8230;]</p>\n<p>The post <a href=\"https://hechingerreport.org/proof-points-math-vocabulary/\">Talk nerdy to me: Teachers who use math vocabulary help students do better in math</a> appeared first on <a href=\"https://hechingerreport.org\">The Hechinger Report</a>.</p>",
        "source": "hechingerreport.org",
        "published": "Mon, 05 Jan 2026 11:00:00 +0000",
        "fetched_at": "2026-01-19T23:18:04.677930Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 3,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "title": "Universal prekindergarten has arrived; now we must sustain it",
        "summary": "County offices of education across the state are calling on the governor and the Legislature to support universal prekindergarten with sustained funding.",
        "source": "edsource.org",
        "published": "Tue, 06 Jan 2026 03:38:57 +0000",
        "fetched_at": "2026-01-19T23:18:03.360786Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "title": "The path to universal preschool in California: Avoiding past mistakes",
        "summary": "California is expanding its transitional kindergarten (TK) to a universal prekindergarten (UPK) system, and must learn from the mistakes of the 1971 federal effort to create a universal early care and education system, which was vetoed by President Nixon.",
        "source": "edsource.org",
        "published": "Tue, 23 Dec 2025 07:03:30 +0000",
        "fetched_at": "2026-01-19T23:18:03.360879Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "title": "As we expand universal preschool access, let’s ensure teachers mirror their students’ ethnicity",
        "summary": "Author&#8217;s original hed: As Universal Preschool Access Expands to Reach More Families of Color, So Do Inequitable Practices Such as Racial Bias, Exclusionary Discipline and Lack of Cultural Representation, Leading to a Crisis for Black Boys As California progresses toward universal preschool access, the need increases for training, hiring and retaining early childhood male educators who are racially and ethnically representative of the children... <span class=\"read-more\"><a href=\"https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393\">read more</a></span>",
        "source": "edsource.org",
        "published": "Tue, 09 Jul 2024 15:53:36 +0000",
        "fetched_at": "2026-01-19T23:18:03.365245Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "title": "Survey: Californians are worried about student health, lukewarm toward a state school bond",
        "summary": "The annual Public Policy Institute of California survey on education issues found wide support for universal TK and teaching about slavery but divisions on transgender issues.",
        "source": "edsource.org",
        "published": "Thu, 11 Apr 2024 05:11:37 +0000",
        "fetched_at": "2026-01-19T23:18:03.365856Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "title": "Federal appeals court pauses ruling on student gender identity disclosure in California",
        "summary": "An appeals court panel wrote that it is “skeptical” of the lower court’s decision, which would challenge policies adopted by 598 of the state’s nearly 1,000 local school districts.",
        "source": "edsource.org",
        "published": "Thu, 08 Jan 2026 00:04:46 +0000",
        "fetched_at": "2026-01-19T23:18:03.360760Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/clovis-unified-preschool-program-gets-creative-with-state-arts-funding/743835",
        "title": "Clovis Unified preschool program gets creative with state arts funding",
        "summary": "Clovis Unified is using $150,000 of state arts funding to provide arts, music and theater education to preschool students through an interactive farm exhibit.",
        "source": "edsource.org",
        "published": "Mon, 03 Nov 2025 08:05:00 +0000",
        "fetched_at": "2026-01-19T23:18:03.361463Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      },
      {
        "url": "https://edsource.org/2025/california-tk-english-screening-tools/743756",
        "title": "California rethinks how to identify 4-year-olds who need extra help learning English",
        "summary": "The challenge is that children at this age are still developing language skills. In the past, students would sometimes cry and put their heads down on the desk during tests.",
        "source": "edsource.org",
        "published": "Tue, 28 Oct 2025 07:04:00 +0000",
        "fetched_at": "2026-01-19T23:18:03.361523Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 3.6999999999999997,
        "temp_score_trend": 3.3
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251226045324.htm",
        "title": "Scientists replayed evolution and found a surprise",
        "summary": "Environmental change doesn’t affect evolution in a single, predictable way. In large-scale computer simulations, scientists discovered that some fluctuating conditions help populations evolve higher fitness, while others slow or even derail progress. Two populations facing different kinds of change can end up on completely different evolutionary paths. The findings challenge the idea that one population’s response can represent a whole species.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 30 Dec 2025 15:57:09 EST",
        "fetched_at": "2026-01-19T23:18:16.844650Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "title": "Researchers turn avocado toast into biodegradable food packaging",
        "summary": "A strong yet degradable bioplastic made from avocado peels and stale bread tackles two global challenges: food waste and plastic pollution",
        "source": "www.anthropocenemagazine.org",
        "published": "Thu, 15 Jan 2026 13:00:29 +0000",
        "fetched_at": "2026-01-19T23:18:19.709300Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260106001914.htm",
        "title": "The poison frog that fooled scientists for decades",
        "summary": "Researchers discovered that a poison frog species described decades ago was based on a mix-up involving the wrong museum specimen. The frog tied to the official species name turned out to be brown, not the colorful animal shown in the original photo. After tracing old records and images, scientists corrected the error and reclassified the frog as part of an already-known species. The case underscores how vital museum collections are—and how even small mistakes can ripple through science for years.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 06 Jan 2026 20:59:08 EST",
        "fetched_at": "2026-01-19T23:18:16.844587Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "title": "A hidden world inside DNA is finally revealed",
        "summary": "DNA doesn’t just sit still inside our cells — it folds, loops, and rearranges in ways that shape how genes behave. Researchers have now mapped this hidden architecture in unprecedented detail, showing how genome structure changes from cell to cell and over time. These insights reveal why many disease-linked mutations outside genes can still cause harm. The findings could speed up the discovery of genetic risks and inspire new ways to target diseases.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 08 Jan 2026 21:16:11 EST",
        "fetched_at": "2026-01-19T23:18:16.844564Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260101160854.htm",
        "title": "Coral reefs have a hidden daily rhythm scientists just discovered",
        "summary": "Coral reefs appear to run a daily timetable for microscopic life in nearby waters. Scientists found that microbial populations above reefs rise and fall over the course of a single day, shaped by feeding, predation, and coral-driven processes. Some microbes peak during daylight, while others surge at night. These rhythms offer new clues about how reefs influence their surrounding environment.",
        "source": "www.sciencedaily.com",
        "published": "Fri, 09 Jan 2026 01:28:03 EST",
        "fetched_at": "2026-01-19T23:18:16.844614Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251216081930.htm",
        "title": "Living cells may generate electricity from motion",
        "summary": "Cells may generate their own electrical signals through microscopic membrane motions. Researchers show that active molecular processes can create voltage spikes similar to those used by neurons. These signals could help drive ion transport and explain key biological functions. The work may also guide the design of intelligent, bio-inspired materials.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 16 Dec 2025 08:54:08 EST",
        "fetched_at": "2026-01-19T23:18:16.844740Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003589",
        "title": "Characterization of RNA interference in the cnidarian <i>Nematostella vectensis</i> reveals partial target silencing but lack of small RNA amplification",
        "summary": "<p>by Yael Admoni, Magda Lewandowska, Reuven Aharoni, Junchao Shi, Xudong Zhang, Qi Chen, Yehu Moran</p>\n\nRNA interference (RNAi) is a sequence-specific mRNA degradation mechanism, in which short interfering RNAs (siRNAs) guide Argonaute proteins to complementary targets, resulting in their degradation. In many organisms, RNAi also serves antiviral roles by processing viral double-stranded RNA (dsRNA) into siRNAs that prevent viral replication. Antiviral RNAi is considered an ancestral mechanism which invertebrates rely on for defense against viruses, whereas vertebrates have evolved instead the interferon pathway. Recent studies suggest that sea anemones, members of the basally-branching phylum Cnidaria, might possess an innate immune response with more vertebrate characteristics than previously thought; however, it is unknown whether cnidarians also employ RNAi as an antiviral response similarly to nematodes and insects. Here, we characterize the response of the model cnidarian <i>Nematostella vectensis</i> to simulated viral infection. We injected dsRNA with eGFP sequence into eGFP-expressing transgenic zygotes and show that siRNAs mapping to the eGFP sequence are generated and induce a moderate but significant knockdown of eGFP expression. Interestingly, we detected no evidence for secondary siRNA production, despite their crucial role in the amplification of antiviral response in other organisms. Notably, siRNA pathway components are specifically upregulated upon dsRNA injection, while microRNA pathway components are downregulated. Furthermore, injection of mRNA coding for self-replicating viral gene fused to eGFP, also induced upregulation of siRNA-related genes and a mild decrease in transgene expression. Overall, we propose that <i>N. vectensis</i> possesses an siRNA-mediated response that lacks secondary amplification and likely functions as a short-term antiviral mechanism.",
        "source": "journals.plos.org",
        "published": "2026-01-05T14:00:00Z",
        "fetched_at": "2026-01-19T23:18:18.167213Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 1,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003572",
        "title": "The Rho GTPase regulator ARHGEF3 orchestrates hair placode budding by coordinating cell fate and P-cadherin patterning in mice",
        "summary": "<p>by Krithika Kalyanakrishnan, Amy Beaudin, Alexandra Jetté, Sarah Ghezelbash, Diana Ioana Hotea, Jie Chen, Philippe Lefrançois, Mélanie Laurin</p>\n\nDuring embryogenesis, cells self-organize into precise patterns that enable tissues and organs to acquire specialized functions. Despite its importance, the molecular choreography driving these collective cellular behaviors remains poorly understood, posing a major challenge in developmental biology and limiting progress in regenerative medicine. Here, we use the developing mouse hair follicle as a model mini-organ to investigate the early events of epithelial bud formation. We identify the Rho GTPase regulator ARHGEF3 as a critical upstream factor that restricts cell fate acquisition and establishes a radial gradient of P-cadherin across the placode during early hair follicle development. In <i>Arhgef3</i> knockout embryos, placodes are enlarged and exhibit elevated P-cadherin levels at cell-cell junctions, disrupting gradient formation without affecting E-cadherin distribution. This defect correlates with aberrant epithelial organization and increased incidence of straight hair follicle downgrowth. Our findings position ARHGEF3 as a novel regulator of cadherin patterning and placode polarization, and suggest broader roles in the morphogenesis of other epithelial appendages governed by similar developmental programs.",
        "source": "journals.plos.org",
        "published": "2026-01-05T14:00:00Z",
        "fetched_at": "2026-01-19T23:18:18.167241Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 1,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "title": "A new test reveals which antibiotics truly kill bacteria",
        "summary": "Some antibiotics stop bacteria from growing without actually killing them, allowing infections to return later. Scientists at the University of Basel created a new test that tracks individual bacteria to see which drugs truly eliminate them. When tested on tuberculosis and other serious lung infections, the method revealed big differences in how bacteria tolerate treatment. The findings could lead to more precise therapies and better predictions of treatment success.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 12 Jan 2026 21:33:16 EST",
        "fetched_at": "2026-01-19T23:18:16.844530Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260103155032.htm",
        "title": "The invisible microbes that help keep us healthy",
        "summary": "Not all microbes are villains—many are vital to keeping us healthy. Researchers have created a world-first database that tracks beneficial bacteria and natural compounds linked to immune strength, stress reduction, and resilience. The findings challenge the long-standing obsession with germs as threats and instead highlight the hidden health benefits of biodiversity. This shift could influence everything from urban design to environmental restoration.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 04 Jan 2026 07:14:46 EST",
        "fetched_at": "2026-01-19T23:18:16.844605Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "title": "The Rebirth of Pennsylvania’s Infamous Burning Town",
        "summary": "<p>“There’s not much there anymore, it’s pretty much just a crossroads.”</p>\n<p>I read the posts online telling me not to bother, but I wanted to go anyway. Certainly I could feel something as we got close: the sense of desperation, of ruin and abandon. So I drove with a small group of friends deep into eastern Pennsylvania—coal country—through towns with names like Frackville, Pottsville, Ashland. Many downtowns had at least one house that had burned to ruin and been left abandoned. It was early June, but clouds covered the sky and we drove through a slight but persistent rain.</p>\n<p>We were on our way to Centralia, Pennsylvania. The Burning Town.</p>\n<p>The coal that made this valley famous accreted in layers over tens of thousands of years, organic swamp matter turning first to peat, and then compressed over millennia into billions of tons of anthracite—the densest and most pure form of coal—the stuff that made this region of Pennsylvania famous. Mines first opened here in 1856 and Centralia was incorporated as a town a decade later. Through the years bitter labor disputes broke out over exploitative treatment of the (largely Irish immigrant) miners, leading to regular outbreaks of violence. Add to that the boom and bust cycle of the coal industry—and the environmental desolation and impoverishment of the region—and you end up with a town that is deeply scarred, both literally and metaphorically.</p>\n<p>But the story that made Centralia famous began in May 1962, when officials set fire to the trash in a local landfill in an open strip-mine pit. This wasn’t the first year they’d done this, and there were firefighters stationed to ensure the blaze didn’t get out of control. After two days, the trash fire seemed to have burned itself out. But this time, for whatever reason (the actual cause was never fully determined), something went wrong. The landfill burn had lit the coal mines beneath the town.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106279/image.jpg\" width=\"auto\" /></figure>\n<p>Over the years, numerous attempts were made to put out the fire. Nothing worked. In all, federal, state, and local governments spent over $3.3 million on the blaze, which raged on, uncontrollably. Over time, residents reported that their basements were strangely hot, and in 1979, the mayor John Coddington lowered a thermometer into an underground fuel tank at the gas station he owned, only to discover that the gasoline was 172 degrees Fahrenheit. And then on Valentine’s Day, 1981, a twelve-year old boy fell into a four-foot sinkhole that opened up in his grandmother’s backyard, barely rescued by his fourteen year-old cousin. A plume of lethal carbon monoxide bellowed out from the hole.</p>\n<p>Realizing that topsoil was the only thing separating the town from a massive, raging inferno, the federal government finally decided to clear the town. The United States Congress allocated money for a buyout, which nearly all of the town’s 1,000 or so residents took. By 1990, 63 people remained in the town. Two years later, governor Bob Casey invoked eminent domain and condemned all the remaining buildings. By 2021, only five homes were still left standing.</p>\n<p>I had come here expecting that we would find ruin and neglect, toxicity and destitution. I expected Centralia to be an exemplar of the <em>eerie: </em>A place where once there had been a town, place of thriving life, and instead now was only absence, an emptiness, a void.</p>\n<p>What we found instead, strangely, was beauty. Centralia, despite everything I’d been led to expect, was thriving.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106274/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>The Burning Town has come to stand in as a kind of exemplar of a post-industrial wasteland, a place where human folly reached its apex, scorching the land. All but abandoned, it became known primarily for the vents that poured smoke from the fire below, and for Graffiti Highway—a closed stretch of Route 61 covered in tags, doodles of genitalia, and declarations of love.</p>\n<p>When adapting the video game franchise <em>Silent Hill </em>for film, screenwriter Roger Avary used Centralia as a model for both the town’s backstory and its look. For years it drew curious onlookers and legend trippers, while the name “Centralia” itself became an almost byword for late capitalism: a term for that mixture of rapacious profit-seeking and thoughtless stewardship that created America’s own Chernobyl.</p>\n<p>Locals see the story a little differently, though their version borrows from similar themes. Phil, a tour guide at Pioneer Tunnel in neighboring Ashland, pointed out that while the grim toil of the mines claimed many human lives, their closure left the valley with little else to offer. He explained how the families that didn’t leave Centralia were harassed, as government forces tried to drive them off their land. Those that stayed had to go to court to defend their right to live on this abandoned land, all because they wanted to keep the mineral rights to their property. So now, people like Phil assume that the government is just waiting them out. Once they’re gone, putting out the fire will be easy enough. “They’ll take all that red hot coals, but also they’re going to get that rich anthracite coal,” he told us. “And I’m sure they’ll sell that. But are the people or the relatives going to get anything? It’s very doubtful. It’ll probably go to the federal government. Or the coal baron, maybe?”</p>\n<p>His voice, I noticed after a while, has a peculiar kind of nostalgia for the worst times in the world. Like so many others in these towns, he seems to long for a return, another chance for Pennsylvanians to throw their children back into the maw of the mine. Anything for a chance to get the coal jobs will come back. Anything in service of waking the Mountain once more.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106256/image.jpg\" width=\"auto\" /></figure>\n<p>When we finally got to Centralia, we were met not with destruction or despair, but with what seemed at first simply like nothing. The streets are still laid out, and there are still a handful of houses left, but the graffiti highway has been covered over. Any abandoned buildings have long been torn down.</p>\n<p>It’s why, if you ask around these days, folks will tell you there’s nothing to see in Centralia. “I drove through Centralia 2 weeks ago,” one local commented on a <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1cw0xqc/looking_to_visit_centralia_is_it_still_legal_to_go/\">Reddit thread</a>. “I didn’t realize till after I had already passed it. That should tell you everything you need to know.” In another thread a different local <a href=\"https://www.reddit.com/r/Pennsylvania/comments/1ikd2rs/i_have_some_questions_regarding_traveling_through/\">commented</a>, “What is the draw? It’s just empty ground now.”</p>\n<p>But emptiness can tell its own story. Standing on the empty streets of Centralia, I thought mainly of Cal Flynn’s <em>Islands of Abandonment: Nature Rebounding in the Post-Human Landscape. </em>Flynn travels the world to places that have been forsworn by humanity: not the pristine, untouched wilderness, but places abandoned, like Chernobyl and the exclusion zone that divides the island of Cyprus between its Greek and Turkish halves. Places where, Flynn writes, “nature has been allowed to work unfettered.” Such places are often thriving with plant and animal life. Abandonment, she writes, “<em>is </em>rewilding, in a very pure sense, as humans draw back and nature reclaims what once was hers.”</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106273/image.jpg\" width=\"auto\" /></figure>\n<p>What Flynn makes clear is that while we tend to think of human activity on the landscape as not only damaging but <em>irreversible</em>, this may not always be the case. We believe, in our hubris, that we have the power to wreck nature for good. And while it’s true that places like the Bikini Atoll and Chernobyl will be radioactive for unimaginable human lifetimes, that doesn’t mean that other species haven’t moved in and, left unmolested by human activity, found ways to flourish.</p>\n<p>Flynn’s book catalogs a variety of ways in which nature has reclaimed places that we’ve left behind, often with surprising speed. When Estonia, for example, became independent of the Soviet Union, some 245 million square miles of collectivist farmlands were simply abandoned. They weren’t plowed over, repurposed, or re-seeded. They simply were left alone. Flora immediately went to work: soon these fields were covered in wildflowers and weeds, and then thorn bushes and brambles, and then the skinny shoots of young spruce trees. Now, thirty-five years later, Estonia is now one of the most forested countries in Europe, having nearly doubled the size of its forests by doing … nothing. Half the country is now a forest, and over 90 percent of those forests have naturally regenerated.</p>\n<p>When I say that Centralia is <em>thriving, </em>this is what I mean. It is a landscape pulsing with life, overflowing with lush greenery. The old grid of streets is still visible, and there are still a handful of houses with carefully mowed lawns sitting in defiance. But everything else is the wild and vital province of nature. Turkeyfoot, broom-sedge, and switchgrass and silky dogwood. Young white oaks and linden trees push their way through this cacophony of life. Everywhere that’s not asphalt is a riot of green in every possible shade. And all of this is possible, at least in part, because the state and federal governments have forbidden any new human settlement, giving the wild and the lush and untrammeled room to grow.</p>\n<p>Not all of this is just nature. In 2021, the Eastern Pennsylvania Coalition for Abandoned Mine Reclamation planted 250 apple trees in the hope of attracting butterflies. EPCAMR has hosted annual trash clean-ups in the town, but a few years ago turned to planting and furthering the former town’s potential as an unofficial wildlife sanctuary. “We’re trying to get that area designated as a monarch way station eventually,” Robert “Bobby” Hughes, executive director of EPCAMR said at the time. But as vital as this work is, it seems primarily that the rewilding of Centralia is simply the work of leaving it alone.</p>\n<p>Standing in what was once a small, otherwise forgettable town, I came to understand how folly, mistake, calamitous hubris, neglect, and plain stupidity—could all be weapons in an arsenal to rewild and reforest the Earth, a future waiting in places we mistakenly believe we have irredeemably scarred.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106280/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>Beyond the town itself, the thing people have come to mourn here is the Graffiti Highway, which for years was a strange destination before it was covered over in 2020. It began, as these things often do, as spontaneous tagging and defacement. But over time, more taggers added their names, their designs, their art, and their stories, until it had become a makeshift historical record of the people who live here.</p>\n<p>Over time, it had begun to encroach on the natural history that was also unfolding, spilling out beyond the asphalt and into the forest, as trees and plants started to get defaced. It became an attractive nuisance, repeated bonfires and ATV crashes straining local resources, so when coal company Pagnotti Enterprises bought the land in 2018, they chose to bury the road in dirt and erased it for good. There is now, in the words of many Redditors, no reason to go to Centralia. But the company’s decision also obliterated what some saw as a vital piece in the region’s history. Pagnotti’s<a href=\"https://www.google.com/search?q=pagnotti+enterprises&amp;oq=pagnotti+enterprises&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM4MjBqMGo3qAIAsAIA&amp;sourceid=chrome&amp;ie=UTF-8#lrd=0x89c51a61c01ed687:0x1b1a2cd6c4d6b514,1,,,,\"> reviews</a> on Google are uniformly one-star ratings alongside comments like “You ruined graffiti highway,” “ruined a landmark, nice piles of dirt, go die,” and so on.</p>\n<p>For those who contributed to the Graffiti Highway, it had marked loves and losses, honored the dead and celebrated the living, all in a hundred different colors. (Park Street in Centralia has since begun to take the place of the old Graffiti Highway, decorated with a variety of tags, but at the moment it has nowhere near the density of the original Graffiti Highway. Some monuments take time to rebuild.)</p>\n<p>Kutztown University professor Deryl Johnson has called the story of Graffiti Highway an “epilogue” to the story of Centralia itself, but I’m not sure I agree. The story of Centralia is still very much unfolding—it did not end in 1982, and it did not end in 2020. Now that the highway is gone, the tourist attraction draw of this place has waned, leaving even more space for the natural world to reclaim the land. A new chapter has begun, and there may be other chapters in the story yet to come—chapters whose shape and direction we can only guess at.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106277/image.jpg\" width=\"auto\" /></figure>\n<hr class=\"baseline-grid-hr\" />\n<p>If you think of Centralia in terms of human habitation, it’s a ghost town, a few stubborn holdouts fighting against entropy and inertia. If you think of Centralia in terms of legend tripping and ruin porn, it’s nothing at all, barely a wide spot in the road. But if you think of Centralia as an unintended nature preserve, it is absolutely bursting with life and potential and possibility.</p>\n<p>Yet still the ground burns. Just out of the grid of streets that was once the town, down Big Mine Run Road, are the vents themselves: small holes in the sides of the hills like something out of Tolkien that lead down to inferno below. These days, the smoke itself is rarely visible, but when rain filters down to the fires, it comes back out as steam. So on the rainy day of our visit, we watched as these vents let out a small, steady stream of white steam, proof of the heat somewhere beneath our feet.</p>\n<p>It was an odd sensation. The wisps seemed peaceful, laconic, almost soothing. And at the same time, it seemed as though at any moment the entire valley would explode. Somehow it felt like both of these things at once.</p>\n<p>Looking at these gentle wisps of smoke, it is difficult to picture the smoldering inferno they emerged from. A fire that has raged out of control for sixty years, unending and older than most people you know. You try and you fail every time.</p>\n<p>Which is to say, Centralia’s mine fire is a thing that should not be. I can describe to you its history, the actions of the people involved. I can describe to you what the surface looks like, the species of plants, the words etched into the tombstones at the Odd Fellows Cemetery. But the secret, raging, burning heart of the Valley remains elusive.</p>\n<p>The plumes are a subtle reminder, easy to miss, that there is a reason for this pristine, thriving wildness all around us. That the coal mines underground are a price that has to be paid, paid to an underworld god that must be forever fed.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 17:18:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211445Z",
        "tags": [
          {
            "name": "transformation",
            "score": 9
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 19,
        "timeliness_score": 3,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "title": "20 Places to Travel and Transform Yourself in 2026, from Atlas Obscura",
        "summary": "<p>Looking for your next adventure? These 20 extraordinary destinations might just change how you see the world in 2026. Each place on this list asks something of you—patience, curiosity, humility, wonder—and gives something back in return. They’re not just trips; they’re invitations to travel differently, and to come home changed.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>1.</strong><a href=\"https://www.atlasobscura.com/places/fes-el-bali\"> <strong>Fes el-Bali in Fez, </strong>Morocco</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106235/image.jpg\" width=\"auto\" /></figure>\n<p>Step through the<a href=\"https://www.atlasobscura.com/places/the-blue-gate-of-fes-fez-morocco\"> Blue Gate</a> into the world's largest car-free medieval city—9,400 winding alleyways where 150,000 people live as their ancestors did. Getting lost among leather tanneries and spice souks forces you to surrender control and trust strangers, a reminder that not everything worth finding can be Googled.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November for mild temperatures</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>2.</strong><a href=\"https://www.atlasobscura.com/places/waitomo-glowworm-caves\"> <strong>Glowworm Caves in Waitomo, New Zealand</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106238/image.jpg\" width=\"auto\" /></figure>\n<p>Float silently through pitch-black caves beneath thousands of bioluminescent larvae creating nature's own planetarium. The <a href=\"https://www.atlasobscura.com/articles/video-wonder-new-zealands-twinkling-glowworm-caves\">boat journey</a> requires complete silence—no talking, no cameras. In our age of constant documentation, experiencing something you can't immediately share teaches you that some moments are meant to be felt, not captured.</p>\n<p><strong>Best time to visit:</strong> December-March (summer) for warmer weather above ground.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>3.</strong><a href=\"https://www.atlasobscura.com/places/kallur-lighthouse\"> Kallur Lighthouse in Kalsoy, <strong>Faroe Islands, Kingdom of Denmark</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106233/image.jpg\" width=\"auto\" /></figure>\n<p>Eighteen volcanic islands with dramatic cliffs,<a href=\"https://www.atlasobscura.com/places/gasadalur-village-2\"> grass-roofed villages</a>, and more sheep than people. Hike to Kallur Lighthouse or photograph Múlafossur waterfall cascading into the ocean. Weather changes every hour—all four seasons in a single day.</p>\n<p><strong>Best time to visit:</strong> June-July for longest days and accessible trails.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>4.</strong><a href=\"https://www.atlasobscura.com/places/cappadocia\"> <strong>Cappadocia in Aksaray, Turkey</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106232/image.jpg\" width=\"auto\" /></figure>\n<p><br />Volcanic eruptions created fairy chimneys, hidden<a href=\"https://www.atlasobscura.com/places/derinkuyu-underground-city\"> cave churches with Byzantine frescoes, and underground cities</a>. One such city was even <a href=\"https://www.atlasobscura.com/articles/derinkuyu-turkey-underground-city-strange-maps\">discovered by a local resident</a> during a home renovation project. Take a hot air balloon ride at sunrise, explore the underground cities carved eight levels deep, or stay in a cave hotel.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for ideal balloon weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>5.</strong><a href=\"https://www.atlasobscura.com/places/into-the-glacier\"> Langjökull<strong> Glacier Ice Caves near Húsafell, Iceland</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106231/image.jpg\" width=\"auto\" /></figure>\n<p>November through March, Iceland's glaciers reveal crystalline caves in impossible shades of blue. Because ice constantly melts and refreezes, you never see the same cave twice—each visit is literally once-in-human-history.</p>\n<p><strong>Best time to visit:</strong> January-February for most dramatic ice formations.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>6.</strong><a href=\"https://www.atlasobscura.com/places/petra\"> <strong>Petra, Jordan</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106230/image.jpg\" width=\"auto\" /></figure>\n<p>Walk through the narrow Siq canyon and emerge facing the Treasury—a 2,000-year-old facade carved into rose-red rock. This Nabataean city features hundreds of tombs and temples carved into sandstone. Climb to the Monastery or hike to <a class=\"underline underline underline-offset-2 decoration-1 decoration-current/40 hover:decoration-current focus:decoration-current\" href=\"https://www.atlasobscura.com/places/little-petra\">Little Petra</a> for solitude.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November. Early morning light makes the sandstone glow.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>7.</strong><a href=\"https://www.atlasobscura.com/places/cerro-fitz-roy\"><strong> Cerro Fitz Roy in El Chaltén, Argentina</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106229/image.jpg\" width=\"auto\" /></figure>\n<p>The Patagonia logo mountain. This 3,405-meter granite spire offers saw-toothed peaks and glacial lakes in impossible turquoise. The trek to Laguna de Los Tres delivers sunrise views that turn granite into a golden shade of pink. If you want extra adventure and you have time to take your journey northward, start in El Chaltén and then journey to the small town of <a href=\"https://www.atlasobscura.com/articles/nahuelito-argentina-loch-ness-monster-bariloche-patagonia\">Bariloche</a>, where Argentina's own Loch Ness monster is rumored to live.</p>\n<p><strong>Best time to visit:</strong> December-February (summer) for most stable weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>8.</strong><a href=\"https://www.atlasobscura.com/places/bagan\"> <strong>Bagan in Nyaung-U, Myanmar</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106228/image.jpg\" width=\"auto\" /></figure>\n<p>Over 2,000 Buddhist temples and pagodas built between the 11th-13th centuries dot ancient plains. Rent an e-bike to explore, climb select temples for sunrise, or take a hot air balloon ride. Less crowded than Angkor Wat, equally impressive.</p>\n<p><strong>Best time to visit:</strong> November-February (cool, dry season) for comfortable exploration.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>9.</strong><a href=\"https://www.atlasobscura.com/places/salar-de-uyuni-bolivian-salt-flat\"> <strong>Uyuni Salt Flat in Daniel Campos, Bolivia</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106239/image.jpg\" width=\"auto\" /></figure>\n<p>The world's largest salt flat—4,000 square miles of blinding white hexagons. During rainy season, thin water transforms it into the world's largest mirror, reflecting perfect sky. For more inspiration, check out these beautiful <a href=\"https://www.atlasobscura.com/articles/salt-flat-landscape-bolivia\">photos</a> and <a href=\"https://www.atlasobscura.com/articles/satellite-calibration-salar-de-uyuni\">satellite images</a>. Standing on these salt flats, where ground becomes sky and distance becomes meaningless, you understand that Earth still breaks every assumption about what's possible.</p>\n<p><strong>Best time to visit:</strong> December-April for mirror effect, May-October for hexagonal patterns.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>10.</strong><a href=\"https://www.atlasobscura.com/places/plitvi-ka-jezera-plitvice-lakes\"> <strong>Plitvice Lakes in Plitvička Jezera, Croatia</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106226/image.jpg\" width=\"auto\" /></figure>\n<p>Sixteen terraced lakes connected by waterfalls cascade through forested canyons in shifting shades of azure, green, and blue. Wooden walkways let you walk directly over crystal-clear waters.</p>\n<p><strong>Best time to visit:</strong> May-June or September for lush greenery and fewer crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>11.</strong><a href=\"https://www.atlasobscura.com/places/jigokudani-park-japan\"> <strong>Jigokudani Monkey Park in Yamanouchi, Japan<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106225/image.jpg\" width=\"auto\" /></figure>\n<p>Wild Japanese macaques soak in natural hot springs with snow falling around them in \"Hell's Valley.\" They look <a href=\"https://www.atlasobscura.com/articles/welcome-to-the-monkey-park\">hilariously human</a>—eyes closed in contentment, grooming each other. A hike through snowy forest leads to nature's most charming spa.</p>\n<p><strong>Best time to visit:</strong> December-March when snow creates dramatic contrast.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>12. <a href=\"https://www.atlasobscura.com/categories/route-66\">Route 66, USA</a><br /></strong></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106224/image.jpg\" width=\"auto\" /></figure>\n<p>In 2026, the<a href=\"https://www.atlasobscura.com/articles/route-66-highlights\"> Mother Road</a> celebrates its 100th birthday. The 2,400-mile stretch from<a href=\"https://www.atlasobscura.com/places/beginning-end-historic-route-66-chicago\"> Chicago</a> to<a href=\"https://www.atlasobscura.com/places/route-66-end-trail\"> Santa Monica</a> retains vintage motels, neon signs, diners, and quirky attractions—pure Americana.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for mild weather across climate zones.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>13.</strong><a href=\"https://www.atlasobscura.com/places/root-bridges-cherrapungee\"> <strong>Root Bridges in Cherrapunji, India</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106223/image.jpg\" width=\"auto\" /></figure>\n<p>In one of Earth's wettest places, the <a href=\"https://www.atlasobscura.com/articles/living-root-bridges-india\">Khasi people - truly artisans - </a>grow bridges from rubber tree roots over 10-15 years. Some are 500+ years old and still strengthening. The double-decker bridge requires 3,000 steps but teaches that patience beats speed, that working with nature trumps dominating it, and the best solutions might take longer than a single lifetime.</p>\n<p><strong>Best time to visit:</strong> November-February (dry season) for safer paths.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>14.</strong><a href=\"https://www.atlasobscura.com/places/havasupai-falls\"> <strong>Havasupai Falls in Supai, Arizona, USA</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106240/image.jpg\" width=\"auto\" /></figure>\n<p>Hidden in the Grand Canyon, waterfalls pour into pools so turquoise they don't look real. Calcium carbonate creates desert-meets-Caribbean waters. Requires 10-mile hike and advance permits from the Havasupai Tribe.</p>\n<p><strong>Best time to visit:</strong> March-May or September-October for mild temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>15.</strong><a href=\"https://www.atlasobscura.com/places/socotra-island\"> <strong>Socotra Island, Yemen</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106221/image.jpg\" width=\"auto\" /></figure>\n<p>Split from Africa millions of years ago, over a third of the plant species here exist nowhere else. Dragon's blood trees look like Dr. Seuss illustrations alongside desert roses and pink dunes. Standing among these otherworldly trees reminds you that isolation creates irreplaceable uniqueness worth protecting.</p>\n<p><strong>Best time to visit:</strong> November-March for comfortable temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>16.</strong> <a href=\"https://www.atlasobscura.com/things-to-do/hallstatt-austria\"><strong>Hallstatt, Austria</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106236/image.jpg\" width=\"auto\" /></figure>\n<p>An Alpine village so picturesque that<a href=\"https://www.atlasobscura.com/places/hallstatt-china\"> a Chinese mining company built a replica</a> to bring some Europe into Asia. The original Hallstatt - in Austria - is well-worth a visit. It features<a href=\"https://www.atlasobscura.com/places/salzwelten\"> ancient salt mines</a> and the<a href=\"https://www.atlasobscura.com/places/hallstatt-charnel-house\"> Charnel House</a> with painted skulls. And... maybe you'll get to the Chinese one next.</p>\n<p><strong>Best time to visit:</strong> May-June or September for smaller crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>17.</strong><a href=\"https://www.atlasobscura.com/places/ta-prohm\"> Ta Prohm near Siem Reap, Cambodia</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106237/image.jpg\" width=\"auto\" /></figure>\n<p>This hidden temple near Angkor Wat is being slowly consumed by jungle. At Ta Prohm, massive tree roots cascade over 12th-century stone and <a href=\"https://www.atlasobscura.com/places/dinosaur-angkor-wat\">curious carvings</a> stir controversy. Nature's patient reclamation—neither destroying nor preserving, but transforming—teaches that endings and beginnings are often the same thing. What could be viewed as overgrown has become beauty.</p>\n<p><strong>Best time to visit:</strong> November-February (dry, cool season).</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>18.</strong><a href=\"https://www.atlasobscura.com/places/marble-caves-of-chile-chico\"> <strong>Marble Caves in Puerto Río Tranquilo, Chile</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106218/image.jpg\" width=\"auto\" /></figure>\n<p>Six thousand years of water carved swirling marble caverns reflecting Lake General Carrera's turquoise water in otherworldly blue. Best explored by kayak.</p>\n<p><strong>Best time to visit:</strong> December-February when glacial melt intensifies the blue.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>19.</strong><a href=\"https://www.atlasobscura.com/places/eduard-bohlen-shipwreck\"> Eduard Bohlen Shipwreck in <strong>Skeleton Coast, Namibia<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106217/image.jpg\" width=\"auto\" /></figure>\n<p>Where the Namib Desert meets the Atlantic, rusted shipwrecks dot beaches alongside seal colonies and<a href=\"https://www.atlasobscura.com/articles/namibia-lions-hunt-seals\"> desert-adapted lions</a>. This coastline—where sailors once perished and wildlife now thrives—proves that what looks like desolation to some is home to others.</p>\n<p><strong>Best time to visit:</strong> May-October for wildlife viewing and cooler temperatures. And for adventure, you can even stay in a <a href=\"https://www.atlasobscura.com/places/shipwreck-lodge\">\"shipwreck.\"</a></p>\n<h2 class=\"article-subheading-pre-rd\"><strong>20.</strong><a href=\"https://www.atlasobscura.com/places/zhangye-national-geopark\"> <strong>Zhangye National Geopark in Zhangye Shi, China<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106216/image.jpg\" width=\"auto\" /></figure>\n<p>Rainbow mountains striped in red, yellow, orange, green, and blue—millions of years of mineral deposits creating nature's abstract painting. Best after it rains, when colors intensify.</p>\n<p><strong>Best time to visit:</strong> June-September for vibrant colors after summer rains.</p>\n<p> </p>\n<p>Each of these destinations offer more than photo opportunities—they're invitations to see where humans and nature have collided and created extraordinary things. They’re invitations to pause and reflect. They're invitations to change and grow.</p>\n<p>The world welcomes you for a transformative 2026. Let’s Go.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 05:58:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211471Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "title": "Discover Arizona’s Majesty",
        "summary": "<p>Arizona is wild in its environmental diversity, boasting five of the six distinct types of ecological biomes. Tundra, forest, woodland, scrub, grassland, and desert biomes are spread across the state, with four deserts, over 210 named mountain ranges, a biblical-scale monsoon season—and, of course, the Grand Canyon. The Sonoran Desert, which stretches across much of the state’s southern half, is a “lush desert,” meaning that it receives rain twice a year, and thus features a visually stunning blend of sepia tones and deep green vegetation.</p>\n<p>The state’s rich culture reflects the diversity of its Native populations and the many who have migrated to the area, along with a strong connection to Mexican cultural heritage. The region is the ancestral and current home to twenty-two federally recognized Native American tribes, including Diné (Navajo Nation) and the Tohono O'odham Nation.</p>\n<h3>Northern Region: Flagstaff and Holbrook</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Rainbow Forest\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/3d9f05e0-b5c9-4e76-b602-b0ba966c55661bc89aed0ef0a7e6e3_Wood%20and%20rock%20converge%20in%20the%20Rainbow%20Forest,%20where%20nothing%20is%20exactly%20as%20it%20seems.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Behold Arizona’s Sublime Beauty</h3>\n<p>The Rainbow Forest includes the largest and most colorful displays of petrified wood in Petrified Forest National Park.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Ancient geology and celestial discovery converge in Northern Arizona, inviting travelers to reflect on humanity’s place between the stars above and the eons below. Many visitors come for the Grand Canyon, but Northern Arizona contains multitudes. The high-elevation region features rugged mountain ranges, the state’s highest peak, and four distinct seasons, making it a destination for winter sports, mountaineering, and astronomy. The charming city of Flagstaff serves as home base to Northern Arizona University, the regional destination ski resort Snowbowl, and the Flagstaff Mountain Film Festival.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106241/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/lowell-observatory\">Lowell Observatory</a></h3>\n<p>Stargazers flock to Lowell Observatory, a world-class astronomy destination on the edge of Flagstaff. The site has been in continuous operation since the late 1800s, when it was established by Percival Lowell, a financier and astronomer who became obsessed with the possibility of life on Mars. Lowell had the means to fund his fascinations, and thus Lowell Observatory was built, with Northern Arizona selected as its site for its high elevation and dark skies. Pluto was discovered here, and the city’s commitment was recognized in 2001, when Flagstaff became the first International Dark Sky City.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106242/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www2.lowell.edu/users/elgb/observing_site.html\">Mars Hill and Anderson Mesa</a></h3>\n<p>Just west of Flagstaff proper sits Mars Hill, part of Lowell Observatory’s campus and the site of the apocryphal origin story of the theory of dark matter. As you drive up the hill, spot the iconic dome of the Clark Refractor, a telescope dating back to the 1800s. Continue your astronomy tour by heading southeast to spot Anderson Mesa, a flattop plateau in Coconino County that hosts Anderson Mesa Station, a dark-sky astronomical observatory.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106243/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/petrified-forest-national-park\">Petrified Forest National Park</a></h3>\n<p>Is it rock? Is it wood? The answer is yes at Petrified Forest National Park, where hundreds of millions of years of the organic process of permineralization have turned what was once a forest of trees into a wavy psychedelic desert landscape laden with fossils. These artifacts of the Triassic period (the era when dinosaurs are thought to have first appeared) include compression fossils of leaves, seeds, insects, and fish as well as scattered petrified logs.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106244/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/articles/850116.htm#6/27.450/-89.143\">Rainbow Forest</a></h3>\n<p>Nestled within Petrified Forest National Park, the Rainbow Forest features huge, vibrant rocks in deep reds, yellows, blues, and purples. The rocks began life as trees, petrified over hundreds of millions of years, and draw their vivid hues from minerals like manganese, iron oxide, quartz, and hematite. Pop into the Rainbow Forest Museum to learn about the geological and cultural history of the land, which is the historic home of the Ancestral Puebloan people.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106245/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.visitarizona.com/places/parks-monuments/painted-desert\">Painted Desert</a></h3>\n<p>Before you leave Petrified Forest National Park, head to the park’s north side to visit the Painted Desert, another region of the park with unique geological characteristics. Here, find badlands with distinctly visible layers—looking like they were painted with a steady hand. These layers are the result of stratification of shale, mudstone, and siltstone, each of which carry a distinctive pigment.</p>\n<h3>Central Region: Clarkdale, Camp Verde, and Jerome</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Montezuma Castle National Monument\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/c6c0b689-49fc-4ef9-9f08-85c4686f34528819d03b04ca73676d__High%20rise%20apartment_%20takes%20on%20new%20meaning%20at%20Montezuma%20Castle.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Explore Vibrant Arts, Culture, and Experiences</h3>\n<p>Evidence suggests the construction at Montezuma Castle National Monument began in the 1100s. It was occupied until as late as 1395.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>In Central Arizona, Saguaros stand watch over canyons and copper towns, linking ancient ingenuity, industrial ambition, and enduring cultural roots. The region features the sprawling state capital city of Phoenix, but the whole area is rich with Indigenous culture as well as niche historic sites dedicated to preserving the stories of the Wild West. Copper mining was and is a significant industry in the region, and the remnants of the extraction business are conserved in installations like the town of Jerome’s Mine Museum.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106246/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/verde-canyon-railroad\">Verde Canyon Railroad</a></h3>\n<p>The Verde Canyon Railroad, a quirky heritage railroad that runs 20 miles from Clarkdale to Perkinsville, features a vintage diesel locomotive powers that this sightseeing excursion, bringing riders through the vibrant wilderness landscape. In the canyon, keep your eyes peeled for the bald eagles who frequent the area.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106247/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://historicbridges.org/b_h_fipsm.php?bsearch=04025\">Perkinsville Trestle</a></h3>\n<p>As you ride the Verde Canyon Railroad, you’ll pass over a series of gorges formed by the Verde River. These steep valleys are spanned by metal trestles—making for extraordinary vistas from the open-air viewing cars. When your rail car traverses the Perkinsville Trestle, the tracks, directly underneath the car, are obscured to riders, creating the feeling that the railroad has taken flight.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106248/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.arizonacopperartmuseum.com\">Arizona Copper Art Museum</a></h3>\n<p>The deposits of copper embedded in Arizona’s earth have enticed miners since Native people harvested ore to make tools and jewelry. Since the early 1900s, industrial mining has pulled copper from the land. The former mining town Clarkdale is home to the Arizona Copper Art Museum, which stands as a testament to the creative uses of the mineral. On a visit, check out the distillery room, where you’ll find elaborate copper vessel systems for winemaking.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106249/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/montezuma-castle-national-monument\">Montezuma Castle National Monument</a></h3>\n<p>Pull off the highway in Camp Verde to stop by Montezuma Castle National Monument, a historic site that honors and preserves the prehistoric cliff dwelling architecture of the Indigenous Sinagua people. Built into a limestone cliff is a multi-level 20-room dwelling that is noted as one of the best-preserved examples of pre-contact architecture.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/moca/planyourvisit/exploring-montezuma-well.htm\">Montezuma Well</a></h3>\n<p>Within Montezuma Castle National Monument lies a giant hole: Montezuma Well. Nearly 400 feet from shore to shore, the “well” is in fact a huge, naturally occurring spring-fed limestone sinkhole full of carbonated, arsenic-laden water. The well serves as home to five species of fauna that exist nowhere else in the world, including the water scorpion.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106250/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/jeromes-sliding-jail\">Jerome’s Sliding Jail</a></h3>\n<p>In Jerome (population 464), the main attraction is a small jail structure that was erected in the early 1900s on the slope of a mountain. Dynamite from nearby mines caused the jail to literally slide down the hill until finding stasis on the main thoroughfare. Now a visitor’s attraction, the jail harks back to the days of the Wild West, when hard-drinking rabble-rousers would sleep it off within the cell’s walls.</p>\n<h3>Southern Region: Bisbee, Tubac, and Patagonia</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Pronghorn Antelope in the Buenos Aires National Wildlife Refuge\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/f5d06809-5120-43bc-820f-df69590282a120d65582e662de3d08_usfws-pronghorn-buenos-aires-natinal-wildlife-refuge.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Experience Arizona’s Welcoming Warmth and Ties to Nature</h3>\n<p>The Buenos Aires National Wildlife Refuge is home to hundreds of species, including the pronghorn antelope, mule deer, and puma.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Where wild canyons bloom and hummingbirds hover, artists, dreamers, and makers create in harmony with the desert’s vivid, living canvas. Known for its miles of Saguaro cacti, Southern Arizona is home to a large swath of the Sonoran Desert, about 370 miles of the U.S.-Mexico border, and the city of Tucson.</p>\n<p>The Sonoran Desert is home to a diversity of flora and fauna, including prickly pear, Gila monsters, roadrunners, and the western diamondback rattlesnake. For more sedate engagements with local culture, Tucson is a dining hotspot: a UNESCO City of Gastronomy, a designation awarded to sites of global culinary significance.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106251/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.bisbeebreakfastclub.com\">Bisbee Breakfast Club</a></h3>\n<p>Bisbee Breakfast Club locations can be spotted across Southern Arizona, but Bisbee is the home of the original. Within the nondescript beige building, the charmingly weathered interior is classic American diner with a Southwestern twist. Nosh on regional Mexican favorites like huevos rancheros and fan-fave house specialties like the Copper Queen Skillet, a mashup of eggs, potatoes, and seemingly every kind of breakfast meat: bacon, ham, sausage, and spicy sausage gravy.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www.oldbisbeebrewingcompany.com\">Old Bisbee Brewing Co.</a></h3>\n<p>For a bite and a brew in the kitschy town, the Old Bisbee Brewing Co. offers an eclectic and sophisticated menu of draft beers, brewed on-site. Strict IPA buffs will appreciate the heady Double Hopped IPA, while those with more experimental tastes may delight in the Mayan Stout, brewed using a heritage Mesoamerican bean.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106252/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.tubacarts.org\">Tubac Center for the Arts</a></h3>\n<p>Luxe meets rustic at Tubac, an arts and leisure complex tucked between the Tumacácori and Santa Rita mountains. Find the ritzy side at Tubac Golf Resort &amp; Spa, where golfers flock to the 27-hole course and spa-goers indulge, but the arts and the grounds are the real draw. Explore Tubac to find four galleries, a performance space, and arts library, plus a trail system that connects with the Juan Bautista de Anza National Historic Trail.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106253/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.fws.gov/refuge/buenos-aires\">Buenos Aires National Wildlife Refuge</a></h3>\n<p>Near the border town of Sasabe, 117,000 acres of public grassland desert serves as an ecological reserve. Habitat restoration makes the refuge a safe haven for 50+ mammal species, with the land sheltering endangered species including the masked bobwhite quail. Find an open-access trail system as well as guided hikes, and complimentary public-access campsites. Keep your eyes peeled for deer, javelina, coyotes, skunks, rabbits—even the occasional jaguar.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106254/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://tucsonbirds.org/paton-center/\">Paton Center for Hummingbirds</a></h3>\n<p>Patagonia’s Paton Center for Hummingbirds is a conservation space for more than 250 bird species, including the rare violet-crowned hummingbird. The 1.4-acre woodland site began its life as the yard of a pair of local birdwatchers, who in the 1970s began inviting others to join them in marveling at the tiny avian pollinators. From there, the local Audubon Society acquired the property, which is lovingly managed as an oasis for birds and birders alike.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106255/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/chir/index.htm\">Chiricahua National Monument</a></h3>\n<p>Find rocks on rocks on rocks at Chiricahua National Monument, where physics-defying rock stacks give an otherworldly feel to the ecological environs. The result of a historical volcanic event, the area’s rock formations (officially known as hoodoos and rhyolite pinnacles) look like blocks stacked by the hands of giants. Travelers can take in their weird splendor from 17 miles of maintained trails and campground facilities.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 09:57:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211466Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211450Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/places/moment-point-zero",
        "title": "‘Moment - Point Zéro’ in Brussels, Belgium",
        "summary": "<p><img alt=\"\" height=\"200\" src=\"https://img.atlasobscura.com/RRjDsRFiBpoiwoe2Tl2mkt-t5n4wEf0TJjzSx_9gI2U/rs:fill:300:200:1/g:ce/c:2097:1398:nowe:457:310/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3BsYWNl/X2ltYWdlcy8xNDll/NWI5My02ZGI4LTQ5/NjEtYTk1OS04MzYy/OWIyYzA5ZDMzMmUy/OTgwMWNmNzMzODBj/OTlfUDEwNzA4MzYu/SlBH.jpg\" width=\"300\" /></p> <p>Molenbeek-Saint-Jean is a municipality located northwest of the city centre of Brussels. Like the rest of Brussels, it is renovating its urban spaces to provide a pleasant living environment for its residents. In 2014, the Place Communale was renovated. The work included a piece of art by the famous Brussels artist Joëlle Tuerlinckx.</p>\n<p>As the work was to be installed in the centre of the square, the artist came up with the idea of creating a 'Point Zero', which is a reference to the point from which distances to other cities are measured (as in <a href=\"https://www.atlasobscura.com/places/middelpunt-van-leuven\">Leuven</a> ). This concept carries significant symbolic value in a community as multicultural as this one, where nearly one-third of the population has foreign origins. The zero point thus becomes the symbolic starting point for calculating distances to all the countries with which the population has cultural and social ties.</p>\n<p>The artwork comprises a 12.5-ton block of blue Hainaut stone, which arrived in Molenbeek by boat on January 8, 2014. The choice of material and mode of transport is a reminder that Molenbeek was the point at which the building materials used to construct the capital arrived, creating an additional link with the municipality's history. After being sculpted by Jean Dalemans, the stone was buried in the square's ground. Only the top is visible: a disc with a diameter of 58 cm in the middle of the cobblestones. Therefore, most of the block is invisible underground.</p>\n<p>The work was the subject of fierce criticism as soon as it was installed: the total cost of purchasing the block, transporting it, carving it and installing it was estimated at €80,000. This is a considerable amount to spend on a piece of art that is buried in the ground and therefore almost invisible.</p>\n<p>However, this was the artist's intention: for most of the block to be hidden under the cobblestones. According to her, unlike other monuments in public spaces, this monument does not symbolise anything, but rather the moment of its installation — hence its name, 'Moment—Point Zero'.</p>\n<p>The symbolic significance of this work continues to elude many people, who still consider it a waste of public money. It has already been cited in the press as an example of a work of art whose cost is considered disproportionate. Nevertheless, it is still there today. It is the only permanent piece by this renowned Belgian conceptual artist that can be seen in a public space. Visitors must therefore take its symbolic dimension into account when viewing the work, or they may be disappointed by this stone disc that barely emerges from the ground!</p>",
        "source": "www.atlasobscura.com",
        "published": "Sun, 18 Jan 2026 14:00:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211408Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "title": "Inside America’s First Destination Ski Town",
        "summary": "<p>In the heart of Idaho, about 150 miles east of Boise, the steep slopes of Bald Mountain tower over a sun-kissed valley. For roughly a century, visitors have flocked to Sun Valley from all over the country for its premiere skiing and snowboarding. But behind these sought-after slopes, there’s an impressive history and one-of-a-kind cultural experiences that make it a unique destination.</p>\n<p>Hollywood’s most celebrated stars have traveled to the valley for decades, yet Sun Valley has managed to maintain a laid-back local life and spirit even amid such A-list appeal. That rare blend of low-pretension modernity—coupled with nonstop flights from eight major metropolitan areas, including Chicago, Seattle, and Los Angeles—make Sun Valley a low-stress, culture-packed getaway.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106264/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">A History of Innovation</h2>\n<p>Long before the glistening snow and sun-soaked days helped launch Sun Valley into a skier's dreamland, a sparkle of another sort caught national attention: silver. In the 1870s, the first discoveries of the precious metal attracted prospectors from across the nation.</p>\n<p>An anchor of the region, the <a href=\"https://visitsunvalley.com/lodging/sun-valley-lodge/\">Sun Valley Resort</a>, with slopes that cater to beginners and seasoned veterans in equal measure, has hosted some of the most iconic stars of the Golden Age of Hollywood.</p>\n<p>But it was born in part out of necessity: The Great Depression hit the railroad business hard in the region. In 1936, Averell Harriman, the chairman of the Union Pacific Railroad at the time, had the idea to boost traffic on its lines by building an exclusive European-style destination ski resort. At the time there were virtually no U.S. ski areas that had upscale lodging and dining right at the slopes.</p>\n<p>To add to the must-see appeal, the resort unveiled the first-ever chairlift on nearby Proctor Mountain. The brainchild of James Curran, an engineer with the railroad, its inspiration came from a surprising place: bananas. While traveling in tropical regions, Curran had seen bananas hooked in bunches and hauled to the dock by pulley systems. Why not try the same with people?</p>\n<p>That December, “Life Magazine” featured the new technology, which helped position the resort as a go-to getaway. The lift, which moved skiers 20 feet off the ground for more than 3,500 feet with a 1,150-foot gain in elevation, opened up the sport to people who might not have otherwise had the stamina for the activity.</p>\n<p>Cinema’s elite, including Marilyn Monroe, Ingrid Bergman, Frank Sinatra and Clark Gable, stayed at the resort, and Ernest Hemingway, whose <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">burial site</a> is also in Sun Valley, finished “For Whom the Bell Tolls” in suite 206 of the Sun Valley lodge. More recently, the region has also attracted business elites and tech giants like Microsoft founder Bill Gates and Apple CEO Tim Cook.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106260/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Laid-Back Local Vibe</h2>\n<p>Today in Sun Valley Village, the walkable heart of the resort, that glamorous essence is anchored by an affable vibe and crowd-pleasing activities. The 1937 opera house now serves as a movie theater, which features films by snow and skiboard filmmaker Warren Miller, among other classics. Ice skating enthusiasts may want to check out the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/get-to-know-every-ice-rink-in-the-wood-river-valley/\">Sun Valley ice rink</a>, a known hangout for Olympic athletes as they prepare for the popular Sun Valley on Ice shows. And additional dining, shopping, and entertainment options abound in nearby Ketchum, located less than two miles down the road (which also has its own free outdoor ice rink, open from late December until mid-February).</p>\n<p>Dining in Sun Valley can be as cosmopolitan or low-key as your tastes crave. For a rustic, homestyle pick, <a href=\"https://www.kneadery.com\">The Kneadery</a> in North Ketchum serves up hearty breakfast and lunch dishes and has been a local go-to since 1974. Owners Dillon and Heather Witmer have cultivated an impressive collection of Western art and artifacts for decades, and diners will spot a canoe hanging from the dining room ceiling, while a taxidermied grizzly bear and mounted antlers on wood-paneled walls add to the cozy, lodge-like feel.</p>\n<p>For a contemporary option be sure to check out Cookbook, which offers flavor-packed bites ranging from grilled Idaho trout to house-made pesto and inventive pizzas. The restaurant, which was originally located in a 1932 church but has since moved to a larger location, serves up plenty of vegetarian options as well, and is commended by guests for its great service and family friendly atmosphere.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106259/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Vibrant Off-Slope Culture</h2>\n<p>Even if you never hit the slopes, Sun Valley is full of high-quality, even quirky, cultural experiences all year long. The <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> in Ketchum is a regional hub for contemporary and local art, formed in 1971. Each year, the museum hosts resident artists and features exhibitions and events featuring visual arts, film, music, and more.</p>\n<p>When the Wood River Valley is blanketed in snow, the region is also host to the <a href=\"https://sunvalleyfilmfestival.org\">Sun Valley Film Festival</a>, an annual, five-day event that has featured legendary filmmakers and Hollywood’s best, including Clint Eastwood, Jodie Foster, and Woody Harrelson, since 2011. Screenings, cocktail and coffee chats, and big-ticket parties honor the greatest names in film and introduce emerging artists. Monthly movies and educational programming are also offered year-round.</p>\n<p>Each January, respected culinary masters and rising food stars emerge at the <a href=\"https://visitsunvalley.com/events/sun-valley-food-wine-celebration-2/\">Sun Valley Food &amp; Wine Celebration</a>. The Sun Valley Culinary Institute hosts this popular, five-day event, featuring James Beard Award winners, champions from the Food Network “Chopped” reality show, exclusive chef dinners, cooking classes, and spirited Après Ski events.</p>\n<p>The Sun Valley Pavilion buzzes in summer with sound at the <a href=\"https://www.svmusicfestival.org\">​​Sun Valley Music Festival</a>, a month-long event that offers world-class musicians performing in a relaxed outdoor venue.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106265/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Spirited Character</h2>\n<p>Sun Valley residents take pride in their rich heritage, cause for memorable celebrations. As the trees in downtown Ketchum begin to morph from green to fiery orange and red, over a thousand sheep amble along Main Street for the <a href=\"https://www.atlasobscura.com/articles/podcast-trailing-of-the-sheep\">Trailing of the Sheep Festival</a>. Each fall, Sun Valley honors the annual sheep migration from the summer’s high mountain pastures to the warmer grazing and lambing regions in the south, an event known historically as “trailing.” The festival is packed with wool-making classes, culinary lessons, live music and folklore, and more.</p>\n<p>For Labor Day, Sun Valley residents celebrate another part of their heritage at <a href=\"https://www.wagondays.com\">Wagon Days</a>. Founded in 1958, the tradition honors the history and mining heritage of the region, including one of the weekend’s most anticipated events: the Big Hitch Parade, which showcases antique buggies, carriages, carts, and more parading through downtown Ketchum.</p>\n<p>Whether you’re an avid skier or just want to soak in sunny days as you experience a culturally rich pocket of American history, surprises await in Sun Valley.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 06 Jan 2026 16:23:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211461Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-the-well-maine",
        "title": "Forged by Nature: The Farm-to-Table Restaurant on an Actual Farm",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>When Jason Williams was a kid in the ’80s, he had a favorite TV show. It wasn’t a cartoon. It was more like a documentary show. Like the educational kind.</p>\n<p><strong>Jason Williams:</strong> I was obsessed with the show <em>Great Chefs Great Cities</em>, which was a program back on in the early, late ’80s, probably, where they’d go to different restaurant kitchens and make a dish.</p>\n<p><strong>Kelly: </strong>Jason grew up on the East Coast in a small town. It was nice, but it was not the ideal place to learn to become a chef.</p>\n<p><strong>Jason:</strong> I grew up in New Hampshire and didn’t have a lot of access to crazy ingredients.</p>\n<p><strong>Kelly:</strong> The closest bigger town was across the border in Maine. But when he went there as a kid, he wasn’t going for the food.</p>\n<p><strong>Jason:</strong> So I’d come to Portland growing up as a kid. We used to come over here and skateboard and, you know, all that fun stuff and just kind of be in the city.</p>\n<p><strong>Kelly:</strong> Back then, the big city of Portland, Maine wasn’t necessarily known for its food scene. It was not featured on <em>Great Chefs Great Cities</em>. But these days, Maine’s reputation in the food world is different. And Jason Williams, now Chef Jason Williams, is a big part of that.</p>\n<p><strong>Jason:</strong> What drew me to Maine was just the accessibility we have, like the ocean right here, incredible cold water seafood. We’re two miles from the ocean and we’re on a 120-acre farm. The farmers are all approachable, the fishermen are all good people, you know, there’s so much abundance.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. This episode was produced in partnership with the Maine Office of Tourism. It’s Maine week on the show, so every day we are introducing you to someone from that great state: people who live and work in Maine and who fuel their creativity with its rugged beauty.</p>\n<p>Today it’s all about eating well at Chef Jason’s hyper-local farm-to-table restaurant, The Well, in Cape Elizabeth, Maine. And yeah, you probably have been to a farm-to-table restaurant before, but this one really is different. The food that was probably picked hours before the meal is growing right near where people sit down to dinner. Same with the flowers. Chef Jason really believes in what he’s doing. And it shows.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106206/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Okay, so let’s go back to how Jason got started. After he fell in love with <em>Great Chefs Great Cities</em>, he went to culinary school. He left New England to work in restaurants around the country, classy kitchens, high-end resorts, a renowned seafood restaurant on Maui, a winery in Napa Valley. But eventually he started to miss the Northeast.</p>\n<p><strong>Jason:</strong> Thought about raising a family, and New England’s kind of the perfect place to raise kids, so we came here for vacation and just kind of fell back in love with it.</p>\n<p><strong>Kelly:</strong> It was about two decades ago, and Portland, Maine had changed after Jason left. He got a job working at a local restaurant, and one day he was driving around to farmers markets looking for ingredients when he found a special place.</p>\n<p><strong>Jason:</strong> I just happened to drive up this road, and I had just a really cool feeling when I rounded the corner, and I’m like, wait a second, this is a farm? Wait a second, I could get all my shopping done right here? So I just pulled in. It is a 120-acre farm, about three miles from the ocean. A produce farm, it’s fourth generation.</p>\n<p><strong>Kelly: </strong>It’s called Jordan’s Farm, run by the Jordan family. It’s a few miles south of Portland in the town of Cape Elizabeth, which conveniently is also where Jason was living. So he started getting produce from Jordan’s Farm and bringing it back to the restaurant where he was working.</p>\n<p><strong>Jason:</strong> They allowed me to kind of come out back and hand select produce and stuff like that, which is huge in my world.</p>\n<p><strong>Kelly: </strong>Eventually, after a few years of shopping at the farm …</p>\n<p><strong>Jason: </strong>I just pitched them the idea. I drew up a picture of a flatbed trailer and was like, what if we just did a food trailer here and I can work in your off hours? If it doesn’t work, we’ll wheel away and uh throw some grass seed down and it’ll be like it never happened.</p>\n<p><strong>Kelly: </strong>What Jason was proposing was to literally build a kitchen on the back of a flatbed trailer. That way, if the project was not a success, he would just tow it away and the Jordans could get back to business as usual. Jason was nervous. He’d never run a restaurant before, but the farm …</p>\n<p><strong>Jason:</strong> They went for it. They were like, great idea, and they were so supportive and just really let me make this happen.</p>\n<p><strong>Kelly:</strong> Jason got the blessing of the chef where he was working and went out on his own, building out that kitchen trailer at Jordan’s farm.</p>\n<p><strong>Jason:</strong> Busted out the graph paper. I was like, okay, well, you know, small dimensions, what can we actually do for equipment? Just a leap of faith, obviously. I tried to do it on a tight budget. I didn’t come out swinging with a huge space, a state-of-the-art kitchen. I just kind of built what was necessary for me to make nice food.</p>\n<p><strong>Kelly:</strong> He didn’t know how to run a restaurant. He did know how to make nice food. Every day, he would go into Jordan’s farm, see what looked best, and design a couple of dishes around what they had. He called his project The Well, as in eating well, also as in a watering hole, a place where people gather. And since he got to invent the menu every morning, he could get really specific.</p>\n<p><strong>Jason: </strong>So you can really play on the weather, what’s fresh, just the mood. Everything changes. You know, Maine can be 80 degrees one day and 50 degrees the next day and rainy. If it’s cold, I might throw a soup on. I can just adapt to what’s around me.</p>\n<p><strong>Kelly: </strong>He started slow and simple.</p>\n<p><strong>Jason: </strong>We didn’t have a dishwasher. I started off with just kind of compostable plates. I was just doing like a chalkboard menu with a couple items, and I had a suggested donation box here where people would just kind of come in, drop cash, and I really like people were kind of shocked by it, you know, it wasn’t something that you saw a lot, you know, 15 years ago, really, especially in this town.</p>\n<p><strong>Kelly: </strong>Jason knew that was a gamble. The restaurant business is hard, and this was a restaurant on a farm stand. People were coming there to get produce to take home and cook for themselves. They weren’t necessarily looking to spend money on prepared food. Turns out, Jason was wrong.</p>\n<p><strong>Jason: </strong>So people would start lining up an hour before I even opened, and then all of a sudden I would be out of food in like two hours, just ripping through 70 people. We’d put a little chalkboard menu up at the top of the thing that said “The Well is dry,” and “try again the next day.”</p>\n<p><strong>Kelly:</strong> At that point, Jason knew he had to expand. He built out a bigger kitchen in a real building, no wheels underneath. He hired staff, started adding menu items, not just a few things written in chalk. He added more formal seating. Before it had been picnic tables, now there would be gazebos for private dining. He started sourcing stuff from other local producers, butchers, and growers. But the concept was the same: Whatever looked best that morning, that’s what he would use.</p>\n<p><strong>Jason:</strong> And then I started introducing, probably like year seven or something, I started introducing a tasting menu, an option, just like, okay, if you want to, if you trust me, we can do a five-course tasting menu and see what happens.</p>\n<p><strong>Kelly: </strong>What happened was people did trust him. The tasting menu became a huge part of his business. And now that’s what The Well does. Every day he’s open, it’s five fresh courses chosen that morning.</p>\n<p><strong>Jason:</strong> A veggie course, a fish course, a grain pasta course, and then kind of your fourth course protein and a dessert. It’s really nice because I can just grab totes and walk up to the farm stand, which is like 50 yards away, and hand select whatever I need for the night.</p>\n<p>I can just adapt to what’s around me, the weather, and just new stuff that looks incredible up there. The seasons are so dramatic here in Maine. You know, things happen so quick. It’s really nice to be able to just capture that and be able to use those things that they’re hiding and put them right into play.</p>\n<p><strong>Kelly:</strong> A wood-grilled lamb loin with local corn and housemade barbecue sauce. A homemade brioche donut and vanilla ice cream with peaches picked that morning.</p>\n<p><strong>Jason: </strong>I’m not throwing a bunch of weird ingredients at you, but everything’s got to be seasoned well, cooked, executed well. So I’m really focused on those details, those small things. The fundamentals: seasoning, balance, flow of a whole tasting menu.</p>\n<p>People get so pigeonholed into what they’re comfortable ordering or eating, and maybe they’ll find out that they actually do like carrots or zucchini now, and it’s not how they remembered it from their grandmother’s mushy peas or whatever.</p>\n<p>I get inspired by like I see these farmers working crazy, so it’s nice. I really want to do my best to kind of make them proud. I want them to know that their product is first and foremost, and that I’m doing it justice.</p>\n<p><strong>Kelly:</strong> The Well at Jordan’s Farm has become one of the Portland area’s most popular restaurants. These days, there are a lot of great restaurants in Maine. In recent years, the state’s food scene has grown. And just like at the well, it brings together so much of what makes Maine Maine. The independence, the seasonality, the creativity. And now The Well has been part of that community for 15 years.</p>\n<p><strong>Jason:</strong> It’s really refreshing here that things are still chef-owned, smaller scale, a lot of integrity. I feel super proud of it now, 15 years later, you know, it’s been a labor of love. I worked so—I’ve never worked so hard at anything in my life, really. But it’s been—it feels good now, you know. People are celebrating years and years and years of anniversaries, of birthdays. Yeah, it feels great. I mean, what more can you ask for? In the hospitality business, you know, to feel that love back. It’s really nice.</p>\n<p><strong>Kelly:</strong> Who knows? If there’s a reboot of <em>Great Chefs Great Cities</em>, Jason and the other restaurants that have sprung up in and around Portland, Maine might make the cut this time.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>This episode was produced by Katie Thornton. Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 24 Dec 2025 07:15:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211481Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-hanako-nakazato-pottery",
        "title": "Forged by Nature: How Maine Shapes This Artist’s Pottery",
        "summary": "<div>\n<p class=\"&lt;iframe\">&gt;<strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers:</strong><span style=\"font-weight: 400;\"> Hanako Nakazato says, when she was a kid, she didn’t want to work in pottery.</span></p>\n<p><strong>Hanako Nakazato:</strong><span style=\"font-weight: 400;\"> I grew up in Karatsu, which is known for history of pottery. So when I was younger, I wasn’t interested in pottery. It was too close to home.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Karatsu is in southern Japan. It’s been a hub of pottery making for hundreds of years. Hanako comes from a family of renowned potters. So, at first, she wanted to try something different. But, after she moved to the United States at 16, slowly that started to change.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> As I spent many years away from home, I started to appreciate my own cultural heritage.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">It started with food, sort of.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">I love food, and I realized the Japanese dining experience is very unique. Not just the ingredients, but the table setting is very unique—the presentation of the food—and pottery plays a big role in that.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> So, Hanako knew what she had to do next.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I wanted to create a tool to enjoy food, and that was the start. European style, everything is unified, and it’s very clean. But if you go to a Japanese restaurant, repetition is often avoided. So, you would have different kinds of pottery on the table. It’s not just white things and the round things. You might start seeing something white or clean, but then next might be something in wood or bamboo or metal or glass. Texture is different, material might be different.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">To Hanako, there was something beautiful about all these different variations. Something that to her had a deeper meaning.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">We mix all different kinds of materials and shapes and heights, and it’s creating something balanced or unified out of chaotic situations.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Since 2010, Hanako has been living and practicing in both Japan and in rural Midcoast Maine. She says Maine’s environment is like the Japanese diningware she came to love. Varied, messy even, but also cohesive and balanced. Craggy, rocky hills next to placid blue lakes, dense forests near the wide open ocean. It’s all there, she says, and it all inspires Hanako and other artists like her.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Maine has the beauty and inspires people, artistic people, to create something beautiful. To be independent and to create your own beautiful life because of the beautiful nature. That’s what I appreciate, Maine.</span></p>\n<p><span style=\"font-weight: 400;\">I’m Kelly McEvers, and this is </span><em><span style=\"font-weight: 400;\">Atlas Obscura</span></em><span style=\"font-weight: 400;\">, a celebration of the world’s strange, incredible, and wondrous places. This episode was produced in partnership with the Maine Office of Tourism. It’s Maine week on the show, so every day we are introducing you to someone from that great state. People who live and work and get inspired by Maine’s rugged beauty.</span></p>\n<p><span style=\"font-weight: 400;\">Today is all about the pottery of Hanako Nakazato and the philosophy she brings to it. It’s a philosophy that perfectly unites the two places she spends her time: Karatsu, Japan, and the 2000-person town of Union, Maine. Two places that inspire artists with their sense of community and the beauty of nature.</span></p>\n<p><em><span style=\"font-weight: 400;\">This is an edited transcript of the </span></em><a href=\"https://www.atlasobscura.com/podcast\"><em><span style=\"font-weight: 400;\">Atlas Obscura Podcast</span></em></a><em><span style=\"font-weight: 400;\">: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </span></em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em><span style=\"font-weight: 400;\">Apple Podcasts</span></em></a><em><span style=\"font-weight: 400;\">, </span></em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em><span style=\"font-weight: 400;\">Spotify</span></em></a><em><span style=\"font-weight: 400;\">, and all major podcast apps.</span></em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106207/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Maine, it’s not New York City. You see a lot of greens, sometimes I see turkeys in traffic. Yeah, we’re living in the countryside of mid-coast Maine. I love it.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> If you know much about Maine, you know it can be quiet and peaceful, but you also probably know that it gets pretty rugged. Being in rural Maine is a physical experience, and that resonates with Hanako. Because, so is throwing pottery on a wheel.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">I used to be a serious athlete, and I like to understand the world in a physical way. And pottery is very—it requires a certain level of aestheticism.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">You can see that in the way Hanako makes work. She starts by taking a big piece of clay and tossing it onto a table over and over, kneading it to soften it up. Then …</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> You put the chunk of clay on the wheelhead.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Then she pounds the sides of that chunk, centering it and guiding it upward as she does. On the top portion of the spinning mound of clay, she begins to shape a bowl or a cup. Then she uses a traditional tool that’s used in Karatsu.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">A special rib, special tool, throwing tool, called gyubera.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">The gyubera kind of looks like a cow’s tongue. She uses it to press the walls of the cup or bowl against her outside hand and shape the pottery. Then she slices the bowl off the top of the spinning mound and begins forging another one from the clay that remains. And another and another. In her home studio with white walls and floor-to-ceiling windows that look out over the main wilderness, Hanako does this work almost like meditation as the light shifts outside.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I’m a production potter, so I can make a couple hundred pieces a day. If I decide to make a cup, I make 50, or hundreds of them. Just to get in a flow. I love working in a flow, because I let go of myself and just work on the wheel, spinning, and it’s all physical. You’re not even thinking. I usually listen to house music and it’s all about the rhythm and then just doing the repetition.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Hanako says the key is letting her mind get out of the way.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">That’s when the true beauty comes out. Pottery as a clay, as a material, it’s very responsive to the touch or the movement, and you have to work with intuition, you have to use senses. You can’t really think too hard.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Hanako wants her art to be used: bowls, plates, cups, and carafts, but there’s always something unique about each one. An unexpected angle, a sloping edge. And since moving to Maine, the local landscape has found its way into her work too.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I often find my shape is influenced by what I see in nature. I love being in Maine because it has the ocean, the blueberry field, and the woods, and light. Light is magical here. I used to make black or white or something monotone pottery because I was more into creating shapes. But since I moved to Maine, I started making something more colorful or blue. And I think I was influenced by Maine, ocean or sky, or dark night. Yeah, definitely have a different color palette since I lived in Maine. </span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Hanako’s style is rooted in Japan too. One of her guiding philosophies to lead with your heart and your body rather than your mind doesn’t just show up in her process. It’s embedded in the name of her studio, Mono Hanako.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> “Mono” means “thing” in Japanese. “Pottery” in Japanese is called “yakimono.” “Yaki” is “fired,” “mono” is “thing.” But I want my pottery to be versatile. If you call this a mug, it limits the usage function as a drinking vessel, maybe just for coffee or tea. But if you call it a thing, you could use it for soup, or you could use it for ice cream, dessert bowl, or you could put, you know, a bouquet of herbs.</span></p>\n<p><span style=\"font-weight: 400;\">So it will open up the other possibilities of usage. So I want to call my pottery a thing, rather than giving a special name like a soup bowl or a dessert bowl or you know, ramen bowl. Because beyond that, people cannot really think about it. You know, oh, you have to use for ramen only. The pottery might be the same, but if you put different things, this will look differently. And I like the continuous change.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Trying to avoid the limiting confines of your thinking mind, staying away from perfection, celebrating and embracing variety, like the variety found in the tableware in a traditional Japanese meal. All this is baked into Hanukkah’s philosophy, not just in art, but in life.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I think there is a Zen influence. Perfection is often avoided in Zen philosophy.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">And in Maine, that variety, that ruggedness, that beautiful imperfection is all around her.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Nature is not trying to be perfect. It just—it’s there.</span></p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em><span style=\"font-weight: 400;\">This episode was produced by Katie Thornton. Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Casey Holford, and Luz Flemming. Our theme music is by Sam Tyndall.</span></em></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 23 Dec 2025 07:15:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211486Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211525Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/sean-sherman-turtle-island-cookbook",
        "title": "On 'Turtle Island,' Indigenous Food Is Not the Past—It’s the Future",
        "summary": "<div>\n<p><em>Join Gastro Obscura's Sam O'Brien each week for Kitchen Dispatch as she tests new recipes and explores wondrous foods from her home kitchen. <a href=\"https://www.atlasobscura.com/newsletters/gastro-obscura\">Subscribe to get it in the Gastro newsletter</a>.</em></p>\n</div>\n<p>One of my favorite parts of researching <em>The Gastro Obscura Cookbook</em> is talking to leaders in the food world about the recipes that matter most to them. When it comes to Indigenous food of North America, few experts rival <a href=\"https://seansherman.com/\">Sean Sherman</a>. An Oglala Lakota chef raised on the Pine Ridge Reservation of South Dakota, Sherman has devoted his career to studying and promoting Indigenous cuisine.</p>\n<p>From his <a href=\"https://www.atlasobscura.com/users/hogarth/lists/minneapolis\">Minneapolis</a> restaurant, <a href=\"https://www.atlasobscura.com/places/owamni\">Owamni</a>—which focuses on native ingredients and eschews post-colonial additions like dairy, wheat flour, sugar, and pork—to his first cookbook, <a href=\"https://seansherman.com/books/\"><em>The Sioux Chef’s Indigenous Kitchen</em></a>, Sherman has made it his mission to showcase the bounty of Indigenous foodways.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106267/image.jpg\" width=\"auto\" /></figure>\n<p>But his latest project is probably his most ambitious: <a href=\"https://www.penguinrandomhouse.com/books/712577/turtle-island-by-sean-sherman-with-kate-nelson-and-kristin-donnelly/\"><em>Turtle Island</em></a>, a cookbook covering the cuisines of Indigenous communities across North America (known as “Turtle Island” to many Indigenous tribes). From Maya turkey <em>pibil</em> of the Yucatán Peninsula to Yurok hot-smoked salmon of Northern California, Sherman’s book covers an impressive swath of Indigenous culinary diversity.</p>\n<p>I recently spoke with Sherman about his new book, his mission, and the recipe that he believes best embodies Indigeneity. Here’s an excerpt of our conversation.</p>\n<p><strong>Sam O’Brien</strong>: I’d like to start by talking about <em>Turtle Island</em>, which is impressively ambitious in its scope. You’re tackling all these different regions and communities. Can you talk about the process of making it?</p>\n<p><strong>Sean Sherman:</strong> The vision was to showcase all this Indigenous diversity that’s still very much alive, erasing these colonial construct borders and looking at this tapestry of diversity. I wanted to create something that wasn’t out there for people as a resource because a book like this didn’t really exist.</p>\n<p>It felt like a continuation of my work because <em>The Sioux Chef’s Indigenous Kitchen</em> was a much smaller project. But that book was really just laying out the initial philosophy of how I was going about approaching Indigenous foods in today’s world and restructuring things, removing fry bread, removing all colonial ingredients like dairy and wheat flour, cane sugar, and beef, pork, and chicken, and just focusing on how you identify and cook what’s regional and Indigenous, and still paying homage to a lot of the tribes and their traditions.</p>\n<p>So with this book, I wanted to go a little bit bigger, and I wanted to see the connection of Indigenous peoples everywhere, whether you’re Indigenous in Southern Mexico or Northern Alaska or the middle of the United States.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106268/image.jpg\" width=\"auto\" /></figure>\n<p><strong>SO:</strong> Speaking of that vast diversity, did you learn anything in terms of how the food you grew up eating compares to other communities around North America?</p>\n<p><strong>SS:</strong> I didn't grow up with a lot of Indigenous foods, like many people in tribal communities. We grew up in segregated communities as reservation systems. A lot of us grew up with commodity foods from the government, with canned vegetables, meats, and fruits, and empty white carbs like powdered milk and sugar. It's created health epidemics in tribal communities.</p>\n<p>A lot of this work about food sovereignty is bringing an understanding of our own foods back to us. We can work on rebuilding our food systems, not be reliant on government food programs that have made us really sick, and bring a lot of pride and connection back to our ancestors.</p>\n<p>But envisioning this future means not being stuck in the past and making a couple of recipes or just adopting fry bread, but looking at so much more. Most of the recipes [in the book] were built with a future in mind because we weren’t trying to recreate the past. There’s a handful of traditional recipes in the book, but most of them are just interpretations of what we can do moving forward. To me, this is a futurist book of just looking at what would happen if we included the Indigenous perspective on our food systems and we could really showcase so much vast diversity in the regionality of our foods everywhere.</p>\n<p><strong>SO:</strong> Speaking of commodity foods and colonial ingredients, in <em>Turtle</em> <em>Island</em>, it’s striking to see the contrast between how you talk about your experience eating the commodity foods that were forced on you and how you talk about eating Indigenous foods at community gatherings. It’s so vivid reading about foods like wóžapi [a berry sauce] and tȟaníǧa [a bison or beef intestine soup]. How often were you able to eat foods like that growing up?</p>\n<p><strong>SS:</strong> We had wóžapi a few times a year. It was typically special, like holidays or birthdays. We would harvest the chokecherries as kids in the summer, and then my grandmother would make big batches of it, and we’d use it here and there. We also had a handful of foods like the tȟaníǧa, the intestine soup, like the thíŋpsiŋla [also known as “prairie turnips”].</p>\n<p>So there were a handful of recipes that survived. I didn’t have to go far back into history because this was just my grandparents’ generation that was the first generation stripped away from all their stuff. Because my grandparents were born at the beginning of the century, they grew up speaking Lakota first, but they’re one of the first generations to be pushed through boarding schools and cut their hair, learn Christianity, and just be stripped away with what it meant to be Lakota.</p>\n<p>But a lot of Lakota culture has been very strong and survived. We still have a lot of music. Our language is strong. Our stories are strong. But food was missing. So this work was really just trying to figure out why it was missing and what can we do to bring it back.</p>\n<p><strong>SO:</strong> I know it’s hard to pick one, but are there any recipes from <em>Turtle Island</em>, <em>The Sioux Chef,</em> or your restaurant that you think especially embody the story you’re trying to share with the world?</p>\n<p><strong>SS:</strong> I feel like different readers, especially if you’re from Indigenous backgrounds, will connect with different recipes from different regions. But for me, there’s a recipe called pápa waháŋpi, and it’s a dried bison soup. It’s a really traditional-style recipe, but to me, it tasted so much like home. You have the thíŋpsiŋla, the prairie turnips, from the Great Plains and the Dakotas, and a simple mushroom broth and the dried bison. It was just a really simple soup, but it had so much character to me, and it really spoke to home. It just connected to my soul.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106270/image.jpg\" width=\"auto\" /></figure>\n<p><strong>SO:</strong> I’d love to make it. I know where I live, in Philadelphia, it might be hard to track down an ingredient like prairie turnip. Is it okay to make substitutions?</p>\n<p><strong>SS:</strong> Yes. And we offered some substitutions in the book of what people can do to at least try to mimic it. But some of these will be very special, and that’s just the way it was designed. When we wrote this book, the publisher knew that not everybody was going to be able to make every recipe. We don’t have to have instant access to everything because you’re not going to find thíŋpsiŋla in the market. You’re not going to find javelina [wild boar] at your local Whole Foods, and you’re probably not going to find seal meat at Target. Some of these recipes are special; you might need to be in the right region at the right time with the right group of people to experience them.</p>\n<p><strong>SO:</strong> I get that. In some ways, the book is a reference that’s telling a story, not just being like, <em>Oh, you have to make this specific recipe</em>. It’s educational in a very beautiful way.</p>\n<p><strong>SS:</strong> Yeah. That’s what it was meant to be, to use the power of the language of food to talk about some really important things. And some of these are difficult histories. Some things we don’t learn because we grew up in America. We don’t learn about American history, except through an obscured colonial viewpoint at best. And so there’s so much to talk about everywhere, and there’s so much connection that Indigenous peoples have that they’ve had to go through. And so food is a really great way to be able to convey a lot of that knowledge.</p>\n<p class=\"p1\"><em>This interview has been edited and condensed for clarity.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Sun, 11 Jan 2026 09:20:00 -0500",
        "fetched_at": "2026-01-19T23:18:26.211456Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-01-19T23:16:52.803667Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-01-19T23:16:52.804059Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-01-19T23:16:52.803311Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-01-19T23:16:52.805020Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2024/04/22/fimi-launches-mini-3-drone-featuring-sony-48mp-sensor-and-249g-weight/",
        "title": "FIMI launches Mini 3 drone featuring Sony 48MP sensor and 249g weight",
        "summary": "<figure><img alt=\"FIMI launches Mini 3 drone featuring Sony 48MP sensor and 249g weight\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"638\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/04/%E6%88%AA%E5%B1%8F2024-04-22-14.49.47.png?fit=1024%2C638&amp;ssl=1\" width=\"1024\" /></figure>FIMI, a subsidiary of Xiaomi that specializes in producing drones and related accessories, recently launched the FIMI Mini 3 drone for the global market, featuring a Sony 1/2-inch 48MP CMOS sensor and a lightweight of 249g. Several third-party retailers have listed the domestic version of the Mini 3 drone on e-commerce platforms, priced at RMB [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 22 Apr 2024 06:50:29 +0000",
        "fetched_at": "2026-01-19T23:16:52.814923Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-01-19T23:16:52.804618Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-01-19T23:16:52.805311Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-01-19T23:16:52.805573Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-01-19T23:16:52.809078Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/27/huawei-vivo-and-oppo-help-establish-first-global-fast-charging-standard-under-itu/",
        "title": "Huawei, vivo, and OPPO help establish first global fast-charging standard under ITU",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/charger-marcus-urbenz-4xMAiJZPQXI-unsplash.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>The International Telecommunication Union (ITU) has approved and released L.1004, a universal fast-charging standard for mobile terminals co-authored by China’s CAICT with Huawei, vivo, and OPPO. The standard enables cross-brand and cross-device fast charging and is intended to reduce charger duplication and electronic waste. [TechNode reporting]",
        "source": "technode.com",
        "published": "Mon, 27 Oct 2025 10:51:44 +0000",
        "fetched_at": "2026-01-19T23:16:52.804141Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/google/langextract",
        "title": "google/langextract",
        "summary": "<p>A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</p><hr /><p align=\"center\"> <a href=\"https://github.com/google/langextract\"> <img alt=\"LangExtract Logo\" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/logo.svg?sanitize=true\" width=\"128\" /> </a> </p> \n<h1>LangExtract</h1> \n<p><a href=\"https://pypi.org/project/langextract/\"><img alt=\"PyPI version\" src=\"https://img.shields.io/pypi/v/langextract.svg?sanitize=true\" /></a> <a href=\"https://github.com/google/langextract\"><img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/google/langextract.svg?style=social&amp;label=Star\" /></a> <img alt=\"Tests\" src=\"https://github.com/google/langextract/actions/workflows/ci.yaml/badge.svg?sanitize=true\" /> <a href=\"https://doi.org/10.5281/zenodo.17015089\"><img alt=\"DOI\" src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.17015089.svg?sanitize=true\" /></a></p> \n<h2>Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#introduction\">Introduction</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#why-langextract\">Why LangExtract?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#installation\">Installation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup for Cloud Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#adding-custom-model-providers\">Adding Custom Model Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-openai-models\">Using OpenAI Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-local-llms-with-ollama\">Using Local LLMs with Ollama</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#more-examples\">More Examples</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#romeo-and-juliet-full-text-extraction\"><em>Romeo and Juliet</em> Full Text Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#medication-extraction\">Medication Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#radiology-report-structuring-radextract\">Radiology Report Structuring: RadExtract</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#community-providers\">Community Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#contributing\">Contributing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#testing\">Testing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#disclaimer\">Disclaimer</a></li> \n</ul> \n<h2>Introduction</h2> \n<p>LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.</p> \n<h2>Why LangExtract?</h2> \n<ol> \n <li><strong>Precise Source Grounding:</strong> Maps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.</li> \n <li><strong>Reliable Structured Outputs:</strong> Enforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.</li> \n <li><strong>Optimized for Long Documents:</strong> Overcomes the \"needle-in-a-haystack\" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.</li> \n <li><strong>Interactive Visualization:</strong> Instantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.</li> \n <li><strong>Flexible LLM Support:</strong> Supports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.</li> \n <li><strong>Adaptable to Any Domain:</strong> Define extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.</li> \n <li><strong>Leverages LLM World Knowledge:</strong> Utilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.</li> \n</ol> \n<h2>Quick Start</h2> \n<blockquote> \n <p><strong>Note:</strong> Using cloud-hosted models like Gemini requires an API key. See the <a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup</a> section for instructions on how to get and configure your key.</p> \n</blockquote> \n<p>Extract structured information with just a few lines of code.</p> \n<h3>1. Define Your Extraction Task</h3> \n<p>First, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.</p> \n<pre><code class=\"language-python\">import langextract as lx\nimport textwrap\n\n# 1. Define the prompt and extraction rules\nprompt = textwrap.dedent(\"\"\"\\\n    Extract characters, emotions, and relationships in order of appearance.\n    Use exact text for extractions. Do not paraphrase or overlap entities.\n    Provide meaningful attributes for each entity to add context.\"\"\")\n\n# 2. Provide a high-quality example to guide the model\nexamples = [\n    lx.data.ExampleData(\n        text=\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\",\n        extractions=[\n            lx.data.Extraction(\n                extraction_class=\"character\",\n                extraction_text=\"ROMEO\",\n                attributes={\"emotional_state\": \"wonder\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"emotion\",\n                extraction_text=\"But soft!\",\n                attributes={\"feeling\": \"gentle awe\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"relationship\",\n                extraction_text=\"Juliet is the sun\",\n                attributes={\"type\": \"metaphor\"}\n            ),\n        ]\n    )\n]\n</code></pre> \n<blockquote> \n <p><strong>Note:</strong> Examples drive model behavior. Each <code>extraction_text</code> should ideally be verbatim from the example's <code>text</code> (no paraphrasing), listed in order of appearance. LangExtract raises <code>Prompt alignment</code> warnings by default if examples don't follow this pattern—resolve these for best results.</p> \n</blockquote> \n<h3>2. Run the Extraction</h3> \n<p>Provide your input text and the prompt materials to the <code>lx.extract</code> function.</p> \n<pre><code class=\"language-python\"># The input text to be processed\ninput_text = \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n\n# Run the extraction\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n)\n</code></pre> \n<blockquote> \n <p><strong>Model Selection</strong>: <code>gemini-2.5-flash</code> is the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning, <code>gemini-2.5-pro</code> may provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the <a href=\"https://ai.google.dev/gemini-api/docs/rate-limits#tier-2\">rate-limit documentation</a> for details.</p> \n <p><strong>Model Lifecycle</strong>: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\">official model version documentation</a> to stay informed about the latest stable and legacy versions.</p> \n</blockquote> \n<h3>3. Visualize the Results</h3> \n<p>The extractions can be saved to a <code>.jsonl</code> file, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.</p> \n<pre><code class=\"language-python\"># Save the results to a JSONL file\nlx.io.save_annotated_documents([result], output_name=\"extraction_results.jsonl\", output_dir=\".\")\n\n# Generate the visualization from the file\nhtml_content = lx.visualize(\"extraction_results.jsonl\")\nwith open(\"visualization.html\", \"w\") as f:\n    if hasattr(html_content, 'data'):\n        f.write(html_content.data)  # For Jupyter/Colab\n    else:\n        f.write(html_content)\n</code></pre> \n<p>This creates an animated and interactive HTML file:</p> \n<p><img alt=\"Romeo and Juliet Basic Visualization \" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif\" /></p> \n<blockquote> \n <p><strong>Note on LLM Knowledge Utilization:</strong> This example demonstrates extractions that stay close to the text evidence - extracting \"longing\" for Lady Juliet's emotional state and identifying \"yearning\" from \"gazed longingly at the stars.\" The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding <code>\"identity\": \"Capulet family daughter\"</code> or <code>\"literary_context\": \"tragic heroine\"</code>). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.</p> \n</blockquote> \n<h3>Scaling to Longer Documents</h3> \n<p>For larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:</p> \n<pre><code class=\"language-python\"># Process Romeo &amp; Juliet directly from Project Gutenberg\nresult = lx.extract(\n    text_or_documents=\"https://www.gutenberg.org/files/1513/1513-0.txt\",\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n    extraction_passes=3,    # Improves recall through multiple passes\n    max_workers=20,         # Parallel processing for speed\n    max_char_buffer=1000    # Smaller contexts for better accuracy\n)\n</code></pre> \n<p>This approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file. <strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">See the full <em>Romeo and Juliet</em> extraction example →</a></strong> for detailed results and performance insights.</p> \n<h3>Vertex AI Batch Processing</h3> \n<p>Save costs on large-scale tasks by enabling Vertex AI Batch API: <code>language_model_params={\"vertexai\": True, \"batch\": {\"enabled\": True}}</code>.</p> \n<p>See an example of the Vertex AI Batch API usage in <a href=\"https://raw.githubusercontent.com/google/langextract/main/docs/examples/batch_api_example.md\">this example</a>.</p> \n<h2>Installation</h2> \n<h3>From PyPI</h3> \n<pre><code class=\"language-bash\">pip install langextract\n</code></pre> \n<p><em>Recommended for most users. For isolated environments, consider using a virtual environment:</em></p> \n<pre><code class=\"language-bash\">python -m venv langextract_env\nsource langextract_env/bin/activate  # On Windows: langextract_env\\Scripts\\activate\npip install langextract\n</code></pre> \n<h3>From Source</h3> \n<p>LangExtract uses modern Python packaging with <code>pyproject.toml</code> for dependency management:</p> \n<p><em>Installing with <code>-e</code> puts the package in development mode, allowing you to modify the code without reinstalling.</em></p> \n<pre><code class=\"language-bash\">git clone https://github.com/google/langextract.git\ncd langextract\n\n# For basic installation:\npip install -e .\n\n# For development (includes linting tools):\npip install -e \".[dev]\"\n\n# For testing (includes pytest):\npip install -e \".[test]\"\n</code></pre> \n<h3>Docker</h3> \n<pre><code class=\"language-bash\">docker build -t langextract .\ndocker run --rm -e LANGEXTRACT_API_KEY=\"your-api-key\" langextract python your_script.py\n</code></pre> \n<h2>API Key Setup for Cloud Models</h2> \n<p>When using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to set up an API key. On-device models don't require an API key. For developers using local LLMs, LangExtract offers built-in support for Ollama and can be extended to other third-party APIs by updating the inference endpoints.</p> \n<h3>API Key Sources</h3> \n<p>Get API keys from:</p> \n<ul> \n <li><a href=\"https://aistudio.google.com/app/apikey\">AI Studio</a> for Gemini models</li> \n <li><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview\">Vertex AI</a> for enterprise use</li> \n <li><a href=\"https://platform.openai.com/api-keys\">OpenAI Platform</a> for OpenAI models</li> \n</ul> \n<h3>Setting up API key in your environment</h3> \n<p><strong>Option 1: Environment Variable</strong></p> \n<pre><code class=\"language-bash\">export LANGEXTRACT_API_KEY=\"your-api-key-here\"\n</code></pre> \n<p><strong>Option 2: .env File (Recommended)</strong></p> \n<p>Add your API key to a <code>.env</code> file:</p> \n<pre><code class=\"language-bash\"># Add API key to .env file\ncat &gt;&gt; .env &lt;&lt; 'EOF'\nLANGEXTRACT_API_KEY=your-api-key-here\nEOF\n\n# Keep your API key secure\necho '.env' &gt;&gt; .gitignore\n</code></pre> \n<p>In your Python code:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\"\n)\n</code></pre> \n<p><strong>Option 3: Direct API Key (Not Recommended for Production)</strong></p> \n<p>You can also provide the API key directly in your code, though this is not recommended for production use:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    api_key=\"your-api-key-here\"  # Only use this for testing/development\n)\n</code></pre> \n<p><strong>Option 4: Vertex AI (Service Accounts)</strong></p> \n<p>Use <a href=\"https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform\">Vertex AI</a> for authentication with service accounts:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    language_model_params={\n        \"vertexai\": True,\n        \"project\": \"your-project-id\",\n        \"location\": \"global\"  # or regional endpoint\n    }\n)\n</code></pre> \n<h2>Adding Custom Model Providers</h2> \n<p>LangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.</p> \n<ul> \n <li>Add new model support independently of the core library</li> \n <li>Distribute your provider as a separate Python package</li> \n <li>Keep custom dependencies isolated</li> \n <li>Override or extend built-in providers via priority-based resolution</li> \n</ul> \n<p>See the detailed guide in <a href=\"https://raw.githubusercontent.com/google/langextract/main/langextract/providers/README.md\">Provider System Documentation</a> to learn how to:</p> \n<ul> \n <li>Register a provider with <code>@registry.register(...)</code></li> \n <li>Publish an entry point for discovery</li> \n <li>Optionally provide a schema with <code>get_schema_class()</code> for structured output</li> \n <li>Integrate with the factory via <code>create_model(...)</code></li> \n</ul> \n<h2>Using OpenAI Models</h2> \n<p>LangExtract supports OpenAI models (requires optional dependency: <code>pip install langextract[openai]</code>):</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gpt-4o\",  # Automatically selects OpenAI provider\n    api_key=os.environ.get('OPENAI_API_KEY'),\n    fence_output=True,\n    use_schema_constraints=False\n)\n</code></pre> \n<p>Note: OpenAI models require <code>fence_output=True</code> and <code>use_schema_constraints=False</code> because LangExtract doesn't implement schema constraints for OpenAI yet.</p> \n<h2>Using Local LLMs with Ollama</h2> \n<p>LangExtract supports local inference using Ollama, allowing you to run models without API keys:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemma2:2b\",  # Automatically selects Ollama provider\n    model_url=\"http://localhost:11434\",\n    fence_output=False,\n    use_schema_constraints=False\n)\n</code></pre> \n<p><strong>Quick setup:</strong> Install Ollama from <a href=\"https://ollama.com/\">ollama.com</a>, run <code>ollama pull gemma2:2b</code>, then <code>ollama serve</code>.</p> \n<p>For detailed installation, Docker setup, and examples, see <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/ollama/\"><code>examples/ollama/</code></a>.</p> \n<h2>More Examples</h2> \n<p>Additional examples of LangExtract in action:</p> \n<h3><em>Romeo and Juliet</em> Full Text Extraction</h3> \n<p>LangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of <em>Romeo and Juliet</em> from Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">View <em>Romeo and Juliet</em> Full Text Example →</a></strong></p> \n<h3>Medication Extraction</h3> \n<blockquote> \n <p><strong>Disclaimer:</strong> This demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.</p> \n</blockquote> \n<p>LangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/medication_examples.md\">View Medication Examples →</a></strong></p> \n<h3>Radiology Report Structuring: RadExtract</h3> \n<p>Explore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.</p> \n<p><strong><a href=\"https://huggingface.co/spaces/google/radextract\">View RadExtract Demo →</a></strong></p> \n<h2>Community Providers</h2> \n<p>Extend LangExtract with custom model providers! Check out our <a href=\"https://raw.githubusercontent.com/google/langextract/main/COMMUNITY_PROVIDERS.md\">Community Provider Plugins</a> registry to discover providers created by the community or add your own.</p> \n<p>For detailed instructions on creating a provider plugin, see the <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/custom_provider_plugin/\">Custom Provider Plugin Example</a>.</p> \n<h2>Contributing</h2> \n<p>Contributions are welcome! See <a href=\"https://github.com/google/langextract/raw/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> to get started with development, testing, and pull requests. You must sign a <a href=\"https://cla.developers.google.com/about\">Contributor License Agreement</a> before submitting patches.</p> \n<h2>Testing</h2> \n<p>To run tests locally from the source:</p> \n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/google/langextract.git\ncd langextract\n\n# Install with test dependencies\npip install -e \".[test]\"\n\n# Run all tests\npytest tests\n</code></pre> \n<p>Or reproduce the full CI matrix locally with tox:</p> \n<pre><code class=\"language-bash\">tox  # runs pylint + pytest on Python 3.10 and 3.11\n</code></pre> \n<h3>Ollama Integration Testing</h3> \n<p>If you have Ollama installed locally, you can run integration tests:</p> \n<pre><code class=\"language-bash\"># Test Ollama integration (requires Ollama running with gemma2:2b model)\ntox -e ollama-integration\n</code></pre> \n<p>This test will automatically detect if Ollama is available and run real inference tests.</p> \n<h2>Development</h2> \n<h3>Code Formatting</h3> \n<p>This project uses automated formatting tools to maintain consistent code style:</p> \n<pre><code class=\"language-bash\"># Auto-format all code\n./autoformat.sh\n\n# Or run formatters separately\nisort langextract tests --profile google --line-length 80\npyink langextract tests --config pyproject.toml\n</code></pre> \n<h3>Pre-commit Hooks</h3> \n<p>For automatic formatting checks:</p> \n<pre><code class=\"language-bash\">pre-commit install  # One-time setup\npre-commit run --all-files  # Manual run\n</code></pre> \n<h3>Linting</h3> \n<p>Run linting before submitting PRs:</p> \n<pre><code class=\"language-bash\">pylint --rcfile=.pylintrc langextract tests\n</code></pre> \n<p>See <a href=\"https://raw.githubusercontent.com/google/langextract/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for full development guidelines.</p> \n<h2>Disclaimer</h2> \n<p>This is not an officially supported Google product. If you use LangExtract in production or publications, please cite accordingly and acknowledge usage. Use is subject to the <a href=\"https://github.com/google/langextract/raw/main/LICENSE\">Apache 2.0 License</a>. For health-related applications, use of LangExtract is also subject to the <a href=\"https://developers.google.com/health-ai-developer-foundations/terms\">Health AI Developer Foundations Terms of Use</a>.</p> \n<hr /> \n<p><strong>Happy Extracting!</strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:04.686977Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/thanh_truong_a99577c6b879/the-three-phases-of-data-pipelines-3d1c",
        "title": "The Three Phases of Data Pipelines",
        "summary": "<p>We have all experienced it: you are browsing Amazon for a new smartphone, you add it to your cart, and before you can even reach for your credit card, the site suggests a perfectly matching protective case or high-speed charger. It feels like magic—or perhaps a bit like mind-reading.</p>\n\n<p>As engineers, however, we know that “magic” is simply the byproduct of a sophisticated data pipeline. Behind that seamless recommendation is a complex engine designed, built, and maintained to capture your clicks, process your history, and feed algorithms in real-time. To understand the mechanics of this experience, we must look at the three critical phases of the data lifecycle—Design, Build, and Maintain—through the lens of foundational architectural trade-offs.</p>\n\n<h2>\n  \n  \n  Design Is a Brutal Trade-off Between Speed and Order\n</h2>\n\n<p>The first phase of any pipeline is design, where the data engineer acts as an architect. Before a single line of code is written, you must make foundational architectural trade-offs that dictate the system’s ROI, scalability, and long-term reliability.</p>\n\n<p>The primary tension lies between latency and structure. In a professional data context, latency is defined as the time between the moment a data event occurs in a source system and the moment that data is available to be queried in an analytics system.</p>\n\n<ul>\n<li>Low Latency (High Freshness): If your business requires near-real-time data, you usually have less time to clean, validate, or reshape that data before it is stored.</li>\n<li>Rigid Structure (High Quality): If you require highly organized and validated data up-front (schema-on-write), you must accept higher latency. The processing required to transform that data takes time.</li>\n</ul>\n\n<p>Reflection: The Strategic Mindset Data engineers must be architects first. Design is a preventative measure; the choices made here regarding how structure is applied are not merely technical preferences. They are the primary drivers of infrastructure cost. The wrong choice dictates failure before the pipeline even starts.</p>\n\n<h2>\n  \n  \n  The “Opportunity Window” and the High Cost of Real-Time\n</h2>\n\n<p>A central part of the design phase is the choice between batch and real-time architecture. This isn’t just a choice of “fast vs. slow”; it is a decision regarding matching technical architecture to user behavior.</p>\n\n<p>In a batch architecture, data is collected over a fixed period and processed on a schedule (e.g., a 2:00 AM job processing yesterday’s orders). In a real-time architecture, data is processed continuously as events happen. For a recommendation engine, the stakes are clear:</p>\n\n<p>“It wouldn’t make sense to rely on a batch job that runs at night to recommend products to a customer shopping at 2PM. By the time the nightly job runs, the customer is long gone.”</p>\n\n<p>While real-time is necessary for Amazon’s use case, a Senior Consultant knows it comes with significantly higher infrastructure complexity, specialized software components (like stream processors), and increased operational overhead.</p>\n\n<p>Reflection: Business-Engineering Alignment Choosing real-time when a nightly batch would suffice inflates costs and complexity without adding business value. Conversely, choosing batch when freshness is a hard requirement—like in-session recommendations—makes the data, and the engineering effort, worthless. Success is found in aligning the architecture with the “shelf-life” of the data’s value.</p>\n\n<h2>\n  \n  \n  The Power of “Decoupling” via Message Buses\n</h2>\n\n<p>Once the design is finalized, we move to the Build phase. This involves assembling the components that physically move data. A key strategy for modern, high-traffic systems is using a message bus or event queue, such as Apache Kafka or AWS Kinesis.</p>\n\n<p>When a user clicks “Add to Cart,” the front-end application publishes an event and pushes it into the message bus. The bus acts as a high-speed buffer, holding events temporarily. This “decouples” the system: the front-end application doesn’t need to know which service will process the data or how long it will take. It publishes the message and moves on, preventing the front-end from “hanging” or crashing during traffic spikes.</p>\n\n<p>Reflection: The Value of Asynchronous Processing Decoupling allows the user-facing application to remain lightning-fast while the heavy lifting—running machine learning models—happens behind the scenes. Even if it takes a “second or two” for the recommendation to appear, the asynchronous nature of the pipeline ensures the core shopping experience is never compromised by the complexity of the analytical engine.</p>\n\n<h2>\n  \n  \n  The “Silent Failure” Is Scarier Than a System Crash\n</h2>\n\n<p>The work doesn’t end when the code is deployed; that’s where the risk begins. In the Maintenance phase, the focus shifts to ensuring the system remains accurate. While a system crash is loud and obvious, the “silent failure” is the true nightmare.</p>\n\n<p>A silent failure occurs when the pipeline succeeds technically but produces corrupted data. Imagine a source database price column changing from USD to Euros. The column name and data type remain the same, so the pipeline continues to run with “green” lights.</p>\n\n<p>“The real nightmare is this: The pipeline succeeds technically, but silently produces garbage data… Technically, everything is green. But in reality, the business is making decisions on corrupted data.”</p>\n\n<p>The impact is catastrophic: revenue dashboards become fiction, and machine learning models—like our recommendation engine—begin learning from incorrect signals, eventually poisoning the entire user experience.</p>\n\n<p>Reflection: Uptime is a Vanity Metric “Technical uptime” is a false metric if the data quality is compromised. A senior engineer prioritizes automated alerts, schema monitoring, and value-range validation. If data quality fails, the system must notice it immediately. Monitoring must move beyond “Is the server on?” to “Is the data true?”</p>\n\n<h2>\n  \n  \n  The Success of the Invisible Engineer\n</h2>\n\n<p>When a data engineer is successful, their work is invisible. The customer receives a spot-on recommendation, the CFO receives an accurate report, and the data scientist receives clean data. The “magic” is actually the result of rigorous engineering trade-offs and vigilant maintenance.</p>\n\n<p>However, as we look ahead, we must remember that “latency” is multi-faceted. There is Data Latency (how fresh the data is) and Query Latency (how fast the dashboard responds). These two often work against each other, and balancing them is the next great challenge for any data organization.</p>\n\n<p>If “fast” and “accurate” are often at odds, how do you decide which one your business can afford to lose first?</p>",
        "source": "dev.to",
        "published": "Mon, 19 Jan 2026 22:02:46 +0000",
        "fetched_at": "2026-01-19T23:17:09.816103Z",
        "tags": [
          {
            "name": "transformation",
            "score": 11
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 29,
        "timeliness_score": 2,
        "final_score": 10.1,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/yichuan-w/LEANN",
        "title": "yichuan-w/LEANN",
        "summary": "<p>RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.</p><hr /><p align=\"center\"> <img alt=\"LEANN Logo\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/logo-text.png\" width=\"400\" /> </p> \n<p align=\"center\"> <img alt=\"Python Versions\" src=\"https://img.shields.io/badge/Python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue.svg?sanitize=true\" /> <img alt=\"CI Status\" src=\"https://github.com/yichuan-w/LEANN/actions/workflows/build-and-publish.yml/badge.svg?sanitize=true\" /> <img alt=\"Platform\" src=\"https://img.shields.io/badge/Platform-Ubuntu%20%26%20Arch%20%26%20WSL%20%7C%20macOS%20(ARM64%2FIntel)-lightgrey\" /> <img alt=\"MIT License\" src=\"https://img.shields.io/badge/License-MIT-green.svg?sanitize=true\" /> <img alt=\"MCP Integration\" src=\"https://img.shields.io/badge/MCP-Native%20Integration-blue\" /> <a href=\"https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ckd2f6w1-OX08~NN4gkWhh10PRVBj1Q\"> <img alt=\"Join Slack\" src=\"https://img.shields.io/badge/Slack-Join-4A154B?logo=slack&amp;logoColor=white\" /> </a> <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/wechat_user_group.JPG\" title=\"Join WeChat group\"> <img alt=\"Join WeChat group\" src=\"https://img.shields.io/badge/WeChat-Join-2DC100?logo=wechat&amp;logoColor=white\" /> </a> </p> \n<div align=\"center\"> \n <a href=\"https://forms.gle/rDbZf864gMNxhpTq8\"> <img alt=\"Take Survey\" src=\"https://img.shields.io/badge/📣_Community_Survey-Help_Shape_v0.4-007ec6?style=for-the-badge&amp;logo=google-forms&amp;logoColor=white\" /> </a> \n <p> We track <b>zero telemetry</b>. This survey is the ONLY way to tell us if you want <br /> <b>GPU Acceleration</b> or <b>More Integrations</b> next.<br /> 👉 <a href=\"https://forms.gle/rDbZf864gMNxhpTq8\"><b>Click here to cast your vote (2 mins)</b></a> </p> \n</div> \n<h2 align=\"center\" class=\"heading-element\" dir=\"auto\" tabindex=\"-1\"> The smallest vector index in the world. RAG Everything with LEANN! </h2> \n<p>LEANN is an innovative vector database that democratizes personal AI. Transform your laptop into a powerful RAG system that can index and search through millions of documents while using <strong>97% less storage</strong> than traditional solutions <strong>without accuracy loss</strong>.</p> \n<p>LEANN achieves this through <em>graph-based selective recomputation</em> with <em>high-degree preserving pruning</em>, computing embeddings on-demand instead of storing them all. <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#%EF%B8%8F-architecture--how-it-works\">Illustration Fig →</a> | <a href=\"https://arxiv.org/abs/2506.08276\">Paper →</a></p> \n<p><strong>Ready to RAG Everything?</strong> Transform your laptop into a personal AI assistant that can semantic search your <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-personal-data-manager-process-any-documents-pdf-txt-md\">file system</a></strong>, <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-your-personal-email-secretary-rag-on-apple-mail\">emails</a></strong>, <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-time-machine-for-the-web-rag-your-entire-browser-history\">browser history</a></strong>, <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories\">chat history</a></strong> (<a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories\">WeChat</a>, <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-imessage-history-your-personal-conversation-archive\">iMessage</a>), <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive\">agent memory</a></strong> (<a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive\">ChatGPT</a>, <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-chat-history-your-personal-ai-conversation-archive\">Claude</a>), <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform\">live data</a></strong> (<a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#slack-messages-search-your-team-conversations\">Slack</a>, <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-twitter-bookmarks-your-personal-tweet-library\">Twitter</a>), <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-code-integration-transform-your-development-workflow\">codebase</a></strong>* , or external knowledge bases (i.e., 60M documents) - all on your laptop, with zero cloud costs and complete privacy.</p> \n<p>* Claude Code only supports basic <code>grep</code>-style keyword search. <strong>LEANN</strong> is a drop-in <strong>semantic search MCP service fully compatible with Claude Code</strong>, unlocking intelligent retrieval without changing your workflow. 🔥 Check out <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md\">the easy setup →</a></p> \n<h2>Why LEANN?</h2> \n<p align=\"center\"> <img alt=\"LEANN vs Traditional Vector DB Storage Comparison\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/effects.png\" width=\"70%\" /> </p> \n<blockquote> \n <p><strong>The numbers speak for themselves:</strong> Index 60 million text chunks in just 6GB instead of 201GB. From emails to browser history, everything fits on your laptop. <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-storage-comparison\">See detailed benchmarks for different applications below ↓</a></p> \n</blockquote> \n<p>🔒 <strong>Privacy:</strong> Your data never leaves your laptop. No OpenAI, no cloud, no \"terms of service\".</p> \n<p>🪶 <strong>Lightweight:</strong> Graph-based recomputation eliminates heavy embedding storage, while smart graph pruning and CSR format minimize graph storage overhead. Always less storage, less memory usage!</p> \n<p>📦 <strong>Portable:</strong> Transfer your entire knowledge base between devices (even with others) with minimal cost - your personal AI memory travels with you.</p> \n<p>📈 <strong>Scalability:</strong> Handle messy personal data that would crash traditional vector DBs, easily managing your growing personalized data and agent generated memory!</p> \n<p>✨ <strong>No Accuracy Loss:</strong> Maintain the same search quality as heavyweight solutions while using 97% less storage.</p> \n<h2>Installation</h2> \n<h3>📦 Prerequisites: Install uv</h3> \n<p><a href=\"https://docs.astral.sh/uv/getting-started/installation/#installation-methods\">Install uv</a> first if you don't have it. Typically, you can install it with:</p> \n<pre><code class=\"language-bash\">curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> \n<h3>🚀 Quick Install</h3> \n<p>Clone the repository to access all examples and try amazing applications,</p> \n<pre><code class=\"language-bash\">git clone https://github.com/yichuan-w/LEANN.git leann\ncd leann\n</code></pre> \n<p>and install LEANN from <a href=\"https://pypi.org/project/leann/\">PyPI</a> to run them immediately:</p> \n<pre><code class=\"language-bash\">uv venv\nsource .venv/bin/activate\nuv pip install leann\n</code></pre> \n<!--\n> Low-resource? See \"Low-resource setups\" in the [Configuration Guide](docs/configuration-guide.md#low-resource-setups). --> \n<details> \n  <strong>🔧 Build from Source (Recommended for development)</strong>  \n <pre><code class=\"language-bash\">git clone https://github.com/yichuan-w/LEANN.git leann\ncd leann\ngit submodule update --init --recursive\n</code></pre> \n <p><strong>macOS:</strong></p> \n <p>Note: DiskANN requires MacOS 13.3 or later.</p> \n <pre><code class=\"language-bash\">brew install libomp boost protobuf zeromq pkgconf\nuv sync --extra diskann\n</code></pre> \n <p><strong>Linux (Ubuntu/Debian):</strong></p> \n <p>Note: On Ubuntu 20.04, you may need to build a newer Abseil and pin Protobuf (e.g., v3.20.x) for building DiskANN. See <a href=\"https://github.com/yichuan-w/LEANN/issues/30\">Issue #30</a> for a step-by-step note.</p> \n <p>You can manually install <a href=\"https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html\">Intel oneAPI MKL</a> instead of <code>libmkl-full-dev</code> for DiskANN. You can also use <code>libopenblas-dev</code> for building HNSW only, by removing <code>--extra diskann</code> in the command below.</p> \n <pre><code class=\"language-bash\">sudo apt-get update &amp;&amp; sudo apt-get install -y \\\n  libomp-dev libboost-all-dev protobuf-compiler libzmq3-dev \\\n  pkg-config libabsl-dev libaio-dev libprotobuf-dev \\\n  libmkl-full-dev\n\nuv sync --extra diskann\n</code></pre> \n <p><strong>Linux (Arch Linux):</strong></p> \n <pre><code class=\"language-bash\">sudo pacman -Syu &amp;&amp; sudo pacman -S --needed base-devel cmake pkgconf git gcc \\\n  boost boost-libs protobuf abseil-cpp libaio zeromq\n\n# For MKL in DiskANN\nsudo pacman -S --needed base-devel git\ngit clone https://aur.archlinux.org/paru-bin.git\ncd paru-bin &amp;&amp; makepkg -si\nparu -S intel-oneapi-mkl intel-oneapi-compiler\nsource /opt/intel/oneapi/setvars.sh\n\nuv sync --extra diskann\n</code></pre> \n <p><strong>Linux (RHEL / CentOS Stream / Oracle / Rocky / AlmaLinux):</strong></p> \n <p>See <a href=\"https://github.com/yichuan-w/LEANN/issues/50\">Issue #50</a> for more details.</p> \n <pre><code class=\"language-bash\">sudo dnf groupinstall -y \"Development Tools\"\nsudo dnf install -y libomp-devel boost-devel protobuf-compiler protobuf-devel \\\n  abseil-cpp-devel libaio-devel zeromq-devel pkgconf-pkg-config\n\n# For MKL in DiskANN\nsudo dnf install -y intel-oneapi-mkl intel-oneapi-mkl-devel \\\n  intel-oneapi-openmp || sudo dnf install -y intel-oneapi-compiler\nsource /opt/intel/oneapi/setvars.sh\n\nuv sync --extra diskann\n</code></pre> \n</details> \n<h2>Quick Start</h2> \n<p>Our declarative API makes RAG as easy as writing a config file.</p> \n<p>Check out <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/demo.ipynb\">demo.ipynb</a> or <a href=\"https://colab.research.google.com/github/yichuan-w/LEANN/blob/main/demo.ipynb\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg?sanitize=true\" /></a></p> \n<pre><code class=\"language-python\">from leann import LeannBuilder, LeannSearcher, LeannChat\nfrom pathlib import Path\nINDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n\n# Build an index\nbuilder = LeannBuilder(backend_name=\"hnsw\")\nbuilder.add_text(\"LEANN saves 97% storage compared to traditional vector databases.\")\nbuilder.add_text(\"Tung Tung Tung Sahur called—they need their banana‑crocodile hybrid back\")\nbuilder.build_index(INDEX_PATH)\n\n# Search\nsearcher = LeannSearcher(INDEX_PATH)\nresults = searcher.search(\"fantastical AI-generated creatures\", top_k=1)\n\n# Chat with your data\nchat = LeannChat(INDEX_PATH, llm_config={\"type\": \"hf\", \"model\": \"Qwen/Qwen3-0.6B\"})\nresponse = chat.ask(\"How much storage does LEANN save?\", top_k=1)\n</code></pre> \n<h2>RAG on Everything!</h2> \n<p>LEANN supports RAG on various data sources including documents (<code>.pdf</code>, <code>.txt</code>, <code>.md</code>), Apple Mail, Google Search History, WeChat, ChatGPT conversations, Claude conversations, iMessage conversations, and <strong>live data from any platform through MCP (Model Context Protocol) servers</strong> - including Slack, Twitter, and more.</p> \n<h3>Generation Model Setup</h3> \n<h4>LLM Backend</h4> \n<p>LEANN supports many LLM providers for text generation (HuggingFace, Ollama, Anthropic, and Any OpenAI compatible API).</p> \n<details> \n <strong>🔑 OpenAI API Setup (Default)</strong> \n <p>Set your OpenAI API key as an environment variable:</p> \n <pre><code class=\"language-bash\">export OPENAI_API_KEY=\"your-api-key-here\"\n</code></pre> \n <p>Make sure to use <code>--llm openai</code> flag when using the CLI. You can also specify the model name with <code>--llm-model &lt;model-name&gt;</code> flag.</p> \n</details> \n<details> \n <strong>🛠️ Supported LLM &amp; Embedding Providers (via OpenAI Compatibility)</strong> \n <p>Thanks to the widespread adoption of the OpenAI API format, LEANN is compatible out-of-the-box with a vast array of LLM and embedding providers. Simply set the <code>OPENAI_BASE_URL</code> and <code>OPENAI_API_KEY</code> environment variables to connect to your preferred service.</p> \n <pre><code class=\"language-sh\">export OPENAI_API_KEY=\"xxx\"\nexport OPENAI_BASE_URL=\"http://localhost:1234/v1\" # base url of the provider\n</code></pre> \n <p>To use OpenAI compatible endpoint with the CLI interface:</p> \n <p>If you are using it for text generation, make sure to use <code>--llm openai</code> flag and specify the model name with <code>--llm-model &lt;model-name&gt;</code> flag.</p> \n <p>If you are using it for embedding, set the <code>--embedding-mode openai</code> flag and specify the model name with <code>--embedding-model &lt;MODEL&gt;</code>.</p> \n <hr /> \n <p>Below is a list of base URLs for common providers to get you started.</p> \n <h3>🖥️ Local Inference Engines (Recommended for full privacy)</h3> \n <table> \n  <thead> \n   <tr> \n    <th>Provider</th> \n    <th>Sample Base URL</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td><strong>Ollama</strong></td> \n    <td><code>http://localhost:11434/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>LM Studio</strong></td> \n    <td><code>http://localhost:1234/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>vLLM</strong></td> \n    <td><code>http://localhost:8000/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>llama.cpp</strong></td> \n    <td><code>http://localhost:8080/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>SGLang</strong></td> \n    <td><code>http://localhost:30000/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>LiteLLM</strong></td> \n    <td><code>http://localhost:4000</code></td> \n   </tr> \n  </tbody> \n </table> \n <hr /> \n <h3>☁️ Cloud Providers</h3> \n <blockquote> \n  <p><strong>🚨 A Note on Privacy:</strong> Before choosing a cloud provider, carefully review their privacy and data retention policies. Depending on their terms, your data may be used for their own purposes, including but not limited to human reviews and model training, which can lead to serious consequences if not handled properly.</p> \n </blockquote> \n <table> \n  <thead> \n   <tr> \n    <th>Provider</th> \n    <th>Base URL</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td><strong>OpenAI</strong></td> \n    <td><code>https://api.openai.com/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>OpenRouter</strong></td> \n    <td><code>https://openrouter.ai/api/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>Gemini</strong></td> \n    <td><code>https://generativelanguage.googleapis.com/v1beta/openai/</code></td> \n   </tr> \n   <tr> \n    <td><strong>x.AI (Grok)</strong></td> \n    <td><code>https://api.x.ai/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>Groq AI</strong></td> \n    <td><code>https://api.groq.com/openai/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>DeepSeek</strong></td> \n    <td><code>https://api.deepseek.com/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>SiliconFlow</strong></td> \n    <td><code>https://api.siliconflow.cn/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>Zhipu (BigModel)</strong></td> \n    <td><code>https://open.bigmodel.cn/api/paas/v4/</code></td> \n   </tr> \n   <tr> \n    <td><strong>Mistral AI</strong></td> \n    <td><code>https://api.mistral.ai/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>Anthropic</strong></td> \n    <td><code>https://api.anthropic.com/v1</code></td> \n   </tr> \n   <tr> \n    <td><strong>Jina AI</strong> (Embeddings)</td> \n    <td><code>https://api.jina.ai/v1</code></td> \n   </tr> \n  </tbody> \n </table> \n <blockquote> \n  <p><strong>💡 Tip: Separate Embedding Provider</strong></p> \n  <p>To use a different provider for embeddings (e.g., Jina AI) while using another for LLM, use <code>--embedding-api-base</code> and <code>--embedding-api-key</code>:</p> \n  <pre><code class=\"language-bash\">leann build my-index --docs ./docs \\\n  --embedding-mode openai \\\n  --embedding-model jina-embeddings-v3 \\\n  --embedding-api-base https://api.jina.ai/v1 \\\n  --embedding-api-key $JINA_API_KEY\n</code></pre> \n </blockquote> \n <p>If your provider isn't on this list, don't worry! Check their documentation for an OpenAI-compatible endpoint—chances are, it's OpenAI Compatible too!</p> \n</details> \n<details> \n <strong>🔧 Ollama Setup (Recommended for full privacy)</strong> \n <p><strong>macOS:</strong></p> \n <p>First, <a href=\"https://ollama.com/download/mac\">download Ollama for macOS</a>.</p> \n <pre><code class=\"language-bash\"># Pull a lightweight model (recommended for consumer hardware)\nollama pull llama3.2:1b\n</code></pre> \n <p><strong>Linux:</strong></p> \n <pre><code class=\"language-bash\"># Install Ollama\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Start Ollama service manually\nollama serve &amp;\n\n# Pull a lightweight model (recommended for consumer hardware)\nollama pull llama3.2:1b\n</code></pre> \n</details> \n<h2>⭐ Flexible Configuration</h2> \n<p>LEANN provides flexible parameters for embedding models, search strategies, and data processing to fit your specific needs.</p> \n<p>📚 <strong>Need configuration best practices?</strong> Check our <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/configuration-guide.md\">Configuration Guide</a> for detailed optimization tips, model selection advice, and solutions to common issues like slow embeddings or poor search quality.</p> \n<details> \n <strong>📋 Click to expand: Common Parameters (Available in All Examples)</strong> \n <p>All RAG examples share these common parameters. <strong>Interactive mode</strong> is available in all examples - simply run without <code>--query</code> to start a continuous Q&amp;A session where you can ask multiple questions. Type 'quit' to exit.</p> \n <pre><code class=\"language-bash\"># Environment Variables (GPU Device Selection)\nLEANN_EMBEDDING_DEVICE       # GPU for embedding model (e.g., cuda:0, cuda:1, cpu)\nLEANN_LLM_DEVICE             # GPU for HFChat LLM (e.g., cuda:1, or \"cuda\" for multi-GPU auto)\n\n# Core Parameters (General preprocessing for all examples)\n--index-dir DIR              # Directory to store the index (default: current directory)\n--query \"YOUR QUESTION\"      # Single query mode. Omit for interactive chat (type 'quit' to exit), and now you can play with your index interactively\n--max-items N                # Limit data preprocessing (default: -1, process all data)\n--force-rebuild              # Force rebuild index even if it exists\n\n# Embedding Parameters\n--embedding-model MODEL      # e.g., facebook/contriever, text-embedding-3-small, mlx-community/Qwen3-Embedding-0.6B-8bit or nomic-embed-text\n--embedding-mode MODE        # sentence-transformers, openai, mlx, or ollama\n\n# LLM Parameters (Text generation models)\n--llm TYPE                   # LLM backend: openai, ollama, hf, or anthropic (default: openai)\n--llm-model MODEL            # Model name (default: gpt-4o) e.g., gpt-4o-mini, llama3.2:1b, Qwen/Qwen2.5-1.5B-Instruct\n--thinking-budget LEVEL      # Thinking budget for reasoning models: low/medium/high (supported by o3, o3-mini, GPT-Oss:20b, and other reasoning models)\n\n# Search Parameters\n--top-k N                    # Number of results to retrieve (default: 20)\n--search-complexity N        # Search complexity for graph traversal (default: 32)\n\n# Chunking Parameters\n--chunk-size N               # Size of text chunks (default varies by source: 256 for most, 192 for WeChat)\n--chunk-overlap N            # Overlap between chunks (default varies: 25-128 depending on source)\n\n# Index Building Parameters\n--backend-name NAME          # Backend to use: hnsw or diskann (default: hnsw)\n--graph-degree N             # Graph degree for index construction (default: 32)\n--build-complexity N         # Build complexity for index construction (default: 64)\n--compact / --no-compact     # Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.\n--recompute / --no-recompute # Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.\n</code></pre> \n</details> \n<h3>📄 Personal Data Manager: Process Any Documents (<code>.pdf</code>, <code>.txt</code>, <code>.md</code>)!</h3> \n<p>Ask questions directly about your personal PDFs, documents, and any directory containing your files!</p> \n<p align=\"center\"> <img alt=\"LEANN Document Search Demo\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/paper_clear.gif\" width=\"600\" /> </p> \n<p>The example below asks a question about summarizing our paper (uses default data in <code>data/</code>, which is a directory with diverse data sources: two papers, Pride and Prejudice, and a Technical report about LLM in Huawei in Chinese), and this is the <strong>easiest example</strong> to run here:</p> \n<pre><code class=\"language-bash\">source .venv/bin/activate # Don't forget to activate the virtual environment\npython -m apps.document_rag --query \"What are the main techniques LEANN explores?\"\n</code></pre> \n<details> \n <strong>📋 Click to expand: Document-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--data-dir DIR           # Directory containing documents to process (default: data)\n--file-types .ext .ext   # Filter by specific file types (optional - all LlamaIndex supported types if omitted)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Process all documents with larger chunks for academic papers\npython -m apps.document_rag --data-dir \"~/Documents/Papers\" --chunk-size 1024\n\n# Filter only markdown and Python files with smaller chunks\npython -m apps.document_rag --data-dir \"./docs\" --chunk-size 256 --file-types .md .py\n\n# Enable AST-aware chunking for code files\npython -m apps.document_rag --enable-code-chunking --data-dir \"./my_project\"\n\n# Or use the specialized code RAG for better code understanding\npython -m apps.code_rag --repo-dir \"./my_codebase\" --query \"How does authentication work?\"\n</code></pre> \n</details> \n<h3>🎨 ColQwen: Multimodal PDF Retrieval with Vision-Language Models</h3> \n<p>Search through PDFs using both text and visual understanding with ColQwen2/ColPali models. Perfect for research papers, technical documents, and any PDFs with complex layouts, figures, or diagrams.</p> \n<blockquote> \n <p><strong>🍎 Mac Users</strong>: ColQwen is optimized for Apple Silicon with MPS acceleration for faster inference!</p> \n</blockquote> \n<pre><code class=\"language-bash\"># Build index from PDFs\npython -m apps.colqwen_rag build --pdfs ./my_papers/ --index research_papers\n\n# Search with text queries\npython -m apps.colqwen_rag search research_papers \"How does attention mechanism work?\"\n\n# Interactive Q&amp;A\npython -m apps.colqwen_rag ask research_papers --interactive\n</code></pre> \n<details> \n <strong>📋 Click to expand: ColQwen Setup &amp; Usage</strong> \n <h4>Prerequisites</h4> \n <pre><code class=\"language-bash\"># Install dependencies\nuv pip install colpali_engine pdf2image pillow matplotlib qwen_vl_utils einops seaborn\nbrew install poppler  # macOS only, for PDF processing\n</code></pre> \n <h4>Build Index</h4> \n <pre><code class=\"language-bash\">python -m apps.colqwen_rag build \\\n  --pdfs ./pdf_directory/ \\\n  --index my_index \\\n  --model colqwen2  # or colpali\n</code></pre> \n <h4>Search</h4> \n <pre><code class=\"language-bash\">python -m apps.colqwen_rag search my_index \"your question here\" --top-k 5\n</code></pre> \n <h4>Models</h4> \n <ul> \n  <li><strong>ColQwen2</strong> (<code>colqwen2</code>): Latest vision-language model with improved performance</li> \n  <li><strong>ColPali</strong> (<code>colpali</code>): Proven multimodal retriever</li> \n </ul> \n <p>For detailed usage, see the <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/COLQWEN_GUIDE.md\">ColQwen Guide</a>.</p> \n</details> \n<h3>📧 Your Personal Email Secretary: RAG on Apple Mail!</h3> \n<blockquote> \n <p><strong>Note:</strong> The examples below currently support macOS only. Windows support coming soon.</p> \n</blockquote> \n<p align=\"center\"> <img alt=\"LEANN Email Search Demo\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/mail_clear.gif\" width=\"600\" /> </p> \n<p>Before running the example below, you need to grant full disk access to your terminal/VS Code in System Preferences → Privacy &amp; Security → Full Disk Access.</p> \n<pre><code class=\"language-bash\">python -m apps.email_rag --query \"What's the food I ordered by DoorDash or Uber Eats mostly?\"\n</code></pre> \n<p><strong>780K email chunks → 78MB storage.</strong> Finally, search your email like you search Google.</p> \n<details> \n <strong>📋 Click to expand: Email-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--mail-path PATH         # Path to specific mail directory (auto-detects if omitted)\n--include-html          # Include HTML content in processing (useful for newsletters)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Search work emails from a specific account\npython -m apps.email_rag --mail-path \"~/Library/Mail/V10/WORK_ACCOUNT\"\n\n# Find all receipts and order confirmations (includes HTML)\npython -m apps.email_rag --query \"receipt order confirmation invoice\" --include-html\n</code></pre> \n</details> \n<details> \n <strong>📋 Click to expand: Example queries you can try</strong> \n <p>Once the index is built, you can ask questions like:</p> \n <ul> \n  <li>\"Find emails from my boss about deadlines\"</li> \n  <li>\"What did John say about the project timeline?\"</li> \n  <li>\"Show me emails about travel expenses\"</li> \n </ul> \n</details> \n<h3>🔍 Time Machine for the Web: RAG Your Entire Chrome Browser History!</h3> \n<p align=\"center\"> <img alt=\"LEANN Browser History Search Demo\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/google_clear.gif\" width=\"600\" /> </p> \n<pre><code class=\"language-bash\">python -m apps.browser_rag --query \"Tell me my browser history about machine learning?\"\n</code></pre> \n<p><strong>38K browser entries → 6MB storage.</strong> Your browser history becomes your personal search engine.</p> \n<details> \n <strong>📋 Click to expand: Browser-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--chrome-profile PATH    # Path to Chrome profile directory (auto-detects if omitted)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Search academic research from your browsing history\npython -m apps.browser_rag --query \"arxiv papers machine learning transformer architecture\"\n\n# Track competitor analysis across work profile\npython -m apps.browser_rag --chrome-profile \"~/Library/Application Support/Google/Chrome/Work Profile\" --max-items 5000\n</code></pre> \n</details> \n<details> \n <strong>📋 Click to expand: How to find your Chrome profile</strong> \n <p>The default Chrome profile path is configured for a typical macOS setup. If you need to find your specific Chrome profile:</p> \n <ol> \n  <li>Open Terminal</li> \n  <li>Run: <code>ls ~/Library/Application\\ Support/Google/Chrome/</code></li> \n  <li>Look for folders like \"Default\", \"Profile 1\", \"Profile 2\", etc.</li> \n  <li>Use the full path as your <code>--chrome-profile</code> argument</li> \n </ol> \n <p><strong>Common Chrome profile locations:</strong></p> \n <ul> \n  <li>macOS: <code>~/Library/Application Support/Google/Chrome/Default</code></li> \n  <li>Linux: <code>~/.config/google-chrome/Default</code></li> \n </ul> \n</details> \n<details> \n <strong>💬 Click to expand: Example queries you can try</strong> \n <p>Once the index is built, you can ask questions like:</p> \n <ul> \n  <li>\"What websites did I visit about machine learning?\"</li> \n  <li>\"Find my search history about programming\"</li> \n  <li>\"What YouTube videos did I watch recently?\"</li> \n  <li>\"Show me websites I visited about travel planning\"</li> \n </ul> \n</details> \n<h3>💬 WeChat Detective: Unlock Your Golden Memories!</h3> \n<p align=\"center\"> <img alt=\"LEANN WeChat Search Demo\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/wechat_clear.gif\" width=\"600\" /> </p> \n<pre><code class=\"language-bash\">python -m apps.wechat_rag --query \"Show me all group chats about weekend plans\"\n</code></pre> \n<p><strong>400K messages → 64MB storage</strong> Search years of chat history in any language.</p> \n<details> \n <strong>🔧 Click to expand: Installation Requirements</strong> \n <p>First, you need to install the <a href=\"https://github.com/sunnyyoung/WeChatTweak-CLI\">WeChat exporter</a>,</p> \n <pre><code class=\"language-bash\">brew install sunnyyoung/repo/wechattweak-cli\n</code></pre> \n <p>or install it manually (if you have issues with Homebrew):</p> \n <pre><code class=\"language-bash\">sudo packages/wechat-exporter/wechattweak-cli install\n</code></pre> \n <p><strong>Troubleshooting:</strong></p> \n <ul> \n  <li><strong>Installation issues</strong>: Check the <a href=\"https://github.com/sunnyyoung/WeChatTweak-CLI/issues/41\">WeChatTweak-CLI issues page</a></li> \n  <li><strong>Export errors</strong>: If you encounter the error below, try restarting WeChat <pre><code class=\"language-bash\">Failed to export WeChat data. Please ensure WeChat is running and WeChatTweak is installed.\nFailed to find or export WeChat data. Exiting.\n</code></pre> </li> \n </ul> \n</details> \n<details> \n <strong>📋 Click to expand: WeChat-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--export-dir DIR         # Directory to store exported WeChat data (default: wechat_export_direct)\n--force-export          # Force re-export even if data exists\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Search for travel plans discussed in group chats\npython -m apps.wechat_rag --query \"travel plans\" --max-items 10000\n\n# Re-export and search recent chats (useful after new messages)\npython -m apps.wechat_rag --force-export --query \"work schedule\"\n</code></pre> \n</details> \n<details> \n <strong>💬 Click to expand: Example queries you can try</strong> \n <p>Once the index is built, you can ask questions like:</p> \n <ul> \n  <li>\"我想买魔术师约翰逊的球衣，给我一些对应聊天记录?\" (Chinese: Show me chat records about buying Magic Johnson's jersey)</li> \n </ul> \n</details> \n<h3>🤖 ChatGPT Chat History: Your Personal AI Conversation Archive!</h3> \n<p>Transform your ChatGPT conversations into a searchable knowledge base! Search through all your ChatGPT discussions about coding, research, brainstorming, and more.</p> \n<pre><code class=\"language-bash\">python -m apps.chatgpt_rag --export-path chatgpt_export.html --query \"How do I create a list in Python?\"\n</code></pre> \n<p><strong>Unlock your AI conversation history.</strong> Never lose track of valuable insights from your ChatGPT discussions again.</p> \n<details> \n <strong>📋 Click to expand: How to Export ChatGPT Data</strong> \n <p><strong>Step-by-step export process:</strong></p> \n <ol> \n  <li><strong>Sign in to ChatGPT</strong></li> \n  <li><strong>Click your profile icon</strong> in the top right corner</li> \n  <li><strong>Navigate to Settings</strong> → <strong>Data Controls</strong></li> \n  <li><strong>Click \"Export\"</strong> under Export Data</li> \n  <li><strong>Confirm the export</strong> request</li> \n  <li><strong>Download the ZIP file</strong> from the email link (expires in 24 hours)</li> \n  <li><strong>Extract or use directly</strong> with LEANN</li> \n </ol> \n <p><strong>Supported formats:</strong></p> \n <ul> \n  <li><code>.html</code> files from ChatGPT exports</li> \n  <li><code>.zip</code> archives from ChatGPT</li> \n  <li>Directories with multiple export files</li> \n </ul> \n</details> \n<details> \n <strong>📋 Click to expand: ChatGPT-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--export-path PATH           # Path to ChatGPT export file (.html/.zip) or directory (default: ./chatgpt_export)\n--separate-messages         # Process each message separately instead of concatenated conversations\n--chunk-size N              # Text chunk size (default: 512)\n--chunk-overlap N           # Overlap between chunks (default: 128)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Basic usage with HTML export\npython -m apps.chatgpt_rag --export-path conversations.html\n\n# Process ZIP archive from ChatGPT\npython -m apps.chatgpt_rag --export-path chatgpt_export.zip\n\n# Search with specific query\npython -m apps.chatgpt_rag --export-path chatgpt_data.html --query \"Python programming help\"\n\n# Process individual messages for fine-grained search\npython -m apps.chatgpt_rag --separate-messages --export-path chatgpt_export.html\n\n# Process directory containing multiple exports\npython -m apps.chatgpt_rag --export-path ./chatgpt_exports/ --max-items 1000\n</code></pre> \n</details> \n<details> \n <strong>💡 Click to expand: Example queries you can try</strong> \n <p>Once your ChatGPT conversations are indexed, you can search with queries like:</p> \n <ul> \n  <li>\"What did I ask ChatGPT about Python programming?\"</li> \n  <li>\"Show me conversations about machine learning algorithms\"</li> \n  <li>\"Find discussions about web development frameworks\"</li> \n  <li>\"What coding advice did ChatGPT give me?\"</li> \n  <li>\"Search for conversations about debugging techniques\"</li> \n  <li>\"Find ChatGPT's recommendations for learning resources\"</li> \n </ul> \n</details> \n<h3>🤖 Claude Chat History: Your Personal AI Conversation Archive!</h3> \n<p>Transform your Claude conversations into a searchable knowledge base! Search through all your Claude discussions about coding, research, brainstorming, and more.</p> \n<pre><code class=\"language-bash\">python -m apps.claude_rag --export-path claude_export.json --query \"What did I ask about Python dictionaries?\"\n</code></pre> \n<p><strong>Unlock your AI conversation history.</strong> Never lose track of valuable insights from your Claude discussions again.</p> \n<details> \n <strong>📋 Click to expand: How to Export Claude Data</strong> \n <p><strong>Step-by-step export process:</strong></p> \n <ol> \n  <li><strong>Open Claude</strong> in your browser</li> \n  <li><strong>Navigate to Settings</strong> (look for gear icon or settings menu)</li> \n  <li><strong>Find Export/Download</strong> options in your account settings</li> \n  <li><strong>Download conversation data</strong> (usually in JSON format)</li> \n  <li><strong>Place the file</strong> in your project directory</li> \n </ol> \n <p><em>Note: Claude export methods may vary depending on the interface you're using. Check Claude's help documentation for the most current export instructions.</em></p> \n <p><strong>Supported formats:</strong></p> \n <ul> \n  <li><code>.json</code> files (recommended)</li> \n  <li><code>.zip</code> archives containing JSON data</li> \n  <li>Directories with multiple export files</li> \n </ul> \n</details> \n<details> \n <strong>📋 Click to expand: Claude-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--export-path PATH           # Path to Claude export file (.json/.zip) or directory (default: ./claude_export)\n--separate-messages         # Process each message separately instead of concatenated conversations\n--chunk-size N              # Text chunk size (default: 512)\n--chunk-overlap N           # Overlap between chunks (default: 128)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Basic usage with JSON export\npython -m apps.claude_rag --export-path my_claude_conversations.json\n\n# Process ZIP archive from Claude\npython -m apps.claude_rag --export-path claude_export.zip\n\n# Search with specific query\npython -m apps.claude_rag --export-path claude_data.json --query \"machine learning advice\"\n\n# Process individual messages for fine-grained search\npython -m apps.claude_rag --separate-messages --export-path claude_export.json\n\n# Process directory containing multiple exports\npython -m apps.claude_rag --export-path ./claude_exports/ --max-items 1000\n</code></pre> \n</details> \n<details> \n <strong>💡 Click to expand: Example queries you can try</strong> \n <p>Once your Claude conversations are indexed, you can search with queries like:</p> \n <ul> \n  <li>\"What did I ask Claude about Python programming?\"</li> \n  <li>\"Show me conversations about machine learning algorithms\"</li> \n  <li>\"Find discussions about software architecture patterns\"</li> \n  <li>\"What debugging advice did Claude give me?\"</li> \n  <li>\"Search for conversations about data structures\"</li> \n  <li>\"Find Claude's recommendations for learning resources\"</li> \n </ul> \n</details> \n<h3>💬 iMessage History: Your Personal Conversation Archive!</h3> \n<p>Transform your iMessage conversations into a searchable knowledge base! Search through all your text messages, group chats, and conversations with friends, family, and colleagues.</p> \n<pre><code class=\"language-bash\">python -m apps.imessage_rag --query \"What did we discuss about the weekend plans?\"\n</code></pre> \n<p><strong>Unlock your message history.</strong> Never lose track of important conversations, shared links, or memorable moments from your iMessage history.</p> \n<details> \n <strong>📋 Click to expand: How to Access iMessage Data</strong> \n <p><strong>iMessage data location:</strong></p> \n <p>iMessage conversations are stored in a SQLite database on your Mac at:</p> \n <pre><code>~/Library/Messages/chat.db\n</code></pre> \n <p><strong>Important setup requirements:</strong></p> \n <ol> \n  <li> <p><strong>Grant Full Disk Access</strong> to your terminal or IDE:</p> \n   <ul> \n    <li>Open <strong>System Preferences</strong> → <strong>Security &amp; Privacy</strong> → <strong>Privacy</strong></li> \n    <li>Select <strong>Full Disk Access</strong> from the left sidebar</li> \n    <li>Click the <strong>+</strong> button and add your terminal app (Terminal, iTerm2) or IDE (VS Code, etc.)</li> \n    <li>Restart your terminal/IDE after granting access</li> \n   </ul> </li> \n  <li> <p><strong>Alternative: Use a backup database</strong></p> \n   <ul> \n    <li>If you have Time Machine backups or manual copies of the database</li> \n    <li>Use <code>--db-path</code> to specify a custom location</li> \n   </ul> </li> \n </ol> \n <p><strong>Supported formats:</strong></p> \n <ul> \n  <li>Direct access to <code>~/Library/Messages/chat.db</code> (default)</li> \n  <li>Custom database path with <code>--db-path</code></li> \n  <li>Works with backup copies of the database</li> \n </ul> \n</details> \n<details> \n <strong>📋 Click to expand: iMessage-Specific Arguments</strong> \n <h4>Parameters</h4> \n <pre><code class=\"language-bash\">--db-path PATH                    # Path to chat.db file (default: ~/Library/Messages/chat.db)\n--concatenate-conversations       # Group messages by conversation (default: True)\n--no-concatenate-conversations    # Process each message individually\n--chunk-size N                    # Text chunk size (default: 1000)\n--chunk-overlap N                 # Overlap between chunks (default: 200)\n</code></pre> \n <h4>Example Commands</h4> \n <pre><code class=\"language-bash\"># Basic usage (requires Full Disk Access)\npython -m apps.imessage_rag\n\n# Search with specific query\npython -m apps.imessage_rag --query \"family dinner plans\"\n\n# Use custom database path\npython -m apps.imessage_rag --db-path /path/to/backup/chat.db\n\n# Process individual messages instead of conversations\npython -m apps.imessage_rag --no-concatenate-conversations\n\n# Limit processing for testing\npython -m apps.imessage_rag --max-items 100 --query \"weekend\"\n</code></pre> \n</details> \n<details> \n <strong>💡 Click to expand: Example queries you can try</strong> \n <p>Once your iMessage conversations are indexed, you can search with queries like:</p> \n <ul> \n  <li>\"What did we discuss about vacation plans?\"</li> \n  <li>\"Find messages about restaurant recommendations\"</li> \n  <li>\"Show me conversations with John about the project\"</li> \n  <li>\"Search for shared links about technology\"</li> \n  <li>\"Find group chat discussions about weekend events\"</li> \n  <li>\"What did mom say about the family gathering?\"</li> \n </ul> \n</details> \n<h3>MCP Integration: RAG on Live Data from Any Platform</h3> \n<p>Connect to live data sources through the Model Context Protocol (MCP). LEANN now supports real-time RAG on platforms like Slack, Twitter, and more through standardized MCP servers.</p> \n<p><strong>Key Benefits:</strong></p> \n<ul> \n <li><strong>Live Data Access</strong>: Fetch real-time data without manual exports</li> \n <li><strong>Standardized Protocol</strong>: Use any MCP-compatible server</li> \n <li><strong>Easy Extension</strong>: Add new platforms with minimal code</li> \n <li><strong>Secure Access</strong>: MCP servers handle authentication</li> \n</ul> \n<h4>💬 Slack Messages: Search Your Team Conversations</h4> \n<p>Transform your Slack workspace into a searchable knowledge base! Find discussions, decisions, and shared knowledge across all your channels.</p> \n<pre><code class=\"language-bash\"># Test MCP server connection\npython -m apps.slack_rag --mcp-server \"slack-mcp-server\" --test-connection\n\n# Index and search Slack messages\npython -m apps.slack_rag \\\n  --mcp-server \"slack-mcp-server\" \\\n  --workspace-name \"my-team\" \\\n  --channels general dev-team random \\\n  --query \"What did we decide about the product launch?\"\n</code></pre> \n<p><strong>📖 Comprehensive Setup Guide</strong>: For detailed setup instructions, troubleshooting common issues (like \"users cache is not ready yet\"), and advanced configuration options, see our <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/slack-setup-guide.md\"><strong>Slack Setup Guide</strong></a>.</p> \n<p><strong>Quick Setup:</strong></p> \n<ol> \n <li>Install a Slack MCP server (e.g., <code>npm install -g slack-mcp-server</code>)</li> \n <li>Create a Slack App and get API credentials (see detailed guide above)</li> \n <li>Set environment variables: <pre><code class=\"language-bash\">export SLACK_BOT_TOKEN=\"xoxb-your-bot-token\"\nexport SLACK_APP_TOKEN=\"xapp-your-app-token\"  # Optional\n</code></pre> </li> \n <li>Test connection with <code>--test-connection</code> flag</li> \n</ol> \n<p><strong>Arguments:</strong></p> \n<ul> \n <li><code>--mcp-server</code>: Command to start the Slack MCP server</li> \n <li><code>--workspace-name</code>: Slack workspace name for organization</li> \n <li><code>--channels</code>: Specific channels to index (optional)</li> \n <li><code>--concatenate-conversations</code>: Group messages by channel (default: true)</li> \n <li><code>--max-messages-per-channel</code>: Limit messages per channel (default: 100)</li> \n <li><code>--max-retries</code>: Maximum retries for cache sync issues (default: 5)</li> \n <li><code>--retry-delay</code>: Initial delay between retries in seconds (default: 2.0)</li> \n</ul> \n<h4>🐦 Twitter Bookmarks: Your Personal Tweet Library</h4> \n<p>Search through your Twitter bookmarks! Find that perfect article, thread, or insight you saved for later.</p> \n<pre><code class=\"language-bash\"># Test MCP server connection\npython -m apps.twitter_rag --mcp-server \"twitter-mcp-server\" --test-connection\n\n# Index and search Twitter bookmarks\npython -m apps.twitter_rag \\\n  --mcp-server \"twitter-mcp-server\" \\\n  --max-bookmarks 1000 \\\n  --query \"What AI articles did I bookmark about machine learning?\"\n</code></pre> \n<p><strong>Setup Requirements:</strong></p> \n<ol> \n <li>Install a Twitter MCP server (e.g., <code>npm install -g twitter-mcp-server</code>)</li> \n <li>Get Twitter API credentials: \n  <ul> \n   <li>Apply for a Twitter Developer Account at <a href=\"https://developer.twitter.com\">developer.twitter.com</a></li> \n   <li>Create a new app in the Twitter Developer Portal</li> \n   <li>Generate API keys and access tokens with \"Read\" permissions</li> \n   <li>For bookmarks access, you may need Twitter API v2 with appropriate scopes</li> \n  </ul> <pre><code class=\"language-bash\">export TWITTER_API_KEY=\"your-api-key\"\nexport TWITTER_API_SECRET=\"your-api-secret\"\nexport TWITTER_ACCESS_TOKEN=\"your-access-token\"\nexport TWITTER_ACCESS_TOKEN_SECRET=\"your-access-token-secret\"\n</code></pre> </li> \n <li>Test connection with <code>--test-connection</code> flag</li> \n</ol> \n<p><strong>Arguments:</strong></p> \n<ul> \n <li><code>--mcp-server</code>: Command to start the Twitter MCP server</li> \n <li><code>--username</code>: Filter bookmarks by username (optional)</li> \n <li><code>--max-bookmarks</code>: Maximum bookmarks to fetch (default: 1000)</li> \n <li><code>--no-tweet-content</code>: Exclude tweet content, only metadata</li> \n <li><code>--no-metadata</code>: Exclude engagement metadata</li> \n</ul>  \n<details> \n <strong>💡 Click to expand: Example queries you can try</strong> \n <p><strong>Slack Queries:</strong></p> \n <ul> \n  <li>\"What did the team discuss about the project deadline?\"</li> \n  <li>\"Find messages about the new feature launch\"</li> \n  <li>\"Show me conversations about budget planning\"</li> \n  <li>\"What decisions were made in the dev-team channel?\"</li> \n </ul> \n <p><strong>Twitter Queries:</strong></p> \n <ul> \n  <li>\"What AI articles did I bookmark last month?\"</li> \n  <li>\"Find tweets about machine learning techniques\"</li> \n  <li>\"Show me bookmarked threads about startup advice\"</li> \n  <li>\"What Python tutorials did I save?\"</li> \n </ul> \n</details> \n<strong>🔧 Using MCP with CLI Commands</strong> \n<p><strong>Want to use MCP data with regular LEANN CLI?</strong> You can combine MCP apps with CLI commands:</p> \n<pre><code class=\"language-bash\"># Step 1: Use MCP app to fetch and index data\npython -m apps.slack_rag --mcp-server \"slack-mcp-server\" --workspace-name \"my-team\"\n\n# Step 2: The data is now indexed and available via CLI\nleann search slack_messages \"project deadline\"\nleann ask slack_messages \"What decisions were made about the product launch?\"\n\n# Same for Twitter bookmarks\npython -m apps.twitter_rag --mcp-server \"twitter-mcp-server\"\nleann search twitter_bookmarks \"machine learning articles\"\n</code></pre> \n<p><strong>MCP vs Manual Export:</strong></p> \n<ul> \n <li><strong>MCP</strong>: Live data, automatic updates, requires server setup</li> \n <li><strong>Manual Export</strong>: One-time setup, works offline, requires manual data export</li> \n</ul>  \n<details> \n <strong>🔧 Adding New MCP Platforms</strong> \n <p>Want to add support for other platforms? LEANN's MCP integration is designed for easy extension:</p> \n <ol> \n  <li><strong>Find or create an MCP server</strong> for your platform</li> \n  <li><strong>Create a reader class</strong> following the pattern in <code>apps/slack_data/slack_mcp_reader.py</code></li> \n  <li><strong>Create a RAG application</strong> following the pattern in <code>apps/slack_rag.py</code></li> \n  <li><strong>Test and contribute</strong> back to the community!</li> \n </ol> \n <p><strong>Popular MCP servers to explore:</strong></p> \n <ul> \n  <li>GitHub repositories and issues</li> \n  <li>Discord messages</li> \n  <li>Notion pages</li> \n  <li>Google Drive documents</li> \n  <li>And many more in the MCP ecosystem!</li> \n </ul> \n</details> \n<h3>🚀 Claude Code Integration: Transform Your Development Workflow!</h3> \n<details> \n <strong>AST‑Aware Code Chunking</strong> \n <p>LEANN features intelligent code chunking that preserves semantic boundaries (functions, classes, methods) for Python, Java, C#, and TypeScript, improving code understanding compared to text-based chunking.</p> \n <p>📖 Read the <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/ast_chunking_guide.md\">AST Chunking Guide →</a></p> \n</details> \n<p><strong>The future of code assistance is here.</strong> Transform your development workflow with LEANN's native MCP integration for Claude Code. Index your entire codebase and get intelligent code assistance directly in your IDE.</p> \n<p><strong>Key features:</strong></p> \n<ul> \n <li>🔍 <strong>Semantic code search</strong> across your entire project, fully local index and lightweight</li> \n <li>🧠 <strong>AST-aware chunking</strong> preserves code structure (functions, classes)</li> \n <li>📚 <strong>Context-aware assistance</strong> for debugging and development</li> \n <li>🚀 <strong>Zero-config setup</strong> with automatic language detection</li> \n</ul> \n<pre><code class=\"language-bash\"># Install LEANN globally for MCP integration\nuv tool install leann-core --with leann\nclaude mcp add --scope user leann-server -- leann_mcp\n# Setup is automatic - just start using Claude Code!\n</code></pre> \n<p>Try our fully agentic pipeline with auto query rewriting, semantic search planning, and more:</p> \n<p><img alt=\"LEANN MCP Integration\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/mcp_leann.png\" /></p> \n<p><strong>🔥 Ready to supercharge your coding?</strong> <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md\">Complete Setup Guide →</a></p> \n<h2>Command Line Interface</h2> \n<p>LEANN includes a powerful CLI for document processing and search. Perfect for quick document indexing and interactive chat.</p> \n<h3>Installation</h3> \n<p>If you followed the Quick Start, <code>leann</code> is already installed in your virtual environment:</p> \n<pre><code class=\"language-bash\">source .venv/bin/activate\nleann --help\n</code></pre> \n<p><strong>To make it globally available:</strong></p> \n<pre><code class=\"language-bash\"># Install the LEANN CLI globally using uv tool\nuv tool install leann-core --with leann\n\n\n# Now you can use leann from anywhere without activating venv\nleann --help\n</code></pre> \n<blockquote> \n <p><strong>Note</strong>: Global installation is required for Claude Code integration. The <code>leann_mcp</code> server depends on the globally available <code>leann</code> command.</p> \n</blockquote> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># build from a specific directory, and my_docs is the index name(Here you can also build from multiple dict or multiple files)\nleann build my-docs --docs ./your_documents\n\n# Search your documents\nleann search my-docs \"machine learning concepts\"\n\n# Interactive chat with your documents\nleann ask my-docs --interactive\n\n# Ask a single question (non-interactive)\nleann ask my-docs \"Where are prompts configured?\"\n\n# List all your indexes\nleann list\n\n# Remove an index\nleann remove my-docs\n</code></pre> \n<p><strong>Key CLI features:</strong></p> \n<ul> \n <li>Auto-detects document formats (PDF, TXT, MD, DOCX, PPTX + code files)</li> \n <li><strong>🧠 AST-aware chunking</strong> for Python, Java, C#, TypeScript files</li> \n <li>Smart text chunking with overlap for all other content</li> \n <li>Multiple LLM providers (Ollama, OpenAI, HuggingFace)</li> \n <li>Organized index storage in <code>.leann/indexes/</code> (project-local)</li> \n <li>Support for advanced search parameters</li> \n</ul> \n<details> \n <strong>📋 Click to expand: Complete CLI Reference</strong> \n <p>You can use <code>leann --help</code>, or <code>leann build --help</code>, <code>leann search --help</code>, <code>leann ask --help</code>, <code>leann list --help</code>, <code>leann remove --help</code> to get the complete CLI reference.</p> \n <p><strong>Build Command:</strong></p> \n <pre><code class=\"language-bash\">leann build INDEX_NAME --docs DIRECTORY|FILE [DIRECTORY|FILE ...] [OPTIONS]\n\nOptions:\n  --backend {hnsw,diskann}     Backend to use (default: hnsw)\n  --embedding-model MODEL      Embedding model (default: facebook/contriever)\n  --graph-degree N             Graph degree (default: 32)\n  --complexity N               Build complexity (default: 64)\n  --force                      Force rebuild existing index\n  --compact / --no-compact     Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.\n  --recompute / --no-recompute Enable recomputation (default: true)\n</code></pre> \n <p><strong>Search Command:</strong></p> \n <pre><code class=\"language-bash\">leann search INDEX_NAME QUERY [OPTIONS]\n\nOptions:\n  --top-k N                     Number of results (default: 5)\n  --complexity N                Search complexity (default: 64)\n  --recompute / --no-recompute  Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.\n  --pruning-strategy {global,local,proportional}\n</code></pre> \n <p><strong>Ask Command:</strong></p> \n <pre><code class=\"language-bash\">leann ask INDEX_NAME [OPTIONS]\n\nOptions:\n  --llm {ollama,openai,hf,anthropic}    LLM provider (default: ollama)\n  --model MODEL                         Model name (default: qwen3:8b)\n  --interactive                         Interactive chat mode\n  --top-k N                             Retrieval count (default: 20)\n</code></pre> \n <p><strong>List Command:</strong></p> \n <pre><code class=\"language-bash\">leann list\n\n# Lists all indexes across all projects with status indicators:\n# ✅ - Index is complete and ready to use\n# ❌ - Index is incomplete or corrupted\n# 📁 - CLI-created index (in .leann/indexes/)\n# 📄 - App-created index (*.leann.meta.json files)\n</code></pre> \n <p><strong>Remove Command:</strong></p> \n <pre><code class=\"language-bash\">leann remove INDEX_NAME [OPTIONS]\n\nOptions:\n  --force, -f    Force removal without confirmation\n\n# Smart removal: automatically finds and safely removes indexes\n# - Shows all matching indexes across projects\n# - Requires confirmation for cross-project removal\n# - Interactive selection when multiple matches found\n# - Supports both CLI and app-created indexes\n</code></pre> \n</details> \n<h2>🚀 Advanced Features</h2> \n<h3>🎯 Metadata Filtering</h3> \n<p>LEANN supports a simple metadata filtering system to enable sophisticated use cases like document filtering by date/type, code search by file extension, and content management based on custom criteria.</p> \n<pre><code class=\"language-python\"># Add metadata during indexing\nbuilder.add_text(\n    \"def authenticate_user(token): ...\",\n    metadata={\"file_extension\": \".py\", \"lines_of_code\": 25}\n)\n\n# Search with filters\nresults = searcher.search(\n    query=\"authentication function\",\n    metadata_filters={\n        \"file_extension\": {\"==\": \".py\"},\n        \"lines_of_code\": {\"&lt;\": 100}\n    }\n)\n</code></pre> \n<p><strong>Supported operators</strong>: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>in</code>, <code>not_in</code>, <code>contains</code>, <code>starts_with</code>, <code>ends_with</code>, <code>is_true</code>, <code>is_false</code></p> \n<p>📖 <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/metadata_filtering.md\">Complete Metadata filtering guide →</a></strong></p> \n<h3>🔍 Grep Search</h3> \n<p>For exact text matching instead of semantic search, use the <code>use_grep</code> parameter:</p> \n<pre><code class=\"language-python\"># Exact text search\nresults = searcher.search(\"banana‑crocodile\", use_grep=True, top_k=1)\n</code></pre> \n<p><strong>Use cases</strong>: Finding specific code patterns, error messages, function names, or exact phrases where semantic similarity isn't needed.</p> \n<p>📖 <strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/grep_search.md\">Complete grep search guide →</a></strong></p> \n<h2>🏗️ Architecture &amp; How It Works</h2> \n<p align=\"center\"> <img alt=\"LEANN Architecture\" src=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/arch.png\" width=\"800\" /> </p> \n<p><strong>The magic:</strong> Most vector DBs store every single embedding (expensive). LEANN stores a pruned graph structure (cheap) and recomputes embeddings only when needed (fast).</p> \n<p><strong>Core techniques:</strong></p> \n<ul> \n <li><strong>Graph-based selective recomputation:</strong> Only compute embeddings for nodes in the search path</li> \n <li><strong>High-degree preserving pruning:</strong> Keep important \"hub\" nodes while removing redundant connections</li> \n <li><strong>Dynamic batching:</strong> Efficiently batch embedding computations for GPU utilization</li> \n <li><strong>Two-level search:</strong> Smart graph traversal that prioritizes promising nodes</li> \n</ul> \n<p><strong>Backends:</strong></p> \n<ul> \n <li><strong>HNSW</strong> (default): Ideal for most datasets with maximum storage savings through full recomputation</li> \n <li><strong>DiskANN</strong>: Advanced option with superior search performance, using PQ-based graph traversal with real-time reranking for the best speed-accuracy trade-off</li> \n</ul> \n<h2>Benchmarks</h2> \n<p><strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/diskann_vs_hnsw_speed_comparison.py\">DiskANN vs HNSW Performance Comparison →</a></strong> - Compare search performance between both backends</p> \n<p><strong><a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/compare_faiss_vs_leann.py\">Simple Example: Compare LEANN vs FAISS →</a></strong> - See storage savings in action</p> \n<h3>📊 Storage Comparison</h3> \n<table> \n <thead> \n  <tr> \n   <th>System</th> \n   <th>DPR (2.1M)</th> \n   <th>Wiki (60M)</th> \n   <th>Chat (400K)</th> \n   <th>Email (780K)</th> \n   <th>Browser (38K)</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Traditional vector database (e.g., FAISS)</td> \n   <td>3.8 GB</td> \n   <td>201 GB</td> \n   <td>1.8 GB</td> \n   <td>2.4 GB</td> \n   <td>130 MB</td> \n  </tr> \n  <tr> \n   <td>LEANN</td> \n   <td>324 MB</td> \n   <td>6 GB</td> \n   <td>64 MB</td> \n   <td>79 MB</td> \n   <td>6.4 MB</td> \n  </tr> \n  <tr> \n   <td>Savings</td> \n   <td>91%</td> \n   <td>97%</td> \n   <td>97%</td> \n   <td>97%</td> \n   <td>95%</td> \n  </tr> \n </tbody> \n</table> \n<h2>Reproduce Our Results</h2> \n<pre><code class=\"language-bash\">uv run benchmarks/run_evaluation.py    # Will auto-download evaluation data and run benchmarks\nuv run benchmarks/run_evaluation.py benchmarks/data/indices/rpj_wiki/rpj_wiki --num-queries 2000    # After downloading data, you can run the benchmark with our biggest index\n</code></pre> \n<p>The evaluation script downloads data automatically on first run. The last three results were tested with partial personal data, and you can reproduce them with your own data!</p> \n<h2>🔬 Paper</h2> \n<p>If you find Leann useful, please cite:</p> \n<p><strong><a href=\"https://arxiv.org/abs/2506.08276\">LEANN: A Low-Storage Vector Index</a></strong></p> \n<pre><code class=\"language-bibtex\">@misc{wang2025leannlowstoragevectorindex,\n      title={LEANN: A Low-Storage Vector Index},\n      author={Yichuan Wang and Shu Liu and Zhifei Li and Yongji Wu and Ziming Mao and Yilong Zhao and Xiao Yan and Zhiying Xu and Yang Zhou and Ion Stoica and Sewon Min and Matei Zaharia and Joseph E. Gonzalez},\n      year={2025},\n      eprint={2506.08276},\n      archivePrefix={arXiv},\n      primaryClass={cs.DB},\n      url={https://arxiv.org/abs/2506.08276},\n}\n</code></pre> \n<h2>✨ <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/features.md\">Detailed Features →</a></h2> \n<h2>🤝 <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/CONTRIBUTING.md\">CONTRIBUTING →</a></h2> \n<h2>❓ <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/faq.md\">FAQ →</a></h2> \n<h2>📈 <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/roadmap.md\">Roadmap →</a></h2> \n<h2>📄 License</h2> \n<p>MIT License - see <a href=\"https://raw.githubusercontent.com/yichuan-w/LEANN/main/LICENSE\">LICENSE</a> for details.</p> \n<h2>🙏 Acknowledgments</h2> \n<p>Core Contributors: <a href=\"https://yichuan-w.github.io/\">Yichuan Wang</a> &amp; <a href=\"https://github.com/andylizf\">Zhifei Li</a>.</p> \n<p>Active Contributors: <a href=\"https://github.com/gabriel-dehan\">Gabriel Dehan</a>, <a href=\"https://github.com/ASuresh0524\">Aakash Suresh</a></p> \n<p>We welcome more contributors! Feel free to open issues or submit PRs.</p> \n<p>This work is done at <a href=\"https://sky.cs.berkeley.edu/\"><strong>Berkeley Sky Computing Lab</strong></a>.</p> \n<h2>Star History</h2> \n<p><a href=\"https://www.star-history.com/#yichuan-w/LEANN&amp;Date\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=yichuan-w/LEANN&amp;type=Date\" /></a></p> \n<p align=\"center\"> <strong>⭐ Star us on GitHub if Leann is useful for your research or applications!</strong> </p> \n<p align=\"center\"> Made with ❤️ by the Leann team </p> \n<h2>🤖 Explore LEANN with AI</h2> \n<p>LEANN is indexed on <a href=\"https://deepwiki.com/yichuan-w/LEANN\">DeepWiki</a>, so you can ask questions to LLMs using Deep Research to explore the codebase and get help to add new features.</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:04.687011Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 13
          }
        ],
        "structural_score": 29,
        "timeliness_score": 1,
        "final_score": 9.4,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/nautechsystems/nautilus_trader",
        "title": "nautechsystems/nautilus_trader",
        "summary": "<p>A high-performance algorithmic trading platform and event-driven backtester</p><hr /><h1><img src=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png\" width=\"500\" /></h1> \n<p><a href=\"https://codecov.io/gh/nautechsystems/nautilus_trader\"><img alt=\"codecov\" src=\"https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H\" /></a> <a href=\"https://codspeed.io/nautechsystems/nautilus_trader\"><img alt=\"codspeed\" src=\"https://img.shields.io/endpoint?url=https://codspeed.io/badge.json\" /></a> <img alt=\"pythons\" src=\"https://img.shields.io/pypi/pyversions/nautilus_trader\" /> <img alt=\"pypi-version\" src=\"https://img.shields.io/pypi/v/nautilus_trader\" /> <img alt=\"pypi-format\" src=\"https://img.shields.io/pypi/format/nautilus_trader?color=blue\" /> <a href=\"https://pepy.tech/project/nautilus-trader\"><img alt=\"Downloads\" src=\"https://pepy.tech/badge/nautilus-trader\" /></a> <a href=\"https://discord.gg/NautilusTrader\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white\" /></a></p> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Branch</th> \n   <th align=\"left\">Version</th> \n   <th align=\"left\">Status</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\"><code>master</code></td> \n   <td align=\"left\"><a href=\"https://packages.nautechsystems.io/simple/nautilus-trader/index.html\"><img alt=\"version\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json\" /></a></td> \n   <td align=\"left\"><a href=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml\"><img alt=\"build\" src=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>nightly</code></td> \n   <td align=\"left\"><a href=\"https://packages.nautechsystems.io/simple/nautilus-trader/index.html\"><img alt=\"version\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json\" /></a></td> \n   <td align=\"left\"><a href=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml\"><img alt=\"build\" src=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly\" /></a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>develop</code></td> \n   <td align=\"left\"><a href=\"https://packages.nautechsystems.io/simple/nautilus-trader/index.html\"><img alt=\"version\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json\" /></a></td> \n   <td align=\"left\"><a href=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml\"><img alt=\"build\" src=\"https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop\" /></a></td> \n  </tr> \n </tbody> \n</table> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Platform</th> \n   <th align=\"left\">Rust</th> \n   <th align=\"left\">Python</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\"><code>Linux (x86_64)</code></td> \n   <td align=\"left\">1.92.0</td> \n   <td align=\"left\">3.12-3.14</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>Linux (ARM64)</code></td> \n   <td align=\"left\">1.92.0</td> \n   <td align=\"left\">3.12-3.14</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>macOS (ARM64)</code></td> \n   <td align=\"left\">1.92.0</td> \n   <td align=\"left\">3.12-3.14</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>Windows (x86_64)</code></td> \n   <td align=\"left\">1.92.0</td> \n   <td align=\"left\">3.12-3.14</td> \n  </tr> \n </tbody> \n</table> \n<ul> \n <li><strong>Docs</strong>: <a href=\"https://nautilustrader.io/docs/\">https://nautilustrader.io/docs/</a></li> \n <li><strong>Website</strong>: <a href=\"https://nautilustrader.io\">https://nautilustrader.io</a></li> \n <li><strong>Support</strong>: <a href=\"mailto:support@nautilustrader.io\">support@nautilustrader.io</a></li> \n</ul> \n<h2>Introduction</h2> \n<p>NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.</p> \n<p>The platform is <em>AI-first</em>, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.</p> \n<p>NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.</p> \n<p>The platform is also universal, and asset-class-agnostic — with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto, DeFi, and Betting — enabling seamless operations across multiple venues simultaneously.</p> \n<p><img alt=\"nautilus-trader\" src=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png\" title=\"nautilus-trader\" /></p> \n<h2>Features</h2> \n<ul> \n <li><strong>Fast</strong>: Core is written in Rust with asynchronous networking using <a href=\"https://crates.io/crates/tokio\">tokio</a>.</li> \n <li><strong>Reliable</strong>: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.</li> \n <li><strong>Portable</strong>: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.</li> \n <li><strong>Flexible</strong>: Modular adapters mean any REST API or WebSocket feed can be integrated.</li> \n <li><strong>Advanced</strong>: Time in force <code>IOC</code>, <code>FOK</code>, <code>GTC</code>, <code>GTD</code>, <code>DAY</code>, <code>AT_THE_OPEN</code>, <code>AT_THE_CLOSE</code>, advanced order types and conditional triggers. Execution instructions <code>post-only</code>, <code>reduce-only</code>, and icebergs. Contingency orders including <code>OCO</code>, <code>OUO</code>, <code>OTO</code>.</li> \n <li><strong>Customizable</strong>: Add user-defined custom components, or assemble entire systems from scratch leveraging the <a href=\"https://nautilustrader.io/docs/latest/concepts/cache\">cache</a> and <a href=\"https://nautilustrader.io/docs/latest/concepts/message_bus\">message bus</a>.</li> \n <li><strong>Backtesting</strong>: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.</li> \n <li><strong>Live</strong>: Use identical strategy implementations between backtesting and live deployments.</li> \n <li><strong>Multi-venue</strong>: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.</li> \n <li><strong>AI Training</strong>: Backtest engine fast enough to be used to train AI trading agents (RL/ES).</li> \n</ul> \n<p><img alt=\"Alt text\" src=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png\" title=\"nautilus\" /></p> \n<blockquote> \n <p><em>nautilus - from ancient Greek 'sailor' and naus 'ship'.</em></p> \n <p><em>The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.</em></p> \n</blockquote> \n<h2>Why NautilusTrader?</h2> \n<ul> \n <li><strong>Highly performant event-driven Python</strong>: Native binary core components.</li> \n <li><strong>Parity between backtesting and live trading</strong>: Identical strategy code.</li> \n <li><strong>Reduced operational risk</strong>: Enhanced risk management functionality, logical accuracy, and type safety.</li> \n <li><strong>Highly extendable</strong>: Message bus, custom components and actors, custom data, custom adapters.</li> \n</ul> \n<p>Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.</p> \n<p>One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in <a href=\"https://www.rust-lang.org/\">Rust</a> or <a href=\"https://cython.org/\">Cython</a>. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.</p> \n<h2>Why Python?</h2> \n<p>Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the <em>de facto lingua franca</em> of data science, machine learning, and artificial intelligence.</p> \n<h2>Why Rust?</h2> \n<p><a href=\"https://www.rust-lang.org/\">Rust</a> is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is \"blazingly fast\" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.</p> \n<p>Rust's rich type system and ownership model guarantee memory-safety and thread-safety in safe code, eliminating many classes of bugs at compile-time. Overall safety in this project also depends on correctly upheld invariants in unsafe blocks and FFI boundaries.</p> \n<p>The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and <a href=\"https://pyo3.rs\">PyO3</a>—no Rust toolchain is required at install time.</p> \n<p>This project makes the <a href=\"https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html\">Soundness Pledge</a>:</p> \n<blockquote> \n <p>“The intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.”</p> \n</blockquote> \n<blockquote> \n <p>[!NOTE]</p> \n <p><strong>MSRV:</strong> NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.</p> \n</blockquote> \n<h2>Integrations</h2> \n<p>NautilusTrader is modularly designed to work with <em>adapters</em>, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.</p> \n<p>The following integrations are currently supported; see <a href=\"https://nautilustrader.io/docs/latest/integrations/\">docs/integrations/</a> for details:</p> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Name</th> \n   <th align=\"left\">ID</th> \n   <th align=\"left\">Type</th> \n   <th align=\"left\">Status</th> \n   <th align=\"left\">Docs</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\"><a href=\"https://architect.exchange\">AX Exchange</a></td> \n   <td align=\"left\"><code>AX</code></td> \n   <td align=\"left\">Perpetuals Exchange</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/building-orange\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/architect_ax.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://architect.co\">Architect</a></td> \n   <td align=\"left\"><code>ARCHITECT</code></td> \n   <td align=\"left\">Brokerage (multi-venue)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/planned-gray\" /></td> \n   <td align=\"left\">-</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://betfair.com\">Betfair</a></td> \n   <td align=\"left\"><code>BETFAIR</code></td> \n   <td align=\"left\">Sports Betting Exchange</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://binance.com\">Binance</a></td> \n   <td align=\"left\"><code>BINANCE</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://www.bitmex.com\">BitMEX</a></td> \n   <td align=\"left\"><code>BITMEX</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bitmex.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://www.bybit.com\">Bybit</a></td> \n   <td align=\"left\"><code>BYBIT</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://www.coinbase.com/en/international-exchange\">Coinbase International</a></td> \n   <td align=\"left\"><code>COINBASE_INTX</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://databento.com\">Databento</a></td> \n   <td align=\"left\"><code>DATABENTO</code></td> \n   <td align=\"left\">Data Provider</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://www.deribit.com\">Deribit</a></td> \n   <td align=\"left\"><code>DERIBIT</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/building-orange\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/deribit.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://dydx.exchange/\">dYdX v3</a></td> \n   <td align=\"left\"><code>DYDX</code></td> \n   <td align=\"left\">Crypto Exchange (DEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://dydx.exchange/\">dYdX v4</a></td> \n   <td align=\"left\"><code>DYDX</code></td> \n   <td align=\"left\">Crypto Exchange (DEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/building-orange\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://hyperliquid.xyz\">Hyperliquid</a></td> \n   <td align=\"left\"><code>HYPERLIQUID</code></td> \n   <td align=\"left\">Crypto Exchange (DEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/building-orange\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://www.interactivebrokers.com\">Interactive Brokers</a></td> \n   <td align=\"left\"><code>INTERACTIVE_BROKERS</code></td> \n   <td align=\"left\">Brokerage (multi-venue)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://kraken.com\">Kraken</a></td> \n   <td align=\"left\"><code>KRAKEN</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/beta-yellow\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/kraken.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://okx.com\">OKX</a></td> \n   <td align=\"left\"><code>OKX</code></td> \n   <td align=\"left\">Crypto Exchange (CEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://polymarket.com\">Polymarket</a></td> \n   <td align=\"left\"><code>POLYMARKET</code></td> \n   <td align=\"left\">Prediction Market (DEX)</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md\">Guide</a></td> \n  </tr> \n  <tr> \n   <td align=\"left\"><a href=\"https://tardis.dev\">Tardis</a></td> \n   <td align=\"left\"><code>TARDIS</code></td> \n   <td align=\"left\">Crypto Data Provider</td> \n   <td align=\"left\"><img alt=\"status\" src=\"https://img.shields.io/badge/stable-green\" /></td> \n   <td align=\"left\"><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md\">Guide</a></td> \n  </tr> \n </tbody> \n</table> \n<ul> \n <li><strong>ID</strong>: The default client ID for the integrations adapter clients.</li> \n <li><strong>Type</strong>: The type of integration (often the venue type).</li> \n</ul> \n<h3>Status</h3> \n<ul> \n <li><code>planned</code>: Planned for future development.</li> \n <li><code>building</code>: Under construction and likely not in a usable state.</li> \n <li><code>beta</code>: Completed to a minimally working state and in a beta testing phase.</li> \n <li><code>stable</code>: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).</li> \n</ul> \n<p>See the <a href=\"https://nautilustrader.io/docs/latest/integrations/\">Integrations</a> documentation for further details.</p> \n<h2>Versioning and releases</h2> \n<blockquote> \n <p>[!WARNING]</p> \n <p><strong>NautilusTrader is still under active development</strong>. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a <strong>best-effort basis</strong>.</p> \n</blockquote> \n<p>We aim to follow a <strong>bi-weekly release schedule</strong>, though experimental or larger features may cause delays.</p> \n<h3>Branches</h3> \n<p>We aim to maintain a stable, passing build across all branches.</p> \n<ul> \n <li><code>master</code>: Reflects the source code for the latest released version; recommended for production use.</li> \n <li><code>nightly</code>: Daily snapshots of the <code>develop</code> branch for early testing; merged at <strong>14:00 UTC</strong> and as required.</li> \n <li><code>develop</code>: Active development branch for contributors and feature work.</li> \n</ul> \n<blockquote> \n <p>[!NOTE]</p> \n <p>Our <a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md\">roadmap</a> aims to achieve a <strong>stable API for version 2.x</strong> (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.</p> \n</blockquote> \n<h2>Precision mode</h2> \n<p>NautilusTrader supports two precision modes for its core value types (<code>Price</code>, <code>Quantity</code>, <code>Money</code>), which differ in their internal bit-width and maximum decimal precision.</p> \n<ul> \n <li><strong>High-precision</strong>: 128-bit integers with up to 16 decimals of precision, and a larger value range.</li> \n <li><strong>Standard-precision</strong>: 64-bit integers with up to 9 decimals of precision, and a smaller value range.</li> \n</ul> \n<blockquote> \n <p>[!NOTE]</p> \n <p>By default, the official Python wheels ship in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) Python wheels are available because MSVC's C/C++ frontend does not support <code>__int128</code>, preventing the Cython/FFI layer from handling 128-bit integers.</p> \n <p>For pure Rust crates, high-precision works on all platforms (including Windows) since Rust handles <code>i128</code>/<code>u128</code> via software emulation. The default is standard-precision unless you explicitly enable the <code>high-precision</code> feature flag.</p> \n</blockquote> \n<p>See the <a href=\"https://nautilustrader.io/docs/latest/getting_started/installation\">Installation Guide</a> for further details.</p> \n<p><strong>Rust feature flag</strong>: To enable high-precision mode in Rust, add the <code>high-precision</code> feature to your Cargo.toml:</p> \n<pre><code class=\"language-toml\">[dependencies]\nnautilus_model = { version = \"*\", features = [\"high-precision\"] }\n</code></pre> \n<h2>Installation</h2> \n<p>We recommend using the latest supported version of Python and installing <a href=\"https://pypi.org/project/nautilus_trader/\">nautilus_trader</a> inside a virtual environment to isolate dependencies.</p> \n<p><strong>There are two supported ways to install</strong>:</p> \n<ol> \n <li>Pre-built binary wheel from PyPI <em>or</em> the Nautech Systems package index.</li> \n <li>Build from source.</li> \n</ol> \n<blockquote> \n <p>[!TIP]</p> \n <p>We highly recommend installing using the <a href=\"https://docs.astral.sh/uv\">uv</a> package manager with a \"vanilla\" CPython.</p> \n <p>Conda and other Python distributions <em>may</em> work but aren’t officially supported.</p> \n</blockquote> \n<h3>From PyPI</h3> \n<p>To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:</p> \n<pre><code class=\"language-bash\">pip install -U nautilus_trader\n</code></pre> \n<p>Install optional dependencies as 'extras' for specific integrations (e.g., <code>betfair</code>, <code>docker</code>, <code>dydx</code>, <code>ib</code>, <code>polymarket</code>, <code>visualization</code>):</p> \n<pre><code class=\"language-bash\">pip install -U \"nautilus_trader[docker,ib]\"\n</code></pre> \n<p>See the <a href=\"https://nautilustrader.io/docs/latest/getting_started/installation#extras\">Installation Guide</a> for the full list of available extras.</p> \n<h3>From the Nautech Systems package index</h3> \n<p>The Nautech Systems package index (<code>packages.nautechsystems.io</code>) complies with <a href=\"https://peps.python.org/pep-0503/\">PEP-503</a> and hosts both stable and development binary wheels for <code>nautilus_trader</code>. This enables users to install either the latest stable release or pre-release versions for testing.</p> \n<h4>Stable wheels</h4> \n<p>Stable wheels correspond to official releases of <code>nautilus_trader</code> on PyPI, and use standard versioning.</p> \n<p>To install the latest stable release:</p> \n<pre><code class=\"language-bash\">pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple\n</code></pre> \n<blockquote> \n <p>[!TIP]</p> \n <p>Use <code>--extra-index-url</code> instead of <code>--index-url</code> if you want pip to fall back to PyPI automatically:</p> \n</blockquote> \n<h4>Development wheels</h4> \n<p>Development wheels are published from both the <code>nightly</code> and <code>develop</code> branches, allowing users to test features and fixes ahead of stable releases.</p> \n<p>This process also helps preserve compute resources and provides easy access to the exact binaries tested in CI pipelines, while adhering to <a href=\"https://peps.python.org/pep-0440/\">PEP-440</a> versioning standards:</p> \n<ul> \n <li><code>develop</code> wheels use the version format <code>dev{date}+{build_number}</code> (e.g., <code>1.208.0.dev20241212+7001</code>).</li> \n <li><code>nightly</code> wheels use the version format <code>a{date}</code> (alpha) (e.g., <code>1.208.0a20241212</code>).</li> \n</ul> \n<table> \n <thead> \n  <tr> \n   <th align=\"left\">Platform</th> \n   <th align=\"left\">Nightly</th> \n   <th align=\"left\">Develop</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td align=\"left\"><code>Linux (x86_64)</code></td> \n   <td align=\"left\">✓</td> \n   <td align=\"left\">✓</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>Linux (ARM64)</code></td> \n   <td align=\"left\">✓</td> \n   <td align=\"left\">-</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>macOS (ARM64)</code></td> \n   <td align=\"left\">✓</td> \n   <td align=\"left\">✓</td> \n  </tr> \n  <tr> \n   <td align=\"left\"><code>Windows (x86_64)</code></td> \n   <td align=\"left\">✓</td> \n   <td align=\"left\">✓</td> \n  </tr> \n </tbody> \n</table> \n<p><strong>Note</strong>: Development wheels from the <code>develop</code> branch publish for every supported platform except Linux ARM64. Skipping that target keeps CI feedback fast while avoiding unnecessary build resource usage.</p> \n<blockquote> \n <p>[!WARNING]</p> \n <p>We do not recommend using development wheels in production environments, such as live trading controlling real capital.</p> \n</blockquote> \n<h4>Installation commands</h4> \n<p>By default, pip will install the latest stable release. Adding the <code>--pre</code> flag ensures that pre-release versions, including development wheels, are considered.</p> \n<p>To install the latest available pre-release (including development wheels):</p> \n<pre><code class=\"language-bash\">pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple\n</code></pre> \n<p>To install a specific development wheel (e.g., <code>1.221.0a20251026</code> for October 26, 2025):</p> \n<pre><code class=\"language-bash\">pip install nautilus_trader==1.221.0a20251026 --index-url=https://packages.nautechsystems.io/simple\n</code></pre> \n<h4>Available versions</h4> \n<p>You can view all available versions of <code>nautilus_trader</code> on the <a href=\"https://packages.nautechsystems.io/simple/nautilus-trader/index.html\">package index</a>.</p> \n<p>To programmatically fetch and list available versions:</p> \n<pre><code class=\"language-bash\">curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&lt;=&lt;a href=\")[^\"]+(?=\")' | awk -F'#' '{print $1}' | sort\n</code></pre> \n<blockquote> \n <p>[!NOTE]</p> \n <p>On Linux, confirm your glibc version with <code>ldd --version</code> and ensure it reports <strong>2.35</strong> or newer before installing binary wheels.</p> \n</blockquote> \n<h4>Branch updates</h4> \n<ul> \n <li><code>develop</code> branch wheels (<code>.dev</code>): Build and publish continuously with every merged commit.</li> \n <li><code>nightly</code> branch wheels (<code>a</code>): Build and publish daily when we automatically merge the <code>develop</code> branch at <strong>14:00 UTC</strong> (if there are changes).</li> \n</ul> \n<h4>Retention policies</h4> \n<ul> \n <li><code>develop</code> branch wheels (<code>.dev</code>): We retain only the most recent wheel build.</li> \n <li><code>nightly</code> branch wheels (<code>a</code>): We retain only the 30 most recent wheel builds.</li> \n</ul> \n<h4>Verifying build provenance</h4> \n<p>All release artifacts (wheels and source distributions) published to PyPI, GitHub Releases, and the Nautech Systems package index include cryptographic attestations that prove their authenticity and build provenance.</p> \n<p>These attestations are generated automatically during the CI/CD pipeline using <a href=\"https://slsa.dev/\">SLSA</a> build provenance, and can be verified to ensure:</p> \n<ul> \n <li>The artifact was built by the official NautilusTrader GitHub Actions workflow.</li> \n <li>The artifact corresponds to a specific commit SHA in the repository.</li> \n <li>The artifact hasn't been tampered with since it was built.</li> \n</ul> \n<p>To verify a wheel file using the GitHub CLI:</p> \n<pre><code class=\"language-bash\">gh attestation verify nautilus_trader-1.220.0-*.whl --owner nautechsystems\n</code></pre> \n<p>This provides supply chain security by allowing you to cryptographically verify that the installed package came from the official NautilusTrader build process.</p> \n<blockquote> \n <p>[!NOTE]</p> \n <p>Attestation verification requires the <a href=\"https://cli.github.com/\">GitHub CLI</a> (<code>gh</code>) to be installed. Development wheels from <code>develop</code> and <code>nightly</code> branches are also attested and can be verified the same way.</p> \n</blockquote> \n<h3>From source</h3> \n<p>It's possible to install from source using pip if you first install the build dependencies as specified in the <code>pyproject.toml</code>.</p> \n<ol> \n <li> <p>Install <a href=\"https://rustup.rs/\">rustup</a> (the Rust toolchain installer):</p> \n  <ul> \n   <li> <p>Linux and macOS:</p> <pre><code class=\"language-bash\">curl https://sh.rustup.rs -sSf | sh\n</code></pre> </li> \n   <li> <p>Windows:</p> \n    <ul> \n     <li>Download and install <a href=\"https://win.rustup.rs/x86_64\"><code>rustup-init.exe</code></a></li> \n     <li>Install \"Desktop development with C++\" using <a href=\"https://visualstudio.microsoft.com/visual-cpp-build-tools/\">Build Tools for Visual Studio 2022</a></li> \n    </ul> </li> \n   <li> <p>Verify (any system): from a terminal session run: <code>rustc --version</code></p> </li> \n  </ul> </li> \n <li> <p>Enable <code>cargo</code> in the current shell:</p> \n  <ul> \n   <li> <p>Linux and macOS:</p> <pre><code class=\"language-bash\">source $HOME/.cargo/env\n</code></pre> </li> \n   <li> <p>Windows:</p> \n    <ul> \n     <li>Start a new PowerShell</li> \n    </ul> </li> \n  </ul> </li> \n <li> <p>Install <a href=\"https://clang.llvm.org/\">clang</a> (a C language frontend for LLVM):</p> \n  <ul> \n   <li> <p>Linux:</p> <pre><code class=\"language-bash\">sudo apt-get install clang\n</code></pre> </li> \n   <li> <p>Windows:</p> \n    <ol> \n     <li> <p>Add Clang to your <a href=\"https://visualstudio.microsoft.com/visual-cpp-build-tools/\">Build Tools for Visual Studio 2022</a>:</p> \n      <ul> \n       <li>Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (latest) = checked | Modify</li> \n      </ul> </li> \n     <li> <p>Enable <code>clang</code> in the current shell:</p> <pre><code class=\"language-powershell\">[System.Environment]::SetEnvironmentVariable('path', \"C:\\Program Files\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\Llvm\\x64\\bin\\;\" + $env:Path,\"User\")\n</code></pre> </li> \n    </ol> </li> \n   <li> <p>Verify (any system): from a terminal session run: <code>clang --version</code></p> </li> \n  </ul> </li> \n <li> <p>Install uv (see the <a href=\"https://docs.astral.sh/uv/getting-started/installation\">uv installation guide</a> for more details):</p> \n  <ul> \n   <li> <p>Linux and macOS:</p> <pre><code class=\"language-bash\">curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> </li> \n   <li> <p>Windows (PowerShell):</p> <pre><code class=\"language-powershell\">irm https://astral.sh/uv/install.ps1 | iex\n</code></pre> </li> \n  </ul> </li> \n <li> <p>Clone the source with <code>git</code>, and install from the project's root directory:</p> <pre><code class=\"language-bash\">git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader\ncd nautilus_trader\nuv sync --all-extras\n</code></pre> </li> \n</ol> \n<blockquote> \n <p>[!NOTE]</p> \n <p>The <code>--depth 1</code> flag fetches just the latest commit for a faster, lightweight clone.</p> \n</blockquote> \n<ol start=\"6\"> \n <li> <p>Set environment variables for PyO3 compilation (Linux and macOS only):</p> <pre><code class=\"language-bash\"># Linux only: Set the library path for the Python interpreter\nexport LD_LIBRARY_PATH=\"$(python -c 'import sys; print(sys.base_prefix)')/lib:$LD_LIBRARY_PATH\"\n\n# Set the Python executable path for PyO3\nexport PYO3_PYTHON=$(pwd)/.venv/bin/python\n\n# Required for Rust tests when using uv-installed Python\nexport PYTHONHOME=$(python -c \"import sys; print(sys.base_prefix)\")\n</code></pre> </li> \n</ol> \n<blockquote> \n <p>[!NOTE]</p> \n <p>The <code>LD_LIBRARY_PATH</code> export is Linux-specific and not needed on macOS.</p> \n <p>The <code>PYTHONHOME</code> variable is required when running <code>make cargo-test</code> with a <code>uv</code>-installed Python. Without it, tests that depend on PyO3 may fail to locate the Python runtime.</p> \n</blockquote> \n<p>See the <a href=\"https://nautilustrader.io/docs/latest/getting_started/installation\">Installation Guide</a> for other options and further details.</p> \n<h2>Redis</h2> \n<p>Using <a href=\"https://redis.io\">Redis</a> with NautilusTrader is <strong>optional</strong> and only required if configured as the backend for a <a href=\"https://nautilustrader.io/docs/latest/concepts/cache\">cache</a> database or <a href=\"https://nautilustrader.io/docs/latest/concepts/message_bus\">message bus</a>. See the <strong>Redis</strong> section of the <a href=\"https://nautilustrader.io/docs/latest/getting_started/installation#redis\">Installation Guide</a> for further details.</p> \n<h2>Makefile</h2> \n<p>A <code>Makefile</code> is provided to automate most installation and build tasks for development. Some of the targets include:</p> \n<ul> \n <li><code>make install</code>: Installs in <code>release</code> build mode with all dependency groups and extras.</li> \n <li><code>make install-debug</code>: Same as <code>make install</code> but with <code>debug</code> build mode.</li> \n <li><code>make install-just-deps</code>: Installs just the <code>main</code>, <code>dev</code> and <code>test</code> dependencies (does not install package).</li> \n <li><code>make build</code>: Runs the build script in <code>release</code> build mode (default).</li> \n <li><code>make build-debug</code>: Runs the build script in <code>debug</code> build mode.</li> \n <li><code>make build-wheel</code>: Runs uv build with a wheel format in <code>release</code> mode.</li> \n <li><code>make build-wheel-debug</code>: Runs uv build with a wheel format in <code>debug</code> mode.</li> \n <li><code>make cargo-test</code>: Runs all Rust crate tests using <code>cargo-nextest</code>.</li> \n <li><code>make clean</code>: Deletes all build results, such as <code>.so</code> or <code>.dll</code> files.</li> \n <li><code>make distclean</code>: <strong>CAUTION</strong> Removes all artifacts not in the git index from the repository. This includes source files which have not been <code>git add</code>ed.</li> \n <li><code>make docs</code>: Builds the documentation HTML using Sphinx.</li> \n <li><code>make pre-commit</code>: Runs the pre-commit checks over all files.</li> \n <li><code>make ruff</code>: Runs ruff over all files using the <code>pyproject.toml</code> config (with autofix).</li> \n <li><code>make pytest</code>: Runs all tests with <code>pytest</code>.</li> \n <li><code>make test-performance</code>: Runs performance tests with <a href=\"https://codspeed.io\">codspeed</a>.</li> \n</ul> \n<blockquote> \n <p>[!TIP]</p> \n <p>Run <code>make help</code> for documentation on all available make targets.</p> \n</blockquote> \n<blockquote> \n <p>[!TIP]</p> \n <p>See the <a href=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md\">crates/infrastructure/TESTS.md</a> file for running the infrastructure integration tests.</p> \n</blockquote> \n<h2>Examples</h2> \n<p>Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:</p> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py\">indicator</a> example written in Python.</li> \n <li><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/\">indicator</a> implementations written in Cython.</li> \n <li><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/\">strategy</a> examples written in Python.</li> \n <li><a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/\">backtest</a> examples using a <code>BacktestEngine</code> directly.</li> \n</ul> \n<h2>Docker</h2> \n<p>Docker containers are built using the base image <code>python:3.12-slim</code> with the following variant tags:</p> \n<ul> \n <li><code>nautilus_trader:latest</code> has the latest release version installed.</li> \n <li><code>nautilus_trader:nightly</code> has the head of the <code>nightly</code> branch installed.</li> \n <li><code>jupyterlab:latest</code> has the latest release version installed along with <code>jupyterlab</code> and an example backtest notebook with accompanying data.</li> \n <li><code>jupyterlab:nightly</code> has the head of the <code>nightly</code> branch installed along with <code>jupyterlab</code> and an example backtest notebook with accompanying data.</li> \n</ul> \n<p>You can pull the container images as follows:</p> \n<pre><code class=\"language-bash\">docker pull ghcr.io/nautechsystems/&lt;image_variant_tag&gt; --platform linux/amd64\n</code></pre> \n<p>You can launch the backtest example container by running:</p> \n<pre><code class=\"language-bash\">docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64\ndocker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly\n</code></pre> \n<p>Then open your browser at the following address:</p> \n<pre><code class=\"language-bash\">http://127.0.0.1:8888/lab\n</code></pre> \n<blockquote> \n <p>[!WARNING]</p> \n <p>NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the <code>log_level</code> to <code>ERROR</code> in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.</p> \n <ul> \n  <li><a href=\"https://github.com/jupyterlab/jupyterlab/issues/12845\">https://github.com/jupyterlab/jupyterlab/issues/12845</a></li> \n  <li><a href=\"https://github.com/deshaw/jupyterlab-limit-output\">https://github.com/deshaw/jupyterlab-limit-output</a></li> \n </ul> \n</blockquote> \n<h2>Development</h2> \n<p>We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the <a href=\"https://nautilustrader.io/docs/latest/developer_guide/\">Developer Guide</a> for helpful information.</p> \n<blockquote> \n <p>[!TIP]</p> \n <p>Run <code>make build-debug</code> to compile after changes to Rust or Cython code for the most efficient development workflow.</p> \n</blockquote> \n<h3>Testing with Rust</h3> \n<p><a href=\"https://nexte.st\">cargo-nextest</a> is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.</p> \n<p>You can install cargo-nextest by running:</p> \n<pre><code class=\"language-bash\">cargo install cargo-nextest\n</code></pre> \n<blockquote> \n <p>[!TIP]</p> \n <p>Run Rust tests with <code>make cargo-test</code>, which uses <strong>cargo-nextest</strong> with an efficient profile.</p> \n</blockquote> \n<h2>Contributing</h2> \n<p>Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an <a href=\"https://github.com/nautechsystems/nautilus_trader/issues\">issue</a> on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.</p> \n<p>Before getting started, be sure to review the <a href=\"https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope\">open-source scope</a> outlined in the project’s roadmap to understand what’s in and out of scope.</p> \n<p>Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the <a href=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md\">CONTRIBUTING.md</a> file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.</p> \n<blockquote> \n <p>[!NOTE]</p> \n <p>Pull requests should target the <code>develop</code> branch (the default branch). This is where new features and improvements are integrated before release.</p> \n</blockquote> \n<p>Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.</p> \n<h2>Community</h2> \n<p>Join our community of users and contributors on <a href=\"https://discord.gg/NautilusTrader\">Discord</a> to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.</p> \n<blockquote> \n <p>[!WARNING]</p> \n <p>NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.</p> \n <p>All official updates and communications from NautilusTrader will be shared exclusively through <a href=\"https://nautilustrader.io\">https://nautilustrader.io</a>, our <a href=\"https://discord.gg/NautilusTrader\">Discord server</a>, or our X (Twitter) account: <a href=\"https://x.com/NautilusTrader\">@NautilusTrader</a>.</p> \n <p>If you encounter any suspicious activity, please report it to the appropriate platform and contact us at <a href=\"mailto:info@nautechsystems.io\">info@nautechsystems.io</a>.</p> \n</blockquote> \n<h2>License</h2> \n<p>The source code for NautilusTrader is available on GitHub under the <a href=\"https://www.gnu.org/licenses/lgpl-3.0.en.html\">GNU Lesser General Public License v3.0</a>. Contributions to the project are welcome and require the completion of a standard <a href=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md\">Contributor License Agreement (CLA)</a>.</p> \n<hr /> \n<p>NautilusTrader™ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit <a href=\"https://nautilustrader.io\">https://nautilustrader.io</a>.</p> \n<p>© 2015-2026 Nautech Systems Pty Ltd. All rights reserved.</p> \n<p><img alt=\"nautechsystems\" src=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png\" title=\"nautechsystems\" /> <img src=\"https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png\" width=\"128\" /></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:04.687000Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 28,
        "timeliness_score": 1,
        "final_score": 9.1,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/frankbria/ralph-claude-code",
        "title": "frankbria/ralph-claude-code",
        "summary": "<p>Autonomous AI development loop for Claude Code with intelligent exit detection</p><hr /><h1>Ralph for Claude Code</h1> \n<p><a href=\"https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml\"><img alt=\"CI\" src=\"https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml/badge.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true\" /></a> <img alt=\"Version\" src=\"https://img.shields.io/badge/version-0.9.9-blue\" /> <img alt=\"Tests\" src=\"https://img.shields.io/badge/tests-308%20passing-green\" /> <a href=\"https://github.com/frankbria/ralph-claude-code/issues\"><img alt=\"GitHub Issues\" src=\"https://img.shields.io/github/issues/frankbria/ralph-claude-code\" /></a> <a href=\"https://github.com/hesreallyhim/awesome-claude-code\"><img alt=\"Mentioned in Awesome Claude Code\" src=\"https://awesome.re/mentioned-badge.svg?sanitize=true\" /></a> <a href=\"https://x.com/FrankBria18044\"><img alt=\"Follow on X\" src=\"https://img.shields.io/twitter/follow/FrankBria18044?style=social\" /></a></p> \n<blockquote> \n <p><strong>Autonomous AI development loop with intelligent exit detection and rate limiting</strong></p> \n</blockquote> \n<p>Ralph is an implementation of the Geoffrey Huntley's technique for Claude Code that enables continuous autonomous development cycles he named after <a href=\"https://ghuntley.com/ralph/\">Ralph Wiggum</a>. It enables continuous autonomous development cycles where Claude Code iteratively improves your project until completion, with built-in safeguards to prevent infinite loops and API overuse.</p> \n<p><strong>Install once, use everywhere</strong> - Ralph becomes a global command available in any directory.</p> \n<h2>Project Status</h2> \n<p><strong>Version</strong>: v0.9.9 - Active Development <strong>Core Features</strong>: Working and tested <strong>Test Coverage</strong>: 308 tests, 100% pass rate</p> \n<h3>What's Working Now</h3> \n<ul> \n <li>Autonomous development loops with intelligent exit detection</li> \n <li><strong>Dual-condition exit gate</strong>: Requires BOTH completion indicators AND explicit EXIT_SIGNAL</li> \n <li>Rate limiting with hourly reset (100 calls/hour, configurable)</li> \n <li>Circuit breaker with advanced error detection (prevents runaway loops)</li> \n <li>Response analyzer with semantic understanding and two-stage error filtering</li> \n <li><strong>JSON output format support with automatic fallback to text parsing</strong></li> \n <li><strong>Session continuity with <code>--continue</code> flag for context preservation</strong></li> \n <li><strong>Session expiration with configurable timeout (default: 24 hours)</strong></li> \n <li><strong>Modern CLI flags: <code>--output-format</code>, <code>--allowed-tools</code>, <code>--no-continue</code></strong></li> \n <li>Multi-line error matching for accurate stuck loop detection</li> \n <li>5-hour API limit handling with user prompts</li> \n <li>tmux integration for live monitoring</li> \n <li>PRD import functionality</li> \n <li><strong>CI/CD pipeline with GitHub Actions</strong></li> \n <li><strong>Dedicated uninstall script for clean removal</strong></li> \n <li>308 passing tests across 11 test files</li> \n</ul> \n<h3>Recent Improvements</h3> \n<p><strong>v0.9.9 - EXIT_SIGNAL Gate &amp; Uninstall Script</strong></p> \n<ul> \n <li>Fixed premature exit bug: completion indicators now require Claude's explicit <code>EXIT_SIGNAL: true</code></li> \n <li>Added dual-condition check preventing exits when Claude reports work in progress</li> \n <li>Added <code>response_analyzer.sh</code> fix to respect explicit EXIT_SIGNAL over heuristics</li> \n <li>Added dedicated <code>uninstall.sh</code> script for clean Ralph removal</li> \n <li>Session expiration with configurable timeout (default: 24 hours)</li> \n <li>Added 32 new tests for EXIT_SIGNAL behavior and session expiration</li> \n <li>Test count: 308 (up from 276)</li> \n</ul> \n<p><strong>v0.9.8 - Modern CLI for PRD Import</strong></p> \n<ul> \n <li>Modernized <code>ralph_import.sh</code> to use Claude Code CLI JSON output format</li> \n <li>JSON output format support with <code>--output-format json</code> for structured responses</li> \n <li>Enhanced error handling with structured JSON error messages</li> \n <li>Improved file verification with JSON-derived status information</li> \n <li>Backward compatibility with older CLI versions (automatic text fallback)</li> \n <li>Added 11 new tests for modern CLI features</li> \n</ul> \n<p><strong>v0.9.7 - Session Lifecycle Management</strong></p> \n<ul> \n <li>Complete session lifecycle management with automatic reset triggers</li> \n <li>Session auto-reset on: circuit breaker open, manual interrupt, project completion</li> \n <li>Added <code>--reset-session</code> CLI flag for manual session reset</li> \n <li>Session history tracking (last 50 transitions) for debugging</li> \n <li>Added 26 new tests for session continuity features</li> \n</ul> \n<p><strong>v0.9.6 - JSON Output &amp; Session Management</strong></p> \n<ul> \n <li>Extended <code>parse_json_response()</code> to support Claude Code CLI JSON format</li> \n <li>Added session management functions: <code>store_session_id()</code>, <code>get_last_session_id()</code>, <code>should_resume_session()</code></li> \n <li>Cross-platform epoch time utilities in date_utils.sh</li> \n <li>Added 16 new tests covering Claude CLI format and session management</li> \n</ul> \n<p><strong>v0.9.5 - PRD Import Tests</strong></p> \n<ul> \n <li>Added 22 comprehensive tests for <code>ralph_import.sh</code> PRD conversion script</li> \n <li>Tests cover: file format support, output file creation, project naming, error handling</li> \n</ul> \n<p><strong>v0.9.4 - Project Setup Tests</strong></p> \n<ul> \n <li>Added 36 comprehensive tests for <code>setup.sh</code> project initialization script</li> \n <li>Tests cover: directory creation, template copying, git initialization</li> \n</ul> \n<p><strong>v0.9.3 - Installation Tests</strong></p> \n<ul> \n <li>Added 14 comprehensive tests for <code>install.sh</code> global installation script</li> \n <li>Tests cover: directory creation, command installation, dependency detection</li> \n</ul> \n<p><strong>v0.9.2 - Prompt File Fix</strong></p> \n<ul> \n <li>Fixed critical bug: replaced non-existent <code>--prompt-file</code> CLI flag with <code>-p</code> flag</li> \n <li>Modern CLI mode now correctly passes prompt content via <code>-p \"$(cat file)\"</code></li> \n <li>Added error handling for missing prompt files in <code>build_claude_command()</code></li> \n</ul> \n<p><strong>v0.9.1 - Modern CLI Commands (Phase 1.1)</strong></p> \n<ul> \n <li>JSON output format support with <code>--output-format json</code> (default)</li> \n <li>Session continuity using <code>--continue</code> flag for cross-loop context</li> \n <li>Tool permissions via <code>--allowed-tools</code> flag</li> \n <li>CI/CD pipeline with kcov coverage reporting</li> \n</ul> \n<p><strong>v0.9.0 - Circuit Breaker Enhancements</strong></p> \n<ul> \n <li>Fixed multi-line error matching in stuck loop detection</li> \n <li>Eliminated JSON field false positives (e.g., <code>\"is_error\": false</code>)</li> \n <li>Added two-stage error filtering for accurate detection</li> \n</ul> \n<h3>In Progress</h3> \n<ul> \n <li>Expanding test coverage</li> \n <li>Log rotation functionality</li> \n <li>Dry-run mode</li> \n <li>Configuration file support (.ralphrc)</li> \n <li>Metrics and analytics tracking</li> \n <li>Desktop notifications</li> \n <li>Git backup and rollback system</li> \n</ul> \n<p><strong>Timeline to v1.0</strong>: ~4 weeks | <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">Full roadmap</a> | <strong>Contributions welcome!</strong></p> \n<h2>Features</h2> \n<ul> \n <li><strong>Autonomous Development Loop</strong> - Continuously executes Claude Code with your project requirements</li> \n <li><strong>Intelligent Exit Detection</strong> - Dual-condition check requiring BOTH completion indicators AND explicit EXIT_SIGNAL</li> \n <li><strong>Session Continuity</strong> - Preserves context across loop iterations with automatic session management</li> \n <li><strong>Session Expiration</strong> - Configurable timeout (default: 24 hours) with automatic session reset</li> \n <li><strong>Rate Limiting</strong> - Built-in API call management with hourly limits and countdown timers</li> \n <li><strong>5-Hour API Limit Handling</strong> - Detects Claude's 5-hour usage limit and offers wait/exit options</li> \n <li><strong>Live Monitoring</strong> - Real-time dashboard showing loop status, progress, and logs</li> \n <li><strong>Task Management</strong> - Structured approach with prioritized task lists and progress tracking</li> \n <li><strong>Project Templates</strong> - Quick setup for new projects with best-practice structure</li> \n <li><strong>Comprehensive Logging</strong> - Detailed execution logs with timestamps and status tracking</li> \n <li><strong>Configurable Timeouts</strong> - Set execution timeout for Claude Code operations (1-120 minutes)</li> \n <li><strong>Verbose Progress Mode</strong> - Optional detailed progress updates during execution</li> \n <li><strong>Response Analyzer</strong> - AI-powered analysis of Claude Code responses with semantic understanding</li> \n <li><strong>Circuit Breaker</strong> - Advanced error detection with two-stage filtering, multi-line error matching, and automatic recovery</li> \n <li><strong>CI/CD Integration</strong> - GitHub Actions workflow with automated testing</li> \n <li><strong>Clean Uninstall</strong> - Dedicated uninstall script for complete removal</li> \n</ul> \n<h2>Quick Start</h2> \n<p>Ralph has two phases: <strong>one-time installation</strong> and <strong>per-project setup</strong>.</p> \n<pre><code>INSTALL ONCE              USE MANY TIMES\n+-----------------+          +----------------------+\n| ./install.sh    |    -&gt;    | ralph-setup project1 |\n|                 |          | ralph-setup project2 |\n| Adds global     |          | ralph-setup project3 |\n| commands        |          | ...                  |\n+-----------------+          +----------------------+\n</code></pre> \n<h3>Phase 1: Install Ralph (One Time Only)</h3> \n<p>Install Ralph globally on your system:</p> \n<pre><code class=\"language-bash\">git clone https://github.com/frankbria/ralph-claude-code.git\ncd ralph-claude-code\n./install.sh\n</code></pre> \n<p>This adds <code>ralph</code>, <code>ralph-monitor</code>, and <code>ralph-setup</code> commands to your PATH.</p> \n<blockquote> \n <p><strong>Note</strong>: You only need to do this once per system. After installation, you can delete the cloned repository if desired.</p> \n</blockquote> \n<h3>Phase 2: Initialize New Projects (Per Project)</h3> \n<p>For each new project you want Ralph to work on:</p> \n<h4>Option A: Import Existing PRD/Specifications</h4> \n<pre><code class=\"language-bash\"># Convert existing PRD/specs to Ralph format (recommended)\nralph-import my-requirements.md my-project\ncd my-project\n\n# Review and adjust the generated files:\n# - PROMPT.md (Ralph instructions)\n# - @fix_plan.md (task priorities)\n# - specs/requirements.md (technical specs)\n\n# Start autonomous development\nralph --monitor\n</code></pre> \n<h4>Option B: Manual Project Setup</h4> \n<pre><code class=\"language-bash\"># Create blank Ralph project\nralph-setup my-awesome-project\ncd my-awesome-project\n\n# Configure your project requirements manually\n# Edit PROMPT.md with your project goals\n# Edit specs/ with detailed specifications\n# Edit @fix_plan.md with initial priorities\n\n# Start autonomous development\nralph --monitor\n</code></pre> \n<h3>Ongoing Usage (After Setup)</h3> \n<p>Once Ralph is installed and your project is initialized:</p> \n<pre><code class=\"language-bash\"># Navigate to any Ralph project and run:\nralph --monitor              # Integrated tmux monitoring (recommended)\n\n# Or use separate terminals:\nralph                        # Terminal 1: Ralph loop\nralph-monitor               # Terminal 2: Live monitor dashboard\n</code></pre> \n<h3>Uninstalling Ralph</h3> \n<p>To completely remove Ralph from your system:</p> \n<pre><code class=\"language-bash\"># Run the uninstall script\n./uninstall.sh\n\n# Or if you deleted the repo, download and run:\ncurl -sL https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/uninstall.sh | bash\n</code></pre> \n<h2>How It Works</h2> \n<p>Ralph operates on a simple but powerful cycle:</p> \n<ol> \n <li><strong>Read Instructions</strong> - Loads <code>PROMPT.md</code> with your project requirements</li> \n <li><strong>Execute Claude Code</strong> - Runs Claude Code with current context and priorities</li> \n <li><strong>Track Progress</strong> - Updates task lists and logs execution results</li> \n <li><strong>Evaluate Completion</strong> - Checks for exit conditions and project completion signals</li> \n <li><strong>Repeat</strong> - Continues until project is complete or limits are reached</li> \n</ol> \n<h3>Intelligent Exit Detection</h3> \n<p>Ralph uses a <strong>dual-condition check</strong> to prevent premature exits during productive iterations:</p> \n<p><strong>Exit requires BOTH conditions:</strong></p> \n<ol> \n <li><code>completion_indicators &gt;= 2</code> (heuristic detection from natural language patterns)</li> \n <li>Claude's explicit <code>EXIT_SIGNAL: true</code> in the RALPH_STATUS block</li> \n</ol> \n<p><strong>Example behavior:</strong></p> \n<pre><code>Loop 5: Claude outputs \"Phase complete, moving to next feature\"\n        → completion_indicators: 3 (high confidence from patterns)\n        → EXIT_SIGNAL: false (Claude says more work needed)\n        → Result: CONTINUE (respects Claude's explicit intent)\n\nLoop 8: Claude outputs \"All tasks complete, project ready\"\n        → completion_indicators: 4\n        → EXIT_SIGNAL: true (Claude confirms done)\n        → Result: EXIT with \"project_complete\"\n</code></pre> \n<p><strong>Other exit conditions:</strong></p> \n<ul> \n <li>All tasks in <code>@fix_plan.md</code> marked complete</li> \n <li>Multiple consecutive \"done\" signals from Claude Code</li> \n <li>Too many test-focused loops (indicating feature completeness)</li> \n <li>Claude API 5-hour usage limit reached (with user prompt to wait or exit)</li> \n</ul> \n<h2>Importing Existing Requirements</h2> \n<p>Ralph can convert existing PRDs, specifications, or requirement documents into the proper Ralph format using Claude Code.</p> \n<h3>Supported Formats</h3> \n<ul> \n <li><strong>Markdown</strong> (.md) - Product requirements, technical specs</li> \n <li><strong>Text files</strong> (.txt) - Plain text requirements</li> \n <li><strong>JSON</strong> (.json) - Structured requirement data</li> \n <li><strong>Word documents</strong> (.docx) - Business requirements</li> \n <li><strong>PDFs</strong> (.pdf) - Design documents, specifications</li> \n <li><strong>Any text-based format</strong> - Ralph will intelligently parse the content</li> \n</ul> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># Convert a markdown PRD\nralph-import product-requirements.md my-app\n\n# Convert a text specification\nralph-import requirements.txt webapp\n\n# Convert a JSON API spec\nralph-import api-spec.json backend-service\n\n# Let Ralph auto-name the project from filename\nralph-import design-doc.pdf\n</code></pre> \n<h3>What Gets Generated</h3> \n<p>Ralph-import creates a complete project with:</p> \n<ul> \n <li><strong>PROMPT.md</strong> - Converted into Ralph development instructions</li> \n <li><strong>@fix_plan.md</strong> - Requirements broken down into prioritized tasks</li> \n <li><strong>specs/requirements.md</strong> - Technical specifications extracted from your document</li> \n <li><strong>Standard Ralph structure</strong> - All necessary directories and template files</li> \n</ul> \n<p>The conversion is intelligent and preserves your original requirements while making them actionable for autonomous development.</p> \n<h3>Modern CLI Features (v0.9.8)</h3> \n<p>Ralph-import uses modern Claude Code CLI features for improved reliability:</p> \n<ul> \n <li><strong>JSON Output Format</strong>: Structured responses enable precise parsing of conversion results</li> \n <li><strong>Automatic Fallback</strong>: Gracefully handles older CLI versions with text-based parsing</li> \n <li><strong>Enhanced Error Reporting</strong>: Extracts specific error messages and codes from JSON responses</li> \n <li><strong>Session Tracking</strong>: Captures session IDs for potential continuation of interrupted conversions</li> \n</ul> \n<blockquote> \n <p><strong>Note</strong>: These features require Claude Code CLI version 2.0.76 or later. Older versions will work with standard text output.</p> \n</blockquote> \n<h2>Configuration</h2> \n<h3>Rate Limiting &amp; Circuit Breaker</h3> \n<p>Ralph includes intelligent rate limiting and circuit breaker functionality:</p> \n<pre><code class=\"language-bash\"># Default: 100 calls per hour\nralph --calls 50\n\n# With integrated monitoring\nralph --monitor --calls 50\n\n# Check current usage\nralph --status\n</code></pre> \n<p>The circuit breaker automatically:</p> \n<ul> \n <li>Detects API errors and rate limit issues with advanced two-stage filtering</li> \n <li>Opens circuit after 3 loops with no progress or 5 loops with same errors</li> \n <li>Eliminates false positives from JSON fields containing \"error\"</li> \n <li>Accurately detects stuck loops with multi-line error matching</li> \n <li>Gradually recovers with half-open monitoring state</li> \n <li>Provides detailed error tracking and logging with state history</li> \n</ul> \n<h3>Claude API 5-Hour Limit</h3> \n<p>When Claude's 5-hour usage limit is reached, Ralph:</p> \n<ol> \n <li>Detects the limit error automatically</li> \n <li>Prompts you to choose: \n  <ul> \n   <li><strong>Option 1</strong>: Wait 60 minutes for the limit to reset (with countdown timer)</li> \n   <li><strong>Option 2</strong>: Exit gracefully (or auto-exits after 30-second timeout)</li> \n  </ul> </li> \n <li>Prevents endless retry loops that waste time</li> \n</ol> \n<h3>Custom Prompts</h3> \n<pre><code class=\"language-bash\"># Use custom prompt file\nralph --prompt my_custom_instructions.md\n\n# With integrated monitoring\nralph --monitor --prompt my_custom_instructions.md\n</code></pre> \n<h3>Execution Timeouts</h3> \n<pre><code class=\"language-bash\"># Set Claude Code execution timeout (default: 15 minutes)\nralph --timeout 30  # 30-minute timeout for complex tasks\n\n# With monitoring and custom timeout\nralph --monitor --timeout 60  # 60-minute timeout\n\n# Short timeout for quick iterations\nralph --verbose --timeout 5  # 5-minute timeout with progress\n</code></pre> \n<h3>Verbose Mode</h3> \n<pre><code class=\"language-bash\"># Enable detailed progress updates during execution\nralph --verbose\n\n# Combine with other options\nralph --monitor --verbose --timeout 30\n</code></pre> \n<h3>Session Continuity</h3> \n<p>Ralph maintains session context across loop iterations for improved coherence:</p> \n<pre><code class=\"language-bash\"># Sessions are enabled by default with --continue flag\nralph --monitor                 # Uses session continuity\n\n# Start fresh without session context\nralph --no-continue             # Isolated iterations\n\n# Reset session manually (clears context)\nralph --reset-session           # Clears current session\n\n# Check session status\ncat .ralph_session              # View current session file\ncat .ralph_session_history      # View session transition history\n</code></pre> \n<p><strong>Session Auto-Reset Triggers:</strong></p> \n<ul> \n <li>Circuit breaker opens (stagnation detected)</li> \n <li>Manual interrupt (Ctrl+C / SIGINT)</li> \n <li>Project completion (graceful exit)</li> \n <li>Manual circuit breaker reset (<code>--reset-circuit</code>)</li> \n <li>Session expiration (default: 24 hours)</li> \n</ul> \n<p>Sessions are persisted to <code>.ralph_session</code> with a configurable expiration (default: 24 hours). The last 50 session transitions are logged to <code>.ralph_session_history</code> for debugging.</p> \n<h3>Exit Thresholds</h3> \n<p>Modify these variables in <code>~/.ralph/ralph_loop.sh</code>:</p> \n<p><strong>Exit Detection Thresholds:</strong></p> \n<pre><code class=\"language-bash\">MAX_CONSECUTIVE_TEST_LOOPS=3     # Exit after 3 test-only loops\nMAX_CONSECUTIVE_DONE_SIGNALS=2   # Exit after 2 \"done\" signals\nTEST_PERCENTAGE_THRESHOLD=30     # Flag if 30%+ loops are test-only\n</code></pre> \n<p><strong>Circuit Breaker Thresholds:</strong></p> \n<pre><code class=\"language-bash\">CB_NO_PROGRESS_THRESHOLD=3       # Open circuit after 3 loops with no file changes\nCB_SAME_ERROR_THRESHOLD=5        # Open circuit after 5 loops with repeated errors\nCB_OUTPUT_DECLINE_THRESHOLD=70   # Open circuit if output declines by &gt;70%\n</code></pre> \n<p><strong>Completion Indicators with EXIT_SIGNAL Gate:</strong></p> \n<table> \n <thead> \n  <tr> \n   <th>completion_indicators</th> \n   <th>EXIT_SIGNAL</th> \n   <th>Result</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>&gt;= 2</td> \n   <td><code>true</code></td> \n   <td><strong>Exit</strong> (\"project_complete\")</td> \n  </tr> \n  <tr> \n   <td>&gt;= 2</td> \n   <td><code>false</code></td> \n   <td><strong>Continue</strong> (Claude still working)</td> \n  </tr> \n  <tr> \n   <td>&gt;= 2</td> \n   <td>missing</td> \n   <td><strong>Continue</strong> (defaults to false)</td> \n  </tr> \n  <tr> \n   <td>&lt; 2</td> \n   <td><code>true</code></td> \n   <td><strong>Continue</strong> (threshold not met)</td> \n  </tr> \n </tbody> \n</table> \n<h2>Project Structure</h2> \n<p>Ralph creates a standardized structure for each project:</p> \n<pre><code>my-project/\n├── PROMPT.md           # Main development instructions for Ralph\n├── @fix_plan.md        # Prioritized task list (@ prefix = Ralph control file)\n├── @AGENT.md           # Build and run instructions\n├── specs/              # Project specifications and requirements\n│   └── stdlib/         # Standard library specifications\n├── src/                # Source code implementation\n├── examples/           # Usage examples and test cases\n├── logs/               # Ralph execution logs\n└── docs/generated/     # Auto-generated documentation\n</code></pre> \n<h2>Best Practices</h2> \n<h3>Writing Effective Prompts</h3> \n<ol> \n <li><strong>Be Specific</strong> - Clear requirements lead to better results</li> \n <li><strong>Prioritize</strong> - Use <code>@fix_plan.md</code> to guide Ralph's focus</li> \n <li><strong>Set Boundaries</strong> - Define what's in/out of scope</li> \n <li><strong>Include Examples</strong> - Show expected inputs/outputs</li> \n</ol> \n<h3>Project Specifications</h3> \n<ul> \n <li>Place detailed requirements in <code>specs/</code></li> \n <li>Use <code>@fix_plan.md</code> for prioritized task tracking</li> \n <li>Keep <code>@AGENT.md</code> updated with build instructions</li> \n <li>Document key decisions and architecture</li> \n</ul> \n<h3>Monitoring Progress</h3> \n<ul> \n <li>Use <code>ralph-monitor</code> for live status updates</li> \n <li>Check logs in <code>logs/</code> for detailed execution history</li> \n <li>Monitor <code>status.json</code> for programmatic access</li> \n <li>Watch for exit condition signals</li> \n</ul> \n<h2>System Requirements</h2> \n<ul> \n <li><strong>Bash 4.0+</strong> - For script execution</li> \n <li><strong>Claude Code CLI</strong> - <code>npm install -g @anthropic-ai/claude-code</code></li> \n <li><strong>tmux</strong> - Terminal multiplexer for integrated monitoring (recommended)</li> \n <li><strong>jq</strong> - JSON processing for status tracking</li> \n <li><strong>Git</strong> - Version control (projects are initialized as git repos)</li> \n <li><strong>Standard Unix tools</strong> - grep, date, etc.</li> \n</ul> \n<h3>Testing Requirements (Development)</h3> \n<p>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/TESTING.md\">TESTING.md</a> for the comprehensive testing guide.</p> \n<p>If you want to run the test suite:</p> \n<pre><code class=\"language-bash\"># Install BATS testing framework\nnpm install -g bats bats-support bats-assert\n\n# Run all tests (308 tests)\nnpm test\n\n# Run specific test suites\nbats tests/unit/test_rate_limiting.bats\nbats tests/unit/test_exit_detection.bats\nbats tests/unit/test_json_parsing.bats\nbats tests/unit/test_cli_modern.bats\nbats tests/unit/test_cli_parsing.bats\nbats tests/unit/test_session_continuity.bats\nbats tests/integration/test_loop_execution.bats\nbats tests/integration/test_prd_import.bats\nbats tests/integration/test_project_setup.bats\nbats tests/integration/test_installation.bats\n\n# Run error detection and circuit breaker tests\n./tests/test_error_detection.sh\n./tests/test_stuck_loop_detection.sh\n</code></pre> \n<p>Current test status:</p> \n<ul> \n <li><strong>308 tests</strong> across 11 test files</li> \n <li><strong>100% pass rate</strong> (308/308 passing)</li> \n <li>Comprehensive unit and integration tests</li> \n <li>Specialized tests for JSON parsing, CLI flags, circuit breaker, EXIT_SIGNAL behavior, and installation workflows</li> \n</ul> \n<blockquote> \n <p><strong>Note on Coverage</strong>: Bash code coverage measurement with kcov has fundamental limitations when tracing subprocess executions. Test pass rate (100%) is the quality gate. See <a href=\"https://github.com/bats-core/bats-core/issues/15\">bats-core#15</a> for details.</p> \n</blockquote> \n<h3>Installing tmux</h3> \n<pre><code class=\"language-bash\"># Ubuntu/Debian\nsudo apt-get install tmux\n\n# macOS\nbrew install tmux\n\n# CentOS/RHEL\nsudo yum install tmux\n</code></pre> \n<h2>Monitoring and Debugging</h2> \n<h3>Live Dashboard</h3> \n<pre><code class=\"language-bash\"># Integrated tmux monitoring (recommended)\nralph --monitor\n\n# Manual monitoring in separate terminal\nralph-monitor\n</code></pre> \n<p>Shows real-time:</p> \n<ul> \n <li>Current loop count and status</li> \n <li>API calls used vs. limit</li> \n <li>Recent log entries</li> \n <li>Rate limit countdown</li> \n</ul> \n<p><strong>tmux Controls:</strong></p> \n<ul> \n <li><code>Ctrl+B</code> then <code>D</code> - Detach from session (keeps Ralph running)</li> \n <li><code>Ctrl+B</code> then <code>←/→</code> - Switch between panes</li> \n <li><code>tmux list-sessions</code> - View active sessions</li> \n <li><code>tmux attach -t &lt;session-name&gt;</code> - Reattach to session</li> \n</ul> \n<h3>Status Checking</h3> \n<pre><code class=\"language-bash\"># JSON status output\nralph --status\n\n# Manual log inspection\ntail -f logs/ralph.log\n</code></pre> \n<h3>Common Issues</h3> \n<ul> \n <li><strong>Rate Limits</strong> - Ralph automatically waits and displays countdown</li> \n <li><strong>5-Hour API Limit</strong> - Ralph detects and prompts for user action (wait or exit)</li> \n <li><strong>Stuck Loops</strong> - Check <code>@fix_plan.md</code> for unclear or conflicting tasks</li> \n <li><strong>Early Exit</strong> - Review exit thresholds if Ralph stops too soon</li> \n <li><strong>Premature Exit</strong> - Check if Claude is setting <code>EXIT_SIGNAL: false</code> (Ralph now respects this)</li> \n <li><strong>Execution Timeouts</strong> - Increase <code>--timeout</code> value for complex operations</li> \n <li><strong>Missing Dependencies</strong> - Ensure Claude Code CLI and tmux are installed</li> \n <li><strong>tmux Session Lost</strong> - Use <code>tmux list-sessions</code> and <code>tmux attach</code> to reconnect</li> \n <li><strong>Session Expired</strong> - Sessions expire after 24 hours by default; use <code>--reset-session</code> to start fresh</li> \n</ul> \n<h2>Contributing</h2> \n<p>Ralph is actively seeking contributors! We're working toward v1.0.0 with clear priorities and a detailed roadmap.</p> \n<p><strong>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for the complete contributor guide</strong> including:</p> \n<ul> \n <li>Getting started and setup instructions</li> \n <li>Development workflow and commit conventions</li> \n <li>Code style guidelines</li> \n <li>Testing requirements (100% pass rate mandatory)</li> \n <li>Pull request process and code review guidelines</li> \n <li>Quality standards and checklists</li> \n</ul> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># Fork and clone\ngit clone https://github.com/YOUR_USERNAME/ralph-claude-code.git\ncd ralph-claude-code\n\n# Install dependencies and run tests\nnpm install\nnpm test  # All 308 tests must pass\n</code></pre> \n<h3>Priority Contribution Areas</h3> \n<ol> \n <li><strong>Test Implementation</strong> - Help expand test coverage</li> \n <li><strong>Feature Development</strong> - Log rotation, dry-run mode, config files, metrics</li> \n <li><strong>Documentation</strong> - Tutorials, troubleshooting guides, examples</li> \n <li><strong>Real-World Testing</strong> - Use Ralph, report bugs, share feedback</li> \n</ol> \n<p><strong>Every contribution matters</strong> - from fixing typos to implementing major features!</p> \n<h2>License</h2> \n<p>This project is licensed under the MIT License - see the <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE\">LICENSE</a> file for details.</p> \n<h2>Acknowledgments</h2> \n<ul> \n <li>Inspired by the <a href=\"https://ghuntley.com/ralph/\">Ralph technique</a> created by Geoffrey Huntley</li> \n <li>Built for <a href=\"https://claude.ai/code\">Claude Code</a> by Anthropic</li> \n <li>Community feedback and contributions</li> \n</ul> \n<h2>Related Projects</h2> \n<ul> \n <li><a href=\"https://claude.ai/code\">Claude Code</a> - The AI coding assistant that powers Ralph</li> \n <li><a href=\"https://github.com/paul-gauthier/aider\">Aider</a> - Original Ralph technique implementation</li> \n</ul> \n<hr /> \n<h2>Command Reference</h2> \n<h3>Installation Commands (Run Once)</h3> \n<pre><code class=\"language-bash\">./install.sh              # Install Ralph globally\n./uninstall.sh            # Remove Ralph from system (dedicated script)\n./install.sh uninstall    # Alternative: Remove Ralph from system\n./install.sh --help       # Show installation help\n</code></pre> \n<h3>Ralph Loop Options</h3> \n<pre><code class=\"language-bash\">ralph [OPTIONS]\n  -h, --help              Show help message\n  -c, --calls NUM         Set max calls per hour (default: 100)\n  -p, --prompt FILE       Set prompt file (default: PROMPT.md)\n  -s, --status            Show current status and exit\n  -m, --monitor           Start with tmux session and live monitor\n  -v, --verbose           Show detailed progress updates during execution\n  -t, --timeout MIN       Set Claude Code execution timeout in minutes (1-120, default: 15)\n  --output-format FORMAT  Set output format: json (default) or text\n  --allowed-tools TOOLS   Set allowed Claude tools (default: Write,Bash(git *),Read)\n  --no-continue           Disable session continuity (start fresh each loop)\n  --reset-circuit         Reset the circuit breaker\n  --circuit-status        Show circuit breaker status\n  --reset-session         Reset session state manually\n</code></pre> \n<h3>Project Commands (Per Project)</h3> \n<pre><code class=\"language-bash\">ralph-setup project-name     # Create new Ralph project\nralph-import prd.md project  # Convert PRD/specs to Ralph project\nralph --monitor              # Start with integrated monitoring\nralph --status               # Check current loop status\nralph --verbose              # Enable detailed progress updates\nralph --timeout 30           # Set 30-minute execution timeout\nralph --calls 50             # Limit to 50 API calls per hour\nralph --reset-session        # Reset session state manually\nralph-monitor                # Manual monitoring dashboard\n</code></pre> \n<h3>tmux Session Management</h3> \n<pre><code class=\"language-bash\">tmux list-sessions        # View active Ralph sessions\ntmux attach -t &lt;name&gt;     # Reattach to detached session\n# Ctrl+B then D           # Detach from session (keeps running)\n</code></pre> \n<hr /> \n<h2>Development Roadmap</h2> \n<p>Ralph is under active development with a clear path to v1.0.0. See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">IMPLEMENTATION_PLAN.md</a> for the complete roadmap.</p> \n<h3>Current Status: v0.9.9</h3> \n<p><strong>What's Delivered:</strong></p> \n<ul> \n <li>Core loop functionality with intelligent exit detection</li> \n <li><strong>Dual-condition exit gate</strong> (completion indicators + EXIT_SIGNAL)</li> \n <li>Rate limiting (100 calls/hour) and circuit breaker pattern</li> \n <li>Response analyzer with semantic understanding</li> \n <li>308 comprehensive tests (100% pass rate)</li> \n <li>tmux integration and live monitoring</li> \n <li>PRD import functionality with modern CLI JSON parsing</li> \n <li>Installation system and project templates</li> \n <li>Modern CLI commands with JSON output support</li> \n <li>CI/CD pipeline with GitHub Actions</li> \n <li>Comprehensive installation test suite</li> \n <li>Session lifecycle management with auto-reset triggers</li> \n <li>Session expiration with configurable timeout</li> \n <li>Dedicated uninstall script</li> \n</ul> \n<p><strong>Test Coverage Breakdown:</strong></p> \n<ul> \n <li>Unit Tests: 164 (CLI parsing, JSON, exit detection, rate limiting, session continuity)</li> \n <li>Integration Tests: 144 (loop execution, edge cases, installation, project setup, PRD import)</li> \n <li>Test Files: 11</li> \n</ul> \n<h3>Path to v1.0.0 (~4 weeks)</h3> \n<p><strong>Enhanced Testing</strong></p> \n<ul> \n <li>Installation and setup workflow tests</li> \n <li>tmux integration tests</li> \n <li>Monitor dashboard tests</li> \n</ul> \n<p><strong>Core Features</strong></p> \n<ul> \n <li>Log rotation functionality</li> \n <li>Dry-run mode</li> \n <li>Configuration file support - .ralphrc</li> \n</ul> \n<p><strong>Advanced Features &amp; Polish</strong></p> \n<ul> \n <li>Metrics and analytics tracking</li> \n <li>Desktop notifications</li> \n <li>Git backup and rollback system</li> \n <li>End-to-end tests</li> \n <li>Final documentation and release prep</li> \n</ul> \n<p>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_STATUS.md\">IMPLEMENTATION_STATUS.md</a> for detailed progress tracking.</p> \n<h3>How to Contribute</h3> \n<p>Ralph is seeking contributors! See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for the complete guide. Priority areas:</p> \n<ol> \n <li><strong>Test Implementation</strong> - Help expand test coverage (<a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">see plan</a>)</li> \n <li><strong>Feature Development</strong> - Log rotation, dry-run mode, config files</li> \n <li><strong>Documentation</strong> - Usage examples, tutorials, troubleshooting guides</li> \n <li><strong>Bug Reports</strong> - Real-world usage feedback and edge cases</li> \n</ol> \n<hr /> \n<p><strong>Ready to let AI build your project?</strong> Start with <code>./install.sh</code> and let Ralph take it from there!</p> \n<h2>Star History</h2> \n<p><a href=\"https://www.star-history.com/#frankbria/ralph-claude-code&amp;type=date&amp;legend=top-left\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=frankbria/ralph-claude-code&amp;type=date&amp;legend=top-left\" /></a></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:05.897790Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 8.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/hacksider/Deep-Live-Cam",
        "title": "hacksider/Deep-Live-Cam",
        "summary": "<p>real time face swap and one-click video deepfake with only a single image</p><hr /><h1 align=\"center\">Deep-Live-Cam 2.0.1c</h1> \n<p align=\"center\"> Real-time face swap and video deepfake with a single click and only a single image. </p> \n<p align=\"center\"> <a href=\"https://trendshift.io/repositories/11395\" target=\"_blank\"><img alt=\"hacksider%2FDeep-Live-Cam | Trendshift\" height=\"55\" src=\"https://trendshift.io/api/badge/repositories/11395\" style=\"width: 250px; height: 55px;\" width=\"250\" /></a> </p> \n<p align=\"center\"> <img alt=\"Demo GIF\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif\" width=\"800\" /> </p> \n<h2>Disclaimer</h2> \n<p>This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.</p> \n<p>We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.</p> \n<ul> \n <li> <p>Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.</p> </li> \n <li> <p>Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.</p> </li> \n <li> <p>Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.</p> </li> \n <li> <p>User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.</p> </li> \n</ul> \n<p>By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.</p> \n<p>Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.</p> \n<h2>Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)</h2> \n<p><a href=\"https://deeplivecam.net/index.php/quickstart\"> <img height=\"77\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png\" width=\"285\" /></a></p>\n<a href=\"https://deeplivecam.net/index.php/quickstart\"> <h5>This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.</h5> <h6>These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.</h6> <h2>TLDR; Live Deepfake in just 3 Clicks</h2> <p><img alt=\"easysteps\" src=\"https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6\" /></p> \n <ol> \n  <li>Select a face</li> \n  <li>Select which camera to use</li> \n  <li>Press live!</li> \n </ol> <h2>Features &amp; Uses - Everything is in real-time</h2> <h3>Mouth Mask</h3> <p><strong>Retain your original mouth for accurate movement using Mouth Mask</strong></p> <p align=\"center\"> <img alt=\"resizable-gif\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif\" /> </p> <h3>Face Mapping</h3> <p><strong>Use different faces on multiple subjects simultaneously</strong></p> <p align=\"center\"> <img alt=\"face_mapping_source\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif\" /> </p> <h3>Your Movie, Your Face</h3> <p><strong>Watch movies with any face in real-time</strong></p> <p align=\"center\"> <img alt=\"movie\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif\" /> </p> <h3>Live Show</h3> <p><strong>Run Live shows and performances</strong></p> <p align=\"center\"> <img alt=\"show\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif\" /> </p> <h3>Memes</h3> <p><strong>Create Your Most Viral Meme Yet</strong></p> <p align=\"center\"> <img alt=\"show\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif\" width=\"450\" /> <br /> <sub>Created using Many Faces feature in Deep-Live-Cam</sub> </p> <h3>Omegle</h3> <p><strong>Surprise people on Omegle</strong></p> <p align=\"center\"> \n  <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0\" width=\"450\"></video> </p> <h2>Installation (Manual)</h2> <p><strong>Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.</strong></p> </a>\n<details>\n <a href=\"https://deeplivecam.net/index.php/quickstart\"> Click to see the process <h3>Installation</h3> <p>This is more likely to work on your computer but will be slower as it utilizes the CPU.</p> <p><strong>1. Set up Your Platform</strong></p> \n  <ul> \n   <li>Python (3.11 recommended)</li> \n   <li>pip</li> \n   <li>git</li> \n   <li><a href=\"https://www.youtube.com/watch?v=OlNWCpFdVMA\">ffmpeg</a> - <code>iex (irm ffmpeg.tc.ht)</code></li> \n   <li><a href=\"https://visualstudio.microsoft.com/visual-cpp-build-tools/\">Visual Studio 2022 Runtimes (Windows)</a></li> \n  </ul></a> \n <p><strong>2. Clone the Repository</strong></p> \n <pre><code class=\"language-bash\">git clone https://github.com/hacksider/Deep-Live-Cam.git\ncd Deep-Live-Cam\n</code></pre> \n <p><strong>3. Download the Models</strong></p> \n <ol> \n  <li><a href=\"https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth\">GFPGANv1.4</a></li> \n  <li><a href=\"https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx\">inswapper_128_fp16.onnx</a></li> \n </ol> \n <p>Place these files in the \"<strong>models</strong>\" folder.</p> \n <p><strong>4. Install Dependencies</strong></p> \n <p>We highly recommend using a <code>venv</code> to avoid issues.</p> \n <p>For Windows:</p> \n <pre><code class=\"language-bash\">python -m venv venv\nvenv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre> \n <p>For Linux:</p> \n <pre><code class=\"language-bash\"># Ensure you use the installed Python 3.10\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> \n <p><strong>For macOS:</strong></p> \n <p>Apple Silicon (M1/M2/M3) requires specific setup:</p> \n <pre><code class=\"language-bash\"># Install Python 3.11 (specific version is important)\nbrew install python@3.11\n\n# Install tkinter package (required for the GUI)\nbrew install python-tk@3.10\n\n# Create and activate virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre> \n <p>** In case something goes wrong and you need to reinstall the virtual environment **</p> \n <pre><code class=\"language-bash\"># Deactivate the virtual environment\nrm -rf venv\n\n# Reinstall the virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# install the dependencies again\npip install -r requirements.txt\n\n# gfpgan and basicsrs issue fix\npip install git+https://github.com/xinntao/BasicSR.git@master\npip uninstall gfpgan -y\npip install git+https://github.com/TencentARC/GFPGAN.git@master\n</code></pre> \n <p><strong>Run:</strong> If you don't have a GPU, you can run Deep-Live-Cam using <code>python run.py</code>. Note that initial execution will download models (~300MB).</p> \n <h3>GPU Acceleration</h3> \n <p><strong>CUDA Execution Provider (Nvidia)</strong></p> \n <ol> \n  <li>Install <a href=\"https://developer.nvidia.com/cuda-12-8-0-download-archive\">CUDA Toolkit 12.8.0</a></li> \n  <li>Install <a href=\"https://developer.nvidia.com/rdp/cudnn-archive\">cuDNN v8.9.7 for CUDA 12.x</a> (required for onnxruntime-gpu): \n   <ul> \n    <li>Download cuDNN v8.9.7 for CUDA 12.x</li> \n    <li>Make sure the cuDNN bin directory is in your system PATH</li> \n   </ul> </li> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\npip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime-gpu==1.21.0\n</code></pre> \n <ol start=\"3\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider cuda\n</code></pre> \n <p><strong>CoreML Execution Provider (Apple Silicon)</strong></p> \n <p>Apple Silicon (M1/M2/M3) specific installation:</p> \n <ol> \n  <li>Make sure you've completed the macOS setup above using Python 3.10.</li> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-silicon\npip install onnxruntime-silicon==1.13.1\n</code></pre> \n <ol start=\"3\"> \n  <li>Usage (important: specify Python 3.10):</li> \n </ol> \n <pre><code class=\"language-bash\">python3.10 run.py --execution-provider coreml\n</code></pre> \n <p><strong>Important Notes for macOS:</strong></p> \n <ul> \n  <li>You <strong>must</strong> use Python 3.10, not newer versions like 3.11 or 3.13</li> \n  <li>Always run with <code>python3.10</code> command not just <code>python</code> if you have multiple Python versions installed</li> \n  <li>If you get error about <code>_tkinter</code> missing, reinstall the tkinter package: <code>brew reinstall python-tk@3.10</code></li> \n  <li>If you get model loading errors, check that your models are in the correct folder</li> \n  <li>If you encounter conflicts with other Python versions, consider uninstalling them: <pre><code class=\"language-bash\"># List all installed Python versions\nbrew list | grep python\n\n# Uninstall conflicting versions if needed\nbrew uninstall --ignore-dependencies python@3.11 python@3.13\n\n# Keep only Python 3.11\nbrew cleanup\n</code></pre> </li> \n </ul> \n <p><strong>CoreML Execution Provider (Apple Legacy)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-coreml\npip install onnxruntime-coreml==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider coreml\n</code></pre> \n <p><strong>DirectML Execution Provider (Windows)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-directml\npip install onnxruntime-directml==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider directml\n</code></pre> \n <p><strong>OpenVINO™ Execution Provider (Intel)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-openvino\npip install onnxruntime-openvino==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider openvino\n</code></pre> \n</details> \n<h2>Usage</h2> \n<p><strong>1. Image/Video Mode</strong></p> \n<ul> \n <li>Execute <code>python run.py</code>.</li> \n <li>Choose a source face image and a target image/video.</li> \n <li>Click \"Start\".</li> \n <li>The output will be saved in a directory named after the target video.</li> \n</ul> \n<p><strong>2. Webcam Mode</strong></p> \n<ul> \n <li>Execute <code>python run.py</code>.</li> \n <li>Select a source face image.</li> \n <li>Click \"Live\".</li> \n <li>Wait for the preview to appear (10-30 seconds).</li> \n <li>Use a screen capture tool like OBS to stream.</li> \n <li>To change the face, select a new source image.</li> \n</ul> \n<h2>Command Line Arguments (Unmaintained)</h2> \n<pre><code>options:\n  -h, --help                                               show this help message and exit\n  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image\n  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video\n  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory\n  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)\n  --keep-fps                                               keep original fps\n  --keep-audio                                             keep original audio\n  --keep-frames                                            keep temporary frames\n  --many-faces                                             process every face\n  --map-faces                                              map source target faces\n  --mouth-mask                                             mask the mouth region\n  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder\n  --video-quality [0-51]                                   adjust output video quality\n  --live-mirror                                            the live camera display as you see it in the front-facing camera frame\n  --live-resizable                                         the live camera frame is resizable\n  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB\n  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)\n  --execution-threads EXECUTION_THREADS                    number of execution threads\n  -v, --version                                            show program's version number and exit\n</code></pre> \n<p>Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.</p> \n<h2>Press</h2> \n<p><strong>We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.</strong></p> \n<ul> \n <li><a href=\"https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/\"><em>\"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger\"</em></a> - Ars Technica</li> \n <li><a href=\"https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/\"><em>\"Thanks Deep Live Cam, shapeshifters are among us now\"</em></a> - Dataconomy</li> \n <li><a href=\"https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story\"><em>\"This free AI tool lets you become anyone during video-calls\"</em></a> - NewsBytes</li> \n <li><a href=\"https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying\"><em>\"OK, this viral AI live stream software is truly terrifying\"</em></a> - Creative Bloq</li> \n <li><a href=\"https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/\"><em>\"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo\"</em></a> - PetaPixel</li> \n <li><a href=\"https://www.techeblog.com/deep-live-cam-ai-transform-face/\"><em>\"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included\"</em></a> - TechEBlog</li> \n <li><a href=\"https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/\"><em>\"An AI tool that \"makes you look like anyone\" during a video call is going viral online\"</em></a> - Telegrafi</li> \n <li><a href=\"https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts\"><em>\"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts\"</em></a> - Emerge</li> \n <li><a href=\"https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/\"><em>\"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces\"</em></a> - Digital Music News</li> \n <li><a href=\"https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/\"><em>\"This real-time webcam deepfake tool raises alarms about the future of identity theft\"</em></a> - DIYPhotography</li> \n <li><a href=\"https://www.youtube.com/watch?time_continue=1074&amp;v=py4Tc-Y8BcY\"><em>\"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude\"</em></a> - SomeOrdinaryGamers</li> \n <li><a href=\"https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;t=2686\"><em>\"Alright look look look, now look chat, we can do any face we want to look like chat\"</em></a> - IShowSpeed</li> \n <li><a href=\"https://www.youtube.com/watch?v=wnCghLjqv3s&amp;t=551s\"><em>\"They do a pretty good job matching poses, expression and even the lighting\"</em></a> - TechLinked (LTT)</li> \n <li><a href=\"https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html\"><em>\"Als Sean Connery an der Redaktionskonferenz teilnahm\"</em></a> - Golem.de (German)</li> \n <li><a href=\"https://youtu.be/JbUPRmXRUtE?t=3964\"><em>\"What the F</em>**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! \"*</a> - IShowSpeed</li> \n</ul> \n<h2>Credits</h2> \n<ul> \n <li><a href=\"https://ffmpeg.org/\">ffmpeg</a>: for making video-related operations easy</li> \n <li><a href=\"https://github.com/henryruhs\">Henry</a>: One of the major contributor in this repo</li> \n <li><a href=\"https://github.com/deepinsight\">deepinsight</a>: for their <a href=\"https://github.com/deepinsight/insightface\">insightface</a> project which provided a well-made library and models. Please be reminded that the <a href=\"https://github.com/deepinsight/insightface?tab=readme-ov-file#license\">use of the model is for non-commercial research purposes only</a>.</li> \n <li><a href=\"https://github.com/havok2-htwo\">havok2-htwo</a>: for sharing the code for webcam</li> \n <li><a href=\"https://github.com/GosuDRM\">GosuDRM</a>: for the open version of roop</li> \n <li><a href=\"https://github.com/pereiraroland26\">pereiraroland26</a>: Multiple faces support</li> \n <li><a href=\"https://github.com/vic4key\">vic4key</a>: For supporting/contributing to this project</li> \n <li><a href=\"https://github.com/kier007\">kier007</a>: for improving the user experience</li> \n <li><a href=\"https://github.com/qitianai\">qitianai</a>: for multi-lingual support</li> \n <li>and <a href=\"https://github.com/hacksider/Deep-Live-Cam/graphs/contributors\">all developers</a> behind libraries used in this project.</li> \n <li>Footnote: Please be informed that the base author of the code is <a href=\"https://github.com/s0md3v/roop\">s0md3v</a></li> \n <li>All the wonderful users who helped make this project go viral by starring the repo ❤️</li> \n</ul> \n<p><a href=\"https://github.com/hacksider/Deep-Live-Cam/stargazers\"><img alt=\"Stargazers\" src=\"https://reporoster.com/stars/hacksider/Deep-Live-Cam\" /></a></p> \n<h2>Contributions</h2> \n<p><img alt=\"Alt\" src=\"https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true\" title=\"Repobeats analytics image\" /></p> \n<h2>Stars to the Moon 🚀</h2> \n<a href=\"https://star-history.com/#hacksider/deep-live-cam&amp;Date\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;type=Date\" /> \n  </a>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:05.897784Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 18,
        "timeliness_score": 1,
        "final_score": 6.1,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/fengjinglan/portfolio-summarizing-dev-journals-using-google-ai-cloud-run-29jj",
        "title": "Portfolio & Summarizing Dev Journals Using Google AI & Cloud Run",
        "summary": "<p><em>This is a submission for the <a href=\"https://dev.to/challenges/new-year-new-you-google-ai-2025-12-31\">New Year, New You Portfolio Challenge Presented by Google AI</a></em></p>\n\n<h2>\n  \n  \n  About Me\n</h2>\n\n<p>I’m a software engineer with a background in education and instructional design. Before moving into engineering full time, I spent years teaching and designing learning materials, which shaped how I think about clarity, structure, and how people actually absorb technical information.</p>\n\n<p>With this portfolio, I wanted to explore the intersection of <strong>software engineering, learning, and AI-assisted reflection</strong>—not just showcasing projects, but also capturing <em>how</em> I learn and reason about systems over time. This portfolio is both a technical artifact and a learning journal. I want to have a platform that I can store all of my works.</p>\n\n<h2>\n  \n  \n  Portfolio\n</h2>\n\n<p>Here is my live portfolio deployment on Google Cloud Run:</p>\n\n<p>&lt;iframe<br />\n  src=\"<a href=\"https://emily-stacy-portfolio-465092161508.us-central1.run.app/\" rel=\"noopener noreferrer\">https://emily-stacy-portfolio-465092161508.us-central1.run.app/</a>\"<br />\n  style=\"width: 100%; height: 800px; border: 1px solid #e2e8f0; border-radius: 12px;\"<br />\n  loading=\"lazy\"</p>\n\n<blockquote>\n\n</blockquote>\n\n<p>(For the deployment label requirement, I deployed this service with: <code>--update-labels dev-tutorial=blog-devcommunity2026</code>.)</p>\n\n<h2>\n  \n  \n  How I Built It\n</h2>\n\n<p><strong>Frontend</strong></p>\n\n<ul>\n<li>React + TypeScript</li>\n<li>Custom journal schema to support multiple content formats (sections, tables, lists, code blocks)</li>\n<li>Review Mode UI that hides details and emphasizes high-level takeaways</li>\n</ul>\n\n<p><strong>Backend</strong></p>\n\n<ul>\n<li>Node.js + Express</li>\n<li>Deployed as a containerized service on <strong>Google Cloud Run</strong>\n</li>\n<li>A custom summarization endpoint that sends journal content to Google Gemini and normalizes the response</li>\n</ul>\n\n<p><strong>Google AI</strong></p>\n\n<ul>\n<li>Google Gemini (<code>gemini-2.5-flash</code>) for summarization</li>\n<li><p>Instead of assuming a fixed AI response format, I built a resilient extraction layer that can interpret multiple JSON shapes (sections, arrays, nested objects, tables, etc.) with the help of Gemini (Note: Since I’m on the free tier, requests may return 429 (quota exceeded) errors when the usage limit is reached)</p></li>\n<li><p>This mirrors real-world conditions where AI outputs aren’t always predictable</p></li>\n</ul>\n\n<p><strong>Design Decisions</strong></p>\n\n<ul>\n<li><p>I intentionally treated AI as a <em>helper</em>, not a source of truth</p></li>\n<li>\n<p>The system falls back gracefully when summaries can’t be confidently </p>\n<h2>\n  \n  \n  What I'm Most Proud Of\n</h2>\n\n</li>\n<li><p><strong>AI integration</strong>: Handling inconsistent AI outputs without breaking the UI was one of the hardest and most rewarding parts.</p></li>\n<li><p><strong>Learning-first design</strong>: The portfolio doesn’t just show results—it captures the thinking process behind them.</p></li>\n<li><p><strong>End-to-end ownership</strong>: From frontend design to backend APIs to Cloud Run deployment and CI/CD, this project represents full-stack ownership.</p></li>\n<li>\n<p><strong>Practical AI usage</strong>: Instead of flashy demos, the AI feature solves a real personal problem—reviewing and retaining complex technical knowledge.</p>\n\n</li>\n</ul>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fekio9vaikoh3iftbt5ts.png\"><img alt=\" \" height=\"470\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fekio9vaikoh3iftbt5ts.png\" width=\"800\" /></a></p>",
        "source": "dev.to",
        "published": "Mon, 19 Jan 2026 21:39:52 +0000",
        "fetched_at": "2026-01-19T23:17:09.816128Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 14,
        "timeliness_score": 2,
        "final_score": 5.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/obra/superpowers",
        "title": "obra/superpowers",
        "summary": "<p>An agentic skills framework & software development methodology that works.</p><hr /><h1>Superpowers</h1> \n<p>Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable \"skills\" and some initial instructions that make sure your agent uses them.</p> \n<h2>How it works</h2> \n<p>It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it <em>doesn't</em> just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.</p> \n<p>Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.</p> \n<p>After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.</p> \n<p>Next up, once you say \"go\", it launches a <em>subagent-driven-development</em> process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.</p> \n<p>There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.</p> \n<h2>Sponsorship</h2> \n<p>If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider <a href=\"https://github.com/sponsors/obra\">sponsoring my opensource work</a>.</p> \n<p>Thanks!</p> \n<ul> \n <li>Jesse</li> \n</ul> \n<h2>Installation</h2> \n<p><strong>Note:</strong> Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.</p> \n<h3>Claude Code (via Plugin Marketplace)</h3> \n<p>In Claude Code, register the marketplace first:</p> \n<pre><code class=\"language-bash\">/plugin marketplace add obra/superpowers-marketplace\n</code></pre> \n<p>Then install the plugin from this marketplace:</p> \n<pre><code class=\"language-bash\">/plugin install superpowers@superpowers-marketplace\n</code></pre> \n<h3>Verify Installation</h3> \n<p>Check that commands appear:</p> \n<pre><code class=\"language-bash\">/help\n</code></pre> \n<pre><code># Should see:\n# /superpowers:brainstorm - Interactive design refinement\n# /superpowers:write-plan - Create implementation plan\n# /superpowers:execute-plan - Execute plan in batches\n</code></pre> \n<h3>Codex</h3> \n<p>Tell Codex:</p> \n<pre><code>Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md\n</code></pre> \n<p><strong>Detailed docs:</strong> <a href=\"https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md\">docs/README.codex.md</a></p> \n<h3>OpenCode</h3> \n<p>Tell OpenCode:</p> \n<pre><code>Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md\n</code></pre> \n<p><strong>Detailed docs:</strong> <a href=\"https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md\">docs/README.opencode.md</a></p> \n<h2>The Basic Workflow</h2> \n<ol> \n <li> <p><strong>brainstorming</strong> - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.</p> </li> \n <li> <p><strong>using-git-worktrees</strong> - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.</p> </li> \n <li> <p><strong>writing-plans</strong> - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.</p> </li> \n <li> <p><strong>subagent-driven-development</strong> or <strong>executing-plans</strong> - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.</p> </li> \n <li> <p><strong>test-driven-development</strong> - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.</p> </li> \n <li> <p><strong>requesting-code-review</strong> - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.</p> </li> \n <li> <p><strong>finishing-a-development-branch</strong> - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.</p> </li> \n</ol> \n<p><strong>The agent checks for relevant skills before any task.</strong> Mandatory workflows, not suggestions.</p> \n<h2>What's Inside</h2> \n<h3>Skills Library</h3> \n<p><strong>Testing</strong></p> \n<ul> \n <li><strong>test-driven-development</strong> - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)</li> \n</ul> \n<p><strong>Debugging</strong></p> \n<ul> \n <li><strong>systematic-debugging</strong> - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)</li> \n <li><strong>verification-before-completion</strong> - Ensure it's actually fixed</li> \n</ul> \n<p><strong>Collaboration</strong></p> \n<ul> \n <li><strong>brainstorming</strong> - Socratic design refinement</li> \n <li><strong>writing-plans</strong> - Detailed implementation plans</li> \n <li><strong>executing-plans</strong> - Batch execution with checkpoints</li> \n <li><strong>dispatching-parallel-agents</strong> - Concurrent subagent workflows</li> \n <li><strong>requesting-code-review</strong> - Pre-review checklist</li> \n <li><strong>receiving-code-review</strong> - Responding to feedback</li> \n <li><strong>using-git-worktrees</strong> - Parallel development branches</li> \n <li><strong>finishing-a-development-branch</strong> - Merge/PR decision workflow</li> \n <li><strong>subagent-driven-development</strong> - Fast iteration with two-stage review (spec compliance, then code quality)</li> \n</ul> \n<p><strong>Meta</strong></p> \n<ul> \n <li><strong>writing-skills</strong> - Create new skills following best practices (includes testing methodology)</li> \n <li><strong>using-superpowers</strong> - Introduction to the skills system</li> \n</ul> \n<h2>Philosophy</h2> \n<ul> \n <li><strong>Test-Driven Development</strong> - Write tests first, always</li> \n <li><strong>Systematic over ad-hoc</strong> - Process over guessing</li> \n <li><strong>Complexity reduction</strong> - Simplicity as primary goal</li> \n <li><strong>Evidence over claims</strong> - Verify before declaring success</li> \n</ul> \n<p>Read more: <a href=\"https://blog.fsck.com/2025/10/09/superpowers/\">Superpowers for Claude Code</a></p> \n<h2>Contributing</h2> \n<p>Skills live directly in this repository. To contribute:</p> \n<ol> \n <li>Fork the repository</li> \n <li>Create a branch for your skill</li> \n <li>Follow the <code>writing-skills</code> skill for creating and testing new skills</li> \n <li>Submit a PR</li> \n</ol> \n<p>See <code>skills/writing-skills/SKILL.md</code> for the complete guide.</p> \n<h2>Updating</h2> \n<p>Skills update automatically when you update the plugin:</p> \n<pre><code class=\"language-bash\">/plugin update superpowers\n</code></pre> \n<h2>License</h2> \n<p>MIT License - see LICENSE file for details</p> \n<h2>Support</h2> \n<ul> \n <li><strong>Issues</strong>: <a href=\"https://github.com/obra/superpowers/issues\">https://github.com/obra/superpowers/issues</a></li> \n <li><strong>Marketplace</strong>: <a href=\"https://github.com/obra/superpowers-marketplace\">https://github.com/obra/superpowers-marketplace</a></li> \n</ul>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-19T23:17:05.897749Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 13,
        "timeliness_score": 1,
        "final_score": 4.6,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/emmao/--18j9",
        "title": "𝗗𝗲𝘀𝗶𝗴𝗻𝗲𝗱 𝗮 𝗣𝗿𝗼𝗱𝘂𝗰𝘁𝗶𝗼𝗻‑𝗥𝗲𝗮𝗱𝘆 𝗠𝘂𝗹𝘁𝗶‑𝗥𝗲𝗴𝗶𝗼𝗻 𝗔𝗪𝗦 𝗔𝗿𝗰𝗵𝗶𝘁𝗲𝗰𝘁𝘂𝗿𝗲 𝗘𝗞𝗦 | 𝗖𝗜/𝗖𝗗 | 𝗖𝗮𝗻𝗮𝗿𝘆 𝗗𝗲𝗽𝗹𝗼𝘆𝗺𝗲𝗻𝘁𝘀 | 𝗗𝗥 𝗙𝗮𝗶𝗹𝗼𝘃𝗲𝗿",
        "summary": "<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fp20jqk5gukphtqbsnftb.gif\"><img alt=\" \" height=\"337\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fp20jqk5gukphtqbsnftb.gif\" width=\"600\" /></a></p>\n\n<p>I designed a production-grade multi-region AWS architecture to demonstrate how cloud-native platforms achieve high availability, safe deployments, and resilient disaster recovery using Kubernetes and DevOps best practices.<br />\n𝗞𝗲𝘆 𝗛𝗶𝗴𝗵𝗹𝗶𝗴𝗵𝘁𝘀:<br />\n • Automated CI/CD pipelines pushing images to Amazon ECR<br />\n • Canary deployments with automated rollback on EKS<br />\n • Multi-region EKS (Active + Warm Standby)<br />\n • Route 53 failover for seamless regional recovery<br />\n • Aurora Global Database for fast failover and low-latency reads<br />\n • S3 Cross-Region Replication for durable storage<br />\n • CloudWatch + Prometheus for observability and rollback triggers<br />\n𝗛𝗼𝘄 𝗜𝘁 𝗪𝗼𝗿𝗸𝘀:<br />\n Traffic flows through Route 53 → CloudFront → WAF → ALB → EKS.<br />\n New releases roll out via canary pods in the primary region, while the DR region stays in sync.<br />\n On failure, traffic automatically shifts, clusters scale up, and the database is promoted.<br />\nThis design reflects how enterprises build resilient, cost-optimised, and secure production systems.<br />\nhashtag#AWS hashtag#DevOps hashtag#DevSecOps hashtag#EKS hashtag#CloudArchitecture hashtag#SRE hashtag#PlatformEngineering</p>",
        "source": "dev.to",
        "published": "Mon, 19 Jan 2026 22:35:37 +0000",
        "fetched_at": "2026-01-19T23:17:09.816049Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 2,
        "final_score": 4.4,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/aws-builders/creating-a-ai-enabled-slackbot-with-aws-bedrock-knowledge-base-4pdm",
        "title": "Creating a AI-enabled Slackbot with AWS Bedrock Knowledge Base",
        "summary": "<p>One of the lowest-friction, highest-ROI applications of large language models (LLMs) so far has been the internal AI assistant. Yes, AI doesn't have to be all about customer-facing chatbots or fully autonomous agents. Just a simple interface for users to ask questions like the following can be a powerful tool: </p>\n\n<ul>\n<li>\"How do I deploy this service?\"</li>\n<li>\"What's the on-call runbook for this alert?\"</li>\n<li>\"Where is the latest diagram for the design doc?\" </li>\n</ul>\n\n<p>These questions already have answers — scattered across Confluence pages, Google Docs, GitHub READMEs, and Slack threads. The problem isn’t generation. It’s retrieval.</p>\n\n<p>Out of the box, LLMs are great at reasoning and summarization, but they’re completely disconnected from your organization’s institutional knowledge. Prompt stuffing helps a bit. Fine-tuning helps in very narrow cases. But neither scales when your knowledge base changes weekly, or when correctness actually matters.</p>\n\n<p>This is the void that retrieval-augmented generation (RAG) fills.</p>\n\n<p>RAG bridges the gap between probabilistic language models and deterministic internal knowledge. Instead of asking an LLM to guess, you retrieve relevant documents first, then ask the model to synthesize an answer grounded in that context. The result is an assistant that feels intelligent without being reckless — and, crucially, one that stays up to date without constant retraining.</p>\n\n<p>If you're already on AWS, Amazon Bedrock Knowledge Bases provides an easy way to create, deploy, and integrate a RAG into your existing infrastructure. In this post, we'll walk through how to use AWS Bedrock Knowledge Base and connected to a Slackbot for a realistic internal, AI-enabled assistant use case. </p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F7ca44vu37os1l2oonwyx.png\"><img alt=\" \" height=\"390\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F7ca44vu37os1l2oonwyx.png\" width=\"800\" /></a></p>\n\n<h2>\n  \n  \n  Setting up AWS Bedrock Knowledge Base\n</h2>\n\n<p>From AWS console, navigate to Amazon Bedrock. Under Build, choose Knowledge Bases. As of time of writing, AWS currently supports indexing unstructured data via creating a custom vector store, utilizing Kendra GenAI service, or enabling semantic search with structured data (e.g., databases, tables). </p>\n\n<p>Since most internal data is likely to be unstructured (e.g., Confluence documentation, markdown files, etc), we'll choose \"Create knowledge base with vector store\" option. As of time of writing, AWS supports Confluence, Salesforce, Sharepoint, and Web Crawlers on top of S3 (note: there is a limit of 5 data sources at the moment). For the purpose of this demo, let's choose Confluence. To connect, we'll need to store credentials in AWS Secret Manager as described in the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/confluence-data-source-connector.html\" rel=\"noopener noreferrer\">detailed guide</a>. </p>\n\n<p>Next, we need to configure our data source parsing strategy (either AWS default parser or utilizing a foundation model like Claude as a parser) as well as chunking strategy for our vector database. Bedrock will automatically chunk documents, generate embeddings, and store vectors in OpenSearch Serverless service based on our configurations here. The performance of the RAG will depend on these parameters, but for a quick demo, we can use default chunking and use Amazon Titan embeddings to start out with. </p>\n\n<p>Once the vector store is set up, we just have to manually sync our data store by syncing the data source. You can imagine adding Sharepoint for internal PDFs, crawling open source library documentation websites, as well as some internally hosted S3 files. </p>\n\n<h2>\n  \n  \n  Setting up a Slack bot\n</h2>\n\n<p>With the \"hard\" part out of the way, we need to set up a Slack App via the Slack Admin Console. The key things we need are:</p>\n\n<ol>\n<li>Enabling Socket Mode</li>\n<li>Minimally, chat:write, app_mentions:read, and channels:history under OAuth Scopes</li>\n<li>Then grab the bot tokens under \"Basic Information\" page</li>\n</ol>\n\n<p>The final part is to actually code up a Slack bot. We can use the Slack Bolt SDK to quickly spin up a bot using Python. We want the bot to do three things at a high-level:</p>\n\n<ol>\n<li>Parse Slack events (or respond to mentions, slash commands, etc)</li>\n<li>Query the Knowledge Base</li>\n<li>Generate a response</li>\n</ol>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Faphvux2wpb1a54nx4fna.png\"><img alt=\" \" height=\"212\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Faphvux2wpb1a54nx4fna.png\" width=\"593\" /></a></p>\n\n<p>A quick pseudocode could look like:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>def handler(event, context):\n    text = extract_slack_message(event)\n\n    retrieval = bedrock.retrieve(\n        knowledgeBaseId=KB_ID,\n        query=text,\n        retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": 5}}\n    )\n\n    prompt = build_prompt(text, retrieval[\"results\"])\n\n    response = bedrock_runtime.invoke_model(\n        modelId=\"arn:aws:bedrock:us-east-1:...:inference-profile/us.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n        body=prompt\n    )\n\n    post_to_slack(response)\n</code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  Tuning for performance\n</h2>\n\n<p>Now time for the real magic. Because LLMs are non-deterministic, we need to guide it with some context for better performance. While RAG provides most of our \"internal\" knowledge, we can still use prompt engineering to guide the generation side. </p>\n\n<p>You can include a prompt like:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>You are an internal engineering assistant.\n\nAnswer the question using ONLY the provided context.\nIf the answer is not in the context, say you do not know.\n\n&lt;context&gt;\n{{retrieved_chunks}}\n&lt;/context&gt;\n\nQuestion: {{user_question}}\n</code></pre>\n\n</div>\n\n\n\n<p>and pass it with the user's questions to dictate what the LLM will do. </p>\n\n<p>The other dial we can turn is how we embed and store our internal knowledge. AWS has a <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/kb-chunking.html\" rel=\"noopener noreferrer\">great guide on how content chunking works</a> for knowledge bases. The key takeaway is that depending on how the data is structured, different chunking schemes will perform better. For example, lots of Confluence documentation has a natural hierarchical pattern with headings and body, so using hierarchical chunking can link information better and lead to better retrieval performance. </p>\n\n<h2>\n  \n  \n  Wrapping up\n</h2>\n\n<p>AI-enabled Slackbots are quickly becoming the front door to internal knowledge. With Amazon bedrock Knowledge Bases, AWS has made it easy to build a RAG without knowing how to operate and maintain a vector database for the most part. </p>\n\n<p>With powerful LLMs like ChatGPT and Claude, creating a Slack bot is easier than ever. But if you would like to compare your solution with a working model, there is a slightly outdated yet functional example from AWS team on <a href=\"https://github.com/aws-samples/amazon-bedrock-knowledgebase-slackbot/blob/main/lambda/BedrockKbSlackbotFunction/index.py\" rel=\"noopener noreferrer\">Github</a> that you can follow. </p>",
        "source": "dev.to",
        "published": "Mon, 19 Jan 2026 22:35:31 +0000",
        "fetched_at": "2026-01-19T23:17:09.816056Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 2,
        "final_score": 4.4,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}