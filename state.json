{
  "meta": {
    "last_updated": "2026-01-21T23:22:53.447620Z",
    "retention_days": 7
  },
  "posted": {
    "science": [
      {
        "url": "https://phys.org/news/2026-01-flagship-space-telescope-lunar-exploration.html",
        "posted_at": "2026-01-14",
        "score": 7.9,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260108190339.htm",
        "posted_at": "2026-01-14",
        "score": 5.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260114084134.htm",
        "posted_at": "2026-01-15",
        "score": 8.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-microscopy-technique-cell-natural-conditions.html",
        "posted_at": "2026-01-15",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-scientists-enigmatic-cell-devices-rna.html",
        "posted_at": "2026-01-16",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260115220608.htm",
        "posted_at": "2026-01-16",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-tightening-focus-subcellular-snapshots-combined.html",
        "posted_at": "2026-01-17",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260117053528.htm",
        "posted_at": "2026-01-17",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-albumin-abundant-blood-protein-shield.html",
        "posted_at": "2026-01-18",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "posted_at": "2026-01-18",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118233604.htm",
        "posted_at": "2026-01-19",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-vibrational-spectroscopy-technique-enables-nanoscale.html",
        "posted_at": "2026-01-19",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120015646.htm",
        "posted_at": "2026-01-20",
        "score": 11.0,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/lunar-radio-telescope",
        "posted_at": "2026-01-20",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120015654.htm",
        "posted_at": "2026-01-21",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-massive-cloud-metallic-orbiting-mystery.html",
        "posted_at": "2026-01-21",
        "score": 5.1,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "posted_at": "2026-01-14",
        "score": 18.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.08224",
        "posted_at": "2026-01-14",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1130018/ai-companions-chatbots-relationships-2026-breakthrough-technology/",
        "posted_at": "2026-01-14",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/here-are-three-climate-wins-airlines-could-unlock-tomorrow-no-new-technology-required/?utm_source=rss&utm_medium=rss&utm_campaign=the-climate-impact-of-aviation-varies-widely-here-are-three-simple-strategies-to-keep-it-in-check",
        "posted_at": "2026-01-14",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2508.18025",
        "posted_at": "2026-01-15",
        "score": 16.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "posted_at": "2026-01-15",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1130027/generative-coding-ai-software-2026-breakthrough-technology/",
        "posted_at": "2026-01-15",
        "score": 4.8,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/15/the-ai-lab-revolving-door-spins-ever-faster/",
        "posted_at": "2026-01-15",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "posted_at": "2026-01-16",
        "score": 31.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.09745",
        "posted_at": "2026-01-16",
        "score": 17.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1131193/ces-showed-me-why-chinese-tech-companies-feel-so-optimistic/",
        "posted_at": "2026-01-16",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/a-trees-bark-can-take-a-staggeringly-large-bite-out-of-climate-change/?utm_source=rss&utm_medium=rss&utm_campaign=a-trees-bark-can-take-a-staggeringly-large-bite-out-of-climate-change",
        "posted_at": "2026-01-16",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "posted_at": "2026-01-17",
        "score": 26.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.09879",
        "posted_at": "2026-01-17",
        "score": 15.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
        "posted_at": "2026-01-17",
        "score": 4.6,
        "tags": [
          "transformation"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/17/musk-wants-up-to-134b-in-openai-lawsuit-despite-700b-fortune/",
        "posted_at": "2026-01-17",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "posted_at": "2026-01-18",
        "score": 19.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/",
        "posted_at": "2026-01-18",
        "score": 5.0,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/18/moxie-marlinspike-has-a-privacy-conscious-alternative-to-chatgpt/",
        "posted_at": "2026-01-18",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://radiancefields.com/a-ap-rocky-releases-helicopter-music-video-featuring-gaussian-splatting",
        "posted_at": "2026-01-18",
        "score": 2.4,
        "tags": []
      },
      {
        "url": "https://arxiv.org/abs/2507.03585",
        "posted_at": "2026-01-19",
        "score": 20.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/19/rogue-agents-and-shadow-ai-why-vcs-are-betting-big-on-ai-security/",
        "posted_at": "2026-01-19",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/12/1129782/ai-large-language-models-biology-alien-autopsy/",
        "posted_at": "2026-01-19",
        "score": 4.4,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/weve-overlooked-a-key-benefit-of-seaweed-farms-on-ocean-chemistry-for-the-first-time-scientists-quantify/?utm_source=rss&utm_medium=rss&utm_campaign=weve-overlooked-a-key-benefit-of-seaweed-farms-on-ocean-chemistry-for-the-first-time-scientists-quantify",
        "posted_at": "2026-01-19",
        "score": 3.2,
        "tags": []
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "posted_at": "2026-01-20",
        "score": 19.8,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.04521",
        "posted_at": "2026-01-20",
        "score": 18.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/20/1131462/the-uk-government-is-backing-ai-scientists-that-can-run-their-own-experiments/",
        "posted_at": "2026-01-20",
        "score": 4.8,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/lunar-radio-telescope",
        "posted_at": "2026-01-20",
        "score": 4.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "posted_at": "2026-01-21",
        "score": 32.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://arxiv.org/abs/2601.13590",
        "posted_at": "2026-01-21",
        "score": 17.8,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "ontology_shift"
        ]
      },
      {
        "url": "https://www.technologyreview.com/2026/01/21/1131366/rethinking-ais-future-in-an-augmented-workplace/",
        "posted_at": "2026-01-21",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/",
        "posted_at": "2026-01-21",
        "score": 4.2,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "education": [
      {
        "url": "https://theconversation.com/from-a-new-flagship-space-telescope-to-lunar-exploration-global-cooperation-and-competition-will-make-2026-an-exciting-year-for-space-272010",
        "posted_at": "2026-01-14",
        "score": 6.6,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "posted_at": "2026-01-14",
        "score": 3.3,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "posted_at": "2026-01-15",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/opinion-instead-of-defining-black-children-by-their-test-scores-we-should-help-them-overcome-academic-barriers-and-pursue-their-dreams/",
        "posted_at": "2026-01-15",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://hechingerreport.org/proof-points-math-vocabulary/",
        "posted_at": "2026-01-16",
        "score": 5.1,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "posted_at": "2026-01-16",
        "score": 3.6,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "posted_at": "2026-01-17",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.openculture.com/2026/01/can-genius-be-taught.html",
        "posted_at": "2026-01-17",
        "score": 3.3,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "posted_at": "2026-01-18",
        "score": 6.5,
        "tags": [
          "transformation",
          "boundary_crossing"
        ]
      },
      {
        "url": "https://hechingerreport.org/schools-are-closing-across-rural-america-heres-how-a-battle-over-small-districts-is-playing-out-in-one-state/",
        "posted_at": "2026-01-18",
        "score": 2.7,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "posted_at": "2026-01-19",
        "score": 4.4,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/high-school-college-computer-science-lessons/",
        "posted_at": "2026-01-19",
        "score": 2.7,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/lunar-radio-telescope",
        "posted_at": "2026-01-20",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "posted_at": "2026-01-20",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://theconversation.com/how-the-u-s-withdrawal-from-who-could-affect-global-health-powers-and-disease-threats-273768",
        "posted_at": "2026-01-21",
        "score": 6.6,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://hechingerreport.org/homeless-kids-get-special-treatment-at-boston-area-child-care-center/",
        "posted_at": "2026-01-21",
        "score": 4.2,
        "tags": [
          "boundary_crossing"
        ]
      }
    ],
    "mycotech": [
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251216081930.htm",
        "posted_at": "2026-01-14",
        "score": 7.5,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://therevelator.org/sea-turtle-migration/",
        "posted_at": "2026-01-14",
        "score": 4.5,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-cholera-virulence-sought-explanation.html",
        "posted_at": "2026-01-15",
        "score": 10.0,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "posted_at": "2026-01-15",
        "score": 6.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-scientists-enigmatic-cell-devices-rna.html",
        "posted_at": "2026-01-16",
        "score": 7.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "posted_at": "2026-01-16",
        "score": 5.2,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251226045324.htm",
        "posted_at": "2026-01-17",
        "score": 9.6,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-tightening-focus-subcellular-snapshots-combined.html",
        "posted_at": "2026-01-17",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260106001914.htm",
        "posted_at": "2026-01-18",
        "score": 8.2,
        "tags": [
          "transformation",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-albumin-abundant-blood-protein-shield.html",
        "posted_at": "2026-01-18",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-revealing-cell-nanocourier.html",
        "posted_at": "2026-01-19",
        "score": 7.2,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112001034.htm",
        "posted_at": "2026-01-19",
        "score": 5.2,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "posted_at": "2026-01-20",
        "score": 7.5,
        "tags": [
          "boundary_crossing",
          "visibility_gain"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-spatial-imaging-higher-wheat-yields.html",
        "posted_at": "2026-01-20",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260101160854.htm",
        "posted_at": "2026-01-21",
        "score": 7.5,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://phys.org/news/2026-01-soil-ecoacoustics-global-effort-underground.html",
        "posted_at": "2026-01-21",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "posted_at": "2026-01-14",
        "score": 11.4,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/the-search-for-where-consciousness-lives-in-the-brain-1261596/",
        "posted_at": "2026-01-14",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/sean-sherman-turtle-island-cookbook",
        "posted_at": "2026-01-15",
        "score": 7.9,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/2014/09/design-package-2014/",
        "posted_at": "2026-01-15",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "posted_at": "2026-01-16",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.quantamagazine.org/why-theres-no-single-best-way-to-store-information-20260116/",
        "posted_at": "2026-01-16",
        "score": 4.1,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "posted_at": "2026-01-17",
        "score": 12.8,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://nautil.us/why-the-do-nothing-challenge-doesnt-do-much-for-you-1262005/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "posted_at": "2026-01-18",
        "score": 12.1,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/ai-weiwei-gets-artsy-fartsy-about-surveillance/",
        "posted_at": "2026-01-18",
        "score": 4.0,
        "tags": [
          "boundary_crossing"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "posted_at": "2026-01-19",
        "score": 9.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/all-nine-of-jan-van-eycks-surviving-portraits-are-coming-together-for-the-very-first-time-in-history-180988003/",
        "posted_at": "2026-01-19",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/places/moment-point-zero",
        "posted_at": "2026-01-20",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.smithsonianmag.com/smart-news/these-baffling-bone-artifacts-discovered-by-an-amateur-archaeologist-may-be-the-worlds-oldest-whale-harpoons-180988025/",
        "posted_at": "2026-01-20",
        "score": 5.2,
        "tags": [
          "visibility_gain",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.atlasobscura.com/articles/centralia-pennsylvania-rebirth",
        "posted_at": "2026-01-21",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://aeon.co/essays/how-a-playful-literary-hoax-illuminates-classical-queerness?utm_source=rss-feed",
        "posted_at": "2026-01-21",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/05/23/beyond-expo-2025-interview-with-zack-kass-ais-ultimate-challenge-will-be-crisis-of-purpose/",
        "posted_at": "2026-01-14",
        "score": 4.5,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.wired.com/story/neuroscience-procrastination-brain-mechanism-task-avoidance/",
        "posted_at": "2026-01-14",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.scmp.com/news/china/diplomacy/article/3339989/south-korean-leader-lee-takes-pragmatic-approach-reset-ties-china-japan?utm_source=rss_feed",
        "posted_at": "2026-01-15",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/11/04/eric-jing-ant-group-to-strengthen-support-for-hong-kongs-global-finance-and-tech-leadership-with-ai-goglobal-services/",
        "posted_at": "2026-01-15",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://pandaily.com/china-s-fast-radio-telescope-to-be-upgraded-into-a-cosmic-super-probe-with-dozens-of-new-antennas",
        "posted_at": "2026-01-16",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2024/05/26/beyond-expo-2024-navigating-the-future-of-innovation-in-cross-border-e-commerce/",
        "posted_at": "2026-01-16",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/16/x-is-down-for-the-second-time-this-week/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://www.wired.com/story/livestream-welcome-to-the-chinese-century/",
        "posted_at": "2026-01-17",
        "score": 4.0,
        "tags": [
          "value_redefinition"
        ]
      },
      {
        "url": "https://technode.com/2025/06/25/alibaba-merges-ele-me-fliggy-into-e-commerce-unit-in-strategic-shift/",
        "posted_at": "2026-01-18",
        "score": 3.9,
        "tags": [
          "boundary_crossing",
          "value_redefinition"
        ]
      },
      {
        "url": "https://www.scmp.com/news/world/europe/article/3340324/europes-far-right-eyes-run-portugals-presidential-election?utm_source=rss_feed",
        "posted_at": "2026-01-18",
        "score": 3.3,
        "tags": [
          "visibility_gain"
        ]
      },
      {
        "url": "https://techcrunch.com/2026/01/19/looking-ahead-to-2026-whats-next-for-startup-battlefield-200/",
        "posted_at": "2026-01-19",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      },
      {
        "url": "https://www.scmp.com/news/china/diplomacy/article/3340468/how-narrowing-china-us-gap-could-reshape-global-power-play-2035?utm_source=rss_feed",
        "posted_at": "2026-01-19",
        "score": 4.2,
        "tags": [
          "boundary_crossing",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/09/12/satellite-imaging-inclusive-ai-and-privacy-preserving-tech-win-at-ant-groups-global-competition/",
        "posted_at": "2026-01-20",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://spectrum.ieee.org/lunar-radio-telescope",
        "posted_at": "2026-01-20",
        "score": 4.8,
        "tags": [
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://technode.com/2025/06/05/behind-the-blind-box-boom-the-global-ascent-of-pop-marts-labubu/",
        "posted_at": "2026-01-21",
        "score": 4.5,
        "tags": [
          "transformation",
          "scale_shift"
        ]
      },
      {
        "url": "https://www.wired.com/story/china-crystal-capital/",
        "posted_at": "2026-01-21",
        "score": 4.3,
        "tags": [
          "scale_shift"
        ]
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/adam-maj/tiny-gpu",
        "posted_at": "2026-01-14",
        "score": 10.9,
        "tags": [
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/microsoft/PowerToys",
        "posted_at": "2026-01-14",
        "score": 8.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/maame-codes/top-offshore-software-development-companies-reviews-rates-33-got-the-opportunity-to-interview-9c1",
        "posted_at": "2026-01-15",
        "score": 14.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/mudler/LocalAI",
        "posted_at": "2026-01-15",
        "score": 9.7,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/gd-tech-guru/the-great-decoupling-the-data-sovereignty-correction-4m7o",
        "posted_at": "2026-01-16",
        "score": 14.3,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/techresolve/solved-ai-costs-skyrocketing-how-we-cut-our-spend-and-tamed-idle-gpus-4631",
        "posted_at": "2026-01-16",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/jakiru5/how-i-built-my-8-bit-portfolio-with-claude-opus-45-on-antigravity-3a1j",
        "posted_at": "2026-01-17",
        "score": 8.0,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/google/langextract",
        "posted_at": "2026-01-17",
        "score": 7.3,
        "tags": [
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/agusrdz/from-glasses-to-code-the-personal-journey-behind-harmonia-vision-1ofc",
        "posted_at": "2026-01-18",
        "score": 8.6,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/fabianfrankwerner/python-vs-ruby-i-built-the-same-github-analyzer-with-both-51gj",
        "posted_at": "2026-01-18",
        "score": 7.4,
        "tags": [
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://github.com/yt-dlp/yt-dlp",
        "posted_at": "2026-01-19",
        "score": 14.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/deepak_mishra_35863517037/integrating-playwright-with-flask-resolving-the-async-conflict-2d9o",
        "posted_at": "2026-01-19",
        "score": 11.0,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/czlonkowski/n8n-mcp",
        "posted_at": "2026-01-20",
        "score": 14.5,
        "tags": [
          "transformation",
          "boundary_crossing",
          "visibility_gain",
          "scale_shift"
        ]
      },
      {
        "url": "https://dev.to/julesk/a-developers-map-to-shopify-ucp-1c55",
        "posted_at": "2026-01-20",
        "score": 10.4,
        "tags": [
          "transformation",
          "boundary_crossing",
          "scale_shift",
          "ontology_shift"
        ]
      },
      {
        "url": "https://dev.to/deepak_mishra_35863517037/serving-big-data-streaming-responses-with-generators-1eg",
        "posted_at": "2026-01-21",
        "score": 12.2,
        "tags": [
          "transformation",
          "boundary_crossing",
          "value_redefinition",
          "scale_shift"
        ]
      },
      {
        "url": "https://github.com/lukasz-madon/awesome-remote-job",
        "posted_at": "2026-01-21",
        "score": 10.9,
        "tags": [
          "boundary_crossing",
          "visibility_gain",
          "value_redefinition",
          "scale_shift",
          "ontology_shift"
        ]
      }
    ]
  },
  "pending": {
    "science": [
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120015646.htm",
        "title": "A global DNA study reveals a hidden threat in diabetic foot infections",
        "summary": "Scientists have uncovered new clues about why diabetic foot infections can become so severe and difficult to treat. By analyzing the DNA of E. coli bacteria taken from infected wounds around the world, researchers found an unexpected level of diversity, with many strains carrying genes linked to antibiotic resistance and aggressive disease. Rather than a single dangerous strain, multiple types of E. coli appear able to thrive in diabetic foot ulcers, helping explain why infections can worsen quickly and sometimes lead to amputation.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 20 Jan 2026 02:02:20 EST",
        "fetched_at": "2026-01-21T23:21:53.777512Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 14,
        "timeliness_score": 4,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260121034146.htm",
        "title": "A simple blood test mismatch linked to kidney failure and death",
        "summary": "A major global study suggests that a hidden mismatch between two common blood tests could quietly signal serious trouble ahead. When results from creatinine and cystatin C—two markers used to assess kidney health—don’t line up, the risk of kidney failure, heart disease, and even death appears to rise sharply. Researchers found that this gap is especially common among hospitalized and older patients, and that relying on just one test may miss early warning signs.",
        "source": "www.sciencedaily.com",
        "published": "Wed, 21 Jan 2026 12:19:18 EST",
        "fetched_at": "2026-01-21T23:21:53.777462Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.2,
        "temp_score_trend": 5.8
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120095111.htm",
        "title": "Scientists identify hidden protein interaction driving Parkinson’s disease",
        "summary": "Researchers have identified a key molecular interaction that accelerates Parkinson’s disease by damaging the brain’s energy systems. They designed a new treatment that intercepts this harmful process, protecting brain cells and restoring their function. In lab and animal models, the approach improved movement and cognitive performance while reducing inflammation. The findings point toward a new generation of Parkinson’s therapies aimed at the root cause, not just the symptoms.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 20 Jan 2026 10:08:47 EST",
        "fetched_at": "2026-01-21T23:21:53.777497Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.5,
        "temp_score_trend": 5.5
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260118233604.htm",
        "title": "This tiny power module could change how the world uses energy",
        "summary": "As global energy demand surges—driven by AI-hungry data centers, advanced manufacturing, and electrified transportation—researchers at the National Renewable Energy Laboratory have unveiled a breakthrough that could help squeeze far more power from existing electricity supplies. Their new silicon-carbide-based power module, called ULIS, packs dramatically more power into a smaller, lighter, and cheaper design while wasting far less energy in the process.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 19 Jan 2026 07:05:39 EST",
        "fetched_at": "2026-01-21T23:21:53.777584Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120000333.htm",
        "title": "Stanford scientists found a way to regrow cartilage and stop arthritis",
        "summary": "Scientists at Stanford Medicine have discovered a treatment that can reverse cartilage loss in aging joints and even prevent arthritis after knee injuries. By blocking a protein linked to aging, the therapy restored healthy, shock-absorbing cartilage in old mice and injured joints, dramatically improving movement and joint function. Human cartilage samples from knee replacement surgeries also began regenerating when exposed to the treatment.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 20 Jan 2026 23:55:09 EST",
        "fetched_at": "2026-01-21T23:21:53.777518Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120000311.htm",
        "title": "James Webb catches an exoplanet losing its atmosphere in real time",
        "summary": "Astronomers have captured the most dramatic view yet of a planet losing its atmosphere, watching the ultra-hot gas giant WASP-121b for an entire orbit with the James Webb Space Telescope. Instead of a single stream of escaping gas, the planet is wrapped in two colossal helium tails—one trailing behind like a comet, the other stretching ahead toward its star.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 20 Jan 2026 08:01:33 EST",
        "fetched_at": "2026-01-21T23:21:53.777541Z",
        "tags": [
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260117053528.htm",
        "title": "How scientists are turning thyme into precision medicine",
        "summary": "Thyme extract is packed with health-promoting compounds, but it is difficult to control and easy to waste. Researchers created a new technique that traps tiny amounts of the extract inside microscopic capsules, preventing evaporation and irritation. The method delivers consistent nanodoses and could eventually be used in medicines or food products. It may also work for many other natural extracts.",
        "source": "www.sciencedaily.com",
        "published": "Sat, 17 Jan 2026 09:48:30 EST",
        "fetched_at": "2026-01-21T23:21:53.777645Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260115220608.htm",
        "title": "Stretchable OLED displays take a big leap forward",
        "summary": "A new OLED design can stretch dramatically while staying bright, solving a problem that has long limited flexible displays. The breakthrough comes from pairing a highly efficient light-emitting material with tough, transparent MXene-based electrodes. Tests showed the display kept most of its brightness even after repeated stretching. The technology could power future wearable screens and on-skin health sensors.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 15 Jan 2026 22:15:29 EST",
        "fetched_at": "2026-01-21T23:21:53.777721Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://phys.org/news/2026-01-vital-pyrenees-fast.html",
        "title": "Snow is vital for the Pyrenees, and it's disappearing fast",
        "summary": "Snow is a defining feature of mountain ranges, and of winter itself for much of the world. But beyond its scenic value, snow plays a vital role in mountain ecosystems, as well as a range of human socioeconomic activity, and it is one of the climatic elements most sensitive to global warming. In recent decades, its quantity, duration and behavior have all changed significantly.",
        "source": "phys.org",
        "published": "Wed, 21 Jan 2026 18:00:01 EST",
        "fetched_at": "2026-01-21T23:21:55.225722Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.199999999999999,
        "temp_score_trend": 4.799999999999999
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260120095116.htm",
        "title": "Finally explained: Why kidney disease is so deadly for the heart",
        "summary": "Scientists have uncovered why people with chronic kidney disease so often die from heart problems: damaged kidneys release tiny particles into the bloodstream that actively poison the heart. These particles, produced only by diseased kidneys, carry genetic material that disrupts heart function and can lead to heart failure.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 20 Jan 2026 10:40:35 EST",
        "fetched_at": "2026-01-21T23:21:53.777492Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          }
        ],
        "structural_score": 7,
        "timeliness_score": 4,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.1,
        "temp_score_trend": 4.9
      }
    ],
    "ai": [
      {
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "summary": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "source": "venturebeat.com",
        "published": "Fri, 16 Jan 2026 14:01:00 GMT",
        "fetched_at": "2026-01-21T23:21:36.198744Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 9
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 39,
        "timeliness_score": 3,
        "final_score": 21.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "summary": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr /><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr /><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr /><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr /><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr /><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "source": "venturebeat.com",
        "published": "Wed, 07 Jan 2026 20:00:00 GMT",
        "fetched_at": "2026-01-21T23:21:36.198760Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 8
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 32,
        "timeliness_score": 3,
        "final_score": 17.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "summary": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr /><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "source": "venturebeat.com",
        "published": "Mon, 19 Jan 2026 14:00:00 GMT",
        "fetched_at": "2026-01-21T23:21:36.198730Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 24,
        "timeliness_score": 3,
        "final_score": 13.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.08875",
        "title": "Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement",
        "summary": "arXiv:2601.08875v2 Announce Type: replace-cross \nAbstract: Image registration under domain shift remains a fundamental challenge in computer vision and medical imaging: when source and target images exhibit systematic intensity differences, the brightness constancy assumption underlying conventional registration methods is violated, rendering correspondence\n  estimation ill-posed. We propose SAR-Net, a unified framework that addresses this challenge through principled scene-appearance disentanglement. Our key insight is that observed images can be decomposed into domain-invariant scene representations and domain-specific appearance codes, enabling registration\n  via re-rendering rather than direct intensity matching. We establish theoretical conditions under which this decomposition enables consistent cross-domain alignment (Proposition 1) and prove that our scene consistency loss provides a sufficient condition for geometric correspondence in the shared latent\n  space (Proposition 2). Empirically, we validate SAR-Net on the ANHIR (Automatic Non-rigid Histological Image Registration) challenge benchmark, where multi-stain histopathology images exhibit coupled domain shift from different staining protocols and geometric distortion from tissue preparation. Our method\n  achieves a median relative Target Registration Error (rTRE) of 0.25%, outperforming the state-of-the-art MEVIS method (0.27% rTRE) by 7.4%, with robustness of 99.1%. Code is available at https://github.com/D-ST-Sword/SAR-NET",
        "source": "export.arxiv.org",
        "published": "Wed, 21 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-21T23:21:32.102496Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          }
        ],
        "structural_score": 21,
        "timeliness_score": 5,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 17.8,
        "temp_score_trend": 8.2
      },
      {
        "url": "https://arxiv.org/abs/2601.08875",
        "title": "Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement",
        "summary": "arXiv:2601.08875v2 Announce Type: replace-cross \nAbstract: Image registration under domain shift remains a fundamental challenge in computer vision and medical imaging: when source and target images exhibit systematic intensity differences, the brightness constancy assumption underlying conventional registration methods is violated, rendering correspondence\n  estimation ill-posed. We propose SAR-Net, a unified framework that addresses this challenge through principled scene-appearance disentanglement. Our key insight is that observed images can be decomposed into domain-invariant scene representations and domain-specific appearance codes, enabling registration\n  via re-rendering rather than direct intensity matching. We establish theoretical conditions under which this decomposition enables consistent cross-domain alignment (Proposition 1) and prove that our scene consistency loss provides a sufficient condition for geometric correspondence in the shared latent\n  space (Proposition 2). Empirically, we validate SAR-Net on the ANHIR (Automatic Non-rigid Histological Image Registration) challenge benchmark, where multi-stain histopathology images exhibit coupled domain shift from different staining protocols and geometric distortion from tissue preparation. Our method\n  achieves a median relative Target Registration Error (rTRE) of 0.25%, outperforming the state-of-the-art MEVIS method (0.27% rTRE) by 7.4%, with robustness of 99.1%. Code is available at https://github.com/D-ST-Sword/SAR-NET",
        "source": "export.arxiv.org",
        "published": "Wed, 21 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-21T23:21:33.612017Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 8
          }
        ],
        "structural_score": 21,
        "timeliness_score": 5,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "summary": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "source": "venturebeat.com",
        "published": "Mon, 05 Jan 2026 07:45:00 GMT",
        "fetched_at": "2026-01-21T23:21:36.198765Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 23,
        "timeliness_score": 3,
        "final_score": 13.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "summary": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "source": "venturebeat.com",
        "published": "Tue, 13 Jan 2026 13:00:00 GMT",
        "fetched_at": "2026-01-21T23:21:36.198750Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 22,
        "timeliness_score": 3,
        "final_score": 12.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://arxiv.org/abs/2601.12257",
        "title": "Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy",
        "summary": "arXiv:2601.12257v1 Announce Type: cross \nAbstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \\textit{light-occluding} and \\textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.",
        "source": "export.arxiv.org",
        "published": "Wed, 21 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-21T23:21:32.100035Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 5,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 14.600000000000001,
        "temp_score_trend": 7.4
      },
      {
        "url": "https://arxiv.org/abs/2601.13809",
        "title": "DroneVLA: VLA based Aerial Manipulation",
        "summary": "arXiv:2601.13809v1 Announce Type: cross \nAbstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.",
        "source": "export.arxiv.org",
        "published": "Wed, 21 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-21T23:21:32.100922Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 5,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 14.600000000000001,
        "temp_score_trend": 7.4
      },
      {
        "url": "https://arxiv.org/abs/2601.13676",
        "title": "Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery",
        "summary": "arXiv:2601.13676v1 Announce Type: new \nAbstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.",
        "source": "export.arxiv.org",
        "published": "Wed, 21 Jan 2026 00:00:00 -0500",
        "fetched_at": "2026-01-21T23:21:33.609483Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 17,
        "timeliness_score": 5,
        "final_score": 11.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 14.600000000000001,
        "temp_score_trend": 7.4
      }
    ],
    "education": [
      {
        "url": "https://edsource.org/2025/how-one-california-school-came-together-to-pack-20000-meals-for-the-holidays/746481",
        "title": "How one California school came together to pack 20,000 meals for the holidays",
        "summary": "At an Elk Grove high school in Sacramento County, students worked a night in the cafeteria to combat global food insecurity.",
        "source": "edsource.org",
        "published": "Mon, 08 Dec 2025 08:03:00 +0000",
        "fetched_at": "2026-01-21T23:22:13.608995Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 3,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/fresno-unified-data-error-analysis/738872",
        "title": "Fresno Unified error skews state teacher data, analysis shows",
        "summary": "A mistake made by a staff member deflated claims that the state added 3,000 new teachers to its ranks between 2020 and 2024.",
        "source": "edsource.org",
        "published": "Tue, 19 Aug 2025 19:26:35 +0000",
        "fetched_at": "2026-01-21T23:22:13.610161Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 2
          }
        ],
        "structural_score": 8,
        "timeliness_score": 3,
        "final_score": 5.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/technology-education-student-wellbeing/749262",
        "title": "Rethinking screen time in California classrooms",
        "summary": "Effective instruction requires a balance between traditional methods and digital engagement. Here's what school districts, families and the state must do.",
        "source": "edsource.org",
        "published": "Tue, 20 Jan 2026 02:58:44 +0000",
        "fetched_at": "2026-01-21T23:22:13.608644Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 6,
        "timeliness_score": 3,
        "final_score": 4.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2026/california-universal-prekindergarten-implementation/748208",
        "title": "Universal prekindergarten has arrived; now we must sustain it",
        "summary": "County offices of education across the state are calling on the governor and the Legislature to support universal prekindergarten with sustained funding.",
        "source": "edsource.org",
        "published": "Tue, 06 Jan 2026 03:38:57 +0000",
        "fetched_at": "2026-01-21T23:22:13.608777Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/nixon-veto-childcare-lessons/747568",
        "title": "The path to universal preschool in California: Avoiding past mistakes",
        "summary": "California is expanding its transitional kindergarten (TK) to a universal prekindergarten (UPK) system, and must learn from the mistakes of the 1971 federal effort to create a universal early care and education system, which was vetoed by President Nixon.",
        "source": "edsource.org",
        "published": "Tue, 23 Dec 2025 07:03:30 +0000",
        "fetched_at": "2026-01-21T23:22:13.608871Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2025/california-schools-to-use-reading-screening-test/733022",
        "title": "California schools prepare to introduce universal reading screening",
        "summary": "A quick screening test will be administered to all students in kindergarten through second grade to detect possible reading difficulties, but it is not intended to be a final diagnosis.",
        "source": "edsource.org",
        "published": "Tue, 20 May 2025 07:05:00 +0000",
        "fetched_at": "2026-01-21T23:22:13.610811Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393",
        "title": "As we expand universal preschool access, let’s ensure teachers mirror their students’ ethnicity",
        "summary": "Author&#8217;s original hed: As Universal Preschool Access Expands to Reach More Families of Color, So Do Inequitable Practices Such as Racial Bias, Exclusionary Discipline and Lack of Cultural Representation, Leading to a Crisis for Black Boys As California progresses toward universal preschool access, the need increases for training, hiring and retaining early childhood male educators who are racially and ethnically representative of the children... <span class=\"read-more\"><a href=\"https://edsource.org/2024/as-we-expand-universal-preschool-access-lets-ensure-teachers-mirror-their-students-ethnicity/715393\">read more</a></span>",
        "source": "edsource.org",
        "published": "Tue, 09 Jul 2024 15:53:36 +0000",
        "fetched_at": "2026-01-21T23:22:13.613381Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2024/survey-californians-are-worried-about-student-health-lukewarm-toward-a-state-school-bond/709604",
        "title": "Survey: Californians are worried about student health, lukewarm toward a state school bond",
        "summary": "The annual Public Policy Institute of California survey on education issues found wide support for universal TK and teaching about slavery but divisions on transgender issues.",
        "source": "edsource.org",
        "published": "Thu, 11 Apr 2024 05:11:37 +0000",
        "fetched_at": "2026-01-21T23:22:13.613981Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://www.openculture.com/2026/01/watch-the-evolution-of-paris-unfold-in-a-timelapse-video-from-300-bce-to-2025.html",
        "title": "Watch the Evolution of Paris Unfold in a Timelapse Video, from 300 BCE to 2025",
        "summary": "Though it’s easily forgotten in our age of air travel and instantaneous global communication, many a great city is located where it is because of a river. That holds true everywhere from London to Buenos Aires to Tokyo to New York — and even to Los Angeles, despite its own once-uncontrollable river having long since [&#8230;]",
        "source": "www.openculture.com",
        "published": "Tue, 20 Jan 2026 10:05:56 +0000",
        "fetched_at": "2026-01-21T23:22:18.219098Z",
        "tags": [
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 5,
        "timeliness_score": 3,
        "final_score": 4.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 4.4,
        "temp_score_trend": 3.5999999999999996
      },
      {
        "url": "https://edsource.org/2026/appeals-court-pauses-california-gender-law/748472",
        "title": "Federal appeals court pauses ruling on student gender identity disclosure in California",
        "summary": "An appeals court panel wrote that it is “skeptical” of the lower court’s decision, which would challenge policies adopted by 598 of the state’s nearly 1,000 local school districts.",
        "source": "edsource.org",
        "published": "Thu, 08 Jan 2026 00:04:46 +0000",
        "fetched_at": "2026-01-21T23:22:13.608751Z",
        "tags": [
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 4,
        "timeliness_score": 3,
        "final_score": 3.5,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "mycotech": [
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003596",
        "title": "Pangenome graph analysis reveals evolution of resistance breaking in spinach downy mildew",
        "summary": "<p>by Petros Skiadas, Melanie N. Mendel, Joyce Elberse, Guido Van den Ackerveken, Ronnie de Jonge, Michael F. Seidl</p>\n\nFilamentous plant pathogens secrete effectors to successfully establish host infections. In resistant crop varieties, plant immunity can be triggered by immune receptors that recognize these effectors. Resistant crop varieties are grown in large-scale monocultures imposing strong selection pressure on pathogens, driving rapid evolution of effector repertoires resulting in the frequent breakdowns of resistance within just a few growing seasons. The oomycete <i>Peronospora effusa</i>, responsible for downy mildew on spinach, is an example of a rapidly adapting pathogen, but it is yet unknown how <i>P. effusa</i> can successfully overcome resistance of spinach by genomic adaptations. To close this knowledge gap, we here generated genome assemblies and constructed a pangenome graph for 19 isolates corresponding to 19 officially denominated resistance-breaking <i>P. effusa</i> races, which can cause disease on a differential set of spinach cultivars. Haplotype-resolved pangenome graph analyses revealed that many isolates emerged from recent sexual recombination, yet others evolved via prolonged asexual reproduction and loss of heterozygosity. By phasing effector candidates to determine their allelic variation, we identified effector candidates associated to resistance breaking of spinach varieties and reconstructed the evolutionary events that led to their diversification. The here developed and applied computational genomics approaches offer invaluable insights into the molecular mechanisms of the rapid evolution of <i>P. effusa</i>, and points to potential targets for future resistance breeding.",
        "source": "journals.plos.org",
        "published": "2026-01-20T14:00:00Z",
        "fetched_at": "2026-01-21T23:22:29.046578Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 18,
        "timeliness_score": 1,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2025/12/251226045324.htm",
        "title": "Scientists replayed evolution and found a surprise",
        "summary": "Environmental change doesn’t affect evolution in a single, predictable way. In large-scale computer simulations, scientists discovered that some fluctuating conditions help populations evolve higher fitness, while others slow or even derail progress. Two populations facing different kinds of change can end up on completely different evolutionary paths. The findings challenge the idea that one population’s response can represent a whole species.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 30 Dec 2025 15:57:09 EST",
        "fetched_at": "2026-01-21T23:22:27.588715Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.anthropocenemagazine.org/2026/01/researchers-turn-avocado-toast-into-biodegradable-food-packaging/?utm_source=rss&utm_medium=rss&utm_campaign=turning-avocado-toast-into-food-packaging",
        "title": "Researchers turn avocado toast into biodegradable food packaging",
        "summary": "A strong yet degradable bioplastic made from avocado peels and stale bread tackles two global challenges: food waste and plastic pollution",
        "source": "www.anthropocenemagazine.org",
        "published": "Thu, 15 Jan 2026 13:00:29 +0000",
        "fetched_at": "2026-01-21T23:22:30.554836Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 4,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260106001914.htm",
        "title": "The poison frog that fooled scientists for decades",
        "summary": "Researchers discovered that a poison frog species described decades ago was based on a mix-up involving the wrong museum specimen. The frog tied to the official species name turned out to be brown, not the colorful animal shown in the original photo. After tracing old records and images, scientists corrected the error and reclassified the frog as part of an already-known species. The case underscores how vital museum collections are—and how even small mistakes can ripple through science for years.",
        "source": "www.sciencedaily.com",
        "published": "Tue, 06 Jan 2026 20:59:08 EST",
        "fetched_at": "2026-01-21T23:22:27.588652Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 4,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260107225541.htm",
        "title": "A hidden world inside DNA is finally revealed",
        "summary": "DNA doesn’t just sit still inside our cells — it folds, loops, and rearranges in ways that shape how genes behave. Researchers have now mapped this hidden architecture in unprecedented detail, showing how genome structure changes from cell to cell and over time. These insights reveal why many disease-linked mutations outside genes can still cause harm. The findings could speed up the discovery of genetic risks and inspire new ways to target diseases.",
        "source": "www.sciencedaily.com",
        "published": "Thu, 08 Jan 2026 21:16:11 EST",
        "fetched_at": "2026-01-21T23:22:27.588629Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 9,
        "timeliness_score": 4,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003589",
        "title": "Characterization of RNA interference in the cnidarian <i>Nematostella vectensis</i> reveals partial target silencing but lack of small RNA amplification",
        "summary": "<p>by Yael Admoni, Magda Lewandowska, Reuven Aharoni, Junchao Shi, Xudong Zhang, Qi Chen, Yehu Moran</p>\n\nRNA interference (RNAi) is a sequence-specific mRNA degradation mechanism, in which short interfering RNAs (siRNAs) guide Argonaute proteins to complementary targets, resulting in their degradation. In many organisms, RNAi also serves antiviral roles by processing viral double-stranded RNA (dsRNA) into siRNAs that prevent viral replication. Antiviral RNAi is considered an ancestral mechanism which invertebrates rely on for defense against viruses, whereas vertebrates have evolved instead the interferon pathway. Recent studies suggest that sea anemones, members of the basally-branching phylum Cnidaria, might possess an innate immune response with more vertebrate characteristics than previously thought; however, it is unknown whether cnidarians also employ RNAi as an antiviral response similarly to nematodes and insects. Here, we characterize the response of the model cnidarian <i>Nematostella vectensis</i> to simulated viral infection. We injected dsRNA with eGFP sequence into eGFP-expressing transgenic zygotes and show that siRNAs mapping to the eGFP sequence are generated and induce a moderate but significant knockdown of eGFP expression. Interestingly, we detected no evidence for secondary siRNA production, despite their crucial role in the amplification of antiviral response in other organisms. Notably, siRNA pathway components are specifically upregulated upon dsRNA injection, while microRNA pathway components are downregulated. Furthermore, injection of mRNA coding for self-replicating viral gene fused to eGFP, also induced upregulation of siRNA-related genes and a mild decrease in transgene expression. Overall, we propose that <i>N. vectensis</i> possesses an siRNA-mediated response that lacks secondary amplification and likely functions as a short-term antiviral mechanism.",
        "source": "journals.plos.org",
        "published": "2026-01-05T14:00:00Z",
        "fetched_at": "2026-01-21T23:22:29.046761Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 1,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003572",
        "title": "The Rho GTPase regulator ARHGEF3 orchestrates hair placode budding by coordinating cell fate and P-cadherin patterning in mice",
        "summary": "<p>by Krithika Kalyanakrishnan, Amy Beaudin, Alexandra Jetté, Sarah Ghezelbash, Diana Ioana Hotea, Jie Chen, Philippe Lefrançois, Mélanie Laurin</p>\n\nDuring embryogenesis, cells self-organize into precise patterns that enable tissues and organs to acquire specialized functions. Despite its importance, the molecular choreography driving these collective cellular behaviors remains poorly understood, posing a major challenge in developmental biology and limiting progress in regenerative medicine. Here, we use the developing mouse hair follicle as a model mini-organ to investigate the early events of epithelial bud formation. We identify the Rho GTPase regulator ARHGEF3 as a critical upstream factor that restricts cell fate acquisition and establishes a radial gradient of P-cadherin across the placode during early hair follicle development. In <i>Arhgef3</i> knockout embryos, placodes are enlarged and exhibit elevated P-cadherin levels at cell-cell junctions, disrupting gradient formation without affecting E-cadherin distribution. This defect correlates with aberrant epithelial organization and increased incidence of straight hair follicle downgrowth. Our findings position ARHGEF3 as a novel regulator of cadherin patterning and placode polarization, and suggest broader roles in the morphogenesis of other epithelial appendages governed by similar developmental programs.",
        "source": "journals.plos.org",
        "published": "2026-01-05T14:00:00Z",
        "fetched_at": "2026-01-21T23:22:29.046790Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 1,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112211455.htm",
        "title": "A new test reveals which antibiotics truly kill bacteria",
        "summary": "Some antibiotics stop bacteria from growing without actually killing them, allowing infections to return later. Scientists at the University of Basel created a new test that tracks individual bacteria to see which drugs truly eliminate them. When tested on tuberculosis and other serious lung infections, the method revealed big differences in how bacteria tolerate treatment. The findings could lead to more precise therapies and better predictions of treatment success.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 12 Jan 2026 21:33:16 EST",
        "fetched_at": "2026-01-21T23:22:27.588596Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260112001034.htm",
        "title": "The oxygen you breathe depends on a tiny ocean ingredient",
        "summary": "Microscopic ocean algae produce a huge share of Earth’s oxygen—but they need iron to do it. New field research shows that when iron is scarce, phytoplankton waste energy and photosynthesis falters. Climate-driven changes may reduce iron delivery to the oceans, weakening the base of marine food chains. Over time, this could mean fewer krill and fewer whales, seals, and penguins.",
        "source": "www.sciencedaily.com",
        "published": "Mon, 12 Jan 2026 09:01:37 EST",
        "fetched_at": "2026-01-21T23:22:27.588601Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.sciencedaily.com/releases/2026/01/260103155032.htm",
        "title": "The invisible microbes that help keep us healthy",
        "summary": "Not all microbes are villains—many are vital to keeping us healthy. Researchers have created a world-first database that tracks beneficial bacteria and natural compounds linked to immune strength, stress reduction, and resilience. The findings challenge the long-standing obsession with germs as threats and instead highlight the hidden health benefits of biodiversity. This shift could influence everything from urban design to environmental restoration.",
        "source": "www.sciencedaily.com",
        "published": "Sun, 04 Jan 2026 07:14:46 EST",
        "fetched_at": "2026-01-21T23:22:27.588671Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          }
        ],
        "structural_score": 8,
        "timeliness_score": 4,
        "final_score": 6.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 6.8,
        "temp_score_trend": 5.199999999999999
      }
    ],
    "curiosity": [
      {
        "url": "https://www.atlasobscura.com/articles/20-places-to-travel-and-transform-yourself-in-2026-from-atlas-obscura",
        "title": "20 Places to Travel and Transform Yourself in 2026, from Atlas Obscura",
        "summary": "<p>Looking for your next adventure? These 20 extraordinary destinations might just change how you see the world in 2026. Each place on this list asks something of you—patience, curiosity, humility, wonder—and gives something back in return. They’re not just trips; they’re invitations to travel differently, and to come home changed.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>1.</strong><a href=\"https://www.atlasobscura.com/places/fes-el-bali\"> <strong>Fes el-Bali in Fez, </strong>Morocco</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106235/image.jpg\" width=\"auto\" /></figure>\n<p>Step through the<a href=\"https://www.atlasobscura.com/places/the-blue-gate-of-fes-fez-morocco\"> Blue Gate</a> into the world's largest car-free medieval city—9,400 winding alleyways where 150,000 people live as their ancestors did. Getting lost among leather tanneries and spice souks forces you to surrender control and trust strangers, a reminder that not everything worth finding can be Googled.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November for mild temperatures</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>2.</strong><a href=\"https://www.atlasobscura.com/places/waitomo-glowworm-caves\"> <strong>Glowworm Caves in Waitomo, New Zealand</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106238/image.jpg\" width=\"auto\" /></figure>\n<p>Float silently through pitch-black caves beneath thousands of bioluminescent larvae creating nature's own planetarium. The <a href=\"https://www.atlasobscura.com/articles/video-wonder-new-zealands-twinkling-glowworm-caves\">boat journey</a> requires complete silence—no talking, no cameras. In our age of constant documentation, experiencing something you can't immediately share teaches you that some moments are meant to be felt, not captured.</p>\n<p><strong>Best time to visit:</strong> December-March (summer) for warmer weather above ground.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>3.</strong><a href=\"https://www.atlasobscura.com/places/kallur-lighthouse\"> Kallur Lighthouse in Kalsoy, <strong>Faroe Islands, Kingdom of Denmark</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106233/image.jpg\" width=\"auto\" /></figure>\n<p>Eighteen volcanic islands with dramatic cliffs,<a href=\"https://www.atlasobscura.com/places/gasadalur-village-2\"> grass-roofed villages</a>, and more sheep than people. Hike to Kallur Lighthouse or photograph Múlafossur waterfall cascading into the ocean. Weather changes every hour—all four seasons in a single day.</p>\n<p><strong>Best time to visit:</strong> June-July for longest days and accessible trails.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>4.</strong><a href=\"https://www.atlasobscura.com/places/cappadocia\"> <strong>Cappadocia in Aksaray, Turkey</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106232/image.jpg\" width=\"auto\" /></figure>\n<p><br />Volcanic eruptions created fairy chimneys, hidden<a href=\"https://www.atlasobscura.com/places/derinkuyu-underground-city\"> cave churches with Byzantine frescoes, and underground cities</a>. One such city was even <a href=\"https://www.atlasobscura.com/articles/derinkuyu-turkey-underground-city-strange-maps\">discovered by a local resident</a> during a home renovation project. Take a hot air balloon ride at sunrise, explore the underground cities carved eight levels deep, or stay in a cave hotel.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for ideal balloon weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>5.</strong><a href=\"https://www.atlasobscura.com/places/into-the-glacier\"> Langjökull<strong> Glacier Ice Caves near Húsafell, Iceland</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106231/image.jpg\" width=\"auto\" /></figure>\n<p>November through March, Iceland's glaciers reveal crystalline caves in impossible shades of blue. Because ice constantly melts and refreezes, you never see the same cave twice—each visit is literally once-in-human-history.</p>\n<p><strong>Best time to visit:</strong> January-February for most dramatic ice formations.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>6.</strong><a href=\"https://www.atlasobscura.com/places/petra\"> <strong>Petra, Jordan</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106230/image.jpg\" width=\"auto\" /></figure>\n<p>Walk through the narrow Siq canyon and emerge facing the Treasury—a 2,000-year-old facade carved into rose-red rock. This Nabataean city features hundreds of tombs and temples carved into sandstone. Climb to the Monastery or hike to <a class=\"underline underline underline-offset-2 decoration-1 decoration-current/40 hover:decoration-current focus:decoration-current\" href=\"https://www.atlasobscura.com/places/little-petra\">Little Petra</a> for solitude.</p>\n<p><strong>Best time to visit:</strong> March-May or September-November. Early morning light makes the sandstone glow.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>7.</strong><a href=\"https://www.atlasobscura.com/places/cerro-fitz-roy\"><strong> Cerro Fitz Roy in El Chaltén, Argentina</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106229/image.jpg\" width=\"auto\" /></figure>\n<p>The Patagonia logo mountain. This 3,405-meter granite spire offers saw-toothed peaks and glacial lakes in impossible turquoise. The trek to Laguna de Los Tres delivers sunrise views that turn granite into a golden shade of pink. If you want extra adventure and you have time to take your journey northward, start in El Chaltén and then journey to the small town of <a href=\"https://www.atlasobscura.com/articles/nahuelito-argentina-loch-ness-monster-bariloche-patagonia\">Bariloche</a>, where Argentina's own Loch Ness monster is rumored to live.</p>\n<p><strong>Best time to visit:</strong> December-February (summer) for most stable weather.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>8.</strong><a href=\"https://www.atlasobscura.com/places/bagan\"> <strong>Bagan in Nyaung-U, Myanmar</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106228/image.jpg\" width=\"auto\" /></figure>\n<p>Over 2,000 Buddhist temples and pagodas built between the 11th-13th centuries dot ancient plains. Rent an e-bike to explore, climb select temples for sunrise, or take a hot air balloon ride. Less crowded than Angkor Wat, equally impressive.</p>\n<p><strong>Best time to visit:</strong> November-February (cool, dry season) for comfortable exploration.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>9.</strong><a href=\"https://www.atlasobscura.com/places/salar-de-uyuni-bolivian-salt-flat\"> <strong>Uyuni Salt Flat in Daniel Campos, Bolivia</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106239/image.jpg\" width=\"auto\" /></figure>\n<p>The world's largest salt flat—4,000 square miles of blinding white hexagons. During rainy season, thin water transforms it into the world's largest mirror, reflecting perfect sky. For more inspiration, check out these beautiful <a href=\"https://www.atlasobscura.com/articles/salt-flat-landscape-bolivia\">photos</a> and <a href=\"https://www.atlasobscura.com/articles/satellite-calibration-salar-de-uyuni\">satellite images</a>. Standing on these salt flats, where ground becomes sky and distance becomes meaningless, you understand that Earth still breaks every assumption about what's possible.</p>\n<p><strong>Best time to visit:</strong> December-April for mirror effect, May-October for hexagonal patterns.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>10.</strong><a href=\"https://www.atlasobscura.com/places/plitvi-ka-jezera-plitvice-lakes\"> <strong>Plitvice Lakes in Plitvička Jezera, Croatia</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106226/image.jpg\" width=\"auto\" /></figure>\n<p>Sixteen terraced lakes connected by waterfalls cascade through forested canyons in shifting shades of azure, green, and blue. Wooden walkways let you walk directly over crystal-clear waters.</p>\n<p><strong>Best time to visit:</strong> May-June or September for lush greenery and fewer crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>11.</strong><a href=\"https://www.atlasobscura.com/places/jigokudani-park-japan\"> <strong>Jigokudani Monkey Park in Yamanouchi, Japan<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106225/image.jpg\" width=\"auto\" /></figure>\n<p>Wild Japanese macaques soak in natural hot springs with snow falling around them in \"Hell's Valley.\" They look <a href=\"https://www.atlasobscura.com/articles/welcome-to-the-monkey-park\">hilariously human</a>—eyes closed in contentment, grooming each other. A hike through snowy forest leads to nature's most charming spa.</p>\n<p><strong>Best time to visit:</strong> December-March when snow creates dramatic contrast.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>12. <a href=\"https://www.atlasobscura.com/categories/route-66\">Route 66, USA</a><br /></strong></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106224/image.jpg\" width=\"auto\" /></figure>\n<p>In 2026, the<a href=\"https://www.atlasobscura.com/articles/route-66-highlights\"> Mother Road</a> celebrates its 100th birthday. The 2,400-mile stretch from<a href=\"https://www.atlasobscura.com/places/beginning-end-historic-route-66-chicago\"> Chicago</a> to<a href=\"https://www.atlasobscura.com/places/route-66-end-trail\"> Santa Monica</a> retains vintage motels, neon signs, diners, and quirky attractions—pure Americana.</p>\n<p><strong>Best time to visit:</strong> April-May or September-October for mild weather across climate zones.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>13.</strong><a href=\"https://www.atlasobscura.com/places/root-bridges-cherrapungee\"> <strong>Root Bridges in Cherrapunji, India</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106223/image.jpg\" width=\"auto\" /></figure>\n<p>In one of Earth's wettest places, the <a href=\"https://www.atlasobscura.com/articles/living-root-bridges-india\">Khasi people - truly artisans - </a>grow bridges from rubber tree roots over 10-15 years. Some are 500+ years old and still strengthening. The double-decker bridge requires 3,000 steps but teaches that patience beats speed, that working with nature trumps dominating it, and the best solutions might take longer than a single lifetime.</p>\n<p><strong>Best time to visit:</strong> November-February (dry season) for safer paths.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>14.</strong><a href=\"https://www.atlasobscura.com/places/havasupai-falls\"> <strong>Havasupai Falls in Supai, Arizona, USA</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106240/image.jpg\" width=\"auto\" /></figure>\n<p>Hidden in the Grand Canyon, waterfalls pour into pools so turquoise they don't look real. Calcium carbonate creates desert-meets-Caribbean waters. Requires 10-mile hike and advance permits from the Havasupai Tribe.</p>\n<p><strong>Best time to visit:</strong> March-May or September-October for mild temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>15.</strong><a href=\"https://www.atlasobscura.com/places/socotra-island\"> <strong>Socotra Island, Yemen</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106221/image.jpg\" width=\"auto\" /></figure>\n<p>Split from Africa millions of years ago, over a third of the plant species here exist nowhere else. Dragon's blood trees look like Dr. Seuss illustrations alongside desert roses and pink dunes. Standing among these otherworldly trees reminds you that isolation creates irreplaceable uniqueness worth protecting.</p>\n<p><strong>Best time to visit:</strong> November-March for comfortable temperatures.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>16.</strong> <a href=\"https://www.atlasobscura.com/things-to-do/hallstatt-austria\"><strong>Hallstatt, Austria</strong></a></h2>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106236/image.jpg\" width=\"auto\" /></figure>\n<p>An Alpine village so picturesque that<a href=\"https://www.atlasobscura.com/places/hallstatt-china\"> a Chinese mining company built a replica</a> to bring some Europe into Asia. The original Hallstatt - in Austria - is well-worth a visit. It features<a href=\"https://www.atlasobscura.com/places/salzwelten\"> ancient salt mines</a> and the<a href=\"https://www.atlasobscura.com/places/hallstatt-charnel-house\"> Charnel House</a> with painted skulls. And... maybe you'll get to the Chinese one next.</p>\n<p><strong>Best time to visit:</strong> May-June or September for smaller crowds.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>17.</strong><a href=\"https://www.atlasobscura.com/places/ta-prohm\"> Ta Prohm near Siem Reap, Cambodia</a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106237/image.jpg\" width=\"auto\" /></figure>\n<p>This hidden temple near Angkor Wat is being slowly consumed by jungle. At Ta Prohm, massive tree roots cascade over 12th-century stone and <a href=\"https://www.atlasobscura.com/places/dinosaur-angkor-wat\">curious carvings</a> stir controversy. Nature's patient reclamation—neither destroying nor preserving, but transforming—teaches that endings and beginnings are often the same thing. What could be viewed as overgrown has become beauty.</p>\n<p><strong>Best time to visit:</strong> November-February (dry, cool season).</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>18.</strong><a href=\"https://www.atlasobscura.com/places/marble-caves-of-chile-chico\"> <strong>Marble Caves in Puerto Río Tranquilo, Chile</strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106218/image.jpg\" width=\"auto\" /></figure>\n<p>Six thousand years of water carved swirling marble caverns reflecting Lake General Carrera's turquoise water in otherworldly blue. Best explored by kayak.</p>\n<p><strong>Best time to visit:</strong> December-February when glacial melt intensifies the blue.</p>\n<h2 class=\"article-subheading-pre-rd\"><strong>19.</strong><a href=\"https://www.atlasobscura.com/places/eduard-bohlen-shipwreck\"> Eduard Bohlen Shipwreck in <strong>Skeleton Coast, Namibia<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106217/image.jpg\" width=\"auto\" /></figure>\n<p>Where the Namib Desert meets the Atlantic, rusted shipwrecks dot beaches alongside seal colonies and<a href=\"https://www.atlasobscura.com/articles/namibia-lions-hunt-seals\"> desert-adapted lions</a>. This coastline—where sailors once perished and wildlife now thrives—proves that what looks like desolation to some is home to others.</p>\n<p><strong>Best time to visit:</strong> May-October for wildlife viewing and cooler temperatures. And for adventure, you can even stay in a <a href=\"https://www.atlasobscura.com/places/shipwreck-lodge\">\"shipwreck.\"</a></p>\n<h2 class=\"article-subheading-pre-rd\"><strong>20.</strong><a href=\"https://www.atlasobscura.com/places/zhangye-national-geopark\"> <strong>Zhangye National Geopark in Zhangye Shi, China<br /></strong></a></h2>\n<figure class=\"  \"><img alt=\"article-image\" class=\"article-image  \" src=\"https://assets.atlasobscura.com/article_images/106216/image.jpg\" width=\"auto\" /></figure>\n<p>Rainbow mountains striped in red, yellow, orange, green, and blue—millions of years of mineral deposits creating nature's abstract painting. Best after it rains, when colors intensify.</p>\n<p><strong>Best time to visit:</strong> June-September for vibrant colors after summer rains.</p>\n<p> </p>\n<p>Each of these destinations offer more than photo opportunities—they're invitations to see where humans and nature have collided and created extraordinary things. They’re invitations to pause and reflect. They're invitations to change and grow.</p>\n<p>The world welcomes you for a transformative 2026. Let’s Go.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 05:58:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424746Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 3,
        "final_score": 10.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/arizona-guide",
        "title": "Discover Arizona’s Majesty",
        "summary": "<p>Arizona is wild in its environmental diversity, boasting five of the six distinct types of ecological biomes. Tundra, forest, woodland, scrub, grassland, and desert biomes are spread across the state, with four deserts, over 210 named mountain ranges, a biblical-scale monsoon season—and, of course, the Grand Canyon. The Sonoran Desert, which stretches across much of the state’s southern half, is a “lush desert,” meaning that it receives rain twice a year, and thus features a visually stunning blend of sepia tones and deep green vegetation.</p>\n<p>The state’s rich culture reflects the diversity of its Native populations and the many who have migrated to the area, along with a strong connection to Mexican cultural heritage. The region is the ancestral and current home to twenty-two federally recognized Native American tribes, including Diné (Navajo Nation) and the Tohono O'odham Nation.</p>\n<h3>Northern Region: Flagstaff and Holbrook</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Rainbow Forest\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/3d9f05e0-b5c9-4e76-b602-b0ba966c55661bc89aed0ef0a7e6e3_Wood%20and%20rock%20converge%20in%20the%20Rainbow%20Forest,%20where%20nothing%20is%20exactly%20as%20it%20seems.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Behold Arizona’s Sublime Beauty</h3>\n<p>The Rainbow Forest includes the largest and most colorful displays of petrified wood in Petrified Forest National Park.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Ancient geology and celestial discovery converge in Northern Arizona, inviting travelers to reflect on humanity’s place between the stars above and the eons below. Many visitors come for the Grand Canyon, but Northern Arizona contains multitudes. The high-elevation region features rugged mountain ranges, the state’s highest peak, and four distinct seasons, making it a destination for winter sports, mountaineering, and astronomy. The charming city of Flagstaff serves as home base to Northern Arizona University, the regional destination ski resort Snowbowl, and the Flagstaff Mountain Film Festival.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106241/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/lowell-observatory\">Lowell Observatory</a></h3>\n<p>Stargazers flock to Lowell Observatory, a world-class astronomy destination on the edge of Flagstaff. The site has been in continuous operation since the late 1800s, when it was established by Percival Lowell, a financier and astronomer who became obsessed with the possibility of life on Mars. Lowell had the means to fund his fascinations, and thus Lowell Observatory was built, with Northern Arizona selected as its site for its high elevation and dark skies. Pluto was discovered here, and the city’s commitment was recognized in 2001, when Flagstaff became the first International Dark Sky City.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106242/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www2.lowell.edu/users/elgb/observing_site.html\">Mars Hill and Anderson Mesa</a></h3>\n<p>Just west of Flagstaff proper sits Mars Hill, part of Lowell Observatory’s campus and the site of the apocryphal origin story of the theory of dark matter. As you drive up the hill, spot the iconic dome of the Clark Refractor, a telescope dating back to the 1800s. Continue your astronomy tour by heading southeast to spot Anderson Mesa, a flattop plateau in Coconino County that hosts Anderson Mesa Station, a dark-sky astronomical observatory.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106243/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/petrified-forest-national-park\">Petrified Forest National Park</a></h3>\n<p>Is it rock? Is it wood? The answer is yes at Petrified Forest National Park, where hundreds of millions of years of the organic process of permineralization have turned what was once a forest of trees into a wavy psychedelic desert landscape laden with fossils. These artifacts of the Triassic period (the era when dinosaurs are thought to have first appeared) include compression fossils of leaves, seeds, insects, and fish as well as scattered petrified logs.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106244/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/articles/850116.htm#6/27.450/-89.143\">Rainbow Forest</a></h3>\n<p>Nestled within Petrified Forest National Park, the Rainbow Forest features huge, vibrant rocks in deep reds, yellows, blues, and purples. The rocks began life as trees, petrified over hundreds of millions of years, and draw their vivid hues from minerals like manganese, iron oxide, quartz, and hematite. Pop into the Rainbow Forest Museum to learn about the geological and cultural history of the land, which is the historic home of the Ancestral Puebloan people.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106245/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.visitarizona.com/places/parks-monuments/painted-desert\">Painted Desert</a></h3>\n<p>Before you leave Petrified Forest National Park, head to the park’s north side to visit the Painted Desert, another region of the park with unique geological characteristics. Here, find badlands with distinctly visible layers—looking like they were painted with a steady hand. These layers are the result of stratification of shale, mudstone, and siltstone, each of which carry a distinctive pigment.</p>\n<h3>Central Region: Clarkdale, Camp Verde, and Jerome</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Montezuma Castle National Monument\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/c6c0b689-49fc-4ef9-9f08-85c4686f34528819d03b04ca73676d__High%20rise%20apartment_%20takes%20on%20new%20meaning%20at%20Montezuma%20Castle.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Explore Vibrant Arts, Culture, and Experiences</h3>\n<p>Evidence suggests the construction at Montezuma Castle National Monument began in the 1100s. It was occupied until as late as 1395.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>In Central Arizona, Saguaros stand watch over canyons and copper towns, linking ancient ingenuity, industrial ambition, and enduring cultural roots. The region features the sprawling state capital city of Phoenix, but the whole area is rich with Indigenous culture as well as niche historic sites dedicated to preserving the stories of the Wild West. Copper mining was and is a significant industry in the region, and the remnants of the extraction business are conserved in installations like the town of Jerome’s Mine Museum.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106246/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/verde-canyon-railroad\">Verde Canyon Railroad</a></h3>\n<p>The Verde Canyon Railroad, a quirky heritage railroad that runs 20 miles from Clarkdale to Perkinsville, features a vintage diesel locomotive powers that this sightseeing excursion, bringing riders through the vibrant wilderness landscape. In the canyon, keep your eyes peeled for the bald eagles who frequent the area.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106247/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://historicbridges.org/b_h_fipsm.php?bsearch=04025\">Perkinsville Trestle</a></h3>\n<p>As you ride the Verde Canyon Railroad, you’ll pass over a series of gorges formed by the Verde River. These steep valleys are spanned by metal trestles—making for extraordinary vistas from the open-air viewing cars. When your rail car traverses the Perkinsville Trestle, the tracks, directly underneath the car, are obscured to riders, creating the feeling that the railroad has taken flight.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106248/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.arizonacopperartmuseum.com\">Arizona Copper Art Museum</a></h3>\n<p>The deposits of copper embedded in Arizona’s earth have enticed miners since Native people harvested ore to make tools and jewelry. Since the early 1900s, industrial mining has pulled copper from the land. The former mining town Clarkdale is home to the Arizona Copper Art Museum, which stands as a testament to the creative uses of the mineral. On a visit, check out the distillery room, where you’ll find elaborate copper vessel systems for winemaking.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106249/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/montezuma-castle-national-monument\">Montezuma Castle National Monument</a></h3>\n<p>Pull off the highway in Camp Verde to stop by Montezuma Castle National Monument, a historic site that honors and preserves the prehistoric cliff dwelling architecture of the Indigenous Sinagua people. Built into a limestone cliff is a multi-level 20-room dwelling that is noted as one of the best-preserved examples of pre-contact architecture.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/moca/planyourvisit/exploring-montezuma-well.htm\">Montezuma Well</a></h3>\n<p>Within Montezuma Castle National Monument lies a giant hole: Montezuma Well. Nearly 400 feet from shore to shore, the “well” is in fact a huge, naturally occurring spring-fed limestone sinkhole full of carbonated, arsenic-laden water. The well serves as home to five species of fauna that exist nowhere else in the world, including the water scorpion.</p>\n<p> </p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106250/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.atlasobscura.com/places/jeromes-sliding-jail\">Jerome’s Sliding Jail</a></h3>\n<p>In Jerome (population 464), the main attraction is a small jail structure that was erected in the early 1900s on the slope of a mountain. Dynamite from nearby mines caused the jail to literally slide down the hill until finding stasis on the main thoroughfare. Now a visitor’s attraction, the jail harks back to the days of the Wild West, when hard-drinking rabble-rousers would sleep it off within the cell’s walls.</p>\n<h3>Southern Region: Bisbee, Tubac, and Patagonia</h3>\n<div class=\"flip-card\">\n<div class=\"flip-card-inner\">\n<div class=\"flip-card-front\"><img alt=\"Pronghorn Antelope in the Buenos Aires National Wildlife Refuge\" src=\"https://atlas-dev.s3.amazonaws.com/uploads/assets/f5d06809-5120-43bc-820f-df69590282a120d65582e662de3d08_usfws-pronghorn-buenos-aires-natinal-wildlife-refuge.jpg\" /></div>\n<div class=\"flip-card-back\">\n<h3>Experience Arizona’s Welcoming Warmth and Ties to Nature</h3>\n<p>The Buenos Aires National Wildlife Refuge is home to hundreds of species, including the pronghorn antelope, mule deer, and puma.</p>\n</div>\n</div>\n<div class=\"flip-card-instructions\">Tap/hover to learn more!</div>\n</div>\n<p>Where wild canyons bloom and hummingbirds hover, artists, dreamers, and makers create in harmony with the desert’s vivid, living canvas. Known for its miles of Saguaro cacti, Southern Arizona is home to a large swath of the Sonoran Desert, about 370 miles of the U.S.-Mexico border, and the city of Tucson.</p>\n<p>The Sonoran Desert is home to a diversity of flora and fauna, including prickly pear, Gila monsters, roadrunners, and the western diamondback rattlesnake. For more sedate engagements with local culture, Tucson is a dining hotspot: a UNESCO City of Gastronomy, a designation awarded to sites of global culinary significance.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106251/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.bisbeebreakfastclub.com\">Bisbee Breakfast Club</a></h3>\n<p>Bisbee Breakfast Club locations can be spotted across Southern Arizona, but Bisbee is the home of the original. Within the nondescript beige building, the charmingly weathered interior is classic American diner with a Southwestern twist. Nosh on regional Mexican favorites like huevos rancheros and fan-fave house specialties like the Copper Queen Skillet, a mashup of eggs, potatoes, and seemingly every kind of breakfast meat: bacon, ham, sausage, and spicy sausage gravy.</p>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"http://www.oldbisbeebrewingcompany.com\">Old Bisbee Brewing Co.</a></h3>\n<p>For a bite and a brew in the kitschy town, the Old Bisbee Brewing Co. offers an eclectic and sophisticated menu of draft beers, brewed on-site. Strict IPA buffs will appreciate the heady Double Hopped IPA, while those with more experimental tastes may delight in the Mayan Stout, brewed using a heritage Mesoamerican bean.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106252/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.tubacarts.org\">Tubac Center for the Arts</a></h3>\n<p>Luxe meets rustic at Tubac, an arts and leisure complex tucked between the Tumacácori and Santa Rita mountains. Find the ritzy side at Tubac Golf Resort &amp; Spa, where golfers flock to the 27-hole course and spa-goers indulge, but the arts and the grounds are the real draw. Explore Tubac to find four galleries, a performance space, and arts library, plus a trail system that connects with the Juan Bautista de Anza National Historic Trail.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106253/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.fws.gov/refuge/buenos-aires\">Buenos Aires National Wildlife Refuge</a></h3>\n<p>Near the border town of Sasabe, 117,000 acres of public grassland desert serves as an ecological reserve. Habitat restoration makes the refuge a safe haven for 50+ mammal species, with the land sheltering endangered species including the masked bobwhite quail. Find an open-access trail system as well as guided hikes, and complimentary public-access campsites. Keep your eyes peeled for deer, javelina, coyotes, skunks, rabbits—even the occasional jaguar.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106254/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://tucsonbirds.org/paton-center/\">Paton Center for Hummingbirds</a></h3>\n<p>Patagonia’s Paton Center for Hummingbirds is a conservation space for more than 250 bird species, including the rare violet-crowned hummingbird. The 1.4-acre woodland site began its life as the yard of a pair of local birdwatchers, who in the 1970s began inviting others to join them in marveling at the tiny avian pollinators. From there, the local Audubon Society acquired the property, which is lovingly managed as an oasis for birds and birders alike.</p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106255/image.jpg\" width=\"auto\" /></figure>\n<h3 class=\"article-second-subheading-pre-rd\"><a href=\"https://www.nps.gov/chir/index.htm\">Chiricahua National Monument</a></h3>\n<p>Find rocks on rocks on rocks at Chiricahua National Monument, where physics-defying rock stacks give an otherworldly feel to the ecological environs. The result of a historical volcanic event, the area’s rock formations (officially known as hoodoos and rhyolite pinnacles) look like blocks stacked by the hands of giants. Travelers can take in their weird splendor from 17 miles of maintained trails and campground facilities.</p>",
        "source": "www.atlasobscura.com",
        "published": "Mon, 29 Dec 2025 09:57:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424741Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-caroline-mazel-carlton-1000-places",
        "title": "The Quest to Visit 1,000 Places",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p>I’m Kelly McEvers, and this is Atlas Obscura, a celebration of the world’s strange, incredible, and wondrous places.</p>\n<p>So I don’t know about you, but I like to keep track of all the places that I have visited, say, in the past year. I have lists of all the countries that I visit in a given region. Each year I go back to my handwritten calendar planner book because, yes, I still write everything down.</p>\n<p>I have kept track of all my trips, and that helps me remember all the places I’ve visited and the people I saw. Most people I know are, of course, more advanced than this. They actually keep digital records like lists of restaurants where they want to go or Google Maps with pins on places.</p>\n<p>In case you have somehow stumbled upon this podcast and you don’t know too much about Atlas Obscura, we actually have a map, an Atlas, filled with thousands upon thousands of unusual places across the globe. Each place is submitted by a person, and it is a fun tool to use whether you are on vacation or you want to get to know your own hometown better.</p>\n<p>My guest today has visited over 1,000 of these places. Her name is Caroline Mazel-Carlton, and she has been working toward that goal for more than 10 years. This project, Visiting 1,000 places, was about more than just taking items off the list. She says it helped save her life.</p>\n<p>Caroline, welcome.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps. </em><em>This episode contains discussions of suicidal thoughts. If you or someone you know is struggling, contact the Suicide Crisis Hotline by calling or texting 988.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106271/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Caroline Mazel-Carlton: </strong>Oh, I’m getting teary already. It’s so good to be here. Thank you, Kelly.</p>\n<p><strong>Kelly McEvers: </strong>Yeah, welcome. So talk about your first ever visit to an Atlas Obscura place.</p>\n<p><strong>Caroline Mazel-Carlton: </strong>Yeah. So one of the first times that I remember using the Atlas Obscura was when I wanted to take my now-husband on a romantic interlude, like a nice weekend away. And so I was looking for spots—bed and breakfasts—and the Atlas Obscura was so helpful because it showed me that not too far away in Fall River, Massachusetts, you can find <a href=\"https://www.atlasobscura.com/places/lizzie-borden-bed-and-breakfast-and-museum\">Lizzie Borden’s house</a>.</p>\n<p><strong>Kelly: </strong>In case you’re not familiar, in 1892, Lizzie Borden allegedly murdered her parents, Abby and Andrew Borden, in their house with an axe. Lizzie was acquitted. And Caroline believes she was innocent. But the whole thing has become a bit of a folk story.</p>\n<p>And the house where the murders took place still stands now as this untraditional bed and breakfast.</p>\n<p><strong>Caroline: </strong>They had this whole getaway that you could have and sleep in Lizzie Borden’s house. They had dummies set up, sort of positioned where, Andrew Borden, what he would have looked like after the crime had been committed. So it was this beautiful Victorian house full of wonderful <a href=\"https://www.atlasobscura.com/places/leilas-hair-museum\">Victorian hair art</a>, which I’m a big fan of Victorian hair art as well—some great specimens of that there. So it was just an amazing experience.</p>\n<p><strong>Kelly: </strong>And I would imagine that your now husband was into it?</p>\n<p><strong>Caroline: </strong>Oh, yeah, yeah. It was sort of like a litmus test in a way.</p>\n<p><strong>Kelly: </strong>I was going to say, if he passed that, then he knew he was a keeper.</p>\n<p><strong>Caroline: </strong>There’s a beautiful picture of us taken where we were sitting on this like Victorian couch and we have the dummy representing Andrew Borden’s bloody corpse splayed out across our laps. And we’re just brimming with young love. And it’s such a beautiful photograph.</p>\n<p><strong>Kelly: </strong>Yeah. I love it. You’re like, this is the one for me.</p>\n<p><strong>Caroline: </strong>Absolutely. And I did try, when we got married, I tried to convince my mom to let me use that photo for our save the date. But she said, “No, I’m not into the idea of this bloody corpse photo.” So we ended up using a picture from another trip we took to Paris.</p>\n<p><strong>Kelly: </strong>Nice. And I would love to just know where your urge to go places started. What was one of your most memorable trips you took as a kid?</p>\n<p><strong>Caroline: </strong>So my family growing up, we weren’t the type of family that went to the same beach or the same lake house every year for vacation. One of my family mottos was, “We’ll go anywhere once.”</p>\n<p><strong>Kelly: </strong>Oh, I love that.</p>\n<p><strong>Caroline: </strong>And so my dad has always been a history buff, but he’s never shied away from the weirder and grittier parts of American history. Some of my early memories are definitely wandering around graveyards.</p>\n<p>I remember seeing the <a href=\"https://www.atlasobscura.com/places/the-skin-of-little-sorrel-lexington-virginia\">taxidermied horse</a> of Stonewall Jackson in some weird museum in Virginia. One place we went, and sadly, you can’t go here anymore. My dad has sort of, like, a dark streak, like, dark humor.</p>\n<p>And he became obsessed with the <a href=\"https://www.atlasobscura.com/articles/31-days-of-halloween-floyd-collins\">story of this guy named Floyd Collins</a>, who was a cave explorer that actually got trapped and died in the Mammoth Cave system. So my dad and I actually did some caving together and visited the museum that honors this man. A tribute to explorers everywhere, but sadly he did not make it out of the cave.</p>\n<p><strong>Kelly: </strong>Mm-hmm. You actually set this goal of trying to visit 1,000 Atlas Obscura places over a decade ago in 2012. And for so many people, you know, travel and seeing the world, there’s all these reasons we do it, but a lot of it is like: I want a change in perspective, or I want to learn more about this culture. I want to be wowed.</p>\n<p>For you, it sounds like there was a really kind of specific reason that you did this. Can you take us back to that time and talk about what was going on in your life?</p>\n<p><strong>Caroline: </strong>So for me, I grew up experiencing a lot of bullying over how I looked or the way that I acted. And I started to struggle a lot with thoughts of suicide. And in fact, for certain parts of my life I was hospitalized and was in treatment programs where you’re not allowed to leave places like that. So it’s kind of a smaller existence.</p>\n<p>For me, it was always trying to figure out, how do I survive? How do I find a way to exist in this world? And what I realized is, for a lot of us that grapple with suicidal thoughts, it’s not truly that we want to literally die, but that the life that we’re living needs to end. It’s sort of this desire to be transformed in a way.</p>\n<p>For me, trying to figure out how to exist in the world has always been a bit of a battle in and of itself. And I remember one time seeing a book on my uncle. My uncle Doug also loved to travel the world. And he had a book called <em>1,000 Places to See Before You Die.</em></p>\n<p><strong>Kelly: </strong>Okay.</p>\n<p><strong>Caroline: </strong>And I thought about that. And I thought about the power of saying to myself, you know what? You can’t die today because there’s still places that you haven’t seen yet. So I used that book for a while, but then when I discovered Atlas Obscura, I was like, these sites are actually more interesting to me.</p>\n<p>They’re more accessible. They’re weirder. As I visit Atlas Obscura sites, I often learn about weird people like myself. I’ve seen amazing outsider art. So reaching a thousand Atlas Obscura sites before I died became really, really important to me.</p>\n<p><strong>Kelly: </strong>Since then, Caroline has visited Atlas Obscura places around the world, from the <a href=\"https://www.atlasobscura.com/places/grave-of-johnny-appleseed\">grave of Johnny Appleseed</a> in Fort Wayne, Indiana, to a <a href=\"https://www.atlasobscura.com/places/shree-ganesh-darshan-museum\">temple complex</a> in Pune, India, with 500 statues of Lord Ganesh. Once, on a 16-hour layover in Hong Kong, she left the airport and took a tram over the mountains to see the world's <a href=\"https://www.atlasobscura.com/places/tian-tan-buddha\">largest-seated bronze Buddha.</a></p>\n<p>She’s been to the <a href=\"https://www.atlasobscura.com/places/icelandic-phallological-museum\">Icelandic Phallological Museum</a> in Reykjavik and the <a href=\"https://www.atlasobscura.com/places/worlds-largest-czech-egg\">world’s largest Czech egg</a> in Wilson, Kansas, and <a href=\"https://www.atlasobscura.com/places/deyrolle-taxidermy\">a taxidermy shop in Paris</a> that Pablo Picasso and Salvador Dali would visit for inspiration. Taxidermy holds a special place in Caroline’s heart.</p>\n<p><strong>Caroline: </strong>There’s one Atlas Obscura site I’m going to give a shout out to, <a href=\"https://www.atlasobscura.com/places/oles-big-game-steakhouse-and-lounge\">Ole’s Big Game Steakhouse in Nebraska</a>, where you can be surrounded by taxidermy and also you can eat at the same time.</p>\n<p><strong>Kelly: </strong>Which, not going to lie, doesn’t sound great to some people, but I love it.</p>\n<p>Today, Caroline works in suicide prevention. with an organization that does peer support, advocacy, and training for harm reduction. And she brought her 1,000 places goal into that work.</p>\n<p>Caroline has led trainings around the world, and sometimes on these trips, she and her colleagues will visit Atlas Obscura sites together. Caroline says it is really hard to choose a favorite memory.</p>\n<p><strong>Caroline: </strong>Oh, there are so many. I remember one time we were doing an alternatives to suicide training and we were in Tacoma, Washington, and we actually found on Atlas Obscura the grave of Kurt Cobain, who was someone that I looked up to when I was younger, one of my favorite musicians, and who did die by suicide.</p>\n<p>But we went there together and it felt like such a special place to be there and honor him and his role in our lives and the way he could give voice to pain in a way that other people could connect with. I also remember a time where I was giving a talk at The Hague in the Netherlands and we visited a museum.</p>\n<p>I think it’s called Museum of the Mind, which had been a psychiatric hospital. But then they filled it with art, beautiful art made from former psychiatric patients. So going there and to some of the Van Gogh sites. And it’s just been incredible to do that with some of my colleagues who’ve also struggled with thoughts of suicide.</p>\n<p>And I really look at this achievement of reaching a thousand sites as something that we did together. And it felt really special because it was all connected to the journey of healing and embracing our weirdness and our desire to live in a world that’s not always, you know, normative.</p>\n<p><strong>Kelly: </strong>So, I mean, you hit the goal, right? You’re over 1,000. You’re at 1,048, to be exact. So what’s next? I mean, how do you, you know, where do you go from there? Do you set a new goal? Are you just going to keep on keeping on at this point? Do you feel like you’re going to travel differently now?</p>\n<p><strong>Caroline: </strong>Yeah. Well, after meeting the goal, I was like, I can rest a little bit because I honestly thought I’m 43. So I thought I would be at least 50 before I hit 1,000. but I hit it much more quickly than I thought I would. But the thing about Atlas Obscura is there’s always more you can do.</p>\n<p>And one of the things that I really encourage everyone listening to do is to add sites to the Atlas yourself. It’s a thrill for me to do that. I remember one time I was working in Brazil and we were just in this little town that had no Atlas Obscura sites, but I’m like, I’m going to find something.</p>\n<p>And I found this guy with a little, he had a cell phone store, but then he had sort of in the back rooms, all these historical communication devices. Even one of the first Morse code devices and a phonograph. And we got to, through broken English and broken Portuguese, I wrote an article and posted that on the Atlas, and I checked it today, and now eight people have been there.</p>\n<p>When you add a site to the Atlas, you really do change people’s lives. You know, I don’t struggle as much in my life anymore as when I started because the world just seems more weird and welcoming.</p>\n<p><strong>Kelly: </strong>Caroline Mazel-Carlton, thank you so much for sharing your story and thank you for the work that you do helping other people too.</p>\n<p><strong>Caroline: </strong>Absolutely. I just seek to make this place more welcoming and, you know, people are struggling. My organization, we have alternatives to suicide support groups. There are places you can go to talk where people will listen and not shame you or judge you and where we acknowledge that there’s many paths to healing.</p>\n<p>And sometimes that path to healing means walking around a really weird taxidermy store and that’s okay.</p>\n<p><strong>Kelly: </strong>While eating a steak.</p>\n<p><strong>Caroline: </strong>Yes. I’m here for it.</p>\n<p><strong>Kelly: </strong>That was Caroline Mazel-Carlton. She has visited 1,048 Atlas Obscura places. No doubt many more to come. We will put a link to the Atlas in our show notes, so maybe you can start ticking off your own list of 1,000 places. Also, if you or someone you know is struggling, you can contact the 988 Suicide and Crisis Lifeline.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 13 Jan 2026 11:00:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424726Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 15,
        "timeliness_score": 3,
        "final_score": 9.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/foods/tiquira",
        "title": "Tiquira",
        "summary": "<p><img alt=\"\" height=\"200\" src=\"https://img.atlasobscura.com/AVz4e7Gut8Wj5dEAKjG4GdVeQ-Naog6rw3iXhMFXb0k/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy9mMjk5/MWM1Mi05NDFkLTRk/ODYtYjMxZC0xZTU1/OTI0ZjI2M2Q3MDUx/Mzk4NTM2MTc1YzZh/ZDhfRFNDMDk5MTUu/SlBH.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Indigenous Brazilians have fermented alcoholic beverages from the cassava root for thousands of years. These beer-like beverages go by names like </span><em><span style=\"font-weight: 400;\">cauim</span></em><span style=\"font-weight: 400;\">, </span><em><span style=\"font-weight: 400;\">caxiri</span></em><span style=\"font-weight: 400;\">, and </span><em><span style=\"font-weight: 400;\">tarubá</span></em><span style=\"font-weight: 400;\">. Fermentation is an important step in cassava processing—the raw root has chemicals that can turn into cyanide in the human body. Native peoples found that a bit of human saliva and some naturally occurring yeast could eliminate these toxins and improve the nutritious value of the tuber. When the technology of distillation arrived to the Munim River region (now in Maranhão), locals who already drank lightly alcoholic cassava beverages began to distill them. </span><em><span style=\"font-weight: 400;\">Tiquira</span></em><span style=\"font-weight: 400;\"> was born. </span></p>\n<p><span style=\"font-weight: 400;\">The name <em>tiquira</em> is likely derived from the Tupi word </span><em><span style=\"font-weight: 400;\">tykyre </span></em><span style=\"font-weight: 400;\">meaning \"to drip.\" But it is a curiosity that the spirit has flourished in only one Brazilian state, Maranhão. Margot Stinglwagner, founder of </span><a href=\"https://www.guaajatiquira.com/en/index.html\"><span style=\"font-weight: 400;\">Guaaja Tiquira</span></a><span style=\"font-weight: 400;\">, the first modern brand to produce the spirit starting in 2016, says “It’s a spirit that is also unknown in Brazil. A few people have heard about tiquira—but usually only people who have gone to Maranhão once.” Accordingly, the state moved to declare the spirit as a piece of Cultural and Intangible Heritage </span><a href=\"https://www.al.ma.leg.br/noticias/48515\"><span style=\"font-weight: 400;\">in September 2023</span></a><span style=\"font-weight: 400;\">. </span></p>\n<p><span style=\"font-weight: 400;\">Part of the reason that tiquira has remained so isolated is that cachaça, Brazil’s rum, is far easier to produce. Because the rum comes from sugarcane, the sugar for fermentation is already there. “With cassava, you don’t have sugar,” Stinglwagner explains. “You must first transform the carbohydrates into sugar and then you can ferment and distill it.” To achieve this end, Guaaja Tiquira uses food enzymes instead of the traditional human saliva. Guaaja also differs from other distillers because they use full cassava roots where most tiquira moonshiners rely on processed </span><em><span style=\"font-weight: 400;\">farinha de mandioca</span></em><span style=\"font-weight: 400;\">, or cassava flour. </span></p>\n<p><span style=\"font-weight: 400;\">“The majority of people produce it illegally,” laughs Stinglwagner. “The state does nothing about it.” Outside of the urban center, tiquira is invariably a homemade product. Generally, tiquira makers don’t separate the \"heads\" (the first drops of liquor from a distillation, which contain harsher alcohols including toxic methanol and other pungent and volatile flavor compounds) from the \"tails\" (the final liquid produced from distillation, which has a low alcohol content and can have unwelcome bitter flavors), meaning the spirit is stronger and may contain more toxins and impurities. Some even macerate marijuana into the combined spirit to produce the doubly-illicit <em>tiquiconha</em>.</span></p>\n<p><span style=\"font-weight: 400;\">Maranhenses believe that you cannot get wet or bathe after drinking tiquira, lest you become faint or dizzy. Zelinda Machado de Castro e Lima, one of the great chroniclers of folk culture in Maranhão, has recorded other traditions surrounding the drink. Firstly, it is typical to pierce a cashew with a toothpick and soak it in a glass of tiquira for several hours. It is then sucked as a sort of boozy lollipop. She also writes about the belief that those drinking coffee should avoid tiquira, while locals say that fishermen on the coast used the liquor to sanitize wounds incurred on the job. </span></p>\n<p><span style=\"font-weight: 400;\">Finally, there is the curious question of the color of tiquira. In the tourist markets of São Luís, the spirit is always blushing a translucent violet. “They say that the color of tiquira is from tangerine leaves, but we tried to do it and the color from the leaves is not stable,” says Stinglwagner. “It is also not a strong color. The norms and laws for tiquira prohibit the addition of the leaves.” The violet color may be artificial (perhaps from food dyes), but some tiquiras do have a citrusy flavor. </span></p>\n<p><span style=\"font-weight: 400;\">Tiquira today is still largely relegated to the world of moonshining, but with the government’s recognition of the spirit and new legitimate ventures like that of Guaaja Tiquira, Brazil could be seeing more of the cassava liquor outside of its home in Maranhão. </span></p>\n<p><span style=\"font-weight: 400;\">“All the people say to me, ‘What is this new spirit?,’” says Stinglwagner. “I say, ‘It’s not a new spirit, it’s the oldest spirit from Brazil.’”</span></p>\n<p><strong>Know Before You Go</strong></p>\n<p>Tiquira is widely available in the downtown markets of São Luís, Maranhão. Both the local Mercado Central and touristic Mercado das Tulhas have many vendors selling tiquira. The commercial brand, Guaaja Tiquira, is also available in São Luís at Empório Fribal, in addition to Copacabana Palace and Fairmont Hotel in Rio de Janeiro, and Mocotó Bar e Restaurante in São Paulo. </p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 03 Apr 2024 19:17:00 -0400",
        "fetched_at": "2026-01-21T23:22:37.424785Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/sun-valley-americas-first-destination-ski-town",
        "title": "Inside America’s First Destination Ski Town",
        "summary": "<p>In the heart of Idaho, about 150 miles east of Boise, the steep slopes of Bald Mountain tower over a sun-kissed valley. For roughly a century, visitors have flocked to Sun Valley from all over the country for its premiere skiing and snowboarding. But behind these sought-after slopes, there’s an impressive history and one-of-a-kind cultural experiences that make it a unique destination.</p>\n<p>Hollywood’s most celebrated stars have traveled to the valley for decades, yet Sun Valley has managed to maintain a laid-back local life and spirit even amid such A-list appeal. That rare blend of low-pretension modernity—coupled with nonstop flights from eight major metropolitan areas, including Chicago, Seattle, and Los Angeles—make Sun Valley a low-stress, culture-packed getaway.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106264/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">A History of Innovation</h2>\n<p>Long before the glistening snow and sun-soaked days helped launch Sun Valley into a skier's dreamland, a sparkle of another sort caught national attention: silver. In the 1870s, the first discoveries of the precious metal attracted prospectors from across the nation.</p>\n<p>An anchor of the region, the <a href=\"https://visitsunvalley.com/lodging/sun-valley-lodge/\">Sun Valley Resort</a>, with slopes that cater to beginners and seasoned veterans in equal measure, has hosted some of the most iconic stars of the Golden Age of Hollywood.</p>\n<p>But it was born in part out of necessity: The Great Depression hit the railroad business hard in the region. In 1936, Averell Harriman, the chairman of the Union Pacific Railroad at the time, had the idea to boost traffic on its lines by building an exclusive European-style destination ski resort. At the time there were virtually no U.S. ski areas that had upscale lodging and dining right at the slopes.</p>\n<p>To add to the must-see appeal, the resort unveiled the first-ever chairlift on nearby Proctor Mountain. The brainchild of James Curran, an engineer with the railroad, its inspiration came from a surprising place: bananas. While traveling in tropical regions, Curran had seen bananas hooked in bunches and hauled to the dock by pulley systems. Why not try the same with people?</p>\n<p>That December, “Life Magazine” featured the new technology, which helped position the resort as a go-to getaway. The lift, which moved skiers 20 feet off the ground for more than 3,500 feet with a 1,150-foot gain in elevation, opened up the sport to people who might not have otherwise had the stamina for the activity.</p>\n<p>Cinema’s elite, including Marilyn Monroe, Ingrid Bergman, Frank Sinatra and Clark Gable, stayed at the resort, and Ernest Hemingway, whose <a href=\"https://www.atlasobscura.com/places/ernest-hemingway-s-grave\">burial site</a> is also in Sun Valley, finished “For Whom the Bell Tolls” in suite 206 of the Sun Valley lodge. More recently, the region has also attracted business elites and tech giants like Microsoft founder Bill Gates and Apple CEO Tim Cook.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106260/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Laid-Back Local Vibe</h2>\n<p>Today in Sun Valley Village, the walkable heart of the resort, that glamorous essence is anchored by an affable vibe and crowd-pleasing activities. The 1937 opera house now serves as a movie theater, which features films by snow and skiboard filmmaker Warren Miller, among other classics. Ice skating enthusiasts may want to check out the <a href=\"https://visitsunvalley.com/searching-for-sun-valley/get-to-know-every-ice-rink-in-the-wood-river-valley/\">Sun Valley ice rink</a>, a known hangout for Olympic athletes as they prepare for the popular Sun Valley on Ice shows. And additional dining, shopping, and entertainment options abound in nearby Ketchum, located less than two miles down the road (which also has its own free outdoor ice rink, open from late December until mid-February).</p>\n<p>Dining in Sun Valley can be as cosmopolitan or low-key as your tastes crave. For a rustic, homestyle pick, <a href=\"https://www.kneadery.com\">The Kneadery</a> in North Ketchum serves up hearty breakfast and lunch dishes and has been a local go-to since 1974. Owners Dillon and Heather Witmer have cultivated an impressive collection of Western art and artifacts for decades, and diners will spot a canoe hanging from the dining room ceiling, while a taxidermied grizzly bear and mounted antlers on wood-paneled walls add to the cozy, lodge-like feel.</p>\n<p>For a contemporary option be sure to check out Cookbook, which offers flavor-packed bites ranging from grilled Idaho trout to house-made pesto and inventive pizzas. The restaurant, which was originally located in a 1932 church but has since moved to a larger location, serves up plenty of vegetarian options as well, and is commended by guests for its great service and family friendly atmosphere.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106259/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Vibrant Off-Slope Culture</h2>\n<p>Even if you never hit the slopes, Sun Valley is full of high-quality, even quirky, cultural experiences all year long. The <a href=\"https://visitsunvalley.com/to-do/sun-valley-museum-of-art/\">Sun Valley Museum of Art</a> in Ketchum is a regional hub for contemporary and local art, formed in 1971. Each year, the museum hosts resident artists and features exhibitions and events featuring visual arts, film, music, and more.</p>\n<p>When the Wood River Valley is blanketed in snow, the region is also host to the <a href=\"https://sunvalleyfilmfestival.org\">Sun Valley Film Festival</a>, an annual, five-day event that has featured legendary filmmakers and Hollywood’s best, including Clint Eastwood, Jodie Foster, and Woody Harrelson, since 2011. Screenings, cocktail and coffee chats, and big-ticket parties honor the greatest names in film and introduce emerging artists. Monthly movies and educational programming are also offered year-round.</p>\n<p>Each January, respected culinary masters and rising food stars emerge at the <a href=\"https://visitsunvalley.com/events/sun-valley-food-wine-celebration-2/\">Sun Valley Food &amp; Wine Celebration</a>. The Sun Valley Culinary Institute hosts this popular, five-day event, featuring James Beard Award winners, champions from the Food Network “Chopped” reality show, exclusive chef dinners, cooking classes, and spirited Après Ski events.</p>\n<p>The Sun Valley Pavilion buzzes in summer with sound at the <a href=\"https://www.svmusicfestival.org\">​​Sun Valley Music Festival</a>, a month-long event that offers world-class musicians performing in a relaxed outdoor venue.</p>\n<figure class=\"article-image-full-width contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/lg/106265/image.jpg\" width=\"auto\" /></figure>\n<h2 class=\"article-subheading-pre-rd\">Spirited Character</h2>\n<p>Sun Valley residents take pride in their rich heritage, cause for memorable celebrations. As the trees in downtown Ketchum begin to morph from green to fiery orange and red, over a thousand sheep amble along Main Street for the <a href=\"https://www.atlasobscura.com/articles/podcast-trailing-of-the-sheep\">Trailing of the Sheep Festival</a>. Each fall, Sun Valley honors the annual sheep migration from the summer’s high mountain pastures to the warmer grazing and lambing regions in the south, an event known historically as “trailing.” The festival is packed with wool-making classes, culinary lessons, live music and folklore, and more.</p>\n<p>For Labor Day, Sun Valley residents celebrate another part of their heritage at <a href=\"https://www.wagondays.com\">Wagon Days</a>. Founded in 1958, the tradition honors the history and mining heritage of the region, including one of the weekend’s most anticipated events: the Big Hitch Parade, which showcases antique buggies, carriages, carts, and more parading through downtown Ketchum.</p>\n<p>Whether you’re an avid skier or just want to soak in sunny days as you experience a culturally rich pocket of American history, surprises await in Sun Valley.</p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 06 Jan 2026 16:23:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424736Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-the-well-maine",
        "title": "Forged by Nature: The Farm-to-Table Restaurant on an Actual Farm",
        "summary": "<div>\n<p class=\"item-body-text-graf\"><strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers: </strong>When Jason Williams was a kid in the ’80s, he had a favorite TV show. It wasn’t a cartoon. It was more like a documentary show. Like the educational kind.</p>\n<p><strong>Jason Williams:</strong> I was obsessed with the show <em>Great Chefs Great Cities</em>, which was a program back on in the early, late ’80s, probably, where they’d go to different restaurant kitchens and make a dish.</p>\n<p><strong>Kelly: </strong>Jason grew up on the East Coast in a small town. It was nice, but it was not the ideal place to learn to become a chef.</p>\n<p><strong>Jason:</strong> I grew up in New Hampshire and didn’t have a lot of access to crazy ingredients.</p>\n<p><strong>Kelly:</strong> The closest bigger town was across the border in Maine. But when he went there as a kid, he wasn’t going for the food.</p>\n<p><strong>Jason:</strong> So I’d come to Portland growing up as a kid. We used to come over here and skateboard and, you know, all that fun stuff and just kind of be in the city.</p>\n<p><strong>Kelly:</strong> Back then, the big city of Portland, Maine wasn’t necessarily known for its food scene. It was not featured on <em>Great Chefs Great Cities</em>. But these days, Maine’s reputation in the food world is different. And Jason Williams, now Chef Jason Williams, is a big part of that.</p>\n<p><strong>Jason:</strong> What drew me to Maine was just the accessibility we have, like the ocean right here, incredible cold water seafood. We’re two miles from the ocean and we’re on a 120-acre farm. The farmers are all approachable, the fishermen are all good people, you know, there’s so much abundance.</p>\n<p>I’m Kelly McEvers, and this is <em>Atlas Obscura</em>, a celebration of the world’s strange, incredible, and wondrous places. This episode was produced in partnership with the Maine Office of Tourism. It’s Maine week on the show, so every day we are introducing you to someone from that great state: people who live and work in Maine and who fuel their creativity with its rugged beauty.</p>\n<p>Today it’s all about eating well at Chef Jason’s hyper-local farm-to-table restaurant, The Well, in Cape Elizabeth, Maine. And yeah, you probably have been to a farm-to-table restaurant before, but this one really is different. The food that was probably picked hours before the meal is growing right near where people sit down to dinner. Same with the flowers. Chef Jason really believes in what he’s doing. And it shows.</p>\n<p><em>This is an edited transcript of the </em><a href=\"https://www.atlasobscura.com/podcast\"><em>Atlas Obscura Podcast</em></a><em>: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em>Apple Podcasts</em></a><em>, </em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em>Spotify</em></a><em>, and all major podcast apps.</em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106206/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Kelly: </strong>Okay, so let’s go back to how Jason got started. After he fell in love with <em>Great Chefs Great Cities</em>, he went to culinary school. He left New England to work in restaurants around the country, classy kitchens, high-end resorts, a renowned seafood restaurant on Maui, a winery in Napa Valley. But eventually he started to miss the Northeast.</p>\n<p><strong>Jason:</strong> Thought about raising a family, and New England’s kind of the perfect place to raise kids, so we came here for vacation and just kind of fell back in love with it.</p>\n<p><strong>Kelly:</strong> It was about two decades ago, and Portland, Maine had changed after Jason left. He got a job working at a local restaurant, and one day he was driving around to farmers markets looking for ingredients when he found a special place.</p>\n<p><strong>Jason:</strong> I just happened to drive up this road, and I had just a really cool feeling when I rounded the corner, and I’m like, wait a second, this is a farm? Wait a second, I could get all my shopping done right here? So I just pulled in. It is a 120-acre farm, about three miles from the ocean. A produce farm, it’s fourth generation.</p>\n<p><strong>Kelly: </strong>It’s called Jordan’s Farm, run by the Jordan family. It’s a few miles south of Portland in the town of Cape Elizabeth, which conveniently is also where Jason was living. So he started getting produce from Jordan’s Farm and bringing it back to the restaurant where he was working.</p>\n<p><strong>Jason:</strong> They allowed me to kind of come out back and hand select produce and stuff like that, which is huge in my world.</p>\n<p><strong>Kelly: </strong>Eventually, after a few years of shopping at the farm …</p>\n<p><strong>Jason: </strong>I just pitched them the idea. I drew up a picture of a flatbed trailer and was like, what if we just did a food trailer here and I can work in your off hours? If it doesn’t work, we’ll wheel away and uh throw some grass seed down and it’ll be like it never happened.</p>\n<p><strong>Kelly: </strong>What Jason was proposing was to literally build a kitchen on the back of a flatbed trailer. That way, if the project was not a success, he would just tow it away and the Jordans could get back to business as usual. Jason was nervous. He’d never run a restaurant before, but the farm …</p>\n<p><strong>Jason:</strong> They went for it. They were like, great idea, and they were so supportive and just really let me make this happen.</p>\n<p><strong>Kelly:</strong> Jason got the blessing of the chef where he was working and went out on his own, building out that kitchen trailer at Jordan’s farm.</p>\n<p><strong>Jason:</strong> Busted out the graph paper. I was like, okay, well, you know, small dimensions, what can we actually do for equipment? Just a leap of faith, obviously. I tried to do it on a tight budget. I didn’t come out swinging with a huge space, a state-of-the-art kitchen. I just kind of built what was necessary for me to make nice food.</p>\n<p><strong>Kelly:</strong> He didn’t know how to run a restaurant. He did know how to make nice food. Every day, he would go into Jordan’s farm, see what looked best, and design a couple of dishes around what they had. He called his project The Well, as in eating well, also as in a watering hole, a place where people gather. And since he got to invent the menu every morning, he could get really specific.</p>\n<p><strong>Jason: </strong>So you can really play on the weather, what’s fresh, just the mood. Everything changes. You know, Maine can be 80 degrees one day and 50 degrees the next day and rainy. If it’s cold, I might throw a soup on. I can just adapt to what’s around me.</p>\n<p><strong>Kelly: </strong>He started slow and simple.</p>\n<p><strong>Jason: </strong>We didn’t have a dishwasher. I started off with just kind of compostable plates. I was just doing like a chalkboard menu with a couple items, and I had a suggested donation box here where people would just kind of come in, drop cash, and I really like people were kind of shocked by it, you know, it wasn’t something that you saw a lot, you know, 15 years ago, really, especially in this town.</p>\n<p><strong>Kelly: </strong>Jason knew that was a gamble. The restaurant business is hard, and this was a restaurant on a farm stand. People were coming there to get produce to take home and cook for themselves. They weren’t necessarily looking to spend money on prepared food. Turns out, Jason was wrong.</p>\n<p><strong>Jason: </strong>So people would start lining up an hour before I even opened, and then all of a sudden I would be out of food in like two hours, just ripping through 70 people. We’d put a little chalkboard menu up at the top of the thing that said “The Well is dry,” and “try again the next day.”</p>\n<p><strong>Kelly:</strong> At that point, Jason knew he had to expand. He built out a bigger kitchen in a real building, no wheels underneath. He hired staff, started adding menu items, not just a few things written in chalk. He added more formal seating. Before it had been picnic tables, now there would be gazebos for private dining. He started sourcing stuff from other local producers, butchers, and growers. But the concept was the same: Whatever looked best that morning, that’s what he would use.</p>\n<p><strong>Jason:</strong> And then I started introducing, probably like year seven or something, I started introducing a tasting menu, an option, just like, okay, if you want to, if you trust me, we can do a five-course tasting menu and see what happens.</p>\n<p><strong>Kelly: </strong>What happened was people did trust him. The tasting menu became a huge part of his business. And now that’s what The Well does. Every day he’s open, it’s five fresh courses chosen that morning.</p>\n<p><strong>Jason:</strong> A veggie course, a fish course, a grain pasta course, and then kind of your fourth course protein and a dessert. It’s really nice because I can just grab totes and walk up to the farm stand, which is like 50 yards away, and hand select whatever I need for the night.</p>\n<p>I can just adapt to what’s around me, the weather, and just new stuff that looks incredible up there. The seasons are so dramatic here in Maine. You know, things happen so quick. It’s really nice to be able to just capture that and be able to use those things that they’re hiding and put them right into play.</p>\n<p><strong>Kelly:</strong> A wood-grilled lamb loin with local corn and housemade barbecue sauce. A homemade brioche donut and vanilla ice cream with peaches picked that morning.</p>\n<p><strong>Jason: </strong>I’m not throwing a bunch of weird ingredients at you, but everything’s got to be seasoned well, cooked, executed well. So I’m really focused on those details, those small things. The fundamentals: seasoning, balance, flow of a whole tasting menu.</p>\n<p>People get so pigeonholed into what they’re comfortable ordering or eating, and maybe they’ll find out that they actually do like carrots or zucchini now, and it’s not how they remembered it from their grandmother’s mushy peas or whatever.</p>\n<p>I get inspired by like I see these farmers working crazy, so it’s nice. I really want to do my best to kind of make them proud. I want them to know that their product is first and foremost, and that I’m doing it justice.</p>\n<p><strong>Kelly:</strong> The Well at Jordan’s Farm has become one of the Portland area’s most popular restaurants. These days, there are a lot of great restaurants in Maine. In recent years, the state’s food scene has grown. And just like at the well, it brings together so much of what makes Maine Maine. The independence, the seasonality, the creativity. And now The Well has been part of that community for 15 years.</p>\n<p><strong>Jason:</strong> It’s really refreshing here that things are still chef-owned, smaller scale, a lot of integrity. I feel super proud of it now, 15 years later, you know, it’s been a labor of love. I worked so—I’ve never worked so hard at anything in my life, really. But it’s been—it feels good now, you know. People are celebrating years and years and years of anniversaries, of birthdays. Yeah, it feels great. I mean, what more can you ask for? In the hospitality business, you know, to feel that love back. It’s really nice.</p>\n<p><strong>Kelly:</strong> Who knows? If there’s a reboot of <em>Great Chefs Great Cities</em>, Jason and the other restaurants that have sprung up in and around Portland, Maine might make the cut this time.</p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em>This episode was produced by Katie Thornton. Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Casey Holford, and Luz Fleming. Our theme music is by Sam Tyndall.</em></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 24 Dec 2025 07:15:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424757Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/articles/podcast-hanako-nakazato-pottery",
        "title": "Forged by Nature: How Maine Shapes This Artist’s Pottery",
        "summary": "<div>\n<p class=\"&lt;iframe\">&gt;<strong>Listen and subscribe on <a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\">Apple Podcasts</a>, <a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\">Spotify</a>, and all major podcast apps.</strong></p>\n</div>\n<hr class=\"baseline-grid-hr\" />\n<p><strong>Kelly McEvers:</strong><span style=\"font-weight: 400;\"> Hanako Nakazato says, when she was a kid, she didn’t want to work in pottery.</span></p>\n<p><strong>Hanako Nakazato:</strong><span style=\"font-weight: 400;\"> I grew up in Karatsu, which is known for history of pottery. So when I was younger, I wasn’t interested in pottery. It was too close to home.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Karatsu is in southern Japan. It’s been a hub of pottery making for hundreds of years. Hanako comes from a family of renowned potters. So, at first, she wanted to try something different. But, after she moved to the United States at 16, slowly that started to change.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> As I spent many years away from home, I started to appreciate my own cultural heritage.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">It started with food, sort of.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">I love food, and I realized the Japanese dining experience is very unique. Not just the ingredients, but the table setting is very unique—the presentation of the food—and pottery plays a big role in that.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> So, Hanako knew what she had to do next.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I wanted to create a tool to enjoy food, and that was the start. European style, everything is unified, and it’s very clean. But if you go to a Japanese restaurant, repetition is often avoided. So, you would have different kinds of pottery on the table. It’s not just white things and the round things. You might start seeing something white or clean, but then next might be something in wood or bamboo or metal or glass. Texture is different, material might be different.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">To Hanako, there was something beautiful about all these different variations. Something that to her had a deeper meaning.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">We mix all different kinds of materials and shapes and heights, and it’s creating something balanced or unified out of chaotic situations.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Since 2010, Hanako has been living and practicing in both Japan and in rural Midcoast Maine. She says Maine’s environment is like the Japanese diningware she came to love. Varied, messy even, but also cohesive and balanced. Craggy, rocky hills next to placid blue lakes, dense forests near the wide open ocean. It’s all there, she says, and it all inspires Hanako and other artists like her.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Maine has the beauty and inspires people, artistic people, to create something beautiful. To be independent and to create your own beautiful life because of the beautiful nature. That’s what I appreciate, Maine.</span></p>\n<p><span style=\"font-weight: 400;\">I’m Kelly McEvers, and this is </span><em><span style=\"font-weight: 400;\">Atlas Obscura</span></em><span style=\"font-weight: 400;\">, a celebration of the world’s strange, incredible, and wondrous places. This episode was produced in partnership with the Maine Office of Tourism. It’s Maine week on the show, so every day we are introducing you to someone from that great state. People who live and work and get inspired by Maine’s rugged beauty.</span></p>\n<p><span style=\"font-weight: 400;\">Today is all about the pottery of Hanako Nakazato and the philosophy she brings to it. It’s a philosophy that perfectly unites the two places she spends her time: Karatsu, Japan, and the 2000-person town of Union, Maine. Two places that inspire artists with their sense of community and the beauty of nature.</span></p>\n<p><em><span style=\"font-weight: 400;\">This is an edited transcript of the </span></em><a href=\"https://www.atlasobscura.com/podcast\"><em><span style=\"font-weight: 400;\">Atlas Obscura Podcast</span></em></a><em><span style=\"font-weight: 400;\">: a celebration of the world’s strange, incredible, and wondrous places. Find the show on </span></em><a href=\"https://go.skimresources.com/?id=89027X1542228&amp;isjs=1&amp;jv=15.7.1&amp;sref=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fpodcast-montezuma-well&amp;url=https%3A%2F%2Fpodcasts.apple.com%2Fus%2Fpodcast%2Fthe-atlas-obscura-podcast%2Fid1555769970&amp;xs=1&amp;xtz=300&amp;xuuid=f238828fc9c8f1386593b6f8b1d81e7b&amp;xjsf=other_click__contextmenu%20%5B2%5D\"><em><span style=\"font-weight: 400;\">Apple Podcasts</span></em></a><em><span style=\"font-weight: 400;\">, </span></em><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"><em><span style=\"font-weight: 400;\">Spotify</span></em></a><em><span style=\"font-weight: 400;\">, and all major podcast apps.</span></em></p>\n<figure class=\" contains-caption \"><img alt=\"article-image\" class=\"article-image with-structured-caption \" src=\"https://assets.atlasobscura.com/article_images/106207/image.jpg\" width=\"auto\" /></figure>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Maine, it’s not New York City. You see a lot of greens, sometimes I see turkeys in traffic. Yeah, we’re living in the countryside of mid-coast Maine. I love it.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> If you know much about Maine, you know it can be quiet and peaceful, but you also probably know that it gets pretty rugged. Being in rural Maine is a physical experience, and that resonates with Hanako. Because, so is throwing pottery on a wheel.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">I used to be a serious athlete, and I like to understand the world in a physical way. And pottery is very—it requires a certain level of aestheticism.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">You can see that in the way Hanako makes work. She starts by taking a big piece of clay and tossing it onto a table over and over, kneading it to soften it up. Then …</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> You put the chunk of clay on the wheelhead.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Then she pounds the sides of that chunk, centering it and guiding it upward as she does. On the top portion of the spinning mound of clay, she begins to shape a bowl or a cup. Then she uses a traditional tool that’s used in Karatsu.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">A special rib, special tool, throwing tool, called gyubera.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">The gyubera kind of looks like a cow’s tongue. She uses it to press the walls of the cup or bowl against her outside hand and shape the pottery. Then she slices the bowl off the top of the spinning mound and begins forging another one from the clay that remains. And another and another. In her home studio with white walls and floor-to-ceiling windows that look out over the main wilderness, Hanako does this work almost like meditation as the light shifts outside.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I’m a production potter, so I can make a couple hundred pieces a day. If I decide to make a cup, I make 50, or hundreds of them. Just to get in a flow. I love working in a flow, because I let go of myself and just work on the wheel, spinning, and it’s all physical. You’re not even thinking. I usually listen to house music and it’s all about the rhythm and then just doing the repetition.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Hanako says the key is letting her mind get out of the way.</span></p>\n<p><strong>Hanako: </strong><span style=\"font-weight: 400;\">That’s when the true beauty comes out. Pottery as a clay, as a material, it’s very responsive to the touch or the movement, and you have to work with intuition, you have to use senses. You can’t really think too hard.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Hanako wants her art to be used: bowls, plates, cups, and carafts, but there’s always something unique about each one. An unexpected angle, a sloping edge. And since moving to Maine, the local landscape has found its way into her work too.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I often find my shape is influenced by what I see in nature. I love being in Maine because it has the ocean, the blueberry field, and the woods, and light. Light is magical here. I used to make black or white or something monotone pottery because I was more into creating shapes. But since I moved to Maine, I started making something more colorful or blue. And I think I was influenced by Maine, ocean or sky, or dark night. Yeah, definitely have a different color palette since I lived in Maine. </span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">Hanako’s style is rooted in Japan too. One of her guiding philosophies to lead with your heart and your body rather than your mind doesn’t just show up in her process. It’s embedded in the name of her studio, Mono Hanako.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> “Mono” means “thing” in Japanese. “Pottery” in Japanese is called “yakimono.” “Yaki” is “fired,” “mono” is “thing.” But I want my pottery to be versatile. If you call this a mug, it limits the usage function as a drinking vessel, maybe just for coffee or tea. But if you call it a thing, you could use it for soup, or you could use it for ice cream, dessert bowl, or you could put, you know, a bouquet of herbs.</span></p>\n<p><span style=\"font-weight: 400;\">So it will open up the other possibilities of usage. So I want to call my pottery a thing, rather than giving a special name like a soup bowl or a dessert bowl or you know, ramen bowl. Because beyond that, people cannot really think about it. You know, oh, you have to use for ramen only. The pottery might be the same, but if you put different things, this will look differently. And I like the continuous change.</span></p>\n<p><strong>Kelly:</strong><span style=\"font-weight: 400;\"> Trying to avoid the limiting confines of your thinking mind, staying away from perfection, celebrating and embracing variety, like the variety found in the tableware in a traditional Japanese meal. All this is baked into Hanukkah’s philosophy, not just in art, but in life.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> I think there is a Zen influence. Perfection is often avoided in Zen philosophy.</span></p>\n<p><strong>Kelly: </strong><span style=\"font-weight: 400;\">And in Maine, that variety, that ruggedness, that beautiful imperfection is all around her.</span></p>\n<p><strong>Hanako:</strong><span style=\"font-weight: 400;\"> Nature is not trying to be perfect. It just—it’s there.</span></p>\n<p><strong><em>Listen and subscribe on</em></strong><a href=\"https://podcasts.apple.com/us/podcast/the-atlas-obscura-podcast/id1555769970\"> <strong><em>Apple Podcasts</em></strong></a><strong><em>,</em></strong><a href=\"https://open.spotify.com/show/0s0c4Z99PwbW8efTmHckyT\"> <strong><em>Spotify</em></strong></a><strong><em>, and all major podcast apps.</em></strong></p>\n<p><em><span style=\"font-weight: 400;\">This episode was produced by Katie Thornton. Our podcast is a co-production of Atlas Obscura and Sirius XM Podcasts. The people who make our show include Dylan Thuras, Doug Baldinger, Kameel Stanley, Johanna Mayer, Manolo Morales, Amanda McGowan, Casey Holford, and Luz Flemming. Our theme music is by Sam Tyndall.</span></em></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 23 Dec 2025 07:15:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424761Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/foods/nectar-soda",
        "title": "Nectar Soda",
        "summary": "<p><img alt=\"An Aglamesis nectar soda.\" height=\"200\" src=\"https://img.atlasobscura.com/gLqA8RaTQNIL0MupnRjPCWB4QRxXZdJs1eCFvMqaXY8/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3RoaW5n/X2ltYWdlcy80YTQw/MzA1NC04MjBhLTQw/MmEtYmU5My1iYWZi/YWU5ZGViNDc5Y2Rk/YjY1YjA4NGY1MmFm/YzRfQWdsYW1lc2lz/IG5lY3RhciBzb2Rh/IG9uIHRhYmxlIDIu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Though Cincinnati is best known for breweries, another effervescent beverage has a long history in the Queen City: the nectar soda.</span></p>\n<p><span style=\"font-weight: 400;\">Home to the oldest pharmacy college in the U.S. west of the Alleghenies, the</span><a href=\"https://lloydlibrary.org/research/archives/eclectic-medicine/\"><span style=\"font-weight: 400;\"> Eclectic Medical Institute</span></a><span style=\"font-weight: 400;\"> (1845-1952), and</span><a href=\"https://lloydlibrary.org/about/a-brief-history-of-the-lloyd-library-and-museum/\"><span style=\"font-weight: 400;\"> Lloyd Brothers Pharmacists</span></a><span style=\"font-weight: 400;\">, Cincinnati was long on the forefront of the pharmaceutical industry. The city had a number of apothecaries with soda fountains, as well as confectioners serving countless carbonated concoctions—some claiming to cure a variety of ailments, and others simply providing customers with something sweet and refreshing to drink.</span></p>\n<p><span style=\"font-weight: 400;\">Enter the nectar soda. The flavor is a combination of vanilla and bitter almond, and the drink is pastel pink in color—a nod to the hue of almond flowers, according to </span><a href=\"https://dannwoellertthefoodetymologist.wordpress.com/\"><span style=\"font-weight: 400;\">Dann Woellert</span></a><span style=\"font-weight: 400;\">, a Cincinnati food historian, etymologist, and the author of </span><a href=\"https://www.amazon.com/Cincinnati-Candy-History-American-Palate/dp/1467137952\"><em><span style=\"font-weight: 400;\">Cincinnati Candy: A Sweet History</span></em></a><span style=\"font-weight: 400;\">. Nicknamed the “</span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-2-1942-page-55-108/docview/1882746511/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">drink of the gods</span></a><span style=\"font-weight: 400;\">,” the bitter almond flavor of nectar soda balances out what would otherwise be overly sweet vanilla, creating an addictive taste that grows on you with each sip. </span></p>\n<p><span style=\"font-weight: 400;\">Nectar sodas have been served in Cincinnati since at least the late 1870s, though, like many iconic foods and beverages, its precise origins are murky. The only other U.S. city to embrace nectar sodas was New Orleans, but unlike Cincinnati, the tradition fizzled out in the Big Easy in the mid-20th century. Plus, Woellert says that the Queen City popularized them first. “They were served in Cincinnati nearly a decade before New Orleans,” he says.</span></p>\n<p><span style=\"font-weight: 400;\">While the Cincinnati nectar soda has multiple origin stories, each crediting a different pharmacist or confectioner, Woellert has concluded that </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/april-13-1947-page-98-151/docview/1882885311/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">John Mullane</span></a><span style=\"font-weight: 400;\"> created the flavor after traveling to Quebec City to learn the art of confectionery from a prominent Canadian candymaker. He began serving nectar sodas in his confectionery shop in downtown Cincinnati in the late 1870s.</span></p>\n<p><span style=\"font-weight: 400;\">So, why did the nectar soda end up in Cincinnati and New Orleans, of all places? Wollert suspects that the bitter almond and vanilla flavor was used by the French Acadians who settled in both Quebec City and New Orleans.</span></p>\n<p><span style=\"font-weight: 400;\">Though nectar sodas aren’t as common as they were in the early 20th century, when they could be found at countless confectioneries and pharmacy soda fountains across Cincinnati, they’re still served at establishments throughout the city and the surrounding area. Nectar sodas have been on the menu at ice cream and chocolate shop </span><a href=\"https://www.aglamesis.com/\"><span style=\"font-weight: 400;\">Aglamesis Brothers</span></a><span style=\"font-weight: 400;\"> since it opened in Cincinnati in 1908, if not shortly thereafter. That’s according to company president and CEO Randy Young, who is also a third-generation family member. </span></p>\n<p><span style=\"font-weight: 400;\">It’s unclear when nectar sodas were added to the </span><a href=\"https://digital.cincinnatilibrary.org/digital/collection/p16998coll32/id/2220/rec/19\"><span style=\"font-weight: 400;\">menu</span></a><span style=\"font-weight: 400;\"> at </span><a href=\"https://www.graeters.com/\"><span style=\"font-weight: 400;\">Graeter’s</span></a><span style=\"font-weight: 400;\">, a Cincinnati ice cream and chocolate shop that opened in 1870 and now has locations throughout the city and the Midwest, but Chip Graeter, chief of retail operations and a fourth-generation family member, says that they were especially popular throughout the 1940s, 1950s and 1960s.</span></p>\n<p><span style=\"font-weight: 400;\">In a </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/january-28-1947-page-2-26/docview/1882876222/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">January 28, 1947 article</span></a><span style=\"font-weight: 400;\"> in the </span><em><span style=\"font-weight: 400;\">Cincinnati Enquirer</span></em><span style=\"font-weight: 400;\">, Tom Moore, the head of the soda department at Dow Drug Store—which operated 32 soda fountains throughout the metropolitan area at that time—said that “nectar is one of the most popular flavors in all of their stores, and has been for many years.” Five years prior, </span><a href=\"https://www.proquest.com/hnpcincinnatienquirershell/historical-newspapers/august-16-1942-page-63-99/docview/1882739776/sem-2?accountid=39387\"><span style=\"font-weight: 400;\">Dow ran an ad</span></a><span style=\"font-weight: 400;\"> in the same newspaper which read: “Be glad you live in Cincinnati, the only place in the country where you can enjoy a Dow double-dip nectar soda.”</span></p>\n<p><span style=\"font-weight: 400;\">Originally, nectar syrup was made by combining half-and-half or milk with water, bitter almond extract, vanilla extract and red food coloring. While Aglamesis eventually switched to a dairy-free shelf-stable syrup, Graeter's recipe has never changed—it still contains milk and needs to be refrigerated. </span></p>\n<p><span style=\"font-weight: 400;\">Both Aglamesis and Graeter’s make nectar soda by mixing nectar syrup with a dollop of whipped cream, adding a scoop or two of vanilla ice cream, then topping it off with some soda water and more whipped cream.</span></p>\n<p><span style=\"font-weight: 400;\">Though Young says that nectar sodas are most popular with older adults, they’re also a hit with members of younger generations who try them. “People who grew up with them still love them today,” Graeter says. “We still make them in all of our stores, but they're not nearly as popular today as they once were, simply because milkshakes and smoothies have taken over.”  </span></p>\n<p><span style=\"font-weight: 400;\">According to Young, there is a commercially available descendant of </span><a href=\"https://www.coca-cola.com/us/en/brands/barq-s\"><span style=\"font-weight: 400;\">the nectar soda</span></a><span style=\"font-weight: 400;\">. “Commercial soda companies like Barqs and others came out with their version of cream soda—a bright pink soda—which got its flavoring from nectar soda,” he explains.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 03 Dec 2024 11:00:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424781Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 8.6,
        "temp_score_trend": 5.3999999999999995
      },
      {
        "url": "https://www.atlasobscura.com/places/lost-colony-roanoke",
        "title": "The Lost Colony of Roanoke in Manteo, North Carolina",
        "summary": "<p><img alt=\"A recreation of an earthwork structure built by colonists on Roanoke Island.\" height=\"200\" src=\"https://img.atlasobscura.com/xnrro1d9VaNfNUjslrTuOTWclCBs4cq6kRY2j_6wyaA/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3BsYWNl/X2ltYWdlcy8yYTNk/ZTI0NC03OWUzLTQ2/ZWEtYmRlOC1kMWQ4/ZTAyZWIzMmNmYzJh/MWY4MGUzYTEyNjkx/Y2FfRm9ydCBSYWxl/aWdoIC0gTW91bmQu/anBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">Located on the Outer Banks of North Carolina, Roanoke Island is home to one of America’s most enduring mysteries: the disappearance of an entire colony without a trace.</span></p>\n<p><span style=\"font-weight: 400;\">Roanoke Island was first surveyed by English explorers in 1584, when the Spanish Empire was still the dominant colonial power in the Americas. The English statesman Sir Walter Raleigh sought to establish a colony in the region to give the English Crown a foothold on the continent and build a base of operations for privateering—the state-sanctioned practice of raiding foreign commercial vessels. The reconnaissance mission identified Roanoke Island as a promising location, with its soil described as “the most plentiful, sweet, fruitful, and wholesome of all the world.”</span></p>\n<p><span style=\"font-weight: 400;\">Roanoke Island’s natural bounty notwithstanding, the colonization project proved more challenging than expected. Six hundred men arrived on the island in late June the following year, with little time to prepare for the coming winter. Making matters worse, storms damaged an anchored ship storing most of the group’s supplies off the coast, leading to food shortages for the fledgling colony. </span></p>\n<p><span style=\"font-weight: 400;\">These food shortages, paired with disease brought by the Englishmen, escalated tensions between the local Algonquian population and colonists, who turned back to England in the summer of 1586.</span></p>\n<p><span style=\"font-weight: 400;\">In 1587, another expedition led by John White set sail with 118 women, men, and children. Upon their July arrival, colonists started rebuilding and improving upon the infrastructure left behind by the previous colony. But tensions with the local population continued to rise, ultimately leading to an incident where colonists mistakenly attacked a Croatoan village in retaliation for the killing of a colonist by members of the Secotan tribe.</span></p>\n<p><span style=\"font-weight: 400;\">A month after their arrival, on August 18, John White’s granddaughter was born, the first English child born on the North American continent: Virginia Dare. Soon after, White set sail back to England for supplies and additional settlers, expecting to return the following year.</span></p>\n<p><span style=\"font-weight: 400;\">However, White’s return voyage to Roanoke was delayed by several years due to an escalation of the Anglo-Spanish War and increased English interest in colonizing Ireland. When he finally mustered a fleet and arrived on Roanoke Island on August 18, 1590, the settlers were gone, having left few clues aside from a carving of the word “Croatoan.”</span></p>\n<p><span style=\"font-weight: 400;\">Speculation about what happened to the colony abounds, but the colonists’ fate remains a mystery. Popular theories include a hurricane, a famine, a Spanish attack, integration with nearby native populations, or migrations to new locations along the coast. However, to this day, no archeological evidence has been found to support these theories, and many are contradicted by White’s account of arriving at the colony, which did not describe signs of a storm or violent struggle.</span></p>\n<p><span style=\"font-weight: 400;\">Today, visitors to Roanoke Island buy tickets to see “<a href=\"https://www.thelostcolony.org/?gad_source=1&amp;gad_campaignid=1368556233&amp;gclid=CjwKCAiAj8LLBhAkEiwAJjbY77Ly2IBl-X67cyUoLjvibLuAdkIrbpM9GM4ZOIhCgUoU17NDg7d7uRoCZWsQAvD_BwE\">The Lost Colony</a>,” by the late playwright and Pulitzer winner Paul Green, which first opened on July 4th in 1937, and is performed at an amphitheater on the coast. The area also features a <a href=\"https://www.nps.gov/fora/index.htm\">visitor center</a> with a museum dedicated to the lost colony, and manicured grounds and nature trails for a leisurely stroll.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Wed, 21 Jan 2026 16:44:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424649Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.9,
        "temp_score_trend": 5.1
      },
      {
        "url": "https://www.atlasobscura.com/places/anderson-abruzzo-international-balloon-museum",
        "title": "The Anderson Abruzzo Albuquerque International Balloon Museum in Albuquerque, New Mexico",
        "summary": "<p><img alt=\"The exterior of the Anderson Abruzzo International Balloon Museum.\" height=\"200\" src=\"https://img.atlasobscura.com/6Wk0gb1IKqbeyMD5Agx_botFJHmOfgvqMDc3ahNr9P4/rs:fill:300:200:1/g:ce/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL3BsYWNl/X2ltYWdlcy9jMjE3/MGY4OC0zYTA4LTQw/ZTQtYTIwNC0yMDdm/MGE5OTM4Y2RjM2I4/ZGMzYTdmNjQyOThj/MDRfRV9EUlRfQmFs/bG9vbk11c2V1bS1F/eHQuanBn.jpg\" width=\"300\" /></p> <p><span style=\"font-weight: 400;\">The Anderson Abruzzo Albuquerque International Balloon Museum, which opened its doors in 2005, features exhibits that include fascinating artifacts, some of which date back to air travel’s earliest days: The first hot air balloon flight and the first gas balloon flight both took place in Paris in 1783. </span></p>\n<p><span style=\"font-weight: 400;\">Few, if any, museums start with an accidental death. Yet two such tragedies make up the first entries in the timeline of this Albuquerque museum, a center dedicated to exploration through ballooning. But rest assured, a visit to this museum is truly an uplifting experience.</span></p>\n<p><span style=\"font-weight: 400;\">Two renowned Albuquerque balloonists, Maxie Anderson and Ben Abruzzo, completed the first nonstop transatlantic gas balloon flight in 1978. Tragically, Anderson was killed in a balloon accident in Germany five years later. Two years after that, Abruzzo died when a plane he was piloting crashed near Albuquerque.</span></p>\n<p><span style=\"font-weight: 400;\">It’s in their memory that this museum is named, and Albuquerque is a natural home for it, as the city has been hosting the annual Albuquerque International Balloon Fiesta for more than 50 years. The museum offers views overlooking the Balloon Fiesta’s official launch field.</span></p>\n<p><span style=\"font-weight: 400;\">The museum’s architecture, by Studio SW, suggests an inflating balloon on its side and boasts a tensile fabric roof and an inflated balloon in its 75-foot-tall gallery. There are balloon simulators and various exhibits inside, plus balconies, roof decks and a plaza for watching the private balloon rides offered by local businesses.</span></p>",
        "source": "www.atlasobscura.com",
        "published": "Tue, 20 Jan 2026 11:44:00 -0500",
        "fetched_at": "2026-01-21T23:22:37.424705Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 4
          }
        ],
        "structural_score": 10,
        "timeliness_score": 3,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null,
        "temp_score_struct": 7.9,
        "temp_score_trend": 5.1
      }
    ],
    "bigtech": [
      {
        "url": "https://technode.com/2025/11/26/over-5000-global-attendees-celebrate-the-successful-debut-of-the-xin-summit-showcasing-the-next-generation-of-innovation-from-the-greater-bay-area-to-the-world/",
        "title": "Over 5,000 Global Attendees Celebrate the Successful Debut of the XIN Summit, Showcasing the Next Generation of Innovation From the Greater Bay Area to the World",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"312\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/11/3.png?fit=556%2C312&amp;ssl=1\" width=\"556\" /></figure>The inaugural&#160;XIN Summit&#160;concluded on 16 November with a powerful debut presented by&#160;BEYOND Expo — Asia’s largest technology innovation and ecosystem event. Focused on&#160;AI Hardware Ecosystems and Frontier Technologies, the Summit connected&#160;Media Day, the 2025 “Next Star” Global Innovation Challenge Awards Ceremony, a two-day Innovation Summit, curated Innovation Exhibition, and high-efficiency investment matchmaking&#160;to demonstrate how technology, [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 26 Nov 2025 01:51:46 +0000",
        "fetched_at": "2026-01-21T23:21:01.367015Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/30/funflys-last-war-tops-global-mobile-game-revenue-chart-in-september-with-180-million-in-earnings/",
        "title": "Funfly’s Last War tops global mobile game revenue chart in September with $180 million in earnings",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"491\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/last-war.png?fit=1024%2C491&amp;ssl=1\" width=\"1024\" /></figure>According to Sensor Tower, FUNFLY’s mobile title Last War topped the global mobile game revenue chart in September, earning an estimated RMB 1.3 billion ($180 million) in in-app purchases across iOS and Google Play. Last War: Survival Game is a SLG (Simulation and Strategy Game), featuring a chibi-style 3D art design, the game blends runner-shooter [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 30 Oct 2025 02:08:57 +0000",
        "fetched_at": "2026-01-21T23:21:01.367436Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 16,
        "timeliness_score": 3,
        "final_score": 9.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/12/17/french-studio-drama-secures-tencent-investment-for-tactical-shooter-unrecord/",
        "title": "French studio Drama secures Tencent investment for tactical shooter Unrecord",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"576\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/12/unrecord.jpg?fit=1024%2C576&amp;ssl=1\" width=\"1024\" /></figure>French independent game studio Drama Studios said its Unreal Engine 5–powered tactical shooter Unrecord has received a strategic investment from Tencent. The game, presented from the perspective of a police body camera, has drawn global attention for its cinematic visual quality and immersive narrative style. Unrecord previously surpassed 600,000 at its peak on Steam’s wishlist [&#8230;]",
        "source": "technode.com",
        "published": "Wed, 17 Dec 2025 10:03:37 +0000",
        "fetched_at": "2026-01-21T23:21:01.366709Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/09/15/mit-technology-review-releases-2025-50-smartest-companies-list-recognizes-deepseek-game-science-and-unitree-robotics/",
        "title": "MIT Technology Review releases 2025 ’50 Smartest Companies’ list, recognizes Deepseek, Game Science and Unitree Robotics",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"567\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/08/Beijing-forbids-generative-AI-in-online-medical-prescriptions-e1694161793934.jpg?fit=1024%2C567&amp;ssl=1\" width=\"1024\" /></figure>At the EmTech China 2025 Global Technology Summit last Friday, MIT Technology Review unveiled its annual list of the “50 Smartest Companies,” with Deepseek, Game Science, and Unitree Robotics earning spots in the ranking. Deepseek was recognized for achieving world-class model performance at low training costs — a breakthrough in algorithm optimization and resource efficiency [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 15 Sep 2025 07:38:25 +0000",
        "fetched_at": "2026-01-21T23:21:01.368435Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2024/04/22/fimi-launches-mini-3-drone-featuring-sony-48mp-sensor-and-249g-weight/",
        "title": "FIMI launches Mini 3 drone featuring Sony 48MP sensor and 249g weight",
        "summary": "<figure><img alt=\"FIMI launches Mini 3 drone featuring Sony 48MP sensor and 249g weight\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"638\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/04/%E6%88%AA%E5%B1%8F2024-04-22-14.49.47.png?fit=1024%2C638&amp;ssl=1\" width=\"1024\" /></figure>FIMI, a subsidiary of Xiaomi that specializes in producing drones and related accessories, recently launched the FIMI Mini 3 drone for the global market, featuring a Sony 1/2-inch 48MP CMOS sensor and a lightweight of 249g. Several third-party retailers have listed the domestic version of the Mini 3 drone on e-commerce platforms, priced at RMB [&#8230;]",
        "source": "technode.com",
        "published": "Mon, 22 Apr 2024 06:50:29 +0000",
        "fetched_at": "2026-01-21T23:21:01.378829Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 13,
        "timeliness_score": 3,
        "final_score": 8.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/10/09/vivo-x300-pro-to-debut-sony-lyt-828-gimbal-camera-with-enhanced-hdr-and-stabilization/",
        "title": "Vivo X300 Pro to debut Sony LYT-828 gimbal camera with enhanced HDR and stabilization",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"596\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/10/vivo-x300.png?fit=1024%2C596&amp;ssl=1\" width=\"1024\" /></figure>Vivo announced on Wednesday that its upcoming X300 Pro will make the global debut of Sony’s LYT-828, a gimbal-level main camera sensor. The 50MP sensor features a large 1/1.28-inch size and an f/1.57 aperture, offering CIPA 5.5-level stabilization. With Hybrid Frame-HDR fusion technology, it offers a 100dB dynamic range for improved backlit and low-light performance. [&#8230;]",
        "source": "technode.com",
        "published": "Thu, 09 Oct 2025 09:43:32 +0000",
        "fetched_at": "2026-01-21T23:21:01.368007Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 5
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 12,
        "timeliness_score": 3,
        "final_score": 7.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://www.scmp.com/economy/china-economy/article/3340693/how-china-rethinking-export-led-growth-global-trade-walls-rise?utm_source=rss_feed",
        "title": "How China is rethinking export-led growth as global trade walls rise",
        "summary": "Beijing’s recent call to balance trade and investment as part of a push for more sustainable growth reflects a gradual shift towards greater overseas localisation of Chinese supply chains, analysts said, as the country grapples with simmering frictions amid a record trade surplus.\n“Commercial authorities at all levels ... should guide the reasonable and orderly cross-border layout of industrial and supply chains, promote integrated development of trade and investment... and effectively...",
        "source": "www.scmp.com",
        "published": "Wed, 21 Jan 2026 09:08:37 +0000",
        "fetched_at": "2026-01-21T23:20:54.995487Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/19/preview-of-chinese-game-developers-at-gamescom-2025%ef%bc%9ablack-myth-wukong-wuxia-rpgs-and-more/",
        "title": "Preview of Chinese game developers at Gamescom 2025：Black Myth Wukong, wuxia, RPGs and more",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"607\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2025/08/blade-2.png?fit=1024%2C607&amp;ssl=1\" width=\"1024\" /></figure>As one of the world’s largest gaming events, Gamescom has become a key bridge between Europe and the global industry. This year, several Chinese games will debut new trailers or offer hands-on demos to overseas players for the very first time, signaling both confidence in their products and a deeper commitment to engaging with international [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 19 Aug 2025 09:58:32 +0000",
        "fetched_at": "2026-01-21T23:21:01.368925Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/08/12/renault-and-geely-collaborate-to-make-electric-suv-for-overseas-markets-report/",
        "title": "Renault and Geely collaborate to make electric SUV for overseas markets: report",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"350\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2024/09/1-1.png?fit=700%2C350&amp;ssl=1\" width=\"700\" /></figure>Renault is developing an electric sports utility vehicle built on the newest platform from Geely called the Global Intelligent New Energy Architecture (GEA), one of the company’s core technologies that has underpinned the success of its Galaxy lineup, as reported by Chinese media publication AutoPix. The new SUV will have both all-electric and plug-in hybrid [&#8230;]",
        "source": "technode.com",
        "published": "Tue, 12 Aug 2025 09:10:21 +0000",
        "fetched_at": "2026-01-21T23:21:01.369046Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 2
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://technode.com/2025/04/12/huawei-patent-reinvents-periscope-camera-with-retractable-design-reducing-camera-bump/",
        "title": "Huawei patent reinvents periscope camera with retractable design reducing camera bump",
        "summary": "<figure><img alt=\"\" class=\"attachment-rss-image-size size-rss-image-size wp-post-image\" height=\"683\" src=\"https://i0.wp.com/technode.com/wp-content/uploads/2023/09/151451493_l_normal_none-scaled.jpg?fit=1024%2C683&amp;ssl=1\" width=\"1024\" /></figure>Source @xleaks7 revealed on platform X that the United States Patent and Trademark Office (USPTO) approved a Huawei patent last month. According to the patent, Huawei proposes using a drive motor to adjust the distance between the camera module and the image sensor, aiming to enhance the zoom performance of telephoto lenses while maintaining a [&#8230;]",
        "source": "technode.com",
        "published": "Sat, 12 Apr 2025 12:50:52 +0000",
        "fetched_at": "2026-01-21T23:21:01.372802Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 5
          }
        ],
        "structural_score": 11,
        "timeliness_score": 3,
        "final_score": 7.0,
        "reddit_score": null,
        "reddit_comments": null
      }
    ],
    "devcommunity": [
      {
        "url": "https://github.com/google/langextract",
        "title": "google/langextract",
        "summary": "<p>A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</p><hr /><p align=\"center\"> <a href=\"https://github.com/google/langextract\"> <img alt=\"LangExtract Logo\" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/logo.svg?sanitize=true\" width=\"128\" /> </a> </p> \n<h1>LangExtract</h1> \n<p><a href=\"https://pypi.org/project/langextract/\"><img alt=\"PyPI version\" src=\"https://img.shields.io/pypi/v/langextract.svg?sanitize=true\" /></a> <a href=\"https://github.com/google/langextract\"><img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/google/langextract.svg?style=social&amp;label=Star\" /></a> <img alt=\"Tests\" src=\"https://github.com/google/langextract/actions/workflows/ci.yaml/badge.svg?sanitize=true\" /> <a href=\"https://doi.org/10.5281/zenodo.17015089\"><img alt=\"DOI\" src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.17015089.svg?sanitize=true\" /></a></p> \n<h2>Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#introduction\">Introduction</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#why-langextract\">Why LangExtract?</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#installation\">Installation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup for Cloud Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#adding-custom-model-providers\">Adding Custom Model Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-openai-models\">Using OpenAI Models</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#using-local-llms-with-ollama\">Using Local LLMs with Ollama</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#more-examples\">More Examples</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#romeo-and-juliet-full-text-extraction\"><em>Romeo and Juliet</em> Full Text Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#medication-extraction\">Medication Extraction</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#radiology-report-structuring-radextract\">Radiology Report Structuring: RadExtract</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#community-providers\">Community Providers</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#contributing\">Contributing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#testing\">Testing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/google/langextract/main/#disclaimer\">Disclaimer</a></li> \n</ul> \n<h2>Introduction</h2> \n<p>LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.</p> \n<h2>Why LangExtract?</h2> \n<ol> \n <li><strong>Precise Source Grounding:</strong> Maps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.</li> \n <li><strong>Reliable Structured Outputs:</strong> Enforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.</li> \n <li><strong>Optimized for Long Documents:</strong> Overcomes the \"needle-in-a-haystack\" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.</li> \n <li><strong>Interactive Visualization:</strong> Instantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.</li> \n <li><strong>Flexible LLM Support:</strong> Supports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.</li> \n <li><strong>Adaptable to Any Domain:</strong> Define extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.</li> \n <li><strong>Leverages LLM World Knowledge:</strong> Utilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.</li> \n</ol> \n<h2>Quick Start</h2> \n<blockquote> \n <p><strong>Note:</strong> Using cloud-hosted models like Gemini requires an API key. See the <a href=\"https://raw.githubusercontent.com/google/langextract/main/#api-key-setup-for-cloud-models\">API Key Setup</a> section for instructions on how to get and configure your key.</p> \n</blockquote> \n<p>Extract structured information with just a few lines of code.</p> \n<h3>1. Define Your Extraction Task</h3> \n<p>First, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.</p> \n<pre><code class=\"language-python\">import langextract as lx\nimport textwrap\n\n# 1. Define the prompt and extraction rules\nprompt = textwrap.dedent(\"\"\"\\\n    Extract characters, emotions, and relationships in order of appearance.\n    Use exact text for extractions. Do not paraphrase or overlap entities.\n    Provide meaningful attributes for each entity to add context.\"\"\")\n\n# 2. Provide a high-quality example to guide the model\nexamples = [\n    lx.data.ExampleData(\n        text=\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\",\n        extractions=[\n            lx.data.Extraction(\n                extraction_class=\"character\",\n                extraction_text=\"ROMEO\",\n                attributes={\"emotional_state\": \"wonder\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"emotion\",\n                extraction_text=\"But soft!\",\n                attributes={\"feeling\": \"gentle awe\"}\n            ),\n            lx.data.Extraction(\n                extraction_class=\"relationship\",\n                extraction_text=\"Juliet is the sun\",\n                attributes={\"type\": \"metaphor\"}\n            ),\n        ]\n    )\n]\n</code></pre> \n<blockquote> \n <p><strong>Note:</strong> Examples drive model behavior. Each <code>extraction_text</code> should ideally be verbatim from the example's <code>text</code> (no paraphrasing), listed in order of appearance. LangExtract raises <code>Prompt alignment</code> warnings by default if examples don't follow this pattern—resolve these for best results.</p> \n</blockquote> \n<h3>2. Run the Extraction</h3> \n<p>Provide your input text and the prompt materials to the <code>lx.extract</code> function.</p> \n<pre><code class=\"language-python\"># The input text to be processed\ninput_text = \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n\n# Run the extraction\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n)\n</code></pre> \n<blockquote> \n <p><strong>Model Selection</strong>: <code>gemini-2.5-flash</code> is the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning, <code>gemini-2.5-pro</code> may provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the <a href=\"https://ai.google.dev/gemini-api/docs/rate-limits#tier-2\">rate-limit documentation</a> for details.</p> \n <p><strong>Model Lifecycle</strong>: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\">official model version documentation</a> to stay informed about the latest stable and legacy versions.</p> \n</blockquote> \n<h3>3. Visualize the Results</h3> \n<p>The extractions can be saved to a <code>.jsonl</code> file, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.</p> \n<pre><code class=\"language-python\"># Save the results to a JSONL file\nlx.io.save_annotated_documents([result], output_name=\"extraction_results.jsonl\", output_dir=\".\")\n\n# Generate the visualization from the file\nhtml_content = lx.visualize(\"extraction_results.jsonl\")\nwith open(\"visualization.html\", \"w\") as f:\n    if hasattr(html_content, 'data'):\n        f.write(html_content.data)  # For Jupyter/Colab\n    else:\n        f.write(html_content)\n</code></pre> \n<p>This creates an animated and interactive HTML file:</p> \n<p><img alt=\"Romeo and Juliet Basic Visualization \" src=\"https://raw.githubusercontent.com/google/langextract/main/docs/_static/romeo_juliet_basic.gif\" /></p> \n<blockquote> \n <p><strong>Note on LLM Knowledge Utilization:</strong> This example demonstrates extractions that stay close to the text evidence - extracting \"longing\" for Lady Juliet's emotional state and identifying \"yearning\" from \"gazed longingly at the stars.\" The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding <code>\"identity\": \"Capulet family daughter\"</code> or <code>\"literary_context\": \"tragic heroine\"</code>). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.</p> \n</blockquote> \n<h3>Scaling to Longer Documents</h3> \n<p>For larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:</p> \n<pre><code class=\"language-python\"># Process Romeo &amp; Juliet directly from Project Gutenberg\nresult = lx.extract(\n    text_or_documents=\"https://www.gutenberg.org/files/1513/1513-0.txt\",\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemini-2.5-flash\",\n    extraction_passes=3,    # Improves recall through multiple passes\n    max_workers=20,         # Parallel processing for speed\n    max_char_buffer=1000    # Smaller contexts for better accuracy\n)\n</code></pre> \n<p>This approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file. <strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">See the full <em>Romeo and Juliet</em> extraction example →</a></strong> for detailed results and performance insights.</p> \n<h3>Vertex AI Batch Processing</h3> \n<p>Save costs on large-scale tasks by enabling Vertex AI Batch API: <code>language_model_params={\"vertexai\": True, \"batch\": {\"enabled\": True}}</code>.</p> \n<p>See an example of the Vertex AI Batch API usage in <a href=\"https://raw.githubusercontent.com/google/langextract/main/docs/examples/batch_api_example.md\">this example</a>.</p> \n<h2>Installation</h2> \n<h3>From PyPI</h3> \n<pre><code class=\"language-bash\">pip install langextract\n</code></pre> \n<p><em>Recommended for most users. For isolated environments, consider using a virtual environment:</em></p> \n<pre><code class=\"language-bash\">python -m venv langextract_env\nsource langextract_env/bin/activate  # On Windows: langextract_env\\Scripts\\activate\npip install langextract\n</code></pre> \n<h3>From Source</h3> \n<p>LangExtract uses modern Python packaging with <code>pyproject.toml</code> for dependency management:</p> \n<p><em>Installing with <code>-e</code> puts the package in development mode, allowing you to modify the code without reinstalling.</em></p> \n<pre><code class=\"language-bash\">git clone https://github.com/google/langextract.git\ncd langextract\n\n# For basic installation:\npip install -e .\n\n# For development (includes linting tools):\npip install -e \".[dev]\"\n\n# For testing (includes pytest):\npip install -e \".[test]\"\n</code></pre> \n<h3>Docker</h3> \n<pre><code class=\"language-bash\">docker build -t langextract .\ndocker run --rm -e LANGEXTRACT_API_KEY=\"your-api-key\" langextract python your_script.py\n</code></pre> \n<h2>API Key Setup for Cloud Models</h2> \n<p>When using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to set up an API key. On-device models don't require an API key. For developers using local LLMs, LangExtract offers built-in support for Ollama and can be extended to other third-party APIs by updating the inference endpoints.</p> \n<h3>API Key Sources</h3> \n<p>Get API keys from:</p> \n<ul> \n <li><a href=\"https://aistudio.google.com/app/apikey\">AI Studio</a> for Gemini models</li> \n <li><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview\">Vertex AI</a> for enterprise use</li> \n <li><a href=\"https://platform.openai.com/api-keys\">OpenAI Platform</a> for OpenAI models</li> \n</ul> \n<h3>Setting up API key in your environment</h3> \n<p><strong>Option 1: Environment Variable</strong></p> \n<pre><code class=\"language-bash\">export LANGEXTRACT_API_KEY=\"your-api-key-here\"\n</code></pre> \n<p><strong>Option 2: .env File (Recommended)</strong></p> \n<p>Add your API key to a <code>.env</code> file:</p> \n<pre><code class=\"language-bash\"># Add API key to .env file\ncat &gt;&gt; .env &lt;&lt; 'EOF'\nLANGEXTRACT_API_KEY=your-api-key-here\nEOF\n\n# Keep your API key secure\necho '.env' &gt;&gt; .gitignore\n</code></pre> \n<p>In your Python code:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\"\n)\n</code></pre> \n<p><strong>Option 3: Direct API Key (Not Recommended for Production)</strong></p> \n<p>You can also provide the API key directly in your code, though this is not recommended for production use:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    api_key=\"your-api-key-here\"  # Only use this for testing/development\n)\n</code></pre> \n<p><strong>Option 4: Vertex AI (Service Accounts)</strong></p> \n<p>Use <a href=\"https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform\">Vertex AI</a> for authentication with service accounts:</p> \n<pre><code class=\"language-python\">result = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=\"Extract information...\",\n    examples=[...],\n    model_id=\"gemini-2.5-flash\",\n    language_model_params={\n        \"vertexai\": True,\n        \"project\": \"your-project-id\",\n        \"location\": \"global\"  # or regional endpoint\n    }\n)\n</code></pre> \n<h2>Adding Custom Model Providers</h2> \n<p>LangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.</p> \n<ul> \n <li>Add new model support independently of the core library</li> \n <li>Distribute your provider as a separate Python package</li> \n <li>Keep custom dependencies isolated</li> \n <li>Override or extend built-in providers via priority-based resolution</li> \n</ul> \n<p>See the detailed guide in <a href=\"https://raw.githubusercontent.com/google/langextract/main/langextract/providers/README.md\">Provider System Documentation</a> to learn how to:</p> \n<ul> \n <li>Register a provider with <code>@registry.register(...)</code></li> \n <li>Publish an entry point for discovery</li> \n <li>Optionally provide a schema with <code>get_schema_class()</code> for structured output</li> \n <li>Integrate with the factory via <code>create_model(...)</code></li> \n</ul> \n<h2>Using OpenAI Models</h2> \n<p>LangExtract supports OpenAI models (requires optional dependency: <code>pip install langextract[openai]</code>):</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gpt-4o\",  # Automatically selects OpenAI provider\n    api_key=os.environ.get('OPENAI_API_KEY'),\n    fence_output=True,\n    use_schema_constraints=False\n)\n</code></pre> \n<p>Note: OpenAI models require <code>fence_output=True</code> and <code>use_schema_constraints=False</code> because LangExtract doesn't implement schema constraints for OpenAI yet.</p> \n<h2>Using Local LLMs with Ollama</h2> \n<p>LangExtract supports local inference using Ollama, allowing you to run models without API keys:</p> \n<pre><code class=\"language-python\">import langextract as lx\n\nresult = lx.extract(\n    text_or_documents=input_text,\n    prompt_description=prompt,\n    examples=examples,\n    model_id=\"gemma2:2b\",  # Automatically selects Ollama provider\n    model_url=\"http://localhost:11434\",\n    fence_output=False,\n    use_schema_constraints=False\n)\n</code></pre> \n<p><strong>Quick setup:</strong> Install Ollama from <a href=\"https://ollama.com/\">ollama.com</a>, run <code>ollama pull gemma2:2b</code>, then <code>ollama serve</code>.</p> \n<p>For detailed installation, Docker setup, and examples, see <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/ollama/\"><code>examples/ollama/</code></a>.</p> \n<h2>More Examples</h2> \n<p>Additional examples of LangExtract in action:</p> \n<h3><em>Romeo and Juliet</em> Full Text Extraction</h3> \n<p>LangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of <em>Romeo and Juliet</em> from Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/longer_text_example.md\">View <em>Romeo and Juliet</em> Full Text Example →</a></strong></p> \n<h3>Medication Extraction</h3> \n<blockquote> \n <p><strong>Disclaimer:</strong> This demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.</p> \n</blockquote> \n<p>LangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.</p> \n<p><strong><a href=\"https://github.com/google/langextract/raw/main/docs/examples/medication_examples.md\">View Medication Examples →</a></strong></p> \n<h3>Radiology Report Structuring: RadExtract</h3> \n<p>Explore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.</p> \n<p><strong><a href=\"https://huggingface.co/spaces/google/radextract\">View RadExtract Demo →</a></strong></p> \n<h2>Community Providers</h2> \n<p>Extend LangExtract with custom model providers! Check out our <a href=\"https://raw.githubusercontent.com/google/langextract/main/COMMUNITY_PROVIDERS.md\">Community Provider Plugins</a> registry to discover providers created by the community or add your own.</p> \n<p>For detailed instructions on creating a provider plugin, see the <a href=\"https://raw.githubusercontent.com/google/langextract/main/examples/custom_provider_plugin/\">Custom Provider Plugin Example</a>.</p> \n<h2>Contributing</h2> \n<p>Contributions are welcome! See <a href=\"https://github.com/google/langextract/raw/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> to get started with development, testing, and pull requests. You must sign a <a href=\"https://cla.developers.google.com/about\">Contributor License Agreement</a> before submitting patches.</p> \n<h2>Testing</h2> \n<p>To run tests locally from the source:</p> \n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/google/langextract.git\ncd langextract\n\n# Install with test dependencies\npip install -e \".[test]\"\n\n# Run all tests\npytest tests\n</code></pre> \n<p>Or reproduce the full CI matrix locally with tox:</p> \n<pre><code class=\"language-bash\">tox  # runs pylint + pytest on Python 3.10 and 3.11\n</code></pre> \n<h3>Ollama Integration Testing</h3> \n<p>If you have Ollama installed locally, you can run integration tests:</p> \n<pre><code class=\"language-bash\"># Test Ollama integration (requires Ollama running with gemma2:2b model)\ntox -e ollama-integration\n</code></pre> \n<p>This test will automatically detect if Ollama is available and run real inference tests.</p> \n<h2>Development</h2> \n<h3>Code Formatting</h3> \n<p>This project uses automated formatting tools to maintain consistent code style:</p> \n<pre><code class=\"language-bash\"># Auto-format all code\n./autoformat.sh\n\n# Or run formatters separately\nisort langextract tests --profile google --line-length 80\npyink langextract tests --config pyproject.toml\n</code></pre> \n<h3>Pre-commit Hooks</h3> \n<p>For automatic formatting checks:</p> \n<pre><code class=\"language-bash\">pre-commit install  # One-time setup\npre-commit run --all-files  # Manual run\n</code></pre> \n<h3>Linting</h3> \n<p>Run linting before submitting PRs:</p> \n<pre><code class=\"language-bash\">pylint --rcfile=.pylintrc langextract tests\n</code></pre> \n<p>See <a href=\"https://raw.githubusercontent.com/google/langextract/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for full development guidelines.</p> \n<h2>Disclaimer</h2> \n<p>This is not an officially supported Google product. If you use LangExtract in production or publications, please cite accordingly and acknowledge usage. Use is subject to the <a href=\"https://github.com/google/langextract/raw/main/LICENSE\">Apache 2.0 License</a>. For health-related applications, use of LangExtract is also subject to the <a href=\"https://developers.google.com/health-ai-developer-foundations/terms\">Health AI Developer Foundations Terms of Use</a>.</p> \n<hr /> \n<p><strong>Happy Extracting!</strong></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:13.294337Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 11.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/alirezarezvani/claude-skills",
        "title": "alirezarezvani/claude-skills",
        "summary": "<p>A Collection of Skills for Claude Code and Claude AI for real-world Usage. Including Claude Code Subagents, Claude Code Commnads</p><hr /><h1>Claude Skills Library by nginity (Your Agentic Startup Kit)</h1> \n<p><strong>Production-Ready skill packages for Claude AI &amp; Claude Code</strong> - Reusable expertise bundles combining best practices, analysis tools, and strategic frameworks for marketing teams, executive leadership, product development, your web and mobile engineering teams. Many other teams will be included soon and regularly.</p> \n<p><a href=\"https://opensource.org/licenses/MIT\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true\" /></a> <a href=\"https://claude.ai\"><img alt=\"Claude AI\" src=\"https://img.shields.io/badge/Claude-AI-blue.svg?sanitize=true\" /></a> <a href=\"https://claude.ai/code\"><img alt=\"Claude Code\" src=\"https://img.shields.io/badge/Claude-Code-purple.svg?sanitize=true\" /></a> <a href=\"https://github.com/skillcreatorai/Ai-Agent-Skills\"><img alt=\"Multi-Agent Compatible\" src=\"https://img.shields.io/badge/Multi--Agent-Compatible-green.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-available-skills\"><img alt=\"48 Skills\" src=\"https://img.shields.io/badge/Skills-48-brightgreen.svg?sanitize=true\" /></a></p> \n<hr /> \n<h2>⚡ Quick Install</h2> \n<p><strong>Two installation methods available</strong> - choose based on your needs:</p> \n<h3>Method 1: Claude Code Native (Recommended for Claude Code users)</h3> \n<p>Use Claude Code's built-in plugin system for native integration:</p> \n<pre><code class=\"language-bash\"># In Claude Code, run:\n/plugin marketplace add alirezarezvani/claude-skills\n\n# Then install skill bundles:\n/plugin install marketing-skills@claude-code-skills     # 5 marketing skills\n/plugin install engineering-skills@claude-code-skills   # 18 engineering skills\n/plugin install product-skills@claude-code-skills       # 5 product skills\n/plugin install c-level-skills@claude-code-skills       # 2 C-level advisory skills\n/plugin install pm-skills@claude-code-skills            # 6 project management skills\n/plugin install ra-qm-skills@claude-code-skills         # 12 regulatory/quality skills\n\n# Or install individual skills:\n/plugin install content-creator@claude-code-skills      # Single skill\n/plugin install fullstack-engineer@claude-code-skills   # Single skill\n</code></pre> \n<p><strong>Benefits:</strong></p> \n<ul> \n <li>✅ Native Claude Code integration</li> \n <li>✅ Automatic updates with <code>/plugin update</code></li> \n <li>✅ Version management with git tags</li> \n <li>✅ Skills available in <code>~/.claude/skills/</code></li> \n</ul> \n<hr /> \n<h3>Method 2: Universal Installer (Works across all agents)</h3> \n<p>Install to Claude Code, Cursor, VS Code, Amp, Goose, and more - all with one command:</p> \n<pre><code class=\"language-bash\"># Install all 48 skills to all supported agents\nnpx ai-agent-skills install alirezarezvani/claude-skills\n\n# Install to specific agent (Claude Code)\nnpx ai-agent-skills install alirezarezvani/claude-skills --agent claude\n\n# Install single skill\nnpx ai-agent-skills install alirezarezvani/claude-skills/marketing-skill/content-creator\n\n# Install to Cursor\nnpx ai-agent-skills install alirezarezvani/claude-skills --agent cursor\n\n# Preview before installing\nnpx ai-agent-skills install alirezarezvani/claude-skills --dry-run\n</code></pre> \n<p><strong>Benefits:</strong></p> \n<ul> \n <li>✅ Works across 9+ AI agents simultaneously</li> \n <li>✅ One command installs to all agents</li> \n <li>✅ No agent-specific configuration needed</li> \n</ul> \n<p><strong>Supported Agents:</strong> Claude Code, Cursor, VS Code, Copilot, Goose, Amp, Codex, Letta, OpenCode</p> \n<p><strong>Installation Locations:</strong></p> \n<ul> \n <li>Claude Code: <code>~/.claude/skills/</code></li> \n <li>Cursor: <code>.cursor/skills/</code></li> \n <li>VS Code/Copilot: <code>.github/skills/</code></li> \n <li>Goose: <code>~/.config/goose/skills/</code></li> \n <li>Project-specific: <code>.skills/</code></li> \n</ul> \n<hr /> \n<p><strong>Detailed Installation Guide:</strong> See <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/INSTALLATION.md\">INSTALLATION.md</a> for complete instructions, troubleshooting, and manual installation.</p> \n<hr /> \n<h2>📚 Table of Contents</h2> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-quick-install-universal-installer\">Quick Install (Universal Installer)</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-overview\">Overview</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-available-skills\">Available Skills</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-quick-start\">Quick Start</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-how-to-use-with-claude-ai\">How to Use with Claude AI</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-how-to-use-with-claude-code\">How to Use with Claude Code</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-skill-architecture\">Skill Architecture</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-installation\">Installation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-usage-examples\">Usage Examples</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-roadmap\">Roadmap</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-contributing\">Contributing</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-license\">License</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/#-author\">Author</a></li> \n</ul> \n<hr /> \n<h2>🎯 Overview</h2> \n<p>This repository provides <strong>modular, self-contained skill packages</strong> designed to augment Claude AI with specialized domain expertise. Each skill includes:</p> \n<ul> \n <li><strong>📖 Comprehensive documentation</strong> - Workflows, best practices, and strategic frameworks</li> \n <li><strong>🛠️ Python analysis tools</strong> - 68+ CLI utilities for automated analysis and optimization</li> \n <li><strong>📚 Knowledge bases</strong> - Curated reference materials and guidelines</li> \n <li><strong>📋 Ready-to-use templates</strong> - Customizable assets for immediate deployment</li> \n</ul> \n<p><strong>Key Benefits:</strong></p> \n<ul> \n <li>⚡ <strong>Immediate deployment</strong> - Download and use in minutes</li> \n <li>🎯 <strong>Domain expertise</strong> - Battle-tested frameworks from industry experts</li> \n <li>🔧 <strong>Practical tools</strong> - Algorithmic analysis without external API dependencies</li> \n <li>📈 <strong>Measurable ROI</strong> - 40%+ time savings, 30%+ quality improvements</li> \n</ul> \n<hr /> \n<h2>🚀 Available Skills</h2> \n<h3>Marketing Skills</h3> \n<p><strong>5 comprehensive marketing skills</strong> covering content creation, demand generation, product marketing strategy, mobile app optimization, and social media analytics.</p> \n<h4>📝 Content Creator</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Professional-grade brand voice analysis, SEO optimization, and platform-specific content frameworks.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Brand Voice Analyzer</strong> - Analyze text for tone, formality, and readability (Python CLI)</li> \n <li><strong>SEO Optimizer</strong> - Comprehensive SEO scoring and optimization recommendations (Python CLI)</li> \n <li><strong>Brand Guidelines</strong> - 5 personality archetypes and voice framework</li> \n <li><strong>Content Frameworks</strong> - 15+ templates (blog posts, emails, social media, video scripts)</li> \n <li><strong>Social Media Optimization</strong> - Platform-specific guides for LinkedIn, Twitter/X, Instagram, Facebook, TikTok</li> \n <li><strong>Content Calendar Template</strong> - Monthly planning and distribution framework</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/content-creator/SKILL.md\">marketing-skill/content-creator/SKILL.md</a></p> \n<hr /> \n<h4>🎯 Marketing Demand &amp; Acquisition</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Expert demand generation, paid media, SEO, and partnerships for Series A+ startups.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>CAC Calculator</strong> - Calculate channel-specific and blended customer acquisition cost (Python CLI)</li> \n <li><strong>Full-Funnel Strategy</strong> - TOFU → MOFU → BOFU frameworks</li> \n <li><strong>Channel Playbooks</strong> - LinkedIn Ads, Google Ads, Meta, SEO, Partnerships</li> \n <li><strong>HubSpot Integration</strong> - Campaign tracking, attribution, lead scoring</li> \n <li><strong>International Expansion</strong> - EU vs US vs Canada tactics</li> \n <li><strong>Performance Benchmarks</strong> - B2B SaaS CAC and conversion benchmarks</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/marketing-demand-acquisition/SKILL.md\">marketing-skill/marketing-demand-acquisition/SKILL.md</a></p> \n<hr /> \n<h4>🚀 Marketing Strategy &amp; Product Marketing</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Product marketing, positioning, GTM strategy, and competitive intelligence.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>ICP Definition</strong> - Firmographics and psychographics frameworks</li> \n <li><strong>Positioning</strong> - April Dunford positioning methodology</li> \n <li><strong>GTM Strategy</strong> - PLG, Sales-Led, and Hybrid motion playbooks</li> \n <li><strong>Launch Plans</strong> - 90-day product launch frameworks (Tier 1/2/3)</li> \n <li><strong>Competitive Intelligence</strong> - Battlecard templates and analysis frameworks</li> \n <li><strong>International Market Entry</strong> - 5-phase market expansion playbooks</li> \n <li><strong>Sales Enablement</strong> - Training programs and asset development</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/marketing-strategy-pmm/SKILL.md\">marketing-skill/marketing-strategy-pmm/SKILL.md</a></p> \n<hr /> \n<h4>📱 App Store Optimization (ASO)</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Complete ASO toolkit for Apple App Store and Google Play Store optimization.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Keyword Research</strong> - Volume, competition, and relevance analysis frameworks</li> \n <li><strong>Metadata Optimization</strong> - Platform-specific title, description, and keyword optimization</li> \n <li><strong>Conversion Optimization</strong> - A/B testing frameworks and visual asset testing strategies</li> \n <li><strong>Rating &amp; Review Management</strong> - Review monitoring, response templates, sentiment analysis</li> \n <li><strong>Launch Strategies</strong> - Pre-launch checklists, timing optimization, soft launch tactics</li> \n <li><strong>Analytics Tracking</strong> - ASO score calculation, performance benchmarking, competitor tracking</li> \n <li><strong>Platform Support</strong> - Apple App Store (30 char title) and Google Play Store (50 char title)</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/app-store-optimization/SKILL.md\">marketing-skill/app-store-optimization/SKILL.md</a></p> \n<hr /> \n<h4>📊 Social Media Analyzer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Analyze social media campaign performance across platforms with data-driven insights and ROI tracking.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Campaign Metrics Calculator</strong> - Engagement rate, reach, impressions, CTR calculations (Python CLI)</li> \n <li><strong>Performance Analyzer</strong> - ROI analysis and optimization recommendations (Python CLI)</li> \n <li><strong>Multi-Platform Support</strong> - Facebook, Instagram, Twitter/X, LinkedIn, TikTok best practices</li> \n <li><strong>Audience Insights</strong> - Demographics, peak engagement times, content performance patterns</li> \n <li><strong>Trend Detection</strong> - High-performing content types, hashtag analysis, posting patterns</li> \n <li><strong>Competitive Benchmarking</strong> - Industry standard comparisons and gap analysis</li> \n <li><strong>ROI Analysis</strong> - Cost per engagement, campaign effectiveness measurement</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/social-media-analyzer/SKILL.md\">marketing-skill/social-media-analyzer/SKILL.md</a></p> \n<hr /> \n<h3>C-Level Advisory Skills</h3> \n<h4>👔 CEO Advisor</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Executive leadership guidance for strategic decision-making, organizational development, and stakeholder management.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Strategy Analyzer</strong> - Evaluate strategic initiatives and competitive positioning (Python CLI)</li> \n <li><strong>Financial Scenario Analyzer</strong> - Model financial scenarios and business outcomes (Python CLI)</li> \n <li><strong>Executive Decision Framework</strong> - Structured decision-making methodology</li> \n <li><strong>Leadership &amp; Organizational Culture</strong> - Culture building and change management</li> \n <li><strong>Board Governance &amp; Investor Relations</strong> - Stakeholder communication best practices</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Strategic planning and initiative evaluation</li> \n <li>Financial scenario modeling</li> \n <li>Board and investor communication</li> \n <li>Organizational culture development</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/c-level-advisor/ceo-advisor/SKILL.md\">c-level-advisor/ceo-advisor/SKILL.md</a></p> \n<hr /> \n<h4>💻 CTO Advisor</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Technical leadership guidance for engineering teams, architecture decisions, and technology strategy.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Tech Debt Analyzer</strong> - Quantify and prioritize technical debt (Python CLI)</li> \n <li><strong>Team Scaling Calculator</strong> - Model engineering team growth and structure (Python CLI)</li> \n <li><strong>Engineering Metrics Framework</strong> - DORA metrics, velocity, and quality indicators</li> \n <li><strong>Technology Evaluation Framework</strong> - Structured approach to technology selection</li> \n <li><strong>Architecture Decision Records</strong> - ADR templates and best practices</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Technical debt assessment and management</li> \n <li>Engineering team scaling and structure</li> \n <li>Technology evaluation and selection</li> \n <li>Architecture decision documentation</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/c-level-advisor/cto-advisor/SKILL.md\">c-level-advisor/cto-advisor/SKILL.md</a></p> \n<hr /> \n<h3>Product Team Skills</h3> \n<h4>📊 Product Manager Toolkit</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Essential tools and frameworks for modern product management, from discovery to delivery.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>RICE Prioritizer</strong> - Automated feature prioritization with portfolio analysis (Python CLI)</li> \n <li><strong>Customer Interview Analyzer</strong> - AI-powered insight extraction from user interviews (Python CLI)</li> \n <li><strong>PRD Templates</strong> - 4 comprehensive formats (Standard, One-Page, Agile Epic, Feature Brief)</li> \n <li><strong>Discovery Frameworks</strong> - Customer interview guides, hypothesis templates, opportunity solution trees</li> \n <li><strong>Metrics &amp; Analytics</strong> - North Star metrics, funnel analysis, feature success tracking</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Feature prioritization with RICE scoring</li> \n <li>Customer discovery and interview analysis</li> \n <li>PRD development and stakeholder alignment</li> \n <li>Product metrics and success measurement</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/product-manager-toolkit/SKILL.md\">product-team/product-manager-toolkit/SKILL.md</a></p> \n<hr /> \n<h4>🎯 Agile Product Owner</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Sprint execution and backlog management tools for agile product delivery.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>User Story Generator</strong> - INVEST-compliant stories with acceptance criteria (Python CLI)</li> \n <li><strong>Sprint Planner</strong> - Capacity-based sprint planning automation</li> \n <li><strong>Epic Breakdown</strong> - Automatic story generation from epics</li> \n <li><strong>Velocity Tracker</strong> - Sprint metrics and burndown analysis</li> \n <li><strong>Agile Ceremonies</strong> - Frameworks for standups, retros, planning, reviews</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Backlog refinement and grooming</li> \n <li>Sprint planning and capacity allocation</li> \n <li>User story writing and acceptance criteria</li> \n <li>Sprint execution and velocity tracking</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/agile-product-owner/SKILL.md\">product-team/agile-product-owner/SKILL.md</a></p> \n<hr /> \n<h4>🚀 Product Strategist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Strategic planning and vision alignment for heads of product and product leaders.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>OKR Cascade Generator</strong> - Automated company → product → team goal alignment (Python CLI)</li> \n <li><strong>Alignment Scoring</strong> - Vertical and horizontal OKR alignment measurement</li> \n <li><strong>Strategy Templates</strong> - Growth, retention, revenue, and innovation frameworks</li> \n <li><strong>Team Scaling Tools</strong> - Organizational design and structure planning</li> \n <li><strong>Vision Frameworks</strong> - Product vision, positioning, and roadmap development</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Strategic planning and OKR setting</li> \n <li>Product vision and positioning</li> \n <li>Roadmap development and communication</li> \n <li>Team organization and scaling</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/product-strategist/SKILL.md\">product-team/product-strategist/SKILL.md</a></p> \n<hr /> \n<h4>🎨 UX Researcher Designer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>User research and experience design frameworks for creating user-centered products.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Persona Generator</strong> - Data-driven persona creation from user research (Python CLI)</li> \n <li><strong>Journey Mapper</strong> - Customer journey visualization and mapping</li> \n <li><strong>Research Synthesizer</strong> - Pattern identification from user interviews</li> \n <li><strong>Usability Framework</strong> - Testing protocols and heuristic evaluation</li> \n <li><strong>Design Thinking</strong> - Double diamond process, workshops, and facilitation</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>User research planning and execution</li> \n <li>Research synthesis and insight generation</li> \n <li>Persona development and validation</li> \n <li>Journey mapping and experience design</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/ux-researcher-designer/SKILL.md\">product-team/ux-researcher-designer/SKILL.md</a></p> \n<hr /> \n<h4>🎨 UI Design System</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Visual design systems and component architecture for consistent user interfaces.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Design Token Generator</strong> - Complete token system from brand colors (Python CLI)</li> \n <li><strong>Component Architecture</strong> - Atomic design implementation and organization</li> \n <li><strong>Responsive Calculator</strong> - Breakpoint and grid system generation</li> \n <li><strong>Export Formats</strong> - JSON, CSS, SCSS outputs for development handoff</li> \n <li><strong>Documentation Templates</strong> - Storybook integration and component specs</li> \n</ul> \n<p><strong>Core Workflows:</strong></p> \n<ol> \n <li>Design token system creation</li> \n <li>Component library architecture</li> \n <li>Design system documentation</li> \n <li>Developer handoff and implementation</li> \n</ol> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/ui-design-system/SKILL.md\">product-team/ui-design-system/SKILL.md</a></p> \n<hr /> \n<h3>Project Management Team Skills</h3> \n<p><strong>6 world-class Atlassian expert skills</strong> for project and agile delivery teams using Jira and Confluence.</p> \n<h4>📋 Senior Project Management Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Strategic project management for software, SaaS, and digital applications.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>Portfolio management and strategic planning</li> \n <li>Stakeholder alignment and executive reporting</li> \n <li>Risk management and budget oversight</li> \n <li>Cross-functional team leadership</li> \n <li>Roadmap development and project charters</li> \n <li>Atlassian MCP integration for metrics and reporting</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h4>🏃 Scrum Master Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Agile facilitation for software development teams.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>Sprint planning and execution</li> \n <li>Daily standups and retrospectives</li> \n <li>Backlog refinement and grooming</li> \n <li>Velocity tracking and metrics</li> \n <li>Impediment removal and escalation</li> \n <li>Team coaching on agile practices</li> \n <li>Atlassian MCP integration for sprint management</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h4>⚙️ Atlassian Jira Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Jira configuration, JQL mastery, and technical operations.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>Advanced JQL query writing</li> \n <li>Project and workflow configuration</li> \n <li>Custom fields and automation rules</li> \n <li>Dashboards and reporting</li> \n <li>Integration setup and optimization</li> \n <li>Performance tuning</li> \n <li>Atlassian MCP integration for all Jira operations</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h4>📚 Atlassian Confluence Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Knowledge management and documentation architecture.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>Space architecture and organization</li> \n <li>Page templates and macro implementation</li> \n <li>Documentation strategy and governance</li> \n <li>Content collaboration workflows</li> \n <li>Jira integration and linking</li> \n <li>Search optimization and findability</li> \n <li>Atlassian MCP integration for documentation</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h4>🔧 Atlassian Administrator</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>System administration for Atlassian suite.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>User provisioning and access management</li> \n <li>Global configuration and governance</li> \n <li>Security and compliance setup</li> \n <li>SSO and integration deployment</li> \n <li>Performance optimization</li> \n <li>Disaster recovery and license management</li> \n <li>Atlassian MCP integration for system administration</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h4>📄 Atlassian Template Creator Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Template and file creation/modification specialist.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li>Confluence page template design (15+ templates)</li> \n <li>Jira issue template creation</li> \n <li>Blueprint development for complex structures</li> \n <li>Standardized content and governance</li> \n <li>Dynamic content and automation</li> \n <li>Template lifecycle management</li> \n <li>Atlassian MCP integration for template deployment</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>project-management/README.md</code> for details</p> \n<hr /> \n<h3>Engineering Team Skills</h3> \n<p><strong>Complete engineering skills suite with 13 specialized roles</strong> covering architecture, development, testing, security, operations, cloud infrastructure, and enterprise systems.</p> \n<h4>🏗️ Senior Software Architect</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>System architecture design, technology stack decisions, and architecture documentation.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Architecture Diagram Generator</strong> - Create C4, sequence, and component diagrams (Python CLI)</li> \n <li><strong>Project Architect</strong> - Scaffold architecture documentation and ADRs (Python CLI)</li> \n <li><strong>Dependency Analyzer</strong> - Analyze and visualize dependencies (Python CLI)</li> \n <li><strong>Architecture Patterns</strong> - Monolithic, microservices, serverless, event-driven patterns</li> \n <li><strong>System Design Workflows</strong> - Step-by-step architecture design process</li> \n <li><strong>Tech Decision Guide</strong> - Framework for technology stack selection</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>⚛️ Senior Frontend Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Frontend development with React, Next.js, and TypeScript.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Component Generator</strong> - Scaffold React components with TypeScript (Python CLI)</li> \n <li><strong>Bundle Analyzer</strong> - Optimize bundle size and performance (Python CLI)</li> \n <li><strong>Frontend Scaffolder</strong> - Complete frontend project setup (Python CLI)</li> \n <li><strong>React Patterns</strong> - Component composition, hooks, state management</li> \n <li><strong>Next.js Optimization</strong> - App Router, Server Components, performance tuning</li> \n <li><strong>Frontend Best Practices</strong> - Accessibility, SEO, performance optimization</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🔧 Senior Backend Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Backend development with Node.js, Express, GraphQL, Go, and Python.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>API Scaffolder</strong> - Generate REST and GraphQL endpoints (Python CLI)</li> \n <li><strong>Database Migration Tool</strong> - Manage PostgreSQL migrations (Python CLI)</li> \n <li><strong>API Load Tester</strong> - Performance testing and optimization (Python CLI)</li> \n <li><strong>API Design Patterns</strong> - RESTful, GraphQL, microservices architecture</li> \n <li><strong>Database Optimization</strong> - Query optimization, indexing, connection pooling</li> \n <li><strong>Backend Security</strong> - Authentication, authorization, data validation</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>💻 Senior Fullstack Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>End-to-end application development with complete stack integration.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Fullstack Scaffolder</strong> - Complete Next.js + GraphQL + PostgreSQL projects (Python CLI)</li> \n <li><strong>Project Scaffolder</strong> - Production-ready project structure (Python CLI)</li> \n <li><strong>Code Quality Analyzer</strong> - Comprehensive analysis and security scanning (Python CLI)</li> \n <li><strong>Tech Stack Guide</strong> - Complete implementation guides for your stack</li> \n <li><strong>Architecture Patterns</strong> - Full-stack system design and integration</li> \n <li><strong>Development Workflows</strong> - Git, CI/CD, testing, deployment automation</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/fullstack-engineer/SKILL.md\">engineering-team/fullstack-engineer/SKILL.md</a></p> \n<hr /> \n<h4>🧪 Senior QA Testing Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Quality assurance and test automation for comprehensive testing strategies.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Test Suite Generator</strong> - Create unit, integration, E2E tests (Python CLI)</li> \n <li><strong>Coverage Analyzer</strong> - Analyze and report test coverage (Python CLI)</li> \n <li><strong>E2E Test Scaffolder</strong> - Setup Playwright/Cypress tests (Python CLI)</li> \n <li><strong>Testing Strategies</strong> - Testing pyramid, TDD, BDD methodologies</li> \n <li><strong>Test Automation Patterns</strong> - Page objects, fixtures, mocking strategies</li> \n <li><strong>QA Best Practices</strong> - Quality metrics, regression testing, performance testing</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🚀 Senior DevOps Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>CI/CD automation, infrastructure as code, and deployment management.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Pipeline Generator</strong> - Create GitHub Actions/CircleCI pipelines (Python CLI)</li> \n <li><strong>Terraform Scaffolder</strong> - Generate infrastructure as code (Python CLI)</li> \n <li><strong>Deployment Manager</strong> - Automate deployment workflows (Python CLI)</li> \n <li><strong>CI/CD Pipeline Guide</strong> - Best practices for continuous integration/deployment</li> \n <li><strong>Infrastructure as Code</strong> - Terraform, CloudFormation, Kubernetes</li> \n <li><strong>Deployment Strategies</strong> - Blue-green, canary, rolling deployments</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🛡️ Senior SecOps Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Security operations, vulnerability management, and compliance automation.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Security Scanner</strong> - Automated vulnerability scanning (Python CLI)</li> \n <li><strong>Vulnerability Assessor</strong> - Risk assessment and prioritization (Python CLI)</li> \n <li><strong>Compliance Checker</strong> - GDPR, SOC2 compliance validation (Python CLI)</li> \n <li><strong>Security Standards</strong> - OWASP Top 10, security best practices</li> \n <li><strong>Vulnerability Management</strong> - Detection, assessment, remediation workflows</li> \n <li><strong>Compliance Requirements</strong> - Compliance frameworks and automation</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>👁️ Code Reviewer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Automated code review, quality checking, and PR analysis.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>PR Analyzer</strong> - Automated pull request analysis (Python CLI)</li> \n <li><strong>Code Quality Checker</strong> - Quality metrics and scoring (Python CLI)</li> \n <li><strong>Review Report Generator</strong> - Generate comprehensive review reports (Python CLI)</li> \n <li><strong>Code Review Checklist</strong> - Comprehensive review standards</li> \n <li><strong>Coding Standards</strong> - Language-specific conventions and best practices</li> \n <li><strong>Common Anti-patterns</strong> - What to avoid and how to fix</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🔐 Senior Security Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Security architecture, penetration testing, and cryptography implementation.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Threat Modeler</strong> - Automated threat modeling (Python CLI)</li> \n <li><strong>Security Auditor</strong> - Comprehensive security audits (Python CLI)</li> \n <li><strong>Pentest Automator</strong> - Automated penetration testing (Python CLI)</li> \n <li><strong>Security Architecture Patterns</strong> - Zero Trust, defense in depth, secure design</li> \n <li><strong>Penetration Testing Guide</strong> - Testing methodologies and tools</li> \n <li><strong>Cryptography Implementation</strong> - Encryption, hashing, secure communication</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>☁️ AWS Solution Architect</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Expert AWS solution architecture for startups with serverless and cost-optimized design.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Architecture Designer</strong> - Generate architecture patterns and service recommendations (Python CLI)</li> \n <li><strong>Serverless Stack Builder</strong> - Create Lambda, API Gateway, DynamoDB stacks (Python CLI)</li> \n <li><strong>Cost Optimizer</strong> - AWS cost analysis and optimization strategies (Python CLI)</li> \n <li><strong>IaC Generator</strong> - CloudFormation, CDK, Terraform template generation (Python CLI)</li> \n <li><strong>Security Auditor</strong> - AWS security validation and compliance checks (Python CLI)</li> \n <li><strong>Serverless Patterns</strong> - Lambda, API Gateway, DynamoDB, Step Functions, EventBridge</li> \n <li><strong>Event-Driven Architecture</strong> - Microservices with SQS, SNS, Kinesis</li> \n <li><strong>Container Orchestration</strong> - ECS Fargate, EKS best practices</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/aws-solution-architect/SKILL.md\">engineering-team/aws-solution-architect/SKILL.md</a></p> \n<hr /> \n<h4>🏢 Microsoft 365 Tenant Manager</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Comprehensive Microsoft 365 administration for Global Administrators and IT teams.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Tenant Setup Tool</strong> - Initial configuration automation (Python CLI)</li> \n <li><strong>User Management</strong> - Lifecycle operations and bulk provisioning (Python CLI)</li> \n <li><strong>Security Policies</strong> - Conditional Access, MFA, DLP configuration (Python CLI)</li> \n <li><strong>Reporting Suite</strong> - Analytics, audit logs, compliance reports (Python CLI)</li> \n <li><strong>PowerShell Generator</strong> - Microsoft Graph API script generation (Python CLI)</li> \n <li><strong>SharePoint &amp; Teams</strong> - Site provisioning, Teams policy management</li> \n <li><strong>Exchange Online</strong> - Mailbox management, mail flow rules, transport security</li> \n <li><strong>License Management</strong> - Allocation, optimization, cost analysis</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/ms365-tenant-manager/SKILL.md\">engineering-team/ms365-tenant-manager/SKILL.md</a></p> \n<hr /> \n<h4>🧪 TDD Guide</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Comprehensive Test-Driven Development guide with intelligent test generation and coverage analysis.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Test Generation</strong> - Convert requirements, user stories, and API specs to executable tests</li> \n <li><strong>Coverage Analysis</strong> - Parse LCOV, JSON, XML coverage reports with gap identification</li> \n <li><strong>Framework Support</strong> - Jest, Pytest, JUnit, Vitest, Mocha, RSpec with auto-detection</li> \n <li><strong>Quality Review</strong> - Test isolation, assertions, naming conventions, complexity analysis</li> \n <li><strong>Missing Scenarios</strong> - Identify untested edge cases and error conditions</li> \n <li><strong>Red-Green-Refactor</strong> - Step-by-step TDD cycle guidance with best practices</li> \n <li><strong>Metrics Dashboard</strong> - Coverage, complexity, quality scores, execution timing</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/tdd-guide/SKILL.md\">engineering-team/tdd-guide/SKILL.md</a></p> \n<hr /> \n<h4>🔍 Tech Stack Evaluator</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Comprehensive technology evaluation with TCO analysis, security assessment, and migration planning.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Technology Comparison</strong> - Head-to-head framework and tool comparisons with scoring</li> \n <li><strong>Stack Evaluation</strong> - Complete stack assessment for specific use cases (e.g., e-commerce, SaaS)</li> \n <li><strong>TCO Calculator</strong> - Licensing, hosting, developer productivity, and maintenance costs</li> \n <li><strong>Security Assessment</strong> - Vulnerability analysis, update frequency, compliance readiness</li> \n <li><strong>Migration Analyzer</strong> - Legacy to modern migration complexity, risks, and timeline estimation</li> \n <li><strong>Cloud Comparison</strong> - AWS vs Azure vs GCP for specific workloads with cost projections</li> \n <li><strong>Decision Reports</strong> - Matrices with pros/cons, confidence scores, and actionable recommendations</li> \n</ul> \n<p><strong>Learn More:</strong> <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/tech-stack-evaluator/SKILL.md\">engineering-team/tech-stack-evaluator/SKILL.md</a></p> \n<hr /> \n<h3>AI/ML/Data Team Skills</h3> \n<p><strong>5 specialized AI/ML and data engineering skills</strong> for building modern data-driven and AI-powered products.</p> \n<h4>📊 Senior Data Scientist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Statistical modeling, experimentation, and business analytics.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Experiment Designer</strong> - Design A/B tests and statistical experiments (Python CLI)</li> \n <li><strong>Feature Engineering Pipeline</strong> - Automated feature engineering workflows (Python CLI)</li> \n <li><strong>Statistical Analyzer</strong> - Statistical modeling and causal inference (Python CLI)</li> \n <li><strong>Statistical Methods</strong> - Hypothesis testing, regression, time series, causal inference</li> \n <li><strong>Experimentation Framework</strong> - A/B testing, multi-armed bandits, Bayesian optimization</li> \n <li><strong>Analytics Patterns</strong> - Business metrics, dashboards, reporting</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🔧 Senior Data Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Data pipeline engineering, ETL/ELT workflows, and data infrastructure.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Pipeline Orchestrator</strong> - Build data pipelines with Airflow/Spark (Python CLI)</li> \n <li><strong>Data Quality Validator</strong> - Data quality checks and monitoring (Python CLI)</li> \n <li><strong>ETL Generator</strong> - Generate ETL/ELT workflows (Python CLI)</li> \n <li><strong>Data Pipeline Patterns</strong> - Batch, streaming, lambda architecture</li> \n <li><strong>Data Quality Framework</strong> - Validation, monitoring, lineage tracking</li> \n <li><strong>Data Modeling Guide</strong> - Dimensional modeling, data vault, schema design</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>🤖 Senior ML/AI Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>MLOps, model deployment, and LLM integration for production AI systems.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Model Deployment Pipeline</strong> - Deploy ML models to production (Python CLI)</li> \n <li><strong>MLOps Setup Tool</strong> - Setup MLOps infrastructure with MLflow (Python CLI)</li> \n <li><strong>LLM Integration Builder</strong> - Integrate LLMs into applications (Python CLI)</li> \n <li><strong>MLOps Production Patterns</strong> - Model versioning, monitoring, A/B testing</li> \n <li><strong>LLM Integration Guide</strong> - RAG, fine-tuning, prompt engineering</li> \n <li><strong>Model Deployment Strategies</strong> - Serving, scaling, monitoring</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>💬 Senior Prompt Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>LLM optimization, RAG systems, and agentic AI development.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Prompt Optimizer</strong> - Optimize prompts for better LLM responses (Python CLI)</li> \n <li><strong>RAG System Builder</strong> - Build Retrieval Augmented Generation systems (Python CLI)</li> \n <li><strong>Agent Orchestrator</strong> - Design and orchestrate AI agents (Python CLI)</li> \n <li><strong>Advanced Prompting Techniques</strong> - Chain-of-thought, few-shot, meta-prompting</li> \n <li><strong>RAG Architecture Patterns</strong> - Vector search, chunking, reranking</li> \n <li><strong>Agent Design Patterns</strong> - ReAct, tool use, multi-agent systems</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h4>👁️ Senior Computer Vision Engineer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Computer vision, image/video AI, and real-time visual inference.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Vision Model Trainer</strong> - Train object detection and segmentation models (Python CLI)</li> \n <li><strong>Inference Optimizer</strong> - Optimize vision model inference (Python CLI)</li> \n <li><strong>Video Processor</strong> - Process and analyze video streams (Python CLI)</li> \n <li><strong>Vision Architecture Patterns</strong> - Object detection, segmentation, classification</li> \n <li><strong>Real-time Inference Guide</strong> - Edge deployment, optimization, latency reduction</li> \n <li><strong>Computer Vision Production</strong> - Model serving, monitoring, data pipelines</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>engineering-team/README.md</code> for details</p> \n<hr /> \n<h3>Regulatory Affairs &amp; Quality Management Team Skills</h3> \n<p><strong>12 world-class expert skills</strong> for HealthTech and MedTech organizations covering regulatory compliance, quality systems, risk management, security, and audit excellence.</p> \n<h4>📋 Senior Regulatory Affairs Manager (Head of RA)</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Strategic regulatory leadership and cross-functional coordination for market access.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Regulatory Pathway Analyzer</strong> - Analyze optimal regulatory routes (Python CLI)</li> \n <li><strong>Submission Timeline Tracker</strong> - Track submission progress and milestones (Python CLI)</li> \n <li><strong>Regulatory Intelligence Monitor</strong> - Monitor global regulatory changes (Python CLI)</li> \n <li><strong>EU MDR Submission Guide</strong> - Complete MDR submission process</li> \n <li><strong>FDA Submission Guide</strong> - FDA pathways (510k, PMA, De Novo)</li> \n <li><strong>Global Regulatory Pathways</strong> - International frameworks</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>⭐ Senior Quality Manager Responsible Person (QMR)</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Overall quality system responsibility and regulatory compliance oversight.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>QMS Effectiveness Monitor</strong> - Monitor QMS performance metrics (Python CLI)</li> \n <li><strong>Compliance Dashboard Generator</strong> - Generate compliance reports (Python CLI)</li> \n <li><strong>Management Review Analyzer</strong> - Analyze management review data (Python CLI)</li> \n <li><strong>QMR Responsibilities Framework</strong> - Complete role definition</li> \n <li><strong>Quality Leadership Guide</strong> - Strategic quality management</li> \n <li><strong>Management Review Procedures</strong> - Effective management reviews</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>📊 Senior Quality Manager - QMS ISO 13485 Specialist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>ISO 13485 QMS implementation, maintenance, and optimization.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>QMS Compliance Checker</strong> - Check ISO 13485 compliance (Python CLI)</li> \n <li><strong>Design Control Tracker</strong> - Track design control activities (Python CLI)</li> \n <li><strong>Document Control System</strong> - Manage controlled documents (Python CLI)</li> \n <li><strong>ISO 13485 Implementation</strong> - Complete implementation guide</li> \n <li><strong>Design Controls Handbook</strong> - Best practices</li> \n <li><strong>Internal Audit Program</strong> - Audit planning and execution</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🔄 Senior CAPA Officer</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Corrective and preventive action management within QMS.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>CAPA Tracker</strong> - Track CAPA status and effectiveness (Python CLI)</li> \n <li><strong>Root Cause Analyzer</strong> - Facilitate root cause analysis (Python CLI)</li> \n <li><strong>Trend Analysis Tool</strong> - Analyze quality trends (Python CLI)</li> \n <li><strong>CAPA Process Guide</strong> - Complete CAPA procedures</li> \n <li><strong>Root Cause Analysis Methods</strong> - 5 Whys, Fishbone, FTA</li> \n <li><strong>Effectiveness Verification</strong> - CAPA effectiveness assessment</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>📝 Senior Quality Documentation Manager</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Documentation control and review of regulatory documentation.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Document Version Control</strong> - Manage document versions (Python CLI)</li> \n <li><strong>Technical File Builder</strong> - Build regulatory technical files (Python CLI)</li> \n <li><strong>Document Compliance Checker</strong> - Verify compliance (Python CLI)</li> \n <li><strong>Document Control Procedures</strong> - Best practices</li> \n <li><strong>Technical File Requirements</strong> - Regulatory requirements</li> \n <li><strong>Change Control Process</strong> - Change management</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>⚠️ Senior Risk Management Specialist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>ISO 14971 risk management throughout product lifecycle.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Risk Register Manager</strong> - Manage product risk registers (Python CLI)</li> \n <li><strong>FMEA Calculator</strong> - Calculate risk priority numbers (Python CLI)</li> \n <li><strong>Risk Control Tracker</strong> - Track risk control effectiveness (Python CLI)</li> \n <li><strong>ISO 14971 Implementation</strong> - Complete risk management process</li> \n <li><strong>Risk Analysis Methods</strong> - FMEA, FTA, HAZOP</li> \n <li><strong>Post-Production Monitoring</strong> - Post-market risk management</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🔒 Senior Information Security Manager (ISO 27001/27002)</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>ISMS implementation and cybersecurity compliance for medical devices.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>ISMS Compliance Checker</strong> - Check ISO 27001 compliance (Python CLI)</li> \n <li><strong>Security Risk Assessor</strong> - Assess cybersecurity risks (Python CLI)</li> \n <li><strong>Vulnerability Tracker</strong> - Track security vulnerabilities (Python CLI)</li> \n <li><strong>ISO 27001 Implementation</strong> - ISMS implementation guide</li> \n <li><strong>Medical Device Cybersecurity</strong> - Device security requirements</li> \n <li><strong>Security Controls Framework</strong> - ISO 27002 controls</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🇪🇺 Senior MDR 2017/745 Specialist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>EU MDR compliance expertise and consulting.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>MDR Compliance Checker</strong> - Check MDR compliance status (Python CLI)</li> \n <li><strong>Classification Analyzer</strong> - Support device classification (Python CLI)</li> \n <li><strong>UDI Generator</strong> - Generate and validate UDI codes (Python CLI)</li> \n <li><strong>MDR Requirements Overview</strong> - Complete MDR requirements</li> \n <li><strong>Clinical Evaluation Guide</strong> - Clinical evidence requirements</li> \n <li><strong>Technical Documentation MDR</strong> - MDR technical files</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🇺🇸 Senior FDA Consultant and Specialist</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>FDA submission pathways and QSR compliance.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>FDA Submission Packager</strong> - Package FDA submissions (Python CLI)</li> \n <li><strong>QSR Compliance Checker</strong> - Check QSR compliance (Python CLI)</li> \n <li><strong>Predicate Device Analyzer</strong> - Analyze substantial equivalence (Python CLI)</li> \n <li><strong>FDA Submission Pathways</strong> - 510k, PMA, De Novo guidance</li> \n <li><strong>QSR 820 Compliance</strong> - Complete QSR requirements</li> \n <li><strong>FDA Cybersecurity Guide</strong> - FDA cybersecurity requirements</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🔍 Senior QMS Audit Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Internal and external QMS auditing expertise.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>Audit Planner</strong> - Plan and schedule QMS audits (Python CLI)</li> \n <li><strong>Finding Tracker</strong> - Track audit findings and CAPAs (Python CLI)</li> \n <li><strong>Audit Report Generator</strong> - Generate audit reports (Python CLI)</li> \n <li><strong>Audit Program Management</strong> - Planning and scheduling</li> \n <li><strong>Audit Execution Checklist</strong> - Procedures and checklists</li> \n <li><strong>Nonconformity Management</strong> - Finding and CAPA management</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🔐 Senior ISMS Audit Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>Information security management system auditing.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>ISMS Audit Planner</strong> - Plan ISO 27001 audits (Python CLI)</li> \n <li><strong>Security Controls Assessor</strong> - Assess security controls (Python CLI)</li> \n <li><strong>ISMS Finding Tracker</strong> - Track security findings (Python CLI)</li> \n <li><strong>ISO 27001 Audit Guide</strong> - ISMS audit procedures</li> \n <li><strong>Security Controls Assessment</strong> - Control testing methodologies</li> \n <li><strong>ISMS Certification Preparation</strong> - Certification readiness</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h4>🛡️ Senior GDPR/DSGVO Expert</h4> \n<p><strong>Status:</strong> ✅ Production Ready | <strong>Version:</strong> 1.0</p> \n<p>EU GDPR and German DSGVO compliance and auditing.</p> \n<p><strong>What's Included:</strong></p> \n<ul> \n <li><strong>GDPR Compliance Checker</strong> - Check GDPR compliance (Python CLI)</li> \n <li><strong>DPIA Generator</strong> - Generate privacy impact assessments (Python CLI)</li> \n <li><strong>Data Breach Reporter</strong> - Manage breach notifications (Python CLI)</li> \n <li><strong>GDPR Compliance Framework</strong> - Complete GDPR requirements</li> \n <li><strong>DPIA Methodology</strong> - Privacy impact assessment process</li> \n <li><strong>Medical Device Privacy</strong> - Privacy for medical devices</li> \n</ul> \n<p><strong>Learn More:</strong> See <code>ra-qm-team/README.md</code> for details</p> \n<hr /> \n<h2>⚡ Quick Start</h2> \n<h3>For Claude AI Users</h3> \n<ol> \n <li><strong>Download</strong> the skill package you need (or clone this repository)</li> \n <li><strong>Upload</strong> the SKILL.md file to your Claude conversation</li> \n <li><strong>Reference</strong> the skill: \"Using the content-creator skill, help me write a LinkedIn post about AI\"</li> \n</ol> \n<h3>For Claude Code Users</h3> \n<ol> \n <li><strong>Clone</strong> this repository into your project</li> \n <li><strong>Load</strong> the skill in your Claude Code session</li> \n <li><strong>Execute</strong> workflows and run analysis tools directly</li> \n</ol> \n<hr /> \n<h2>🤖 How to Use with Claude AI</h2> \n<p>Claude AI can use these skills to provide specialized expertise in your conversations.</p> \n<h3>Method 1: Upload Skill Documentation</h3> \n<p><strong>Step-by-Step:</strong></p> \n<ol> \n <li> <p><strong>Navigate to the skill folder</strong> you want to use (e.g., <code>marketing-skill/content-creator/</code>)</p> </li> \n <li> <p><strong>Upload the SKILL.md file</strong> to your Claude conversation:</p> \n  <ul> \n   <li>Click the attachment icon 📎</li> \n   <li>Select <code>SKILL.md</code> from the skill folder</li> \n   <li>Upload to the conversation</li> \n  </ul> </li> \n <li> <p><strong>Reference the skill in your prompts:</strong></p> <pre><code>Using the content-creator skill, help me:\n- Write a blog post about sustainable technology\n- Analyze my brand voice from these 3 articles\n- Create a LinkedIn content calendar for November 2025\n</code></pre> </li> \n <li> <p><strong>Access reference materials as needed:</strong></p> \n  <ul> \n   <li>Upload specific reference files (e.g., <code>references/content_frameworks.md</code>)</li> \n   <li>Claude will use the frameworks to guide content creation</li> \n  </ul> </li> \n</ol> \n<h3>Method 2: Use Packaged .zip Archives</h3> \n<p>For easy sharing with your team:</p> \n<ol> \n <li><strong>Download</strong> the pre-packaged .zip file (e.g., <code>content-creator.zip</code>)</li> \n <li><strong>Extract</strong> to your local machine</li> \n <li><strong>Upload SKILL.md</strong> to Claude as described above</li> \n</ol> \n<h3>Example Prompts</h3> \n<p><strong>Content Creator Skill:</strong></p> \n<pre><code>Using the content-creator skill:\n1. Analyze this article for brand voice consistency\n2. Optimize this blog post for the keyword \"marketing automation\"\n3. Create a 30-day LinkedIn content calendar for our product launch\n4. Write a Twitter thread explaining our new feature\n</code></pre> \n<p><strong>CEO Advisor Skill:</strong></p> \n<pre><code>Using the ceo-advisor skill:\n1. Help me evaluate our product expansion strategy\n2. Create a board presentation for Q4 results\n3. Model financial scenarios for hiring 10 new salespeople\n4. Draft investor update email for our Series A round\n</code></pre> \n<p><strong>CTO Advisor Skill:</strong></p> \n<pre><code>Using the cto-advisor skill:\n1. Analyze our technical debt and create a reduction roadmap\n2. Calculate optimal team structure for scaling to 50 engineers\n3. Evaluate whether we should adopt GraphQL or stick with REST\n4. Create an ADR for our microservices migration decision\n</code></pre> \n<p><strong>Product Manager Toolkit:</strong></p> \n<pre><code>Using the product-manager-toolkit skill:\n1. Prioritize our backlog of 50 features using RICE scoring\n2. Analyze customer interview transcripts to extract pain points\n3. Create a PRD for our new analytics dashboard feature\n4. Design a customer discovery interview guide for B2B users\n</code></pre> \n<p><strong>Agile Product Owner:</strong></p> \n<pre><code>Using the agile-product-owner skill:\n1. Generate user stories for our mobile app redesign epic\n2. Plan next sprint with 30 story points capacity\n3. Create acceptance criteria for authentication feature\n4. Analyze our velocity trends over last 6 sprints\n</code></pre> \n<p><strong>Product Strategist:</strong></p> \n<pre><code>Using the product-strategist skill:\n1. Generate OKR cascade from company goals to team level\n2. Create product vision and positioning for new market\n3. Design quarterly roadmap with strategic themes\n4. Plan product team scaling from 5 to 20 people\n</code></pre> \n<p><strong>UX Researcher Designer:</strong></p> \n<pre><code>Using the ux-researcher-designer skill:\n1. Create data-driven personas from 20 user interviews\n2. Map customer journey for onboarding experience\n3. Design usability test protocol for checkout flow\n4. Synthesize research findings into actionable insights\n</code></pre> \n<p><strong>UI Design System:</strong></p> \n<pre><code>Using the ui-design-system skill:\n1. Generate complete design token system from brand color #0066CC\n2. Create component library architecture using atomic design\n3. Define responsive breakpoints and grid system\n4. Export design tokens as CSS variables for developers\n</code></pre> \n<p><strong>Fullstack Engineer:</strong></p> \n<pre><code>Using the fullstack-engineer skill:\n1. Scaffold a new Next.js + GraphQL + PostgreSQL project\n2. Analyze code quality and security vulnerabilities in existing project\n3. Implement clean architecture patterns for backend API\n4. Set up CI/CD pipeline with GitHub Actions and Docker\n</code></pre> \n<h3>Tips for Best Results</h3> \n<p>✅ <strong>DO:</strong></p> \n<ul> \n <li>Reference the skill name explicitly in your prompts</li> \n <li>Upload relevant reference materials for complex tasks</li> \n <li>Ask Claude to use specific frameworks or templates from the skill</li> \n <li>Provide context about your industry, audience, or constraints</li> \n</ul> \n<p>❌ <strong>DON'T:</strong></p> \n<ul> \n <li>Assume Claude remembers the skill across different conversations (re-upload if needed)</li> \n <li>Mix too many skills in one conversation (focus on one domain at a time)</li> \n <li>Skip uploading the SKILL.md file (it contains essential workflows)</li> \n</ul> \n<hr /> \n<h2>💻 How to Use with Claude Code</h2> \n<p>Claude Code can execute the Python analysis tools and integrate skills into your development workflow.</p> \n<h3>Setup</h3> \n<ol> \n <li> <p><strong>Clone this repository</strong> into your project or workspace:</p> <pre><code class=\"language-bash\">git clone https://github.com/alirezarezvani/claude-skills.git\ncd claude-skills\n</code></pre> </li> \n <li> <p><strong>Install Python dependencies</strong> (if needed):</p> <pre><code class=\"language-bash\"># Most scripts use standard library only\npip install pyyaml  # Optional, for future features\n</code></pre> </li> \n <li> <p><strong>Verify installation</strong>:</p> <pre><code class=\"language-bash\">python marketing-skill/content-creator/scripts/brand_voice_analyzer.py --help\npython marketing-skill/content-creator/scripts/seo_optimizer.py --help\n</code></pre> </li> \n</ol> \n<h3>Using Analysis Tools</h3> \n<h4>Brand Voice Analyzer</h4> \n<p>Analyze any text file for brand voice characteristics and readability:</p> \n<pre><code class=\"language-bash\"># Analyze with human-readable output\npython marketing-skill/content-creator/scripts/brand_voice_analyzer.py article.txt\n\n# Analyze with JSON output for automation\npython marketing-skill/content-creator/scripts/brand_voice_analyzer.py article.txt json\n</code></pre> \n<p><strong>Output includes:</strong></p> \n<ul> \n <li>Formality score (informal → formal scale)</li> \n <li>Tone analysis (professional, friendly, authoritative, etc.)</li> \n <li>Perspective (first-person, third-person)</li> \n <li>Flesch Reading Ease score</li> \n <li>Sentence structure analysis</li> \n <li>Improvement recommendations</li> \n</ul> \n<h4>SEO Optimizer</h4> \n<p>Comprehensive SEO analysis and optimization:</p> \n<pre><code class=\"language-bash\"># Basic SEO analysis\npython marketing-skill/content-creator/scripts/seo_optimizer.py blog-post.md \"primary keyword\"\n\n# With secondary keywords\npython marketing-skill/content-creator/scripts/seo_optimizer.py blog-post.md \"marketing automation\" \"email marketing,lead nurturing\"\n</code></pre> \n<p><strong>Output includes:</strong></p> \n<ul> \n <li>SEO score (0-100)</li> \n <li>Keyword density analysis (primary, secondary, LSI keywords)</li> \n <li>Content structure evaluation (headings, paragraphs, links)</li> \n <li>Readability assessment</li> \n <li>Meta tag suggestions (title, description, URL, OG tags)</li> \n <li>Actionable optimization recommendations</li> \n</ul> \n<h4>Tech Debt Analyzer (CTO Advisor)</h4> \n<p>Quantify and prioritize technical debt:</p> \n<pre><code class=\"language-bash\">python c-level-advisor/cto-advisor/scripts/tech_debt_analyzer.py /path/to/codebase\n</code></pre> \n<h4>Team Scaling Calculator (CTO Advisor)</h4> \n<p>Model engineering team growth:</p> \n<pre><code class=\"language-bash\">python c-level-advisor/cto-advisor/scripts/team_scaling_calculator.py --current-size 10 --target-size 50\n</code></pre> \n<h4>Financial Scenario Analyzer (CEO Advisor)</h4> \n<p>Model business scenarios:</p> \n<pre><code class=\"language-bash\">python c-level-advisor/ceo-advisor/scripts/financial_scenario_analyzer.py scenarios.yaml\n</code></pre> \n<h4>Strategy Analyzer (CEO Advisor)</h4> \n<p>Evaluate strategic initiatives:</p> \n<pre><code class=\"language-bash\">python c-level-advisor/ceo-advisor/scripts/strategy_analyzer.py strategy-doc.md\n</code></pre> \n<h4>RICE Prioritizer (Product Manager)</h4> \n<p>Feature prioritization with portfolio analysis:</p> \n<pre><code class=\"language-bash\"># Basic prioritization\npython product-team/product-manager-toolkit/scripts/rice_prioritizer.py features.csv\n\n# With custom team capacity\npython product-team/product-manager-toolkit/scripts/rice_prioritizer.py features.csv --capacity 20\n\n# Output as JSON\npython product-team/product-manager-toolkit/scripts/rice_prioritizer.py features.csv --output json\n</code></pre> \n<h4>Customer Interview Analyzer (Product Manager)</h4> \n<p>Extract insights from user interviews:</p> \n<pre><code class=\"language-bash\"># Analyze single interview\npython product-team/product-manager-toolkit/scripts/customer_interview_analyzer.py interview.txt\n\n# Output as JSON for aggregation\npython product-team/product-manager-toolkit/scripts/customer_interview_analyzer.py interview.txt json\n</code></pre> \n<h4>User Story Generator (Product Owner)</h4> \n<p>Generate INVEST-compliant user stories:</p> \n<pre><code class=\"language-bash\"># Interactive mode\npython product-team/agile-product-owner/scripts/user_story_generator.py\n\n# Generate sprint plan with capacity\npython product-team/agile-product-owner/scripts/user_story_generator.py sprint 30\n</code></pre> \n<h4>OKR Cascade Generator (Product Strategist)</h4> \n<p>Generate aligned OKR hierarchy:</p> \n<pre><code class=\"language-bash\"># Generate OKRs for growth strategy\npython product-team/product-strategist/scripts/okr_cascade_generator.py growth\n\n# Other strategy types: retention, revenue, innovation\npython product-team/product-strategist/scripts/okr_cascade_generator.py retention\n</code></pre> \n<h4>Persona Generator (UX Researcher)</h4> \n<p>Create data-driven personas:</p> \n<pre><code class=\"language-bash\"># Interactive persona creation\npython product-team/ux-researcher-designer/scripts/persona_generator.py\n\n# Export as JSON\npython product-team/ux-researcher-designer/scripts/persona_generator.py --output json\n</code></pre> \n<h4>Design Token Generator (UI Designer)</h4> \n<p>Generate complete design system tokens:</p> \n<pre><code class=\"language-bash\"># Generate tokens from brand color\npython product-team/ui-design-system/scripts/design_token_generator.py \"#0066CC\" modern css\n\n# Output formats: css, json, scss\npython product-team/ui-design-system/scripts/design_token_generator.py \"#0066CC\" modern json\n</code></pre> \n<h4>Project Scaffolder (Fullstack Engineer)</h4> \n<p>Scaffold production-ready fullstack projects:</p> \n<pre><code class=\"language-bash\"># Create new Next.js + GraphQL + PostgreSQL project\npython engineering-team/fullstack-engineer/scripts/project_scaffolder.py my-project --type nextjs-graphql\n\n# Navigate and start\ncd my-project &amp;&amp; docker-compose up -d\n</code></pre> \n<h4>Code Quality Analyzer (Fullstack Engineer)</h4> \n<p>Analyze code quality and security:</p> \n<pre><code class=\"language-bash\"># Analyze existing project\npython engineering-team/fullstack-engineer/scripts/code_quality_analyzer.py /path/to/project\n\n# Get JSON report\npython engineering-team/fullstack-engineer/scripts/code_quality_analyzer.py /path/to/project --json\n</code></pre> \n<h4>Fullstack Scaffolder (Fullstack Engineer)</h4> \n<p>Rapid fullstack project generation:</p> \n<pre><code class=\"language-bash\"># Generate fullstack application structure\npython engineering-team/fullstack-engineer/scripts/fullstack_scaffolder.py my-app --stack nextjs-graphql\n</code></pre> \n<h3>Integrating with Claude Code Workflows</h3> \n<p><strong>Example 1: Automated Content Quality Check</strong></p> \n<pre><code class=\"language-bash\"># In your Claude Code session:\n# 1. Write content using content-creator frameworks\n# 2. Run automated analysis\npython marketing-skill/content-creator/scripts/seo_optimizer.py output.md \"target keyword\"\npython marketing-skill/content-creator/scripts/brand_voice_analyzer.py output.md json\n\n# 3. Claude Code reviews results and suggests improvements\n</code></pre> \n<p><strong>Example 2: Technical Debt Tracking</strong></p> \n<pre><code class=\"language-bash\"># Run monthly tech debt analysis\npython c-level-advisor/cto-advisor/scripts/tech_debt_analyzer.py src/\n\n# Claude Code generates report and roadmap\n# Tracks progress over time\n</code></pre> \n<p><strong>Example 3: Content Pipeline Automation</strong></p> \n<p>Create a workflow in Claude Code:</p> \n<ol> \n <li>Generate content using content frameworks</li> \n <li>Auto-run SEO optimizer on all drafts</li> \n <li>Flag content below SEO score threshold (&lt; 75)</li> \n <li>Apply recommendations automatically</li> \n <li>Re-score and validate</li> \n</ol> \n<h3>Advanced: Custom Skill Development</h3> \n<p>Use this repository as a template to build your own skills:</p> \n<ol> \n <li><strong>Fork this repository</strong></li> \n <li><strong>Create new skill folder</strong> following the architecture pattern</li> \n <li><strong>Develop</strong> your domain-specific tools and frameworks</li> \n <li><strong>Document</strong> workflows in SKILL.md</li> \n <li><strong>Share</strong> with your team or contribute back</li> \n</ol> \n<p>See <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/CLAUDE.md\">CLAUDE.md</a> for detailed architecture and development guidelines.</p> \n<hr /> \n<h2>🏗️ Skill Architecture</h2> \n<p>Each skill package follows a consistent, modular structure:</p> \n<pre><code>{skill-category}/\n└── {skill-name}/\n    ├── SKILL.md                          # Master documentation\n    ├── scripts/                          # Python CLI tools\n    │   ├── {tool_name}.py               # Executable analysis tools\n    │   └── ...\n    ├── references/                       # Knowledge bases\n    │   ├── {framework_name}.md          # Curated guidelines\n    │   └── ...\n    └── assets/                           # User templates\n        ├── {template_name}.md           # Ready-to-use templates\n        └── ...\n</code></pre> \n<h3>Design Principles</h3> \n<ol> \n <li><strong>Self-Contained</strong> - Each skill is fully independent and deployable</li> \n <li><strong>Documentation-Driven</strong> - Success depends on clear, actionable documentation</li> \n <li><strong>Algorithm Over AI</strong> - Use deterministic analysis (code) when possible for speed and reliability</li> \n <li><strong>Template-Heavy</strong> - Provide ready-to-use frameworks users can customize</li> \n <li><strong>Platform-Specific</strong> - Focus on specific, actionable advice over generic best practices</li> \n</ol> \n<h3>Component Responsibilities</h3> \n<table> \n <thead> \n  <tr> \n   <th>Component</th> \n   <th>Purpose</th> \n   <th>Format</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><strong>SKILL.md</strong></td> \n   <td>Entry point, workflows, usage instructions</td> \n   <td>Markdown</td> \n  </tr> \n  <tr> \n   <td><strong>scripts/</strong></td> \n   <td>Automated analysis and optimization tools</td> \n   <td>Python CLI</td> \n  </tr> \n  <tr> \n   <td><strong>references/</strong></td> \n   <td>Expert knowledge, frameworks, guidelines</td> \n   <td>Markdown</td> \n  </tr> \n  <tr> \n   <td><strong>assets/</strong></td> \n   <td>Templates for end-user customization</td> \n   <td>Markdown/YAML</td> \n  </tr> \n </tbody> \n</table> \n<hr /> \n<h2>📦 Installation</h2> \n<h3>Method 1: Universal Installer (Recommended)</h3> \n<p><strong>Fastest way to get started</strong> - Installs to all supported agents automatically:</p> \n<pre><code class=\"language-bash\"># Install all skills to Claude Code, Cursor, VS Code, Amp, Goose, etc.\nnpx ai-agent-skills install alirezarezvani/claude-skills\n\n# Or install to specific agent\nnpx ai-agent-skills install alirezarezvani/claude-skills --agent claude\n\n# Or install single skill\nnpx ai-agent-skills install alirezarezvani/claude-skills/marketing-skill/content-creator\n</code></pre> \n<p><strong>Supported Agents:</strong></p> \n<ul> \n <li>Claude Code (<code>--agent claude</code>) → <code>~/.claude/skills/</code></li> \n <li>Cursor (<code>--agent cursor</code>) → <code>.cursor/skills/</code></li> \n <li>VS Code/Copilot (<code>--agent vscode</code>) → <code>.github/skills/</code></li> \n <li>Goose (<code>--agent goose</code>) → <code>~/.config/goose/skills/</code></li> \n <li>Project-specific (<code>--agent project</code>) → <code>.skills/</code></li> \n</ul> \n<p><strong>Verification:</strong></p> \n<pre><code class=\"language-bash\"># Check installed skills (Claude Code example)\nls ~/.claude/skills/\n\n# Use skills directly in your agent\n# No additional setup required!\n</code></pre> \n<hr /> \n<h3>Method 2: Manual Installation (Alternative)</h3> \n<p>For development, customization, or offline use:</p> \n<h4>Prerequisites</h4> \n<ul> \n <li><strong>Python 3.7+</strong> (for running analysis scripts)</li> \n <li><strong>Claude AI account</strong> or <strong>Claude Code</strong> (for using skills)</li> \n <li><strong>Git</strong> (for cloning repository)</li> \n</ul> \n<h4>Clone Repository</h4> \n<pre><code class=\"language-bash\">git clone https://github.com/alirezarezvani/claude-skills.git\ncd claude-skills\n</code></pre> \n<h4>Install Dependencies</h4> \n<p>Most scripts use Python standard library only. Optional dependencies:</p> \n<pre><code class=\"language-bash\">pip install pyyaml  # For future features\n</code></pre> \n<h4>Verify Installation</h4> \n<pre><code class=\"language-bash\"># Test marketing skills\npython marketing-skill/content-creator/scripts/brand_voice_analyzer.py --help\npython marketing-skill/content-creator/scripts/seo_optimizer.py --help\n\n# Test C-level advisor skills\npython c-level-advisor/cto-advisor/scripts/tech_debt_analyzer.py --help\npython c-level-advisor/cto-advisor/scripts/team_scaling_calculator.py --help\npython c-level-advisor/ceo-advisor/scripts/strategy_analyzer.py --help\npython c-level-advisor/ceo-advisor/scripts/financial_scenario_analyzer.py --help\n\n# Test product team skills\npython product-team/product-manager-toolkit/scripts/rice_prioritizer.py --help\npython product-team/product-manager-toolkit/scripts/customer_interview_analyzer.py --help\npython product-team/agile-product-owner/scripts/user_story_generator.py --help\npython product-team/product-strategist/scripts/okr_cascade_generator.py --help\npython product-team/ux-researcher-designer/scripts/persona_generator.py --help\npython product-team/ui-design-system/scripts/design_token_generator.py --help\n\n# Test engineering team skills\npython engineering-team/fullstack-engineer/scripts/project_scaffolder.py --help\npython engineering-team/fullstack-engineer/scripts/code_quality_analyzer.py --help\npython engineering-team/fullstack-engineer/scripts/fullstack_scaffolder.py --help\n</code></pre> \n<hr /> \n<h2>📖 Usage Examples</h2> \n<h3>Example 1: Blog Post Optimization</h3> \n<p><strong>Scenario:</strong> You've written a blog post and want to optimize it for SEO and brand consistency.</p> \n<pre><code class=\"language-bash\"># Step 1: Check SEO\npython marketing-skill/content-creator/scripts/seo_optimizer.py blog-post.md \"AI automation\"\n\n# Output: SEO Score: 68/100\n# Recommendations:\n# - Add 3 more mentions of primary keyword (current density: 0.8%, target: 1-2%)\n# - Include H2 heading with primary keyword\n# - Add 2 internal links\n# - Meta description too short (current: 120 chars, target: 150-160)\n\n# Step 2: Check brand voice\npython marketing-skill/content-creator/scripts/brand_voice_analyzer.py blog-post.md\n\n# Output:\n# Formality: 7/10 (Professional)\n# Tone: Authoritative, Informative\n# Readability: 65 (Standard - college level)\n# Recommendations:\n# - Reduce sentence length by 15% for better readability\n# - Use more active voice (currently 60%, target: 70%+)\n\n# Step 3: Apply fixes in your editor\n# Step 4: Re-run analysis to verify improvements\n</code></pre> \n<h3>Example 2: LinkedIn Content Calendar</h3> \n<p><strong>Using Claude AI:</strong></p> \n<ol> \n <li> <p>Upload <code>marketing-skill/content-creator/SKILL.md</code></p> </li> \n <li> <p>Prompt:</p> <pre><code>Using the content-creator skill, create a 30-day LinkedIn content calendar\nfor our B2B SaaS company launching a new marketing automation feature.\n\nTarget audience: Marketing directors at mid-sized companies (50-500 employees)\nBrand voice: Expert + Friendly (from the 5 archetypes)\nTopics: Marketing automation, lead nurturing, ROI measurement\n</code></pre> </li> \n <li> <p>Claude generates:</p> \n  <ul> \n   <li>30-day calendar with post types (how-to, case study, tips, thought leadership)</li> \n   <li>Specific post outlines using content frameworks</li> \n   <li>Optimal posting times based on LinkedIn best practices</li> \n   <li>Hashtag recommendations</li> \n   <li>Engagement strategies</li> \n  </ul> </li> \n</ol> \n<h3>Example 3: Technical Debt Assessment</h3> \n<p><strong>Using Claude Code:</strong></p> \n<pre><code class=\"language-bash\"># Run tech debt analysis\npython c-level-advisor/cto-advisor/scripts/tech_debt_analyzer.py /path/to/codebase\n\n# Claude Code processes results and:\n# 1. Identifies top 10 debt items by severity\n# 2. Estimates effort to address (hours/days)\n# 3. Calculates impact on velocity\n# 4. Generates prioritized roadmap\n# 5. Creates Jira tickets with detailed descriptions\n\n# Output: Quarterly tech debt reduction plan\n</code></pre> \n<h3>Example 4: Board Presentation Prep</h3> \n<p><strong>Using CEO Advisor Skill:</strong></p> \n<ol> \n <li> <p>Upload <code>c-level-advisor/ceo-advisor/SKILL.md</code></p> </li> \n <li> <p>Upload <code>c-level-advisor/ceo-advisor/references/board_governance_investor_relations.md</code></p> </li> \n <li> <p>Prompt:</p> <pre><code>Using the ceo-advisor skill, help me prepare a board presentation for Q4 2025.\n\nContext:\n- SaaS company, $5M ARR, 40% YoY growth\n- Raised Series A ($10M) 18 months ago\n- Runway: 24 months\n- Key decision: Expand to European market or double-down on US\n\nInclude: Financial summary, strategic options, recommendation, Q&amp;A prep\n</code></pre> </li> \n <li> <p>Claude generates:</p> \n  <ul> \n   <li>Structured presentation outline using board governance best practices</li> \n   <li>Financial scenario models for both options</li> \n   <li>Risk analysis and mitigation strategies</li> \n   <li>Anticipated board questions with prepared answers</li> \n   <li>Decision framework showing evaluation criteria</li> \n  </ul> </li> \n</ol> \n<hr /> \n<h2>🔗 Related Projects &amp; Tools</h2> \n<p>Explore our complete ecosystem of Claude Code augmentation tools and utilities:</p> \n<h3>🏭 Claude Code Skills &amp; Agents Factory</h3> \n<p><strong>Repository:</strong> <a href=\"https://github.com/alirezarezvani/claude-code-skill-factory\">claude-code-skill-factory</a></p> \n<p><strong>What it is:</strong> Factory toolkit for generating production-ready Claude Skills and Agents at scale.</p> \n<p><strong>Key Features:</strong></p> \n<ul> \n <li>🎯 <strong>69 Factory Presets</strong> across 15 professional domains</li> \n <li>🔧 <strong>Smart Generation</strong> - Automatically determines if Python code or prompt-only instruction is needed</li> \n <li>📦 <strong>Complete Skill Packages</strong> - Generates SKILL.md, Python scripts, references, and sample data</li> \n <li>🚀 <strong>Multi-Platform Support</strong> - Works with Claude.ai, Claude Code, and API</li> \n <li>⚡ <strong>Rapid Prototyping</strong> - Create custom skills in minutes, not hours</li> \n</ul> \n<p><strong>Perfect For:</strong></p> \n<ul> \n <li>Building custom skills beyond the 48 provided in this library</li> \n <li>Generating domain-specific agents for your organization</li> \n <li>Scaling AI customization across teams</li> \n <li>Rapid prototyping of specialized workflows</li> \n</ul> \n<p><strong>Use Case:</strong> \"I need a skill for [your specific domain]? Use the Factory to generate it instantly!\"</p> \n<hr /> \n<h3>💎 Claude Code Tresor (Productivity Toolkit)</h3> \n<p><strong>Repository:</strong> <a href=\"https://github.com/alirezarezvani/claude-code-tresor\">claude-code-tresor</a></p> \n<p><strong>What it is:</strong> Comprehensive productivity enhancement toolkit with 20+ utilities for Claude Code development workflows.</p> \n<p><strong>Key Features:</strong></p> \n<ul> \n <li>🤖 <strong>8 Autonomous Skills</strong> - Background helpers (code quality, security, testing, docs)</li> \n <li>👨‍💻 <strong>8 Expert Agents</strong> - Manual specialists via <code>@</code> mentions (architecture, debugging, performance)</li> \n <li>⚡ <strong>4 Workflow Commands</strong> - Slash commands (<code>/scaffold</code>, <code>/review</code>, <code>/test-gen</code>, <code>/docs-gen</code>)</li> \n <li>📋 <strong>20+ Prompt Templates</strong> - Common development scenarios ready to use</li> \n <li>📚 <strong>Development Standards</strong> - Style guides and best practices</li> \n</ul> \n<p><strong>Perfect For:</strong></p> \n<ul> \n <li>Solo developers seeking productivity acceleration</li> \n <li>Development teams standardizing processes</li> \n <li>Code quality automation and continuous improvement</li> \n <li>Professional Claude Code workflows from scaffolding through deployment</li> \n</ul> \n<p><strong>Use Case:</strong> \"Working on a project in Claude Code? Use Tresor's agents, commands, and skills to supercharge your development workflow!\"</p> \n<hr /> \n<h3>🌟 How These Projects Work Together</h3> \n<p><strong>Complete Claude Code Ecosystem:</strong></p> \n<pre><code>┌─────────────────────────────────────────────────────────┐\n│  Claude Skills Library (This Repository)                │\n│  48 Domain Expert Skills - Marketing to Engineering     │\n│  Use for: Domain expertise, frameworks, best practices  │\n└────────────────┬────────────────────────────────────────┘\n                 │\n        ┌────────┴────────┐\n        │                 │\n        ▼                 ▼\n┌──────────────┐  ┌───────────────────┐\n│ Skill Factory│  │  Claude Tresor    │\n│              │  │                   │\n│ Create MORE  │  │ USE skills in     │\n│ custom skills│  │ development       │\n│              │  │                   │\n│ For: Custom  │  │ For: Daily dev    │\n│ domains &amp;    │  │ workflows, code   │\n│ org-specific │  │ quality, testing  │\n│ needs        │  │ automation        │\n└──────────────┘  └───────────────────┘\n</code></pre> \n<p><strong>Workflow:</strong></p> \n<ol> \n <li><strong>Start here</strong> (Skills Library) - Get 48 production-ready expert skills</li> \n <li><strong>Expand</strong> (Skill Factory) - Generate custom skills for your specific needs</li> \n <li><strong>Supercharge</strong> (Tresor) - Use skills + agents + commands in Claude Code development</li> \n</ol> \n<p><strong>Together they provide:</strong></p> \n<ul> \n <li>✅ 48 ready-to-use expert skills (this repo)</li> \n <li>✅ Unlimited custom skill generation (Factory)</li> \n <li>✅ Complete development workflow automation (Tresor)</li> \n <li>✅ Cross-platform compatibility (Claude.ai, Claude Code, API)</li> \n</ul> \n<p><strong>All repositories by <a href=\"https://alirezarezvani.com\">Alireza Rezvani</a></strong> - Building the complete Claude Code augmentation ecosystem.</p> \n<hr /> \n<h2>🗺️ Roadmap</h2> \n<h3>Current Status (Q4 2025)</h3> \n<p><strong>✅ Phase 1: Complete - 48 Production-Ready Skills</strong></p> \n<p><strong>Marketing Skills (5):</strong></p> \n<ul> \n <li>Content Creator - Brand voice analysis, SEO optimization, social media frameworks</li> \n <li>Marketing Demand &amp; Acquisition - Multi-channel demand gen, paid media, partnerships</li> \n <li>Marketing Strategy &amp; Product Marketing - Positioning, GTM, competitive intelligence</li> \n <li>App Store Optimization (ASO) - App Store &amp; Google Play metadata optimization, keyword research</li> \n <li>Social Media Analyzer - Platform analytics, engagement optimization, competitor benchmarking</li> \n</ul> \n<p><strong>C-Level Advisory Skills (2):</strong></p> \n<ul> \n <li>CEO Advisor - Strategic planning, financial modeling, board governance</li> \n <li>CTO Advisor - Technical debt analysis, team scaling, architecture decisions</li> \n</ul> \n<p><strong>Product Team Skills (5):</strong></p> \n<ul> \n <li>Product Manager Toolkit - RICE prioritization, interview analysis, PRD templates</li> \n <li>Agile Product Owner - User story generation, sprint planning, velocity tracking</li> \n <li>Product Strategist - OKR cascading, strategic planning, vision frameworks</li> \n <li>UX Researcher Designer - Persona generation, journey mapping, research synthesis</li> \n <li>UI Design System - Design tokens, component architecture, system documentation</li> \n</ul> \n<p><strong>Project Management Skills (6):</strong></p> \n<ul> \n <li>Senior PM Expert - Portfolio management, stakeholder alignment, executive reporting</li> \n <li>Scrum Master Expert - Sprint ceremonies, agile coaching, velocity tracking</li> \n <li>Atlassian Jira Expert - JQL mastery, configuration, automation, dashboards</li> \n <li>Atlassian Confluence Expert - Knowledge management, documentation, templates</li> \n <li>Atlassian Administrator - System administration, security, user management</li> \n <li>Atlassian Template Creator - Template design, standardization, 15+ ready templates</li> \n</ul> \n<p><strong>Engineering Team Skills - Core Engineering (13):</strong></p> \n<ul> \n <li>Senior Software Architect - Architecture design, tech decisions, documentation</li> \n <li>Senior Frontend Engineer - React/Next.js development, performance optimization</li> \n <li>Senior Backend Engineer - API design, database optimization, microservices</li> \n <li>Senior Fullstack Engineer - End-to-end development, code quality, DevOps integration</li> \n <li>Senior QA Testing Engineer - Test automation, coverage analysis, E2E testing</li> \n <li>Senior DevOps Engineer - CI/CD pipelines, infrastructure as code, deployment</li> \n <li>Senior SecOps Engineer - Security operations, vulnerability management, compliance</li> \n <li>Code Reviewer - PR analysis, code quality, automated reviews</li> \n <li>Senior Security Engineer - Security architecture, penetration testing, cryptography</li> \n <li>AWS Solution Architect - Serverless architectures, cost optimization, AWS best practices</li> \n <li>Microsoft 365 Tenant Manager - Tenant configuration, security, compliance, automation</li> \n <li>TDD Guide - Test-driven development methodology, test patterns, quality frameworks</li> \n <li>Tech Stack Evaluator - Technology evaluation, vendor selection, architecture decisions</li> \n</ul> \n<p><strong>Engineering Team Skills - AI/ML/Data (5):</strong></p> \n<ul> \n <li>Senior Data Scientist - Statistical modeling, experimentation, analytics</li> \n <li>Senior Data Engineer - Data pipelines, ETL/ELT, data infrastructure</li> \n <li>Senior ML/AI Engineer - MLOps, model deployment, LLM integration</li> \n <li>Senior Prompt Engineer - LLM optimization, RAG systems, agentic AI</li> \n <li>Senior Computer Vision Engineer - Object detection, image/video AI, real-time inference</li> \n</ul> \n<p><strong>Regulatory Affairs &amp; Quality Management (12):</strong></p> \n<ul> \n <li>Senior Regulatory Affairs Manager - Strategic regulatory leadership, submission management</li> \n <li>Senior Quality Manager (QMR) - Overall quality system responsibility</li> \n <li>Senior QMS ISO 13485 Specialist - QMS implementation and certification</li> \n <li>Senior CAPA Officer - Corrective/preventive action management</li> \n <li>Senior Quality Documentation Manager - Regulatory documentation control</li> \n <li>Senior Risk Management Specialist - ISO 14971 risk management</li> \n <li>Senior Information Security Manager - ISO 27001 ISMS and cybersecurity</li> \n <li>Senior MDR 2017/745 Specialist - EU MDR compliance expertise</li> \n <li>Senior FDA Consultant - FDA pathways and QSR compliance</li> \n <li>Senior QMS Audit Expert - Internal and external auditing</li> \n <li>Senior ISMS Audit Expert - Security system auditing</li> \n <li>Senior GDPR/DSGVO Expert - Privacy and data protection compliance</li> \n</ul> \n<h3>Phase 2: Marketing Expansion (Q1 2026)</h3> \n<p><strong>🔄 In Planning:</strong></p> \n<ul> \n <li><strong>SEO Optimizer Skill</strong> - Deep SEO analysis and optimization (standalone expansion)</li> \n <li><strong>Social Media Manager Skill</strong> - Campaign management across platforms</li> \n <li><strong>Campaign Analytics Skill</strong> - Performance measurement and optimization</li> \n</ul> \n<h3>Phase 2: Business &amp; Growth (Q1-Q2 2026)</h3> \n<p><strong>📋 Planned:</strong></p> \n<ul> \n <li><strong>Sales Engineer</strong> - Technical sales, solution design, RFP responses</li> \n <li><strong>Customer Success Manager</strong> - Onboarding, retention, expansion strategies</li> \n <li><strong>Growth Marketer</strong> - Acquisition, activation, viral loops, experimentation</li> \n</ul> \n<h3>Phase 3: Specialized Domains (Q3 2026)</h3> \n<p><strong>💡 Proposed:</strong></p> \n<ul> \n <li><strong>Mobile Engineer</strong> - Swift/Kotlin deep-dive, native platform development</li> \n <li><strong>Blockchain Engineer</strong> - Web3, smart contracts, decentralized systems</li> \n <li><strong>Game Developer</strong> - Game engines, graphics, real-time systems</li> \n <li><strong>IoT Engineer</strong> - Embedded systems, edge computing, hardware integration</li> \n</ul> \n<h3>Projected Impact</h3> \n<table> \n <thead> \n  <tr> \n   <th>Metric</th> \n   <th>Current</th> \n   <th>Target (Q3 2026)</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>Available Skills</td> \n   <td>48</td> \n   <td>55+</td> \n  </tr> \n  <tr> \n   <td>Skill Categories</td> \n   <td>6</td> \n   <td>9</td> \n  </tr> \n  <tr> \n   <td>Python Tools</td> \n   <td>68+</td> \n   <td>110+</td> \n  </tr> \n  <tr> \n   <td>Time Savings</td> \n   <td>70%</td> \n   <td>85%</td> \n  </tr> \n  <tr> \n   <td>Quality Improvement</td> \n   <td>65%</td> \n   <td>80%</td> \n  </tr> \n  <tr> \n   <td>Teams Using</td> \n   <td>Early adopters</td> \n   <td>3,000+</td> \n  </tr> \n  <tr> \n   <td>Organizations</td> \n   <td>25</td> \n   <td>250+</td> \n  </tr> \n  <tr> \n   <td>Industries Covered</td> \n   <td>Tech, HealthTech</td> \n   <td>Tech, Health, Finance, Manufacturing</td> \n  </tr> \n </tbody> \n</table> \n<h3>ROI Metrics (Current - 48 Skills)</h3> \n<p><strong>Time Savings Per Organization:</strong></p> \n<ul> \n <li>Marketing teams: 310 hours/month (Content + Demand Gen + PMM + ASO + Social Media)</li> \n <li>C-level executives: 30 hours/month</li> \n <li>Product teams: 180 hours/month</li> \n <li>Project management teams: 200 hours/month (PM + Agile + Atlassian)</li> \n <li>Core engineering teams: 580 hours/month (13 specialized roles)</li> \n <li>AI/ML/Data teams: 280 hours/month</li> \n <li>Regulatory/Quality teams: 320 hours/month</li> \n <li><strong>Total: 1,900 hours/month per organization</strong></li> \n</ul> \n<p><strong>Financial Impact:</strong></p> \n<ul> \n <li>Time value: $190,000/month (@ $100/hour)</li> \n <li>Quality improvements: $220,000/month (reduced rework)</li> \n <li>Faster delivery: $260,000/month (opportunity value)</li> \n <li>Security risk mitigation: $200,000/month</li> \n <li>ML/AI innovation value: $250,000/month</li> \n <li>Regulatory compliance value: $400,000/month (avoided delays, penalties)</li> \n <li>Marketing efficiency value: $100,000/month (better CAC, conversion, positioning)</li> \n <li>PM/Agile efficiency value: $130,000/month (faster delivery, better stakeholder satisfaction)</li> \n <li><strong>Total: $1,750,000/month value per organization</strong></li> \n <li><strong>Annual ROI: $21.0M per organization</strong></li> \n</ul> \n<p><strong>Productivity Gains:</strong></p> \n<ul> \n <li>Developer velocity: +70% improvement</li> \n <li>Deployment frequency: +200% increase</li> \n <li>Bug reduction: -50%</li> \n <li>Security incidents: -85%</li> \n <li>Code review time: -60%</li> \n <li>Onboarding time: -65%</li> \n <li>ML model deployment time: -80%</li> \n <li>Data pipeline reliability: +95%</li> \n <li>Regulatory submission success: +95%</li> \n <li>Time to market: -40% reduction</li> \n <li>Compliance risk: -90% reduction</li> \n <li>Sprint predictability: +40%</li> \n <li>Project on-time delivery: +25%</li> \n <li>Atlassian efficiency: +70%</li> \n</ul> \n<p><strong>See detailed roadmaps:</strong></p> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/marketing-skill/marketing_skills_roadmap.md\">marketing-skill/marketing_skills_roadmap.md</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/product-team/product_team_implementation_guide.md\">product-team/product_team_implementation_guide.md</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/project-management/README.md\">project-management/README.md</a> | <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/project-management/REAL_WORLD_SCENARIO.md\">project-management/REAL_WORLD_SCENARIO.md</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/START_HERE.md\">engineering-team/START_HERE.md</a> | <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/engineering-team/TEAM_STRUCTURE_GUIDE.md\">engineering-team/TEAM_STRUCTURE_GUIDE.md</a></li> \n <li><a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/ra-qm-team/README.md\">ra-qm-team/README.md</a> | <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/ra-qm-team/final-complete-skills-collection.md\">ra-qm-team/final-complete-skills-collection.md</a></li> \n</ul> \n<hr /> \n<h2>🤝 Contributing</h2> \n<p>Contributions are welcome! This repository aims to democratize professional expertise through reusable skill packages.</p> \n<h3>How to Contribute</h3> \n<ol> \n <li><strong>Fork</strong> this repository</li> \n <li><strong>Create</strong> a feature branch (<code>git checkout -b feature/new-skill</code>)</li> \n <li><strong>Develop</strong> your skill following the architecture guidelines in <a href=\"https://raw.githubusercontent.com/alirezarezvani/claude-skills/main/CLAUDE.md\">CLAUDE.md</a></li> \n <li><strong>Test</strong> your tools and validate documentation</li> \n <li><strong>Submit</strong> a pull request with detailed description</li> \n</ol> \n<h3>Contribution Ideas</h3> \n<ul> \n <li><strong>New Skills</strong> - Domain expertise in your field (finance, HR, product management, etc.)</li> \n <li><strong>Tool Enhancements</strong> - Improve existing Python analysis scripts</li> \n <li><strong>Framework Additions</strong> - Add new templates or methodologies to existing skills</li> \n <li><strong>Documentation</strong> - Improve how-to guides, examples, or translations</li> \n <li><strong>Bug Fixes</strong> - Fix issues in scripts or documentation</li> \n</ul> \n<h3>Quality Standards</h3> \n<p>All contributions should:</p> \n<ul> \n <li>✅ Follow the modular skill architecture pattern</li> \n <li>✅ Include comprehensive SKILL.md documentation</li> \n <li>✅ Provide actionable, specific guidance (not generic advice)</li> \n <li>✅ Use algorithmic tools (Python) when possible, not just documentation</li> \n <li>✅ Include ready-to-use templates or examples</li> \n <li>✅ Be self-contained and independently deployable</li> \n</ul> \n<hr /> \n<h2>📄 License</h2> \n<p>This project is licensed under the <strong>MIT License</strong> - see below for details.</p> \n<pre><code>MIT License\n\nCopyright (c) 2025 Alireza Rezvani\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre> \n<p>You are free to:</p> \n<ul> \n <li>✅ Use these skills commercially</li> \n <li>✅ Modify and adapt to your needs</li> \n <li>✅ Distribute to your team or clients</li> \n <li>✅ Create derivative works</li> \n</ul> \n<hr /> \n<h2>👤 Author</h2> \n<p><strong>Alireza Rezvani</strong></p> \n<p>Building AI-powered tools and frameworks to democratize professional expertise.</p> \n<ul> \n <li>🌐 <strong>Website:</strong> <a href=\"https://alirezarezvani.com\">alirezarezvani.com</a></li> \n <li>📝 <strong>Blog:</strong> <a href=\"https://medium.com/@alirezarezvani\">medium.com/@alirezarezvani</a></li> \n <li>💼 <strong>LinkedIn:</strong> Connect for updates on new skills and AI developments</li> \n <li>📧 <strong>Contact:</strong> Available through website or blog</li> \n</ul> \n<h3>About This Project</h3> \n<p>This repository emerged from years of experience building marketing strategies, leading engineering teams, and advising executives. The goal is simple: <strong>make world-class expertise accessible to everyone</strong> through Claude AI.</p> \n<p>Each skill represents hundreds of hours of domain expertise, distilled into actionable frameworks and automated tools. By sharing these openly, I hope to help teams work smarter, move faster, and achieve better results.</p> \n<p><strong>Follow my journey</strong> building AI-powered professional tools on <a href=\"https://medium.com/@alirezarezvani\">Medium</a>.</p> \n<hr /> \n<h2>🙏 Acknowledgments</h2> \n<ul> \n <li><strong>Anthropic</strong> - For building Claude AI and Claude Code, making this possible</li> \n <li><strong>Early Adopters</strong> - Teams testing these skills and providing feedback</li> \n <li><strong>Open Source Community</strong> - For tools and libraries that power the analysis scripts</li> \n</ul> \n<hr /> \n<h2>📞 Support &amp; Feedback</h2> \n<h3>Getting Help</h3> \n<ul> \n <li><strong>Documentation Issues:</strong> Open an issue in this repository</li> \n <li><strong>Skill Requests:</strong> Submit a feature request describing your use case</li> \n <li><strong>General Questions:</strong> Reach out via my <a href=\"https://alirezarezvani.com\">website</a> or <a href=\"https://medium.com/@alirezarezvani\">blog</a></li> \n</ul> \n<h3>Sharing Your Success</h3> \n<p>Using these skills successfully? I'd love to hear about it:</p> \n<ul> \n <li>Share your story on social media (tag me!)</li> \n <li>Write about your experience on Medium</li> \n <li>Submit a case study for inclusion in this README</li> \n</ul> \n<hr /> \n<h2>⭐ Star History</h2> \n<p><a href=\"https://star-history.com/#alirezarezvani/claude-skills&amp;Date\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=alirezarezvani/claude-skills&amp;type=Date\" /></a></p> \n<hr /> \n<div align=\"center\"> \n <p><strong>⭐ Star this repository</strong> if you find these skills useful!</p> \n <p><strong>🔗 Share</strong> with teams who could benefit from AI-powered expertise</p> \n <p><strong>🚀 Built with Claude AI</strong> | <strong>📦 Packaged for Impact</strong> | <strong>🌍 Open for All</strong></p> \n</div>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:14.549247Z",
        "tags": [
          {
            "name": "transformation",
            "score": 8
          },
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 30,
        "timeliness_score": 1,
        "final_score": 9.7,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/narnaiezzsshaa/operational-indistinguishability-a-technical-guide-to-the-doppelganger-framework-271b",
        "title": "Operational Indistinguishability: A Technical Guide to the Doppelgänger Framework",
        "summary": "<p><strong>Detecting attackers who use your systems exactly as designed</strong></p>\n\n\n\n\n<h2>\n  \n  \n  What Is a Doppelgänger Attack?\n</h2>\n\n<p>A Doppelgänger attack is one where:</p>\n\n<ul>\n<li>Credentials are valid</li>\n<li>Actions are permitted</li>\n<li>Features are used as designed</li>\n<li>Logs show normal activity</li>\n<li>The only anomaly is intent</li>\n</ul>\n\n<p>This is not \"living off the land.\"<br />\nThis is living inside the workflow.</p>\n\n\n\n\n<h2>\n  \n  \n  Uber 2022: A Technical Breakdown\n</h2>\n\n<p><strong>Identity Sampling</strong><br />\nMFA fatigue → behavioral mapping.</p>\n\n<p><strong>Shape Acquisition</strong><br />\nVPN + SSO → legitimate access patterns.</p>\n\n<p><strong>Trust Embedding</strong><br />\nInternal network → automation scripts → privileged credentials.</p>\n\n<p><strong>Workflow Inheritance</strong><br />\nAdmin dashboards → internal tools → no malware.</p>\n\n<p><strong>Intent Substitution</strong><br />\nLegitimate sequences → malicious objectives.</p>\n\n<p><strong>Result:</strong> Uber's security tools detected nothing. The attacker announced themselves.</p>\n\n\n\n\n<h2>\n  \n  \n  SMB Composite Case (22-Person Healthcare Practice)\n</h2>\n\n<p><strong>Identity Sampling</strong><br />\nCompromised email → workflow observation.</p>\n\n<p><strong>Shape Acquisition</strong><br />\nMatching login times → matching cadence.</p>\n\n<p><strong>Trust Embedding</strong><br />\nShared folders → EHR portal → legacy service account.</p>\n\n<p><strong>Workflow Inheritance</strong><br />\nBackup automation → file access → slow exfiltration.</p>\n\n<p><strong>Intent Substitution</strong><br />\nNormal activity → malicious sequence.</p>\n\n<p><strong>Result:</strong> Every log is clean. Every action is permitted. Only the intent is wrong.</p>\n\n\n\n\n<h2>\n  \n  \n  The Doppelgänger Kill Chain\n</h2>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Phase</th>\n<th>Action</th>\n<th>Detection Gap</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Identity Sampling</td>\n<td>Observe behavior, timing, cadence</td>\n<td>Passive recon leaves no logs</td>\n</tr>\n<tr>\n<td>Shape Acquisition</td>\n<td>Learn operational signature</td>\n<td>Learning looks like normal access</td>\n</tr>\n<tr>\n<td>Trust Embedding</td>\n<td>Enter trust graph via valid creds</td>\n<td>Valid auth = valid session</td>\n</tr>\n<tr>\n<td>Workflow Inheritance</td>\n<td>Use existing automation</td>\n<td>Sanctioned tools, expected telemetry</td>\n</tr>\n<tr>\n<td>Intent Substitution</td>\n<td>Malicious goals, legitimate sequences</td>\n<td>Intent is invisible to machines</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>No exploits. No malware. No signatures.<br />\nJust understanding.</p>\n\n\n\n\n<h2>\n  \n  \n  Why Defenders Miss Doppelgängers\n</h2>\n\n<p>Because defenders measure:</p>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>What Defenders See</th>\n<th>What Matters</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Events</td>\n<td>Sequences</td>\n</tr>\n<tr>\n<td>Permissions</td>\n<td>Capabilities</td>\n</tr>\n<tr>\n<td>Anomalies</td>\n<td>Narratives</td>\n</tr>\n<tr>\n<td>Compliance</td>\n<td>Consequence</td>\n</tr>\n<tr>\n<td>Intended behavior</td>\n<td>Lived reality</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>The Doppelgänger exploits the gap between <strong>what the system allows</strong> and <strong>what humans intend</strong>.</p>\n\n\n\n\n<h2>\n  \n  \n  Detection Requirements\n</h2>\n\n<p>Doppelgänger detection requires:</p>\n\n<ul>\n<li>\n<strong>Sequence-aware analytics</strong>—Alert on suspicious sequences, not just events</li>\n<li>\n<strong>Trust-graph traversal</strong>—Map and monitor trust chain movement</li>\n<li>\n<strong>Capability mapping</strong>—What can this identity do vs. what do they normally do?</li>\n<li>\n<strong>Drift-aware baselines</strong>—Per-identity baselines, not global averages</li>\n<li>\n<strong>Identity-centric telemetry</strong>—Correlate actions by identity across systems</li>\n</ul>\n\n<p>Traditional IOCs are useless.</p>\n\n\n\n\n<h2>\n  \n  \n  Engineering Controls\n</h2>\n\n<h3>\n  \n  \n  1. Just-In-Time Privilege Elevation\n</h3>\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>No standing admin access.\nElevation requires:\n  - Explicit request\n  - Justification\n  - Time-bound scope\n  - Audit trail\n</code></pre>\n\n</div>\n\n\n\n<p>The Doppelgänger relies on inherited privilege. Remove standing privilege, force elevation.</p>\n\n<h3>\n  \n  \n  2. Drift Monitoring\n</h3>\n\n<p>Treat drift as telemetry:</p>\n\n<ul>\n<li>\"Temporary\" permissions that persist</li>\n<li>Service accounts with expanding access</li>\n<li>Legacy integrations still running</li>\n<li>Undocumented automation</li>\n</ul>\n\n<p>The Doppelgänger lives in drift.</p>\n\n<h3>\n  \n  \n  3. Trust-Chain Visualization\n</h3>\n\n<p>Map your trust relationships:</p>\n\n<ul>\n<li>What trusts what?</li>\n<li>How far does trust propagate?</li>\n<li>Where are the shortcuts?</li>\n</ul>\n\n<p>Every trust chain is a potential Doppelgänger route.</p>\n\n<h3>\n  \n  \n  4. Sequence-Based Detection\n</h3>\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>IF user accesses HR_system\nAND THEN queries service_principal_keys\nWITHIN 30 minutes\nTHEN escalate\n</code></pre>\n\n</div>\n\n\n\n<p>Each action is legitimate. The sequence is not.</p>\n\n<h3>\n  \n  \n  5. Identity-Centric Baselines\n</h3>\n\n<p>Build baselines per identity:</p>\n\n<ul>\n<li>What does this user normally access?</li>\n<li>When do they normally work?</li>\n<li>What sequences are normal for their role?</li>\n</ul>\n\n<p>Global baselines average away the signal.</p>\n\n\n\n\n<h2>\n  \n  \n  Why SMBs Are Especially Vulnerable\n</h2>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Enterprise Reality</th>\n<th>SMB Reality</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Dedicated security team</td>\n<td>Part-time IT contractor</td>\n</tr>\n<tr>\n<td>Role-based access</td>\n<td>Overlapping roles</td>\n</tr>\n<tr>\n<td>Individual credentials</td>\n<td>Shared credentials</td>\n</tr>\n<tr>\n<td>Documented workflows</td>\n<td>Tribal knowledge</td>\n</tr>\n<tr>\n<td>Change management</td>\n<td>\"We'll fix it later\"</td>\n</tr>\n<tr>\n<td>SIEM + SOC</td>\n<td>Basic logging, if any</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>The Doppelgänger doesn't need sophistication.<br />\nIt needs predictable gaps.</p>\n\n<p>SMB environments are full of them.</p>\n\n\n\n\n<h2>\n  \n  \n  The Gap Between Allowed and Appropriate\n</h2>\n\n<p>The real attack surface:</p>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Allowed</th>\n<th>Appropriate?</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CI/CD reads config files</td>\n<td>At 3 AM, files it's never accessed?</td>\n</tr>\n<tr>\n<td>Help desk resets passwords</td>\n<td>Six executive passwords in ten minutes?</td>\n</tr>\n<tr>\n<td>Backup service accesses shares</td>\n<td>Shares containing M&amp;A documents?</td>\n</tr>\n<tr>\n<td>Admin queries Azure AD</td>\n<td>Every user's group membership in one hour?</td>\n</tr>\n</tbody>\n</table></div>\n\n<p>The Doppelgänger operates in this gap.</p>\n\n\n\n\n<h2>\n  \n  \n  Architectural Implications\n</h2>\n\n<ul>\n<li>\n<strong>Reduce the trust graph</strong>—Every trust relationship is a potential path</li>\n<li>\n<strong>Segment aggressively</strong>—Assume every identity is potentially compromised</li>\n<li>\n<strong>Implement JIT everywhere</strong>—No standing privilege</li>\n<li>\n<strong>Monitor sequences, not just events</strong>—Correlate across time and systems</li>\n<li>\n<strong>Know your own shape</strong>—If you don't know what legitimate looks like, you can't recognize imposters</li>\n</ul>\n\n\n\n\n<h2>\n  \n  \n  Final Thought\n</h2>\n\n<p>The Doppelgänger is not a hacker.<br />\nIt is the shadow of your own system—the version that behaves exactly as designed, but for the wrong reasons.</p>\n\n<p>The most dangerous intrusion is the one that looks like work.</p>\n\n\n\n\n<p>For the epistemological framework behind this model, see <a href=\"https://dev.to/narnaiezzsshaa/the-epistemology-of-offense-and-defense-a-foundational-framework-em0\">The Epistemology of Offense and Defense: A Foundational Framework</a>.</p>\n\n<p>For the mythic-operational context, see <a href=\"https://narnaiezzsshaa.substack.com/p/the-doppelganger-framework\" rel=\"noopener noreferrer\">The Doppelgänger Framework</a> on Substack.</p>\n\n\n\n\n<h2>\n  \n  \n  Related Canon\n</h2>\n\n<p>This framework connects to my technical series on dev.to:</p>\n\n<p><strong><a href=\"https://dev.to/narnaiezzsshaa/series/33895\">Myth-Tech AI/ML Security Framework</a></strong>—A 17-part series mapping mythological archetypes to AI/ML security patterns, including drift detection, memory architecture, and adversarial dynamics.</p>\n\n\n\n\n<h2>\n  \n  \n  Provenance\n</h2>\n\n<p>I've been developing and publishing the Doppelgänger Framework in public since late 2025—across Substack, dev.to, Zenodo, and in my books. If you've encountered similar language or concepts elsewhere, this is the origin point.</p>\n\n<p><strong>Selected Zenodo publications (DOI-timestamped):</strong></p>\n\n<ul>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18058049\" rel=\"noopener noreferrer\">MFR x Myth-Tech</a> — Dec 25, 2025</li>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18091270\" rel=\"noopener noreferrer\">EIOC: Emotional Indicators of Compromise</a> — Dec 29, 2025</li>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18148425\" rel=\"noopener noreferrer\">The EIOC Fork: Dual-Path Framework</a> — Jan 4, 2026</li>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18226784\" rel=\"noopener noreferrer\">The Myth-Tech Bestiary</a> — Jan 12, 2026</li>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18226784\" rel=\"noopener noreferrer\">The 22 Arcana: A Pattern Language for Systemic Distortion</a> — Jan 16, 2026</li>\n<li>\n<a href=\"https://doi.org/10.5281/zenodo.18226784\" rel=\"noopener noreferrer\">Somatic Signatures of the 22 Arcana</a> — Jan 16, 2026</li>\n</ul>\n\n<p><strong>Full archive:</strong> <a href=\"https://orcid.org/0009-0000-1964-6440\" rel=\"noopener noreferrer\">ORCID 0009-0000-1964-6440</a></p>\n\n<p><strong>Books &amp; Frameworks:</strong> <a href=\"https://narnaiezzsshaa.gumroad.com\" rel=\"noopener noreferrer\">Gumroad</a></p>\n\n<p>This framework underlies the care-based security methodology, the Myth-Tech canon, and the sociotechnical approach I use in my consulting work. The lineage is here.</p>\n\n\n\n\n<p><em>This framework is part of the Soft Armor Labs canon.</em></p>",
        "source": "dev.to",
        "published": "Wed, 21 Jan 2026 21:30:03 +0000",
        "fetched_at": "2026-01-21T23:21:19.543427Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          },
          {
            "name": "ontology_shift",
            "score": 8
          }
        ],
        "structural_score": 26,
        "timeliness_score": 2,
        "final_score": 9.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/frankbria/ralph-claude-code",
        "title": "frankbria/ralph-claude-code",
        "summary": "<p>Autonomous AI development loop for Claude Code with intelligent exit detection</p><hr /><h1>Ralph for Claude Code</h1> \n<p><a href=\"https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml\"><img alt=\"CI\" src=\"https://github.com/frankbria/ralph-claude-code/actions/workflows/test.yml/badge.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE\"><img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true\" /></a> <img alt=\"Version\" src=\"https://img.shields.io/badge/version-0.9.9-blue\" /> <img alt=\"Tests\" src=\"https://img.shields.io/badge/tests-308%20passing-green\" /> <a href=\"https://github.com/frankbria/ralph-claude-code/issues\"><img alt=\"GitHub Issues\" src=\"https://img.shields.io/github/issues/frankbria/ralph-claude-code\" /></a> <a href=\"https://github.com/hesreallyhim/awesome-claude-code\"><img alt=\"Mentioned in Awesome Claude Code\" src=\"https://awesome.re/mentioned-badge.svg?sanitize=true\" /></a> <a href=\"https://x.com/FrankBria18044\"><img alt=\"Follow on X\" src=\"https://img.shields.io/twitter/follow/FrankBria18044?style=social\" /></a></p> \n<blockquote> \n <p><strong>Autonomous AI development loop with intelligent exit detection and rate limiting</strong></p> \n</blockquote> \n<p>Ralph is an implementation of the Geoffrey Huntley's technique for Claude Code that enables continuous autonomous development cycles he named after <a href=\"https://ghuntley.com/ralph/\">Ralph Wiggum</a>. It enables continuous autonomous development cycles where Claude Code iteratively improves your project until completion, with built-in safeguards to prevent infinite loops and API overuse.</p> \n<p><strong>Install once, use everywhere</strong> - Ralph becomes a global command available in any directory.</p> \n<h2>Project Status</h2> \n<p><strong>Version</strong>: v0.9.9 - Active Development <strong>Core Features</strong>: Working and tested <strong>Test Coverage</strong>: 308 tests, 100% pass rate</p> \n<h3>What's Working Now</h3> \n<ul> \n <li>Autonomous development loops with intelligent exit detection</li> \n <li><strong>Dual-condition exit gate</strong>: Requires BOTH completion indicators AND explicit EXIT_SIGNAL</li> \n <li>Rate limiting with hourly reset (100 calls/hour, configurable)</li> \n <li>Circuit breaker with advanced error detection (prevents runaway loops)</li> \n <li>Response analyzer with semantic understanding and two-stage error filtering</li> \n <li><strong>JSON output format support with automatic fallback to text parsing</strong></li> \n <li><strong>Session continuity with <code>--continue</code> flag for context preservation</strong></li> \n <li><strong>Session expiration with configurable timeout (default: 24 hours)</strong></li> \n <li><strong>Modern CLI flags: <code>--output-format</code>, <code>--allowed-tools</code>, <code>--no-continue</code></strong></li> \n <li>Multi-line error matching for accurate stuck loop detection</li> \n <li>5-hour API limit handling with user prompts</li> \n <li>tmux integration for live monitoring</li> \n <li>PRD import functionality</li> \n <li><strong>CI/CD pipeline with GitHub Actions</strong></li> \n <li><strong>Dedicated uninstall script for clean removal</strong></li> \n <li>308 passing tests across 11 test files</li> \n</ul> \n<h3>Recent Improvements</h3> \n<p><strong>v0.9.9 - EXIT_SIGNAL Gate &amp; Uninstall Script</strong></p> \n<ul> \n <li>Fixed premature exit bug: completion indicators now require Claude's explicit <code>EXIT_SIGNAL: true</code></li> \n <li>Added dual-condition check preventing exits when Claude reports work in progress</li> \n <li>Added <code>response_analyzer.sh</code> fix to respect explicit EXIT_SIGNAL over heuristics</li> \n <li>Added dedicated <code>uninstall.sh</code> script for clean Ralph removal</li> \n <li>Session expiration with configurable timeout (default: 24 hours)</li> \n <li>Added 32 new tests for EXIT_SIGNAL behavior and session expiration</li> \n <li>Test count: 308 (up from 276)</li> \n</ul> \n<p><strong>v0.9.8 - Modern CLI for PRD Import</strong></p> \n<ul> \n <li>Modernized <code>ralph_import.sh</code> to use Claude Code CLI JSON output format</li> \n <li>JSON output format support with <code>--output-format json</code> for structured responses</li> \n <li>Enhanced error handling with structured JSON error messages</li> \n <li>Improved file verification with JSON-derived status information</li> \n <li>Backward compatibility with older CLI versions (automatic text fallback)</li> \n <li>Added 11 new tests for modern CLI features</li> \n</ul> \n<p><strong>v0.9.7 - Session Lifecycle Management</strong></p> \n<ul> \n <li>Complete session lifecycle management with automatic reset triggers</li> \n <li>Session auto-reset on: circuit breaker open, manual interrupt, project completion</li> \n <li>Added <code>--reset-session</code> CLI flag for manual session reset</li> \n <li>Session history tracking (last 50 transitions) for debugging</li> \n <li>Added 26 new tests for session continuity features</li> \n</ul> \n<p><strong>v0.9.6 - JSON Output &amp; Session Management</strong></p> \n<ul> \n <li>Extended <code>parse_json_response()</code> to support Claude Code CLI JSON format</li> \n <li>Added session management functions: <code>store_session_id()</code>, <code>get_last_session_id()</code>, <code>should_resume_session()</code></li> \n <li>Cross-platform epoch time utilities in date_utils.sh</li> \n <li>Added 16 new tests covering Claude CLI format and session management</li> \n</ul> \n<p><strong>v0.9.5 - PRD Import Tests</strong></p> \n<ul> \n <li>Added 22 comprehensive tests for <code>ralph_import.sh</code> PRD conversion script</li> \n <li>Tests cover: file format support, output file creation, project naming, error handling</li> \n</ul> \n<p><strong>v0.9.4 - Project Setup Tests</strong></p> \n<ul> \n <li>Added 36 comprehensive tests for <code>setup.sh</code> project initialization script</li> \n <li>Tests cover: directory creation, template copying, git initialization</li> \n</ul> \n<p><strong>v0.9.3 - Installation Tests</strong></p> \n<ul> \n <li>Added 14 comprehensive tests for <code>install.sh</code> global installation script</li> \n <li>Tests cover: directory creation, command installation, dependency detection</li> \n</ul> \n<p><strong>v0.9.2 - Prompt File Fix</strong></p> \n<ul> \n <li>Fixed critical bug: replaced non-existent <code>--prompt-file</code> CLI flag with <code>-p</code> flag</li> \n <li>Modern CLI mode now correctly passes prompt content via <code>-p \"$(cat file)\"</code></li> \n <li>Added error handling for missing prompt files in <code>build_claude_command()</code></li> \n</ul> \n<p><strong>v0.9.1 - Modern CLI Commands (Phase 1.1)</strong></p> \n<ul> \n <li>JSON output format support with <code>--output-format json</code> (default)</li> \n <li>Session continuity using <code>--continue</code> flag for cross-loop context</li> \n <li>Tool permissions via <code>--allowed-tools</code> flag</li> \n <li>CI/CD pipeline with kcov coverage reporting</li> \n</ul> \n<p><strong>v0.9.0 - Circuit Breaker Enhancements</strong></p> \n<ul> \n <li>Fixed multi-line error matching in stuck loop detection</li> \n <li>Eliminated JSON field false positives (e.g., <code>\"is_error\": false</code>)</li> \n <li>Added two-stage error filtering for accurate detection</li> \n</ul> \n<h3>In Progress</h3> \n<ul> \n <li>Expanding test coverage</li> \n <li>Log rotation functionality</li> \n <li>Dry-run mode</li> \n <li>Configuration file support (.ralphrc)</li> \n <li>Metrics and analytics tracking</li> \n <li>Desktop notifications</li> \n <li>Git backup and rollback system</li> \n</ul> \n<p><strong>Timeline to v1.0</strong>: ~4 weeks | <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">Full roadmap</a> | <strong>Contributions welcome!</strong></p> \n<h2>Features</h2> \n<ul> \n <li><strong>Autonomous Development Loop</strong> - Continuously executes Claude Code with your project requirements</li> \n <li><strong>Intelligent Exit Detection</strong> - Dual-condition check requiring BOTH completion indicators AND explicit EXIT_SIGNAL</li> \n <li><strong>Session Continuity</strong> - Preserves context across loop iterations with automatic session management</li> \n <li><strong>Session Expiration</strong> - Configurable timeout (default: 24 hours) with automatic session reset</li> \n <li><strong>Rate Limiting</strong> - Built-in API call management with hourly limits and countdown timers</li> \n <li><strong>5-Hour API Limit Handling</strong> - Detects Claude's 5-hour usage limit and offers wait/exit options</li> \n <li><strong>Live Monitoring</strong> - Real-time dashboard showing loop status, progress, and logs</li> \n <li><strong>Task Management</strong> - Structured approach with prioritized task lists and progress tracking</li> \n <li><strong>Project Templates</strong> - Quick setup for new projects with best-practice structure</li> \n <li><strong>Comprehensive Logging</strong> - Detailed execution logs with timestamps and status tracking</li> \n <li><strong>Configurable Timeouts</strong> - Set execution timeout for Claude Code operations (1-120 minutes)</li> \n <li><strong>Verbose Progress Mode</strong> - Optional detailed progress updates during execution</li> \n <li><strong>Response Analyzer</strong> - AI-powered analysis of Claude Code responses with semantic understanding</li> \n <li><strong>Circuit Breaker</strong> - Advanced error detection with two-stage filtering, multi-line error matching, and automatic recovery</li> \n <li><strong>CI/CD Integration</strong> - GitHub Actions workflow with automated testing</li> \n <li><strong>Clean Uninstall</strong> - Dedicated uninstall script for complete removal</li> \n</ul> \n<h2>Quick Start</h2> \n<p>Ralph has two phases: <strong>one-time installation</strong> and <strong>per-project setup</strong>.</p> \n<pre><code>INSTALL ONCE              USE MANY TIMES\n+-----------------+          +----------------------+\n| ./install.sh    |    -&gt;    | ralph-setup project1 |\n|                 |          | ralph-setup project2 |\n| Adds global     |          | ralph-setup project3 |\n| commands        |          | ...                  |\n+-----------------+          +----------------------+\n</code></pre> \n<h3>Phase 1: Install Ralph (One Time Only)</h3> \n<p>Install Ralph globally on your system:</p> \n<pre><code class=\"language-bash\">git clone https://github.com/frankbria/ralph-claude-code.git\ncd ralph-claude-code\n./install.sh\n</code></pre> \n<p>This adds <code>ralph</code>, <code>ralph-monitor</code>, and <code>ralph-setup</code> commands to your PATH.</p> \n<blockquote> \n <p><strong>Note</strong>: You only need to do this once per system. After installation, you can delete the cloned repository if desired.</p> \n</blockquote> \n<h3>Phase 2: Initialize New Projects (Per Project)</h3> \n<p>For each new project you want Ralph to work on:</p> \n<h4>Option A: Import Existing PRD/Specifications</h4> \n<pre><code class=\"language-bash\"># Convert existing PRD/specs to Ralph format (recommended)\nralph-import my-requirements.md my-project\ncd my-project\n\n# Review and adjust the generated files:\n# - PROMPT.md (Ralph instructions)\n# - @fix_plan.md (task priorities)\n# - specs/requirements.md (technical specs)\n\n# Start autonomous development\nralph --monitor\n</code></pre> \n<h4>Option B: Manual Project Setup</h4> \n<pre><code class=\"language-bash\"># Create blank Ralph project\nralph-setup my-awesome-project\ncd my-awesome-project\n\n# Configure your project requirements manually\n# Edit PROMPT.md with your project goals\n# Edit specs/ with detailed specifications\n# Edit @fix_plan.md with initial priorities\n\n# Start autonomous development\nralph --monitor\n</code></pre> \n<h3>Ongoing Usage (After Setup)</h3> \n<p>Once Ralph is installed and your project is initialized:</p> \n<pre><code class=\"language-bash\"># Navigate to any Ralph project and run:\nralph --monitor              # Integrated tmux monitoring (recommended)\n\n# Or use separate terminals:\nralph                        # Terminal 1: Ralph loop\nralph-monitor               # Terminal 2: Live monitor dashboard\n</code></pre> \n<h3>Uninstalling Ralph</h3> \n<p>To completely remove Ralph from your system:</p> \n<pre><code class=\"language-bash\"># Run the uninstall script\n./uninstall.sh\n\n# Or if you deleted the repo, download and run:\ncurl -sL https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/uninstall.sh | bash\n</code></pre> \n<h2>How It Works</h2> \n<p>Ralph operates on a simple but powerful cycle:</p> \n<ol> \n <li><strong>Read Instructions</strong> - Loads <code>PROMPT.md</code> with your project requirements</li> \n <li><strong>Execute Claude Code</strong> - Runs Claude Code with current context and priorities</li> \n <li><strong>Track Progress</strong> - Updates task lists and logs execution results</li> \n <li><strong>Evaluate Completion</strong> - Checks for exit conditions and project completion signals</li> \n <li><strong>Repeat</strong> - Continues until project is complete or limits are reached</li> \n</ol> \n<h3>Intelligent Exit Detection</h3> \n<p>Ralph uses a <strong>dual-condition check</strong> to prevent premature exits during productive iterations:</p> \n<p><strong>Exit requires BOTH conditions:</strong></p> \n<ol> \n <li><code>completion_indicators &gt;= 2</code> (heuristic detection from natural language patterns)</li> \n <li>Claude's explicit <code>EXIT_SIGNAL: true</code> in the RALPH_STATUS block</li> \n</ol> \n<p><strong>Example behavior:</strong></p> \n<pre><code>Loop 5: Claude outputs \"Phase complete, moving to next feature\"\n        → completion_indicators: 3 (high confidence from patterns)\n        → EXIT_SIGNAL: false (Claude says more work needed)\n        → Result: CONTINUE (respects Claude's explicit intent)\n\nLoop 8: Claude outputs \"All tasks complete, project ready\"\n        → completion_indicators: 4\n        → EXIT_SIGNAL: true (Claude confirms done)\n        → Result: EXIT with \"project_complete\"\n</code></pre> \n<p><strong>Other exit conditions:</strong></p> \n<ul> \n <li>All tasks in <code>@fix_plan.md</code> marked complete</li> \n <li>Multiple consecutive \"done\" signals from Claude Code</li> \n <li>Too many test-focused loops (indicating feature completeness)</li> \n <li>Claude API 5-hour usage limit reached (with user prompt to wait or exit)</li> \n</ul> \n<h2>Importing Existing Requirements</h2> \n<p>Ralph can convert existing PRDs, specifications, or requirement documents into the proper Ralph format using Claude Code.</p> \n<h3>Supported Formats</h3> \n<ul> \n <li><strong>Markdown</strong> (.md) - Product requirements, technical specs</li> \n <li><strong>Text files</strong> (.txt) - Plain text requirements</li> \n <li><strong>JSON</strong> (.json) - Structured requirement data</li> \n <li><strong>Word documents</strong> (.docx) - Business requirements</li> \n <li><strong>PDFs</strong> (.pdf) - Design documents, specifications</li> \n <li><strong>Any text-based format</strong> - Ralph will intelligently parse the content</li> \n</ul> \n<h3>Usage Examples</h3> \n<pre><code class=\"language-bash\"># Convert a markdown PRD\nralph-import product-requirements.md my-app\n\n# Convert a text specification\nralph-import requirements.txt webapp\n\n# Convert a JSON API spec\nralph-import api-spec.json backend-service\n\n# Let Ralph auto-name the project from filename\nralph-import design-doc.pdf\n</code></pre> \n<h3>What Gets Generated</h3> \n<p>Ralph-import creates a complete project with:</p> \n<ul> \n <li><strong>PROMPT.md</strong> - Converted into Ralph development instructions</li> \n <li><strong>@fix_plan.md</strong> - Requirements broken down into prioritized tasks</li> \n <li><strong>specs/requirements.md</strong> - Technical specifications extracted from your document</li> \n <li><strong>Standard Ralph structure</strong> - All necessary directories and template files</li> \n</ul> \n<p>The conversion is intelligent and preserves your original requirements while making them actionable for autonomous development.</p> \n<h3>Modern CLI Features (v0.9.8)</h3> \n<p>Ralph-import uses modern Claude Code CLI features for improved reliability:</p> \n<ul> \n <li><strong>JSON Output Format</strong>: Structured responses enable precise parsing of conversion results</li> \n <li><strong>Automatic Fallback</strong>: Gracefully handles older CLI versions with text-based parsing</li> \n <li><strong>Enhanced Error Reporting</strong>: Extracts specific error messages and codes from JSON responses</li> \n <li><strong>Session Tracking</strong>: Captures session IDs for potential continuation of interrupted conversions</li> \n</ul> \n<blockquote> \n <p><strong>Note</strong>: These features require Claude Code CLI version 2.0.76 or later. Older versions will work with standard text output.</p> \n</blockquote> \n<h2>Configuration</h2> \n<h3>Rate Limiting &amp; Circuit Breaker</h3> \n<p>Ralph includes intelligent rate limiting and circuit breaker functionality:</p> \n<pre><code class=\"language-bash\"># Default: 100 calls per hour\nralph --calls 50\n\n# With integrated monitoring\nralph --monitor --calls 50\n\n# Check current usage\nralph --status\n</code></pre> \n<p>The circuit breaker automatically:</p> \n<ul> \n <li>Detects API errors and rate limit issues with advanced two-stage filtering</li> \n <li>Opens circuit after 3 loops with no progress or 5 loops with same errors</li> \n <li>Eliminates false positives from JSON fields containing \"error\"</li> \n <li>Accurately detects stuck loops with multi-line error matching</li> \n <li>Gradually recovers with half-open monitoring state</li> \n <li>Provides detailed error tracking and logging with state history</li> \n</ul> \n<h3>Claude API 5-Hour Limit</h3> \n<p>When Claude's 5-hour usage limit is reached, Ralph:</p> \n<ol> \n <li>Detects the limit error automatically</li> \n <li>Prompts you to choose: \n  <ul> \n   <li><strong>Option 1</strong>: Wait 60 minutes for the limit to reset (with countdown timer)</li> \n   <li><strong>Option 2</strong>: Exit gracefully (or auto-exits after 30-second timeout)</li> \n  </ul> </li> \n <li>Prevents endless retry loops that waste time</li> \n</ol> \n<h3>Custom Prompts</h3> \n<pre><code class=\"language-bash\"># Use custom prompt file\nralph --prompt my_custom_instructions.md\n\n# With integrated monitoring\nralph --monitor --prompt my_custom_instructions.md\n</code></pre> \n<h3>Execution Timeouts</h3> \n<pre><code class=\"language-bash\"># Set Claude Code execution timeout (default: 15 minutes)\nralph --timeout 30  # 30-minute timeout for complex tasks\n\n# With monitoring and custom timeout\nralph --monitor --timeout 60  # 60-minute timeout\n\n# Short timeout for quick iterations\nralph --verbose --timeout 5  # 5-minute timeout with progress\n</code></pre> \n<h3>Verbose Mode</h3> \n<pre><code class=\"language-bash\"># Enable detailed progress updates during execution\nralph --verbose\n\n# Combine with other options\nralph --monitor --verbose --timeout 30\n</code></pre> \n<h3>Session Continuity</h3> \n<p>Ralph maintains session context across loop iterations for improved coherence:</p> \n<pre><code class=\"language-bash\"># Sessions are enabled by default with --continue flag\nralph --monitor                 # Uses session continuity\n\n# Start fresh without session context\nralph --no-continue             # Isolated iterations\n\n# Reset session manually (clears context)\nralph --reset-session           # Clears current session\n\n# Check session status\ncat .ralph_session              # View current session file\ncat .ralph_session_history      # View session transition history\n</code></pre> \n<p><strong>Session Auto-Reset Triggers:</strong></p> \n<ul> \n <li>Circuit breaker opens (stagnation detected)</li> \n <li>Manual interrupt (Ctrl+C / SIGINT)</li> \n <li>Project completion (graceful exit)</li> \n <li>Manual circuit breaker reset (<code>--reset-circuit</code>)</li> \n <li>Session expiration (default: 24 hours)</li> \n</ul> \n<p>Sessions are persisted to <code>.ralph_session</code> with a configurable expiration (default: 24 hours). The last 50 session transitions are logged to <code>.ralph_session_history</code> for debugging.</p> \n<h3>Exit Thresholds</h3> \n<p>Modify these variables in <code>~/.ralph/ralph_loop.sh</code>:</p> \n<p><strong>Exit Detection Thresholds:</strong></p> \n<pre><code class=\"language-bash\">MAX_CONSECUTIVE_TEST_LOOPS=3     # Exit after 3 test-only loops\nMAX_CONSECUTIVE_DONE_SIGNALS=2   # Exit after 2 \"done\" signals\nTEST_PERCENTAGE_THRESHOLD=30     # Flag if 30%+ loops are test-only\n</code></pre> \n<p><strong>Circuit Breaker Thresholds:</strong></p> \n<pre><code class=\"language-bash\">CB_NO_PROGRESS_THRESHOLD=3       # Open circuit after 3 loops with no file changes\nCB_SAME_ERROR_THRESHOLD=5        # Open circuit after 5 loops with repeated errors\nCB_OUTPUT_DECLINE_THRESHOLD=70   # Open circuit if output declines by &gt;70%\n</code></pre> \n<p><strong>Completion Indicators with EXIT_SIGNAL Gate:</strong></p> \n<table> \n <thead> \n  <tr> \n   <th>completion_indicators</th> \n   <th>EXIT_SIGNAL</th> \n   <th>Result</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>&gt;= 2</td> \n   <td><code>true</code></td> \n   <td><strong>Exit</strong> (\"project_complete\")</td> \n  </tr> \n  <tr> \n   <td>&gt;= 2</td> \n   <td><code>false</code></td> \n   <td><strong>Continue</strong> (Claude still working)</td> \n  </tr> \n  <tr> \n   <td>&gt;= 2</td> \n   <td>missing</td> \n   <td><strong>Continue</strong> (defaults to false)</td> \n  </tr> \n  <tr> \n   <td>&lt; 2</td> \n   <td><code>true</code></td> \n   <td><strong>Continue</strong> (threshold not met)</td> \n  </tr> \n </tbody> \n</table> \n<h2>Project Structure</h2> \n<p>Ralph creates a standardized structure for each project:</p> \n<pre><code>my-project/\n├── PROMPT.md           # Main development instructions for Ralph\n├── @fix_plan.md        # Prioritized task list (@ prefix = Ralph control file)\n├── @AGENT.md           # Build and run instructions\n├── specs/              # Project specifications and requirements\n│   └── stdlib/         # Standard library specifications\n├── src/                # Source code implementation\n├── examples/           # Usage examples and test cases\n├── logs/               # Ralph execution logs\n└── docs/generated/     # Auto-generated documentation\n</code></pre> \n<h2>Best Practices</h2> \n<h3>Writing Effective Prompts</h3> \n<ol> \n <li><strong>Be Specific</strong> - Clear requirements lead to better results</li> \n <li><strong>Prioritize</strong> - Use <code>@fix_plan.md</code> to guide Ralph's focus</li> \n <li><strong>Set Boundaries</strong> - Define what's in/out of scope</li> \n <li><strong>Include Examples</strong> - Show expected inputs/outputs</li> \n</ol> \n<h3>Project Specifications</h3> \n<ul> \n <li>Place detailed requirements in <code>specs/</code></li> \n <li>Use <code>@fix_plan.md</code> for prioritized task tracking</li> \n <li>Keep <code>@AGENT.md</code> updated with build instructions</li> \n <li>Document key decisions and architecture</li> \n</ul> \n<h3>Monitoring Progress</h3> \n<ul> \n <li>Use <code>ralph-monitor</code> for live status updates</li> \n <li>Check logs in <code>logs/</code> for detailed execution history</li> \n <li>Monitor <code>status.json</code> for programmatic access</li> \n <li>Watch for exit condition signals</li> \n</ul> \n<h2>System Requirements</h2> \n<ul> \n <li><strong>Bash 4.0+</strong> - For script execution</li> \n <li><strong>Claude Code CLI</strong> - <code>npm install -g @anthropic-ai/claude-code</code></li> \n <li><strong>tmux</strong> - Terminal multiplexer for integrated monitoring (recommended)</li> \n <li><strong>jq</strong> - JSON processing for status tracking</li> \n <li><strong>Git</strong> - Version control (projects are initialized as git repos)</li> \n <li><strong>GNU coreutils</strong> - For the <code>timeout</code> command (execution timeouts) \n  <ul> \n   <li>Linux: Pre-installed on most distributions</li> \n   <li>macOS: Install via <code>brew install coreutils</code> (provides <code>gtimeout</code>)</li> \n  </ul> </li> \n <li><strong>Standard Unix tools</strong> - grep, date, etc.</li> \n</ul> \n<h3>Testing Requirements (Development)</h3> \n<p>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/TESTING.md\">TESTING.md</a> for the comprehensive testing guide.</p> \n<p>If you want to run the test suite:</p> \n<pre><code class=\"language-bash\"># Install BATS testing framework\nnpm install -g bats bats-support bats-assert\n\n# Run all tests (308 tests)\nnpm test\n\n# Run specific test suites\nbats tests/unit/test_rate_limiting.bats\nbats tests/unit/test_exit_detection.bats\nbats tests/unit/test_json_parsing.bats\nbats tests/unit/test_cli_modern.bats\nbats tests/unit/test_cli_parsing.bats\nbats tests/unit/test_session_continuity.bats\nbats tests/integration/test_loop_execution.bats\nbats tests/integration/test_prd_import.bats\nbats tests/integration/test_project_setup.bats\nbats tests/integration/test_installation.bats\n\n# Run error detection and circuit breaker tests\n./tests/test_error_detection.sh\n./tests/test_stuck_loop_detection.sh\n</code></pre> \n<p>Current test status:</p> \n<ul> \n <li><strong>308 tests</strong> across 11 test files</li> \n <li><strong>100% pass rate</strong> (308/308 passing)</li> \n <li>Comprehensive unit and integration tests</li> \n <li>Specialized tests for JSON parsing, CLI flags, circuit breaker, EXIT_SIGNAL behavior, and installation workflows</li> \n</ul> \n<blockquote> \n <p><strong>Note on Coverage</strong>: Bash code coverage measurement with kcov has fundamental limitations when tracing subprocess executions. Test pass rate (100%) is the quality gate. See <a href=\"https://github.com/bats-core/bats-core/issues/15\">bats-core#15</a> for details.</p> \n</blockquote> \n<h3>Installing tmux</h3> \n<pre><code class=\"language-bash\"># Ubuntu/Debian\nsudo apt-get install tmux\n\n# macOS\nbrew install tmux\n\n# CentOS/RHEL\nsudo yum install tmux\n</code></pre> \n<h3>Installing GNU coreutils (macOS)</h3> \n<p>Ralph uses the <code>timeout</code> command for execution timeouts. On macOS, you need to install GNU coreutils:</p> \n<pre><code class=\"language-bash\"># Install coreutils (provides gtimeout)\nbrew install coreutils\n\n# Verify installation\ngtimeout --version\n</code></pre> \n<p>Ralph automatically detects and uses <code>gtimeout</code> on macOS. No additional configuration is required after installation.</p> \n<h2>Monitoring and Debugging</h2> \n<h3>Live Dashboard</h3> \n<pre><code class=\"language-bash\"># Integrated tmux monitoring (recommended)\nralph --monitor\n\n# Manual monitoring in separate terminal\nralph-monitor\n</code></pre> \n<p>Shows real-time:</p> \n<ul> \n <li>Current loop count and status</li> \n <li>API calls used vs. limit</li> \n <li>Recent log entries</li> \n <li>Rate limit countdown</li> \n</ul> \n<p><strong>tmux Controls:</strong></p> \n<ul> \n <li><code>Ctrl+B</code> then <code>D</code> - Detach from session (keeps Ralph running)</li> \n <li><code>Ctrl+B</code> then <code>←/→</code> - Switch between panes</li> \n <li><code>tmux list-sessions</code> - View active sessions</li> \n <li><code>tmux attach -t &lt;session-name&gt;</code> - Reattach to session</li> \n</ul> \n<h3>Status Checking</h3> \n<pre><code class=\"language-bash\"># JSON status output\nralph --status\n\n# Manual log inspection\ntail -f logs/ralph.log\n</code></pre> \n<h3>Common Issues</h3> \n<ul> \n <li><strong>Rate Limits</strong> - Ralph automatically waits and displays countdown</li> \n <li><strong>5-Hour API Limit</strong> - Ralph detects and prompts for user action (wait or exit)</li> \n <li><strong>Stuck Loops</strong> - Check <code>@fix_plan.md</code> for unclear or conflicting tasks</li> \n <li><strong>Early Exit</strong> - Review exit thresholds if Ralph stops too soon</li> \n <li><strong>Premature Exit</strong> - Check if Claude is setting <code>EXIT_SIGNAL: false</code> (Ralph now respects this)</li> \n <li><strong>Execution Timeouts</strong> - Increase <code>--timeout</code> value for complex operations</li> \n <li><strong>Missing Dependencies</strong> - Ensure Claude Code CLI and tmux are installed</li> \n <li><strong>tmux Session Lost</strong> - Use <code>tmux list-sessions</code> and <code>tmux attach</code> to reconnect</li> \n <li><strong>Session Expired</strong> - Sessions expire after 24 hours by default; use <code>--reset-session</code> to start fresh</li> \n <li><strong>timeout: command not found (macOS)</strong> - Install GNU coreutils: <code>brew install coreutils</code></li> \n</ul> \n<h2>Contributing</h2> \n<p>Ralph is actively seeking contributors! We're working toward v1.0.0 with clear priorities and a detailed roadmap.</p> \n<p><strong>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for the complete contributor guide</strong> including:</p> \n<ul> \n <li>Getting started and setup instructions</li> \n <li>Development workflow and commit conventions</li> \n <li>Code style guidelines</li> \n <li>Testing requirements (100% pass rate mandatory)</li> \n <li>Pull request process and code review guidelines</li> \n <li>Quality standards and checklists</li> \n</ul> \n<h3>Quick Start</h3> \n<pre><code class=\"language-bash\"># Fork and clone\ngit clone https://github.com/YOUR_USERNAME/ralph-claude-code.git\ncd ralph-claude-code\n\n# Install dependencies and run tests\nnpm install\nnpm test  # All 308 tests must pass\n</code></pre> \n<h3>Priority Contribution Areas</h3> \n<ol> \n <li><strong>Test Implementation</strong> - Help expand test coverage</li> \n <li><strong>Feature Development</strong> - Log rotation, dry-run mode, config files, metrics</li> \n <li><strong>Documentation</strong> - Tutorials, troubleshooting guides, examples</li> \n <li><strong>Real-World Testing</strong> - Use Ralph, report bugs, share feedback</li> \n</ol> \n<p><strong>Every contribution matters</strong> - from fixing typos to implementing major features!</p> \n<h2>License</h2> \n<p>This project is licensed under the MIT License - see the <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/LICENSE\">LICENSE</a> file for details.</p> \n<h2>Acknowledgments</h2> \n<ul> \n <li>Inspired by the <a href=\"https://ghuntley.com/ralph/\">Ralph technique</a> created by Geoffrey Huntley</li> \n <li>Built for <a href=\"https://claude.ai/code\">Claude Code</a> by Anthropic</li> \n <li>Community feedback and contributions</li> \n</ul> \n<h2>Related Projects</h2> \n<ul> \n <li><a href=\"https://claude.ai/code\">Claude Code</a> - The AI coding assistant that powers Ralph</li> \n <li><a href=\"https://github.com/paul-gauthier/aider\">Aider</a> - Original Ralph technique implementation</li> \n</ul> \n<hr /> \n<h2>Command Reference</h2> \n<h3>Installation Commands (Run Once)</h3> \n<pre><code class=\"language-bash\">./install.sh              # Install Ralph globally\n./uninstall.sh            # Remove Ralph from system (dedicated script)\n./install.sh uninstall    # Alternative: Remove Ralph from system\n./install.sh --help       # Show installation help\n</code></pre> \n<h3>Ralph Loop Options</h3> \n<pre><code class=\"language-bash\">ralph [OPTIONS]\n  -h, --help              Show help message\n  -c, --calls NUM         Set max calls per hour (default: 100)\n  -p, --prompt FILE       Set prompt file (default: PROMPT.md)\n  -s, --status            Show current status and exit\n  -m, --monitor           Start with tmux session and live monitor\n  -v, --verbose           Show detailed progress updates during execution\n  -t, --timeout MIN       Set Claude Code execution timeout in minutes (1-120, default: 15)\n  --output-format FORMAT  Set output format: json (default) or text\n  --allowed-tools TOOLS   Set allowed Claude tools (default: Write,Bash(git *),Read)\n  --no-continue           Disable session continuity (start fresh each loop)\n  --reset-circuit         Reset the circuit breaker\n  --circuit-status        Show circuit breaker status\n  --reset-session         Reset session state manually\n</code></pre> \n<h3>Project Commands (Per Project)</h3> \n<pre><code class=\"language-bash\">ralph-setup project-name     # Create new Ralph project\nralph-import prd.md project  # Convert PRD/specs to Ralph project\nralph --monitor              # Start with integrated monitoring\nralph --status               # Check current loop status\nralph --verbose              # Enable detailed progress updates\nralph --timeout 30           # Set 30-minute execution timeout\nralph --calls 50             # Limit to 50 API calls per hour\nralph --reset-session        # Reset session state manually\nralph-monitor                # Manual monitoring dashboard\n</code></pre> \n<h3>tmux Session Management</h3> \n<pre><code class=\"language-bash\">tmux list-sessions        # View active Ralph sessions\ntmux attach -t &lt;name&gt;     # Reattach to detached session\n# Ctrl+B then D           # Detach from session (keeps running)\n</code></pre> \n<hr /> \n<h2>Development Roadmap</h2> \n<p>Ralph is under active development with a clear path to v1.0.0. See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">IMPLEMENTATION_PLAN.md</a> for the complete roadmap.</p> \n<h3>Current Status: v0.9.9</h3> \n<p><strong>What's Delivered:</strong></p> \n<ul> \n <li>Core loop functionality with intelligent exit detection</li> \n <li><strong>Dual-condition exit gate</strong> (completion indicators + EXIT_SIGNAL)</li> \n <li>Rate limiting (100 calls/hour) and circuit breaker pattern</li> \n <li>Response analyzer with semantic understanding</li> \n <li>308 comprehensive tests (100% pass rate)</li> \n <li>tmux integration and live monitoring</li> \n <li>PRD import functionality with modern CLI JSON parsing</li> \n <li>Installation system and project templates</li> \n <li>Modern CLI commands with JSON output support</li> \n <li>CI/CD pipeline with GitHub Actions</li> \n <li>Comprehensive installation test suite</li> \n <li>Session lifecycle management with auto-reset triggers</li> \n <li>Session expiration with configurable timeout</li> \n <li>Dedicated uninstall script</li> \n</ul> \n<p><strong>Test Coverage Breakdown:</strong></p> \n<ul> \n <li>Unit Tests: 164 (CLI parsing, JSON, exit detection, rate limiting, session continuity)</li> \n <li>Integration Tests: 144 (loop execution, edge cases, installation, project setup, PRD import)</li> \n <li>Test Files: 11</li> \n</ul> \n<h3>Path to v1.0.0 (~4 weeks)</h3> \n<p><strong>Enhanced Testing</strong></p> \n<ul> \n <li>Installation and setup workflow tests</li> \n <li>tmux integration tests</li> \n <li>Monitor dashboard tests</li> \n</ul> \n<p><strong>Core Features</strong></p> \n<ul> \n <li>Log rotation functionality</li> \n <li>Dry-run mode</li> \n <li>Configuration file support - .ralphrc</li> \n</ul> \n<p><strong>Advanced Features &amp; Polish</strong></p> \n<ul> \n <li>Metrics and analytics tracking</li> \n <li>Desktop notifications</li> \n <li>Git backup and rollback system</li> \n <li>End-to-end tests</li> \n <li>Final documentation and release prep</li> \n</ul> \n<p>See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_STATUS.md\">IMPLEMENTATION_STATUS.md</a> for detailed progress tracking.</p> \n<h3>How to Contribute</h3> \n<p>Ralph is seeking contributors! See <a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for the complete guide. Priority areas:</p> \n<ol> \n <li><strong>Test Implementation</strong> - Help expand test coverage (<a href=\"https://raw.githubusercontent.com/frankbria/ralph-claude-code/main/IMPLEMENTATION_PLAN.md\">see plan</a>)</li> \n <li><strong>Feature Development</strong> - Log rotation, dry-run mode, config files</li> \n <li><strong>Documentation</strong> - Usage examples, tutorials, troubleshooting guides</li> \n <li><strong>Bug Reports</strong> - Real-world usage feedback and edge cases</li> \n</ol> \n<hr /> \n<p><strong>Ready to let AI build your project?</strong> Start with <code>./install.sh</code> and let Ralph take it from there!</p> \n<h2>Star History</h2> \n<p><a href=\"https://www.star-history.com/#frankbria/ralph-claude-code&amp;type=date&amp;legend=top-left\"><img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=frankbria/ralph-claude-code&amp;type=date&amp;legend=top-left\" /></a></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:14.549236Z",
        "tags": [
          {
            "name": "transformation",
            "score": 6
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 25,
        "timeliness_score": 1,
        "final_score": 8.2,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/keyshade/common-ci-misconfigurations-that-leak-credentials-1ag1",
        "title": "Common CI Misconfigurations That Leak Credentials",
        "summary": "<p>In this blog, we break down the most common CI misconfigurations that lead to credential leaks in real production systems. We will focus on practical failure modes seen in modern DevOps pipelines and explain how engineering teams can reduce risk without slowing delivery.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>Table of Contents</strong>\n</h2>\n\n<ol>\n<li>Introduction</li>\n<li>Why CI Pipelines Are High Risk</li>\n<li>Common CI Misconfigurations That Leak Credentials\n\n<ul>\n<li>Secrets Printed in Logs</li>\n<li>Long-lived CI Credentials</li>\n<li>Over Privileged CI Runners</li>\n<li>Secrets Baked Into Build Artifacts</li>\n<li>Shared CI Configuration Across Repositories</li>\n<li>Fork and Pull Request Exposure</li>\n<li>Forgotten Pipelines and Environments</li>\n<li>Hardcoded CI Secrets</li>\n</ul>\n</li>\n<li>Tools and Platforms Commonly Involved</li>\n<li>How Better Secret Management Helps</li>\n<li>FAQs</li>\n<li>Final Thoughts</li>\n</ol>\n\n\n\n\n<h2>\n  \n  \n  <strong>Introduction</strong>\n</h2>\n\n<p>CI pipelines are trusted infrastructure. They build code, run tests, publish artifacts, and deploy to production. Because they sit at the center of the delivery process, they often hold powerful credentials.</p>\n\n<p>Most credential and secrets leaks do not happen because of negligence. They happen because CI configuration evolves quietly over time. Debug settings remain enabled. Permissions grow. Old secrets are never rotated. Eventually, something sensitive leaks through logs, artifacts, or misconfigured workflows.</p>\n\n<p>Understanding how these failures occur is the first step toward preventing them.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>Why CI Pipelines Are High Risk</strong>\n</h2>\n\n<p>CI systems commonly have access to:</p>\n\n<ul>\n<li>Cloud provider credentials</li>\n<li>Deployment keys</li>\n<li>Package registry tokens</li>\n<li>Internal service credentials</li>\n</ul>\n\n<p>Unlike application code, CI configuration is rarely reviewed as security critical. YAML files are edited under delivery pressure and rarely revisited. This makes CI a high-value target and a frequent source of accidental leaks.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>Common CI Misconfigurations That Leak Credentials</strong>\n</h2>\n\n<h3>\n  \n  \n  <strong>1. Secrets Printed in Logs</strong>\n</h3>\n\n<p>This is the most common and most underestimated issue.</p>\n\n<p>It usually happens during debugging. A variable is echoed to confirm it exists. Verbose logging is enabled for a CLI. A shell script runs with debug output enabled.</p>\n\n<p>Common examples include:</p>\n\n<ul>\n<li>Environment variables printed directly</li>\n<li>CLI tools logging request headers</li>\n<li>Debug flags left enabled in CI jobs</li>\n</ul>\n\n<p>Once secrets appear in logs, they spread quickly. Logs are stored, indexed, exported, and sometimes shared externally.</p>\n\n<p>How do we reduce risk?</p>\n\n<ul>\n<li>Treat CI logs as public artifacts</li>\n<li>Mask secrets at the CI platform level</li>\n<li>Disable shell debug output by default</li>\n<li>Use tools that redact sensitive output automatically</li>\n</ul>\n\n<p>A clear example of what not to do:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>export API_KEY=\"12345EXAMPLEKEY\"\necho \"Starting deployment with API_KEY=$API_KEY\"\n</code></pre>\n\n</div>\n\n\n\n<p>In this script, the <code>API_KEY</code> is printed directly to the logs, exposing sensitive information. If these logs are stored or shared, the secret is compromised.</p>\n\n<p>A better approach is:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>export API_KEY=\"12345EXAMPLEKEY\"\necho \"Starting deployment\"\n</code></pre>\n\n</div>\n\n\n\n<p>Alternatively, use secret masking tools provided by your CI platform to ensure sensitive data is never logged.</p>\n\n\n\n\n<h3>\n  \n  \n  <strong>2. Long-Lived CI Credentials</strong>\n</h3>\n\n<p>Many pipelines still rely on static credentials that never expire.</p>\n\n<p>Common examples:</p>\n\n<ul>\n<li>Cloud access keys created years ago</li>\n<li>Registry tokens shared across projects</li>\n<li>Deployment secrets reused across environments</li>\n</ul>\n\n<p>These credentials often outlive the services and teams that created them.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Use short-lived credentials wherever possible</li>\n<li>Rotate CI secrets automatically</li>\n<li>Scope credentials per pipeline and per environment</li>\n<li>Remove human owned credentials from CI</li>\n</ul>\n\n\n\n\n<h3>\n  \n  \n  <strong>3. Over Privileged CI Runners</strong>\n</h3>\n\n<p>CI runners frequently have more permissions than necessary.</p>\n\n<p>A single pipeline may be able to:</p>\n\n<ul>\n<li>Deploy to production</li>\n<li>Read all environment secrets</li>\n<li>Modify infrastructure</li>\n</ul>\n\n<p>This creates a large blast radius if a pipeline is compromised.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Apply least-privilege to CI identities</li>\n<li>Separate build, test, and deploy permissions</li>\n<li>Isolate production credentials from non production workflows</li>\n</ul>\n\n\n\n\n<h3>\n  \n  \n  <strong>4. Secrets Baked Into Build Artifacts</strong>\n</h3>\n\n<p>Injecting secrets at build time is a subtle but serious mistake.</p>\n\n<p>This can lead to:</p>\n\n<ul>\n<li>Secrets embedded in container layers</li>\n<li>Credentials stored in build caches</li>\n<li>Tokens copied into compiled artifacts</li>\n</ul>\n\n<p>Once baked in, secrets are difficult to revoke cleanly.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Inject secrets only at runtime</li>\n<li>Keep build artifacts completely secret free</li>\n<li>Audit container images regularly</li>\n</ul>\n\n<p>Let's take a look at a case of what not to do:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>FROM node:16\n\nENV API_KEY=12345EXAMPLEKEY\nENV API_SECRET=abcdeEXAMPLESECRET\n\nCOPY . /app\nWORKDIR /app\nRUN npm install\nCMD [\"npm\", \"start\"]\n</code></pre>\n\n</div>\n\n\n\n<p>In this Dockerfile, the <code>API_KEY</code> and <code>API_SECRET</code> are embedded directly into the container image. If the image is shared or pushed to a public registry, these secrets are exposed.</p>\n\n<p>Instead, we use runtime injection:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>FROM node:16\n\nCOPY . /app\nWORKDIR /app\nRUN npm install\nCMD [\"npm\", \"start\"]\n</code></pre>\n\n</div>\n\n\n\n<p>Now at runtime, inject secrets using environment variables or a secret management tool:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>docker run -e API_KEY=12345EXAMPLEKEY -e API_SECRET=abcdeEXAMPLESECRET my-secure-app\n</code></pre>\n\n</div>\n\n\n\n<p>This approach ensures secrets are never baked into the image and remain secure by leveraging dynamic injection tools like Keyshade.</p>\n\n\n\n\n<h3>\n  \n  \n  <strong>5. Shared CI Configuration Across Repositories</strong>\n</h3>\n\n<p>Shared CI templates improve consistency but can introduce risk.</p>\n\n<p>A template with powerful secrets may be reused in places that do not require them. Internal tools can accidentally inherit production access.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Avoid global secrets in shared templates</li>\n<li>Require explicit opt in for sensitive credentials</li>\n<li>Review inherited permissions regularly</li>\n</ul>\n\n\n\n\n<h3>\n  \n  \n  <strong>6. Fork and Pull Request Exposure</strong>\n</h3>\n\n<p>Public repositories often run CI on pull requests.</p>\n\n<p>If secrets are exposed to untrusted forks, attackers can exfiltrate them with trivial changes.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Never expose secrets to forked builds</li>\n<li>Use separate workflows for untrusted code</li>\n<li>Disable secret access on pull request pipelines</li>\n</ul>\n\n<p>An example of what can go wrong:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>name: CI Pipeline\n\non:\n\n  pull_request:\n\n    branches:\n\n      - main\n\njobs:\n\n  build:\n\n    runs-on: ubuntu-latest\n\n    steps:\n\n      - name: Checkout code\n\n        uses: actions/checkout@v2\n\n      - name: Use secret\n\n        run: echo ${{ secrets.PROD_API_KEY }}\n</code></pre>\n\n</div>\n\n\n\n<p>In this configuration, the <code>PROD_API_KEY</code> secret is accessible during pull request builds. If an attacker forks the repository and modifies the <code>run</code> step to <code>echo</code> the secret, they can easily capture it.</p>\n\n<p>To fix this, you can restrict secret access:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>name: CI Pipeline\n\non:\n\n  pull_request:\n\n    branches:\n\n      - main\n\njobs:\n\n  build:\n\n    if: github.event.pull_request.head.repo.full_name == github.repository\n\n    runs-on: ubuntu-latest\n\n    steps:\n\n      - name: Checkout code\n\n        uses: actions/checkout@v2\n\n      - name: Use secret\n\n        run: echo ${{ secrets.PROD_API_KEY }}\n</code></pre>\n\n</div>\n\n\n\n<p>This ensures secrets are only accessible for pull requests originating from the <span>same repository</span>, not from forks.</p>\n\n\n\n\n<h3>\n  \n  \n  <strong>7. Forgotten Pipelines and Environments</strong>\n</h3>\n\n<p>Old pipelines rarely get deleted.</p>\n\n<p>Staging jobs, preview environments, and deprecated services often retain valid credentials long after they stop being used.</p>\n\n<p>How to reduce risk:</p>\n\n<ul>\n<li>Audit CI pipelines regularly</li>\n<li>Expire secrets for inactive projects automatically</li>\n<li>Track ownership for every pipeline</li>\n</ul>\n\n\n\n\n<h3>\n  \n  \n  <strong>8. Hardcoded CI Secrets</strong>\n</h3>\n\n<p>Hardcoding secrets in CI pipelines is a common yet a very risky shortcut. This happens when sensitive info like API keys or passwords is directly written into CI scripts or YAML files. It might seem quick and easy to us developers, but it opens the door to serious security issues.</p>\n\n<p>Why It’s Risky:</p>\n\n<ul>\n<li>Accidental Leaks:** **Hardcoded secrets can end up in version control (like Git). If the repo is public or shared, anyone can see them.</li>\n<li>Hard to Rotate: Changing secrets means editing code or configs, which can be messy and error-prone.</li>\n<li>Overexposure: Hardcoded secrets are often reused across multiple pipelines or environments, making a single leak much worse.</li>\n</ul>\n\n<p>Here’s a bad practice:<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>env:\n\n  AWS_ACCESS_KEY_ID: AKIAEXAMPLE123\n\n  AWS_SECRET_ACCESS_KEY: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n</code></pre>\n\n</div>\n\n\n\n<p>If this file gets pushed to a public repo, those credentials are compromised instantly.</p>\n\n<p>How<a href=\"http://keyshade.io\" rel=\"noopener noreferrer\">Keyshade.io</a> can help: Keyshade injects secrets dynamically at runtime, so they’re never hardcoded or stored in your CI configs. This means no accidental leaks in your repos and no manual secret rotation headaches. It keeps your pipelines secure by default.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>Tools and Platforms Commonly Involved</strong>\n</h2>\n\n<p>Credential leaks frequently involve CI systems and tooling such as:</p>\n\n<ul>\n<li>GitHub Actions</li>\n<li>GitLab CI</li>\n<li>Jenkins</li>\n<li>CircleCI</li>\n<li>Cloud CLIs and deployment tools</li>\n<li>Container build systems</li>\n</ul>\n\n<p>The risk usually comes from how these tools are configured, not from the tools themselves.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>How Better Secret Management Helps</strong>\n</h2>\n\n<p>Many CI issues persist because secrets are spread across dashboards, variables, scripts, and templates.</p>\n\n<p>Platforms like<a href=\"https://keyshade.io\" rel=\"noopener noreferrer\">Keyshade</a> reduce this surface area by injecting secrets dynamically at runtime, scoped to the exact job and environment that needs them. This limits blast radius, removes static credentials, and reduces manual handling by engineers.</p>\n\n<p>Good tooling makes secure behavior the default, instead of an extra step.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>FAQs</strong>\n</h2>\n\n<h3>\n  \n  \n  <strong>Are CI credential leaks common</strong>\n</h3>\n\n<p>Yes. Many leaks are discovered internally during audits or incident response and never become public. CI logs and pipelines are frequent sources.</p>\n\n<h3>\n  \n  \n  <strong>Should CI pipelines access production secrets</strong>\n</h3>\n\n<p>Only when required and only at runtime. Build and test stages should never need production credentials.</p>\n\n<h3>\n  \n  \n  <strong>Is masking secrets in logs enough</strong>\n</h3>\n\n<p>No. Masking helps reduce accidental exposure but does not prevent misuse or secrets being baked into artifacts.</p>\n\n<h3>\n  \n  \n  <strong>How often should CI secrets be rotated</strong>\n</h3>\n\n<p>As frequently as possible and ideally automatically. Manual rotation does not scale reliably.</p>\n\n\n\n\n<h2>\n  \n  \n  <strong>Final Thoughts</strong>\n</h2>\n\n<p>CI pipelines deserve the same security attention as production services.</p>\n\n<p>Most credential leaks are not the result of sophisticated attacks. They come from defaults, convenience, and forgotten configuration. Strong CI security is not about adding friction. It is about designing systems where leaking secrets is difficult by default.</p>\n\n<p>That is what mature DevOps looks like.</p>",
        "source": "dev.to",
        "published": "Wed, 21 Jan 2026 21:44:16 +0000",
        "fetched_at": "2026-01-21T23:21:19.543422Z",
        "tags": [
          {
            "name": "transformation",
            "score": 12
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 5
          }
        ],
        "structural_score": 21,
        "timeliness_score": 2,
        "final_score": 7.7,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/AlexxIT/go2rtc",
        "title": "AlexxIT/go2rtc",
        "summary": "<p>Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.</p><hr /><h1 align=\"center\"> <p><img alt=\"go2rtc\" src=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/logo.gif\" /> <br /> <a href=\"https://github.com/AlexxIT/go2rtc/stargazers\"><img alt=\"stars\" src=\"https://img.shields.io/github/stars/AlexxIT/go2rtc?style=flat-square&amp;logo=github\" /></a> <a href=\"https://hub.docker.com/r/alexxit/go2rtc\"><img alt=\"docker pulls\" src=\"https://img.shields.io/docker/pulls/alexxit/go2rtc?style=flat-square&amp;logo=docker&amp;logoColor=white&amp;label=pulls\" /></a> <a href=\"https://github.com/AlexxIT/go2rtc/releases\"><img alt=\"releases\" src=\"https://img.shields.io/github/downloads/AlexxIT/go2rtc/total?color=blue&amp;style=flat-square&amp;logo=github\" /></a> <a href=\"https://goreportcard.com/report/github.com/AlexxIT/go2rtc\"><img alt=\"goreport\" src=\"https://goreportcard.com/badge/github.com/AlexxIT/go2rtc\" /></a></p> </h1> \n<p>Ultimate camera streaming application with support for RTSP, WebRTC, HomeKit, FFmpeg, RTMP, etc.</p> \n<p><img alt=\"\" src=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/go2rtc.png\" /></p> \n<ul> \n <li>zero-dependency and zero-config <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary\">small app</a> for all OS (Windows, macOS, Linux, ARM)</li> \n <li>zero-delay for many supported protocols (lowest possible streaming latency)</li> \n <li>streaming from <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp\">RTSP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp\">RTMP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip\">DVRIP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http\">HTTP</a> (FLV/MJPEG/JPEG/TS), <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device\">USB Cameras</a> and <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">other sources</a></li> \n <li>streaming from any sources, supported by <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg</a></li> \n <li>streaming to <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp\">RTSP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">WebRTC</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">MSE/MP4</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-homekit\">HomeKit</a> <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls\">HLS</a> or <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg\">MJPEG</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#publish-stream\">publish</a> any source to popular streaming services (YouTube, Telegram, etc.)</li> \n <li>first project in the World with support streaming from <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit\">HomeKit Cameras</a></li> \n <li>on-the-fly transcoding for unsupported codecs via <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg</a></li> \n <li>play audio files and live streams on some cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera\">speaker</a></li> \n <li>multi-source two-way <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-negotiation\">codecs negotiation</a> \n  <ul> \n   <li>mixing tracks from different sources to single stream</li> \n   <li>auto-match client-supported codecs</li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two-way audio</a> for some cameras</li> \n  </ul> </li> \n <li>can be <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api\">integrated to</a> any smart home platform or be used as <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary\">standalone app</a></li> \n</ul> \n<p><strong>Supported Formats</strong> - describes the communication API: authorization, encryption, command set, structure of media packets</p> \n<ul> \n <li>devices: <code>alsa</code> (Linux audio), <code>v4l2</code> (Linux video)</li> \n <li>files: <code>adts</code>, <code>flv</code>, <code>h264</code>, <code>hevc</code>, <code>hls</code>, <code>mjpeg</code>, <code>mpegts</code>, <code>mp4</code>, <code>wav</code></li> \n <li>network (public and well known): <code>mpjpeg</code>, <code>onvif</code>, <code>rtmp</code>, <code>rtp</code>, <code>rtsp</code>, <code>webrtc</code>, <code>yuv4mpegpipe</code></li> \n <li>network (private and exclusive): <code>bubble</code>, <code>doorbird</code>, <code>dvrip</code>, <code>eseecloud</code>, <code>gopro</code>, <code>hass</code> (Home Assistant), <code>homekit</code> (Apple), <code>isapi</code> (Hikvision), <code>kasa</code> (TP-Link), <code>multitrans</code> (TP-Link), <code>nest</code> (Google), <code>ring</code>, <code>roborock</code>, <code>tapo</code> and <code>vigi</code> (TP-Link), <code>tuya</code>, <code>webtorrent</code>, <code>wyze</code>, <code>xiaomi</code> (Mi Home)</li> \n <li>webrtc related: <code>creality</code>, <code>kinesis</code> (Amazon), <code>openipc</code>, <code>switchbot</code>, <code>whep</code>, <code>whip</code>, <code>wyze</code></li> \n <li>other: <code>ascii</code>, <code>echo</code>, <code>exec</code>, <code>expr</code>, <code>ffmpeg</code></li> \n</ul> \n<p><strong>Supported Protocols</strong> - describes the transport for data transmission</p> \n<ul> \n <li>public: <code>http</code>, <code>pipe</code>, <code>rtmp</code>, <code>rtsp</code>, <code>tcp</code>, <code>udp</code>, <code>webrtc</code>, <code>ws</code> (WebSocket)</li> \n <li>private: <code>cs2</code> (PPPP), <code>hap</code> and <code>hds</code> (HomeKit), <code>tutk</code> (P2P)</li> \n</ul> \n<p><strong>Inspired by:</strong></p> \n<ul> \n <li>series of streaming projects from <a href=\"https://github.com/deepch\">@deepch</a></li> \n <li><a href=\"https://github.com/pion/webrtc\">webrtc</a> go library and whole <a href=\"https://github.com/pion\">@pion</a> team</li> \n <li><a href=\"https://github.com/aler9/rtsp-simple-server\">rtsp-simple-server</a> idea from <a href=\"https://github.com/aler9\">@aler9</a></li> \n <li><a href=\"https://gstreamer.freedesktop.org/\">GStreamer</a> framework pipeline idea</li> \n <li><a href=\"https://mediasoup.org/\">MediaSoup</a> framework routing idea</li> \n <li>HomeKit Accessory Protocol from <a href=\"https://github.com/brutella/hap\">@brutella</a></li> \n <li>creator of the project's logo <a href=\"https://www.instagram.com/v_novoseltsev\">@v_novoseltsev</a></li> \n</ul> \n<blockquote> \n <p>[!CAUTION] The official website of the project is this GitHub repository and go2rtc.org (hosted on GitHub Pages). The website go2rtc[.]com is in no way associated with the authors of this project.</p> \n</blockquote> \n<hr /> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start\">Fast start</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary\">go2rtc: Binary</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-docker\">go2rtc: Docker</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on\">go2rtc: Home Assistant Add-on</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration\">go2rtc: Home Assistant Integration</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-dev-version\">go2rtc: Dev version</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration\">Configuration</a> \n  <ul> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">Module: Streams</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">Two way audio</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp\">Source: RTSP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp\">Source: RTMP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http\">Source: HTTP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-onvif\">Source: ONVIF</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">Source: FFmpeg</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device\">Source: FFmpeg Device</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec\">Source: Exec</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo\">Source: Echo</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-expr\">Source: Expr</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit\">Source: HomeKit</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-bubble\">Source: Bubble</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip\">Source: DVRIP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo\">Source: Tapo</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-kasa\">Source: Kasa</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-multitrans\">Source: Multitrans</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya\">Source: Tuya</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi\">Source: Xiaomi</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-wyze\">Source: Wyze</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-gopro\">Source: GoPro</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ivideon\">Source: Ivideon</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass\">Source: Hass</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi\">Source: ISAPI</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-nest\">Source: Nest</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring\">Source: Ring</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock\">Source: Roborock</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird\">Source: Doorbird</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webrtc\">Source: WebRTC</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent\">Source: WebTorrent</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources\">Incoming sources</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera\">Stream to camera</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#publish-stream\">Publish stream</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#preload-stream\">Preload stream</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api\">Module: API</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp\">Module: RTSP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp\">Module: RTMP</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">Module: WebRTC</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-homekit\">Module: HomeKit</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent\">Module: WebTorrent</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-ngrok\">Module: ngrok</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass\">Module: Hass</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">Module: MP4</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls\">Module: HLS</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg\">Module: MJPEG</a></li> \n   <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-log\">Module: Log</a></li> \n  </ul> </li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#security\">Security</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters\">Codecs filters</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-madness\">Codecs madness</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-negotiation\">Codecs negotiation</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#projects-using-go2rtc\">Projects using go2rtc</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#cameras-experience\">Camera experience</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#tips\">TIPS</a></li> \n</ul> \n<h1>Fast start</h1> \n<ol> \n <li>Download <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary\">binary</a> or use <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-docker\">Docker</a> or Home Assistant <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on\">Add-on</a> or <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration\">Integration</a></li> \n <li>Open web interface: <code>http://localhost:1984/</code></li> \n</ol> \n<p><strong>Optionally:</strong></p> \n<ul> \n <li>add your <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">streams</a> to <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration\">config</a> file</li> \n <li>setup <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">external access</a> to webrtc</li> \n</ul> \n<p><strong>Developers:</strong></p> \n<ul> \n <li>write your own <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api\">web interface</a></li> \n <li>integrate <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api\">web api</a> into your smart home platform</li> \n</ul> \n<h2>go2rtc: Binary</h2> \n<p>Download binary for your OS from <a href=\"https://github.com/AlexxIT/go2rtc/releases/\">latest release</a>:</p> \n<ul> \n <li><code>go2rtc_win64.zip</code> - Windows 10+ 64-bit</li> \n <li><code>go2rtc_win32.zip</code> - Windows 10+ 32-bit</li> \n <li><code>go2rtc_win_arm64.zip</code> - Windows ARM 64-bit</li> \n <li><code>go2rtc_linux_amd64</code> - Linux 64-bit</li> \n <li><code>go2rtc_linux_i386</code> - Linux 32-bit</li> \n <li><code>go2rtc_linux_arm64</code> - Linux ARM 64-bit (ex. Raspberry 64-bit OS)</li> \n <li><code>go2rtc_linux_arm</code> - Linux ARM 32-bit (ex. Raspberry 32-bit OS)</li> \n <li><code>go2rtc_linux_armv6</code> - Linux ARMv6 (for old Raspberry 1 and Zero)</li> \n <li><code>go2rtc_linux_mipsel</code> - Linux MIPS (ex. <a href=\"https://github.com/AlexxIT/XiaomiGateway3\">Xiaomi Gateway 3</a>, <a href=\"https://github.com/gtxaspec/wz_mini_hacks\">Wyze cameras</a>)</li> \n <li><code>go2rtc_mac_amd64.zip</code> - macOS 11+ Intel 64-bit</li> \n <li><code>go2rtc_mac_arm64.zip</code> - macOS ARM 64-bit</li> \n <li><code>go2rtc_freebsd_amd64.zip</code> - FreeBSD 64-bit</li> \n <li><code>go2rtc_freebsd_arm64.zip</code> - FreeBSD ARM 64-bit</li> \n</ul> \n<p>Don't forget to fix the rights <code>chmod +x go2rtc_xxx_xxx</code> on Linux and Mac.</p> \n<p>PS. The application is compiled with the latest versions of the Go language for maximum speed and security. Therefore, the <a href=\"https://go.dev/wiki/MinimumRequirements\">minimum OS versions</a> depend on the Go language.</p> \n<h2>go2rtc: Docker</h2> \n<p>The Docker container <a href=\"https://hub.docker.com/r/alexxit/go2rtc\"><code>alexxit/go2rtc</code></a> supports multiple architectures including <code>amd64</code>, <code>386</code>, <code>arm64</code>, and <code>arm</code>. This container offers the same functionality as the <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on\">Home Assistant Add-on</a> but is designed to operate independently of Home Assistant. It comes preinstalled with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg</a> and <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo\">Python</a>.</p> \n<h2>go2rtc: Home Assistant Add-on</h2> \n<p><a href=\"https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons\"><img alt=\"\" src=\"https://my.home-assistant.io/badges/supervisor_addon.svg?sanitize=true\" /></a></p> \n<ol> \n <li>Install Add-On: \n  <ul> \n   <li>Settings &gt; Add-ons &gt; Plus &gt; Repositories &gt; Add <code>https://github.com/AlexxIT/hassio-addons</code></li> \n   <li>go2rtc &gt; Install &gt; Start</li> \n  </ul> </li> \n <li>Setup <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass\">Integration</a></li> \n</ol> \n<h2>go2rtc: Home Assistant Integration</h2> \n<p><a href=\"https://github.com/AlexxIT/WebRTC\">WebRTC Camera</a> custom component can be used on any <a href=\"https://www.home-assistant.io/installation/\">Home Assistant installation</a>, including <a href=\"https://github.com/AlexxIT/HassWP\">HassWP</a> on Windows. It can automatically download and use the latest version of go2rtc. Or it can connect to an existing version of go2rtc. Addon installation in this case is optional.</p> \n<h2>go2rtc: Dev version</h2> \n<p>Latest, but maybe unstable version:</p> \n<ul> \n <li>Binary: <a href=\"https://nightly.link/AlexxIT/go2rtc/workflows/build/master\">latest nightly release</a></li> \n <li>Docker: <code>alexxit/go2rtc:master</code> or <code>alexxit/go2rtc:master-hardware</code> versions</li> \n <li>Hass Add-on: <code>go2rtc master</code> or <code>go2rtc master hardware</code> versions</li> \n</ul> \n<h1>Configuration</h1> \n<ul> \n <li>by default go2rtc will search <code>go2rtc.yaml</code> in the current work directory</li> \n <li><code>api</code> server will start on default <strong>1984 port</strong> (TCP)</li> \n <li><code>rtsp</code> server will start on default <strong>8554 port</strong> (TCP)</li> \n <li><code>webrtc</code> will use port <strong>8555</strong> (TCP/UDP) for connections</li> \n <li><code>ffmpeg</code> will use default transcoding options</li> \n</ul> \n<p>Configuration options and a complete list of settings can be found in <a href=\"https://github.com/AlexxIT/go2rtc/wiki/Configuration\">the wiki</a>.</p> \n<p>Available modules:</p> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">streams</a></li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api\">api</a> - HTTP API (important for WebRTC support)</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp\">rtsp</a> - RTSP Server (important for FFmpeg support)</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">webrtc</a> - WebRTC Server</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">mp4</a> - MSE, MP4 stream and MP4 snapshot Server</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls\">hls</a> - HLS TS or fMP4 stream Server</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg\">mjpeg</a> - MJPEG Server</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">ffmpeg</a> - FFmpeg integration</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-ngrok\">ngrok</a> - ngrok integration (external access for private network)</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass\">hass</a> - Home Assistant integration</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-log\">log</a> - logs config</li> \n</ul> \n<h2>Module: Streams</h2> \n<p><strong>go2rtc</strong> supports different stream source types. You can config one or multiple links of any type as a stream source.</p> \n<p>Available source types:</p> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp\">rtsp</a> - <code>RTSP</code> and <code>RTSPS</code> cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two-way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp\">rtmp</a> - <code>RTMP</code> streams</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http\">http</a> - <code>HTTP-FLV</code>, <code>MPEG-TS</code>, <code>JPEG</code> (snapshots), <code>MJPEG</code> streams</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-onvif\">onvif</a> - get camera <code>RTSP</code> link and snapshot link using <code>ONVIF</code> protocol</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">ffmpeg</a> - FFmpeg integration (<code>HLS</code>, <code>files</code> and many others)</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device\">ffmpeg:device</a> - local USB Camera or Webcam</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec\">exec</a> - get media from external app output</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo\">echo</a> - get stream link from bash or python</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-expr\">expr</a> - get stream link via built-in expression language</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit\">homekit</a> - streaming from HomeKit Camera</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-bubble\">bubble</a> - streaming from ESeeCloud/dvr163 NVR</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip\">dvrip</a> - streaming from DVR-IP NVR</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-eseecloud\">eseecloud</a> - streaming from ESeeCloud/dvr163 NVR</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo\">tapo</a> - TP-Link Tapo cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring\">ring</a> - Ring cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya\">tuya</a> - Tuya cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi\">xiaomi</a> - Xiaomi cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo\">kasa</a> - TP-Link Kasa cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-gopro\">gopro</a> - GoPro cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ivideon\">ivideon</a> - public cameras from <a href=\"https://tv.ivideon.com/\">Ivideon</a> service</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass\">hass</a> - Home Assistant integration</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi\">isapi</a> - two-way audio for Hikvision (ISAPI) cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock\">roborock</a> - Roborock vacuums with cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird\">doorbird</a> - Doorbird cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webrtc\">webrtc</a> - WebRTC/WHEP sources</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent\">webtorrent</a> - WebTorrent source from another go2rtc</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-wyze\">wyze</a> - Wyze cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support</li> \n</ul> \n<p>Read more about <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources\">incoming sources</a></p> \n<h2>Two-way audio</h2> \n<p>Supported sources:</p> \n<ul> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp\">RTSP cameras</a> with <a href=\"https://www.onvif.org/specs/stream/ONVIF-Streaming-Spec.pdf\">ONVIF Profile T</a> (back channel connection)</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip\">DVRIP</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo\">TP-Link Tapo</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi\">Hikvision ISAPI</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock\">Roborock vacuums</a> models with cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird\">Doorbird</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec\">Exec</a> audio on server</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring\">Ring</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya\">Tuya</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-wyze\">Wyze</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi\">Xiaomi</a> cameras</li> \n <li><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-browser\">Any Browser</a> as IP-camera</li> \n</ul> \n<p>Two-way audio can be used in browser with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">WebRTC</a> technology. The browser will give access to the microphone only for HTTPS sites (<a href=\"https://stackoverflow.com/questions/52759992/how-to-access-camera-and-microphone-in-chrome-without-https\">read more</a>).</p> \n<p>go2rtc also supports <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera\">play audio</a> files and live streams on this cameras.</p> \n<h2>Source: RTSP</h2> \n<pre><code class=\"language-yaml\">streams:\n  sonoff_camera: rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0\n  dahua_camera:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0&amp;unicast=true&amp;proto=Onvif\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1#backchannel=0\n  amcrest_doorbell:\n    - rtsp://username:password@192.168.1.123:554/cam/realmonitor?channel=1&amp;subtype=0#backchannel=0\n  unifi_camera: rtspx://192.168.1.123:7441/fD6ouM72bWoFijxK\n  glichy_camera: ffmpeg:rtsp://username:password@192.168.1.123/live/ch00_1 \n</code></pre> \n<p><strong>Recommendations</strong></p> \n<ul> \n <li><strong>Amcrest Doorbell</strong> users may want to disable two-way audio, because with an active stream, you won't have a working call button. You need to add <code>#backchannel=0</code> to the end of your RTSP link in YAML config file</li> \n <li><strong>Dahua Doorbell</strong> users may want to change <a href=\"https://github.com/AlexxIT/go2rtc/issues/49#issuecomment-2127107379\">audio codec</a> for proper 2-way audio. Make sure not to request backchannel multiple times by adding <code>#backchannel=0</code> to other stream sources of the same doorbell. The <code>unicast=true&amp;proto=Onvif</code> is preferred for 2-way audio as this makes the doorbell accept multiple codecs for the incoming audio</li> \n <li><strong>Reolink</strong> users may want NOT to use RTSP protocol at all, some camera models have a very awful, unusable stream implementation</li> \n <li><strong>Ubiquiti UniFi</strong> users may want to disable HTTPS verification. Use <code>rtspx://</code> prefix instead of <code>rtsps://</code>. And don't use <code>?enableSrtp</code> <a href=\"https://github.com/AlexxIT/go2rtc/issues/81\">suffix</a></li> \n <li><strong>TP-Link Tapo</strong> users may skip login and password, because go2rtc support login <a href=\"https://drmnsamoliu.github.io/video.html\">without them</a></li> \n <li>If your camera has two RTSP links, you can add both as sources. This is useful when streams have different codecs, for example AAC audio with main stream and PCMU/PCMA audio with second stream</li> \n <li>If the stream from your camera is glitchy, try using <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">ffmpeg source</a>. It will not add CPU load if you don't use transcoding</li> \n <li>If the stream from your camera is very glitchy, try to use transcoding with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">ffmpeg source</a></li> \n</ul> \n<p><strong>Other options</strong></p> \n<p>Format: <code>rtsp...#{param1}#{param2}#{param3}</code></p> \n<ul> \n <li>Add custom timeout <code>#timeout=30</code> (in seconds)</li> \n <li>Ignore audio - <code>#media=video</code> or ignore video - <code>#media=audio</code></li> \n <li>Ignore two-way audio API <code>#backchannel=0</code> - important for some glitchy cameras</li> \n <li>Use WebSocket transport <code>#transport=ws...</code></li> \n</ul> \n<p><strong>RTSP over WebSocket</strong></p> \n<pre><code class=\"language-yaml\">streams:\n  # WebSocket with authorization, RTSP - without\n  axis-rtsp-ws:  rtsp://192.168.1.123:4567/axis-media/media.amp?overview=0&amp;camera=1&amp;resolution=1280x720&amp;videoframeskipmode=empty&amp;Axis-Orig-Sw=true#transport=ws://user:pass@192.168.1.123:4567/rtsp-over-websocket\n  # WebSocket without authorization, RTSP - with\n  dahua-rtsp-ws: rtsp://user:pass@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1&amp;proto=Private3#transport=ws://192.168.1.123/rtspoverwebsocket\n</code></pre> \n<h2>Source: RTMP</h2> \n<p>You can get a stream from an RTMP server, for example <a href=\"https://github.com/arut/nginx-rtmp-module\">Nginx with nginx-rtmp-module</a>.</p> \n<pre><code class=\"language-yaml\">streams:\n  rtmp_stream: rtmp://192.168.1.123/live/camera1\n</code></pre> \n<h2>Source: HTTP</h2> \n<p>Support Content-Type:</p> \n<ul> \n <li><strong>HTTP-FLV</strong> (<code>video/x-flv</code>) - same as RTMP, but over HTTP</li> \n <li><strong>HTTP-JPEG</strong> (<code>image/jpeg</code>) - camera snapshot link, can be converted by go2rtc to MJPEG stream</li> \n <li><strong>HTTP-MJPEG</strong> (<code>multipart/x</code>) - simple MJPEG stream over HTTP</li> \n <li><strong>MPEG-TS</strong> (<code>video/mpeg</code>) - legacy <a href=\"https://en.wikipedia.org/wiki/MPEG_transport_stream\">streaming format</a></li> \n</ul> \n<p>Source also supports HTTP and TCP streams with autodetection for different formats: <strong>MJPEG</strong>, <strong>H.264/H.265 bitstream</strong>, <strong>MPEG-TS</strong>.</p> \n<pre><code class=\"language-yaml\">streams:\n  # [HTTP-FLV] stream in video/x-flv format\n  http_flv: http://192.168.1.123:20880/api/camera/stream/780900131155/657617\n  \n  # [JPEG] snapshots from Dahua camera, will be converted to MJPEG stream\n  dahua_snap: http://admin:password@192.168.1.123/cgi-bin/snapshot.cgi?channel=1\n\n  # [MJPEG] stream will be proxied without modification\n  http_mjpeg: https://mjpeg.sanford.io/count.mjpeg\n\n  # [MJPEG or H.264/H.265 bitstream or MPEG-TS]\n  tcp_magic: tcp://192.168.1.123:12345\n\n  # Add custom header\n  custom_header: \"https://mjpeg.sanford.io/count.mjpeg#header=Authorization: Bearer XXX\"\n</code></pre> \n<p><strong>PS.</strong> Dahua camera has a bug: if you select MJPEG codec for RTSP second stream, snapshot won't work.</p> \n<h2>Source: ONVIF</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0\">New in v1.5.0</a></em></p> \n<p>The source is not very useful if you already know RTSP and snapshot links for your camera. But it can be useful if you don't.</p> \n<p><strong>WebUI &gt; Add</strong> webpage support ONVIF autodiscovery. Your server must be on the same subnet as the camera. If you use Docker, you must use \"network host\".</p> \n<pre><code class=\"language-yaml\">streams:\n  dahua1: onvif://admin:password@192.168.1.123\n  reolink1: onvif://admin:password@192.168.1.123:8000\n  tapo1: onvif://admin:password@192.168.1.123:2020\n</code></pre> \n<h2>Source: FFmpeg</h2> \n<p>You can get any stream, file or device via FFmpeg and push it to go2rtc. The app will automatically start FFmpeg with the proper arguments when someone starts watching the stream.</p> \n<ul> \n <li>FFmpeg preistalled for <strong>Docker</strong> and <strong>Hass Add-on</strong> users</li> \n <li><strong>Hass Add-on</strong> users can target files from <a href=\"https://www.home-assistant.io/more-info/local-media/setup-media/\">/media</a> folder</li> \n</ul> \n<p>Format: <code>ffmpeg:{input}#{param1}#{param2}#{param3}</code>. Examples:</p> \n<pre><code class=\"language-yaml\">streams:\n  # [FILE] all tracks will be copied without transcoding codecs\n  file1: ffmpeg:/media/BigBuckBunny.mp4\n\n  # [FILE] video will be transcoded to H264, audio will be skipped\n  file2: ffmpeg:/media/BigBuckBunny.mp4#video=h264\n\n  # [FILE] video will be copied, audio will be transcoded to PCMU\n  file3: ffmpeg:/media/BigBuckBunny.mp4#video=copy#audio=pcmu\n\n  # [HLS] video will be copied, audio will be skipped\n  hls: ffmpeg:https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_16x9/gear5/prog_index.m3u8#video=copy\n\n  # [MJPEG] video will be transcoded to H264\n  mjpeg: ffmpeg:http://185.97.122.128/cgi-bin/faststream.jpg#video=h264\n\n  # [RTSP] video with rotation, should be transcoded, so select H264\n  rotate: ffmpeg:rtsp://12345678@192.168.1.123/av_stream/ch0#video=h264#rotate=90\n</code></pre> \n<p>All transcoding formats have <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/ffmpeg/ffmpeg.go\">built-in templates</a>: <code>h264</code>, <code>h265</code>, <code>opus</code>, <code>pcmu</code>, <code>pcmu/16000</code>, <code>pcmu/48000</code>, <code>pcma</code>, <code>pcma/16000</code>, <code>pcma/48000</code>, <code>aac</code>, <code>aac/16000</code>.</p> \n<p>But you can override them via YAML config. You can also add your own formats to the config and use them with source params.</p> \n<pre><code class=\"language-yaml\">ffmpeg:\n  bin: ffmpeg  # path to ffmpeg binary\n  global: \"-hide_banner\"\n  timeout: 5  # default timeout in seconds for rtsp inputs\n  h264: \"-codec:v libx264 -g:v 30 -preset:v superfast -tune:v zerolatency -profile:v main -level:v 4.1\"\n  mycodec: \"-any args that supported by ffmpeg...\"\n  myinput: \"-fflags nobuffer -flags low_delay -timeout {timeout} -i {input}\"\n  myraw: \"-ss 00:00:20\"\n</code></pre> \n<ul> \n <li>You can use go2rtc stream name as ffmpeg input (ex. <code>ffmpeg:camera1#video=h264</code>)</li> \n <li>You can use <code>video</code> and <code>audio</code> params multiple times (ex. <code>#video=copy#audio=copy#audio=pcmu</code>)</li> \n <li>You can use <code>rotate</code> param with <code>90</code>, <code>180</code>, <code>270</code> or <code>-90</code> values, important with transcoding (ex. <code>#video=h264#rotate=90</code>)</li> \n <li>You can use <code>width</code> and/or <code>height</code> params, important with transcoding (ex. <code>#video=h264#width=1280</code>)</li> \n <li>You can use <code>drawtext</code> to add a timestamp (ex. <code>drawtext=x=2:y=2:fontsize=12:fontcolor=white:box=1:boxcolor=black</code>) \n  <ul> \n   <li>This will greatly increase the CPU of the server, even with hardware acceleration</li> \n  </ul> </li> \n <li>You can use <code>timeout</code> param to set RTSP input timeout in seconds (ex. <code>#timeout=10</code>)</li> \n <li>You can use <code>raw</code> param for any additional FFmpeg arguments (ex. <code>#raw=-vf transpose=1</code>)</li> \n <li>You can use <code>input</code> param to override default input template (ex. <code>#input=rtsp/udp</code> will change RTSP transport from TCP to UDP+TCP) \n  <ul> \n   <li>You can use raw input value (ex. <code>#input=-timeout {timeout} -i {input}</code>)</li> \n   <li>You can add your own input templates</li> \n  </ul> </li> \n</ul> \n<p>Read more about <a href=\"https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration\">hardware acceleration</a>.</p> \n<p><strong>PS.</strong> It is recommended to check the available hardware in the WebUI add page.</p> \n<h2>Source: FFmpeg Device</h2> \n<p>You can get video from any USB camera or Webcam as RTSP or WebRTC stream. This is part of FFmpeg integration.</p> \n<ul> \n <li>check available devices in web interface</li> \n <li><code>video_size</code> and <code>framerate</code> must be supported by your camera!</li> \n <li>for Linux supported only video for now</li> \n <li>for macOS you can stream FaceTime camera or whole desktop!</li> \n <li>for macOS important to set right framerate</li> \n</ul> \n<p>Format: <code>ffmpeg:device?{input-params}#{param1}#{param2}#{param3}</code></p> \n<pre><code class=\"language-yaml\">streams:\n  linux_usbcam:   ffmpeg:device?video=0&amp;video_size=1280x720#video=h264\n  windows_webcam: ffmpeg:device?video=0#video=h264\n  macos_facetime: ffmpeg:device?video=0&amp;audio=1&amp;video_size=1280x720&amp;framerate=30#video=h264#audio=pcma\n</code></pre> \n<p><strong>PS.</strong> It is recommended to check the available devices in the WebUI add page.</p> \n<h2>Source: Exec</h2> \n<p>Exec source can run any external application and expect data from it. Two transports are supported - <strong>pipe</strong> (<em>from <a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0\">v1.5.0</a></em>) and <strong>RTSP</strong>.</p> \n<p>If you want to use <strong>RTSP</strong> transport, the command must contain the <code>{output}</code> argument in any place. On launch, it will be replaced by the local address of the RTSP server.</p> \n<p><strong>pipe</strong> reads data from app stdout in different formats: <strong>MJPEG</strong>, <strong>H.264/H.265 bitstream</strong>, <strong>MPEG-TS</strong>. Also pipe can write data to app stdin in two formats: <strong>PCMA</strong> and <strong>PCM/48000</strong>.</p> \n<p>The source can be used with:</p> \n<ul> \n <li><a href=\"https://ffmpeg.org/\">FFmpeg</a> - go2rtc ffmpeg source just a shortcut to exec source</li> \n <li><a href=\"https://ffmpeg.org/ffplay.html\">FFplay</a> - play audio on your server</li> \n <li><a href=\"https://gstreamer.freedesktop.org/\">GStreamer</a></li> \n <li><a href=\"https://www.raspberrypi.com/documentation/computers/camera_software.html\">Raspberry Pi Cameras</a></li> \n <li>any of your own software</li> \n</ul> \n<p>Pipe commands support parameters (format: <code>exec:{command}#{param1}#{param2}</code>):</p> \n<ul> \n <li><code>killsignal</code> - signal which will be sent to stop the process (numeric form)</li> \n <li><code>killtimeout</code> - time in seconds for forced termination with sigkill</li> \n <li><code>backchannel</code> - enable backchannel for two-way audio</li> \n <li><code>starttimeout</code> - time in seconds for waiting first byte from RTSP</li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  stream: exec:ffmpeg -re -i /media/BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp {output}\n  picam_h264: exec:libcamera-vid -t 0 --inline -o -\n  picam_mjpeg: exec:libcamera-vid -t 0 --codec mjpeg -o -\n  pi5cam_h264: exec:libcamera-vid -t 0 --libav-format h264 -o -\n  canon: exec:gphoto2 --capture-movie --stdout#killsignal=2#killtimeout=5\n  play_pcma: exec:ffplay -fflags nobuffer -f alaw -ar 8000 -i -#backchannel=1\n  play_pcm48k: exec:ffplay -fflags nobuffer -f s16be -ar 48000 -i -#backchannel=1\n</code></pre> \n<h2>Source: Echo</h2> \n<p>Some sources may have a dynamic link. And you will need to get it using a Bash or Python script. Your script should echo a link to the source. RTSP, FFmpeg or any of the <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">supported sources</a>.</p> \n<p><strong>Docker</strong> and <strong>Hass Add-on</strong> users has preinstalled <code>python3</code>, <code>curl</code>, <code>jq</code>.</p> \n<p>Check examples in <a href=\"https://github.com/AlexxIT/go2rtc/wiki/Source-Echo-examples\">wiki</a>.</p> \n<pre><code class=\"language-yaml\">streams:\n  apple_hls: echo:python3 hls.py https://developer.apple.com/streaming/examples/basic-stream-osx-ios5.html\n</code></pre> \n<h2>Source: Expr</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.2\">New in v1.8.2</a></em></p> \n<p>Like <code>echo</code> source, but uses the built-in <a href=\"https://github.com/antonmedv/expr\">expr</a> expression language.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/expr/README.md\">read more</a></em></p> \n<h2>Source: HomeKit</h2> \n<p><strong>Important:</strong></p> \n<ul> \n <li>You can use HomeKit Cameras <strong>without Apple devices</strong> (iPhone, iPad, etc.), it's just a yet another protocol</li> \n <li>HomeKit device can be paired with only one ecosystem. So, if you have paired it to an iPhone (Apple Home), you can't pair it with Home Assistant or go2rtc. Or if you have paired it to go2rtc, you can't pair it with an iPhone</li> \n <li>HomeKit device should be on the same network with working <a href=\"https://en.wikipedia.org/wiki/Multicast_DNS\">mDNS</a> between the device and go2rtc</li> \n</ul> \n<p>go2rtc supports importing paired HomeKit devices from <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass\">Home Assistant</a>. So you can use HomeKit camera with Hass and go2rtc simultaneously. If you are using Hass, I recommend pairing devices with it; it will give you more options.</p> \n<p>You can pair device with go2rtc on the HomeKit page. If you can't see your devices, reload the page. Also, try rebooting your HomeKit device (power off). If you still can't see it, you have a problem with mDNS.</p> \n<p>If you see a device but it does not have a pairing button, it is paired to some ecosystem (Apple Home, Home Assistant, HomeBridge etc). You need to delete the device from that ecosystem, and it will be available for pairing. If you cannot unpair the device, you will have to reset it.</p> \n<p><strong>Important:</strong></p> \n<ul> \n <li>HomeKit audio uses very non-standard <strong>AAC-ELD</strong> codec with very non-standard params and specification violations</li> \n <li>Audio can't be played in <code>VLC</code> and probably any other player</li> \n <li>Audio should be transcoded for use with MSE, WebRTC, etc.</li> \n</ul> \n<p>Recommended settings for using HomeKit Camera with WebRTC, MSE, MP4, RTSP:</p> \n<pre><code>streams:\n  aqara_g3:\n    - hass:Camera-Hub-G3-AB12\n    - ffmpeg:aqara_g3#audio=aac#audio=opus\n</code></pre> \n<p>RTSP link with \"normal\" audio for any player: <code>rtsp://192.168.1.123:8554/aqara_g3?video&amp;audio=aac</code></p> \n<p><strong>This source is in active development!</strong> Tested only with <a href=\"https://www.aqara.com/eu/product/camera-hub-g3\">Aqara Camera Hub G3</a> (both EU and CN versions).</p> \n<h2>Source: Bubble</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1\">New in v1.6.1</a></em></p> \n<p>Other names: <a href=\"http://www.eseecloud.com/\">ESeeCloud</a>, <a href=\"http://help.dvr163.com/\">dvr163</a>.</p> \n<ul> \n <li>you can skip <code>username</code>, <code>password</code>, <code>port</code>, <code>ch</code> and <code>stream</code> if they are default</li> \n <li>set up separate streams for different channels and streams</li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  camera1: bubble://username:password@192.168.1.123:34567/bubble/live?ch=0&amp;stream=0\n</code></pre> \n<h2>Source: DVRIP</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0\">New in v1.2.0</a></em></p> \n<p>Other names: DVR-IP, NetSurveillance, Sofia protocol (NETsurveillance ActiveX plugin XMeye SDK).</p> \n<ul> \n <li>you can skip <code>username</code>, <code>password</code>, <code>port</code>, <code>channel</code> and <code>subtype</code> if they are default</li> \n <li>set up separate streams for different channels</li> \n <li>use <code>subtype=0</code> for Main stream, and <code>subtype=1</code> for Extra1 stream</li> \n <li>only the TCP protocol is supported</li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  only_stream: dvrip://username:password@192.168.1.123:34567?channel=0&amp;subtype=0\n  only_tts: dvrip://username:password@192.168.1.123:34567?backchannel=1\n  two_way_audio:\n    - dvrip://username:password@192.168.1.123:34567?channel=0&amp;subtype=0\n    - dvrip://username:password@192.168.1.123:34567?backchannel=1\n</code></pre> \n<h2>Source: EseeCloud</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.10\">New in v1.9.10</a></em></p> \n<pre><code class=\"language-yaml\">streams:\n  camera1: eseecloud://user:pass@192.168.1.123:80/livestream/12\n</code></pre> \n<h2>Source: Tapo</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0\">New in v1.2.0</a></em></p> \n<p><a href=\"https://www.tapo.com/\">TP-Link Tapo</a> proprietary camera protocol with <strong>two way audio</strong> support.</p> \n<ul> \n <li>stream quality is the same as <a href=\"https://www.tapo.com/en/faq/34/\">RTSP protocol</a></li> \n <li>use the <strong>cloud password</strong>, this is not the RTSP password! you do not need to add a login!</li> \n <li>you can also use <strong>UPPERCASE</strong> MD5 hash from your cloud password with <code>admin</code> username</li> \n <li>some new camera firmwares require SHA256 instead of MD5</li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  # cloud password without username\n  camera1: tapo://cloud-password@192.168.1.123\n  # admin username and UPPERCASE MD5 cloud-password hash\n  camera2: tapo://admin:UPPERCASE-MD5@192.168.1.123\n  # admin username and UPPERCASE SHA256 cloud-password hash\n  camera3: tapo://admin:UPPERCASE-SHA256@192.168.1.123\n  # VGA stream (the so called substream, the lower resolution one)\n  camera4: tapo://cloud-password@192.168.1.123?subtype=1 \n  # HD stream (default)\n  camera5: tapo://cloud-password@192.168.1.123?subtype=0 \n</code></pre> \n<pre><code class=\"language-bash\">echo -n \"cloud password\" | md5 | awk '{print toupper($0)}'\necho -n \"cloud password\" | shasum -a 256 | awk '{print toupper($0)}'\n</code></pre> \n<h2>Source: Kasa</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0\">New in v1.7.0</a></em></p> \n<p><a href=\"https://www.kasasmart.com/\">TP-Link Kasa</a> non-standard protocol <a href=\"https://medium.com/@hu3vjeen/reverse-engineering-tp-link-kc100-bac4641bf1cd\">more info</a>.</p> \n<ul> \n <li><code>username</code> - urlsafe email, <code>alex@gmail.com</code> -&gt; <code>alex%40gmail.com</code></li> \n <li><code>password</code> - base64password, <code>secret1</code> -&gt; <code>c2VjcmV0MQ==</code></li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  kc401: kasa://username:password@192.168.1.123:19443/https/stream/mixed\n</code></pre> \n<p>Tested: KD110, KC200, KC401, KC420WS, EC71.</p> \n<h2>Source: Multitrans</h2> \n<p>Two-way audio support for Chinese version of <a href=\"https://www.tp-link.com.cn/list_2549.html\">TP-Link cameras</a>.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/multitrans/README.md\">read more</a></em></p> \n<h2>Source: Tuya</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13\">New in v1.9.13</a></em></p> \n<p><a href=\"https://www.tuya.com/\">Tuya</a> proprietary camera protocol with <strong>two way audio</strong> support. Go2rtc supports <code>Tuya Smart API</code> and <code>Tuya Cloud API</code>.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/tuya/README.md\">read more</a></em></p> \n<h2>Source: Xiaomi</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13\">New in v1.9.13</a></em></p> \n<p>This source allows you to view cameras from the <a href=\"https://home.mi.com/\">Xiaomi Mi Home</a> ecosystem.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/xiaomi/README.md\">read more</a></em></p> \n<h2>Source: Wyze</h2> \n<p>This source allows you to stream from <a href=\"https://wyze.com/\">Wyze</a> cameras using native P2P protocol - no <code>docker-wyze-bridge</code> required. Supports H.264/H.265 video, AAC/G.711 audio, and two-way audio.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/wyze/README.md\">read more</a></em></p> \n<h2>Source: GoPro</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.3\">New in v1.8.3</a></em></p> \n<p>Support streaming from <a href=\"https://gopro.com/\">GoPro</a> cameras, connected via USB or Wi-Fi to Linux, Mac, Windows.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/gopro/README.md\">read more</a></em></p> \n<h2>Source: Ivideon</h2> \n<p>Support public cameras from the service <a href=\"https://tv.ivideon.com/\">Ivideon</a>.</p> \n<pre><code class=\"language-yaml\">streams:\n  quailcam: ivideon:100-tu5dkUPct39cTp9oNEN2B6/0\n</code></pre> \n<h2>Source: Hass</h2> \n<p>Support import camera links from <a href=\"https://www.home-assistant.io/\">Home Assistant</a> config files:</p> \n<ul> \n <li><a href=\"https://www.home-assistant.io/integrations/generic/\">Generic Camera</a>, setup via GUI</li> \n <li><a href=\"https://www.home-assistant.io/integrations/homekit_controller/\">HomeKit Camera</a></li> \n <li><a href=\"https://www.home-assistant.io/integrations/onvif/\">ONVIF</a></li> \n <li><a href=\"https://github.com/humbertogontijo/homeassistant-roborock\">Roborock</a> vacuums with camera</li> \n</ul> \n<pre><code class=\"language-yaml\">hass:\n  config: \"/config\"  # skip this setting if you Hass add-on user\n\nstreams:\n  generic_camera: hass:Camera1  # Settings &gt; Integrations &gt; Integration Name\n  aqara_g3: hass:Camera-Hub-G3-AB12\n</code></pre> \n<p><strong>WebRTC Cameras</strong> (<em>from <a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0\">v1.6.0</a></em>)</p> \n<p>Any cameras in WebRTC format are supported. But at the moment Home Assistant only supports some <a href=\"https://www.home-assistant.io/integrations/nest/\">Nest</a> cameras in this format.</p> \n<p><strong>Important.</strong> The Nest API only allows you to get a link to a stream for 5 minutes. Do not use this with Frigate! If the stream expires, Frigate will consume all available RAM on your machine within seconds. It's recommended to use <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-nest\">Nest source</a> - it supports extending the stream.</p> \n<pre><code class=\"language-yaml\">streams:\n  # link to Home Assistant Supervised\n  hass-webrtc1: hass://supervisor?entity_id=camera.nest_doorbell\n  # link to external Hass with Long-Lived Access Tokens\n  hass-webrtc2: hass://192.168.1.123:8123?entity_id=camera.nest_doorbell&amp;token=eyXYZ...\n</code></pre> \n<p><strong>RTSP Cameras</strong></p> \n<p>By default, the Home Assistant API does not allow you to get a dynamic RTSP link to a camera stream. So more cameras, like <a href=\"https://www.home-assistant.io/integrations/tuya/\">Tuya</a>, and possibly others, can also be imported using <a href=\"https://github.com/felipecrs/hass-expose-camera-stream-source#importing-home-assistant-cameras-to-go2rtc-andor-frigate\">this method</a>.</p> \n<h2>Source: ISAPI</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>This source type supports only backchannel audio for the Hikvision ISAPI protocol. So it should be used as a second source in addition to the RTSP protocol.</p> \n<pre><code class=\"language-yaml\">streams:\n  hikvision1:\n    - rtsp://admin:password@192.168.1.123:554/Streaming/Channels/101\n    - isapi://admin:password@192.168.1.123:80/\n</code></pre> \n<h2>Source: Nest</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0\">New in v1.6.0</a></em></p> \n<p>Currently, only WebRTC cameras are supported.</p> \n<p>For simplicity, it is recommended to connect the Nest/WebRTC camera to the <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass\">Home Assistant</a>. But if you can somehow get the below parameters, Nest/WebRTC source will work without Hass.</p> \n<pre><code class=\"language-yaml\">streams:\n  nest-doorbell: nest:?client_id=***&amp;client_secret=***&amp;refresh_token=***&amp;project_id=***&amp;device_id=***\n</code></pre> \n<h2>Source: Ring</h2> \n<p>This source type support Ring cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two way audio</a> support. If you have a <code>refresh_token</code> and <code>device_id</code> - you can use it in <code>go2rtc.yaml</code> config file. Otherwise, you can use the go2rtc interface and add your ring account (WebUI &gt; Add &gt; Ring). Once added, it will list all your Ring cameras.</p> \n<pre><code class=\"language-yaml\">streams:\n  ring: ring:?device_id=XXX&amp;refresh_token=XXX\n  ring_snapshot: ring:?device_id=XXX&amp;refresh_token=XXX&amp;snapshot\n</code></pre> \n<h2>Source: Roborock</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>This source type supports Roborock vacuums with cameras. Known working models:</p> \n<ul> \n <li>Roborock S6 MaxV - only video (the vacuum has no microphone)</li> \n <li>Roborock S7 MaxV - video and two-way audio</li> \n <li>Roborock Qrevo MaxV - video and two-way audio</li> \n</ul> \n<p>Source supports loading Roborock credentials from Home Assistant <a href=\"https://github.com/humbertogontijo/homeassistant-roborock\">custom integration</a> or the <a href=\"https://www.home-assistant.io/integrations/roborock\">core integration</a>. Otherwise, you need to log in to your Roborock account (MiHome account is not supported). Go to: go2rtc WebUI &gt; Add webpage. Copy <code>roborock://...</code> source for your vacuum and paste it to <code>go2rtc.yaml</code> config.</p> \n<p>If you have a graphic PIN for your vacuum, add it as a numeric PIN (lines: 123, 456, 789) to the end of the <code>roborock</code> link.</p> \n<h2>Source: Doorbird</h2> \n<p>This source type supports <a href=\"https://www.doorbird.com/\">Doorbird</a> devices including MJPEG stream, audio stream as well as two-way audio.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/doorbird/README.md\">read more</a></em></p> \n<h2>Source: WebRTC</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>This source type supports four connection formats.</p> \n<p><strong>whep</strong></p> \n<p><a href=\"https://datatracker.ietf.org/doc/draft-murillo-whep/\">WebRTC/WHEP</a> is replaced by <a href=\"https://datatracker.ietf.org/doc/charter-ietf-wish/02/\">WebRTC/WISH</a> standard for WebRTC video/audio viewers. But it may already be supported in some third-party software. It is supported in go2rtc.</p> \n<p><strong>go2rtc</strong></p> \n<p>This format is only supported in go2rtc. Unlike WHEP, it supports asynchronous WebRTC connections and two-way audio.</p> \n<p><strong>openipc</strong> (<em>from <a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0\">v1.7.0</a></em>)</p> \n<p>Support connection to <a href=\"https://openipc.org/\">OpenIPC</a> cameras.</p> \n<p><strong>wyze (via docker-wyze-bridge)</strong> (<em>from <a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1\">v1.6.1</a></em>)</p> \n<p>Legacy method to connect to <a href=\"https://www.wyze.com/\">Wyze</a> cameras using WebRTC protocol via <a href=\"https://github.com/mrlt8/docker-wyze-bridge\">docker-wyze-bridge</a>. For native P2P support without docker-wyze-bridge, see <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-wyze\">Source: Wyze</a>.</p> \n<p><strong>kinesis</strong> (<em>from <a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1\">v1.6.1</a></em>)</p> \n<p>Supports <a href=\"https://aws.amazon.com/kinesis/video-streams/\">Amazon Kinesis Video Streams</a>, using WebRTC protocol. You need to specify the signalling WebSocket URL with all credentials in query params, <code>client_id</code> and <code>ice_servers</code> list in <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/RTCIceServer\">JSON format</a>.</p> \n<p><strong>switchbot</strong></p> \n<p>Support connection to <a href=\"https://us.switch-bot.com/\">SwitchBot</a> cameras that are based on Kinesis Video Streams. Specifically, this includes <a href=\"https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-2k\">Pan/Tilt Cam Plus 2K</a> and <a href=\"https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-3k\">Pan/Tilt Cam Plus 3K</a> and <a href=\"https://www.switchbot.jp/products/switchbot-smart-video-doorbell\">Smart Video Doorbell</a>. <code>Outdoor Spotlight Cam 1080P</code>, <code>Outdoor Spotlight Cam 2K</code>, <code>Pan/Tilt Cam</code>, <code>Pan/Tilt Cam 2K</code>, <code>Indoor Cam</code> are based on Tuya, so this feature is not available.</p> \n<pre><code class=\"language-yaml\">streams:\n  webrtc-whep:      webrtc:http://192.168.1.123:1984/api/webrtc?src=camera1\n  webrtc-go2rtc:    webrtc:ws://192.168.1.123:1984/api/ws?src=camera1\n  webrtc-openipc:   webrtc:ws://192.168.1.123/webrtc_ws#format=openipc#ice_servers=[{\"urls\":\"stun:stun.kinesisvideo.eu-north-1.amazonaws.com:443\"}]\n  webrtc-wyze:      webrtc:http://192.168.1.123:5000/signaling/camera1?kvs#format=wyze\n  webrtc-kinesis:   webrtc:wss://...amazonaws.com/?...#format=kinesis#client_id=...#ice_servers=[{...},{...}]\n  webrtc-switchbot: webrtc:wss://...amazonaws.com/?...#format=switchbot#resolution=hd#play_type=0#client_id=...#ice_servers=[{...},{...}]\n</code></pre> \n<p><strong>PS.</strong> For <code>kinesis</code> sources, you can use <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo\">echo</a> to get connection params using <code>bash</code>, <code>python</code> or any other script language.</p> \n<h2>Source: WebTorrent</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>This source can get a stream from another go2rtc via <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent\">WebTorrent</a> protocol.</p> \n<pre><code class=\"language-yaml\">streams:\n  webtorrent1: webtorrent:?share=huofssuxaty00izc&amp;pwd=k3l2j9djeg8v8r7e\n</code></pre> \n<h2>Incoming sources</h2> \n<p>By default, go2rtc establishes a connection to the source when any client requests it. Go2rtc drops the connection to the source when it has no clients left.</p> \n<ul> \n <li>Go2rtc also can accepts incoming sources in <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp\">RTSP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp\">RTMP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http\">HTTP</a> and <strong>WebRTC/WHIP</strong> formats</li> \n <li>Go2rtc won't stop such a source if it has no clients</li> \n <li>You can push data only to an existing stream (create a stream with empty source in config)</li> \n <li>You can push multiple incoming sources to the same stream</li> \n <li>You can push data to a non-empty stream, so it will have additional codecs inside</li> \n</ul> \n<p><strong>Examples</strong></p> \n<ul> \n <li>RTSP with any codec <pre><code class=\"language-yaml\">ffmpeg -re -i BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp rtsp://localhost:8554/camera1\n</code></pre> </li> \n <li>HTTP-MJPEG with MJPEG codec <pre><code class=\"language-yaml\">ffmpeg -re -i BigBuckBunny.mp4 -c mjpeg -f mpjpeg http://localhost:1984/api/stream.mjpeg?dst=camera1\n</code></pre> </li> \n <li>HTTP-FLV with H264, AAC codecs <pre><code class=\"language-yaml\">ffmpeg -re -i BigBuckBunny.mp4 -c copy -f flv http://localhost:1984/api/stream.flv?dst=camera1\n</code></pre> </li> \n <li>MPEG-TS with H264 codec <pre><code class=\"language-yaml\">ffmpeg -re -i BigBuckBunny.mp4 -c copy -f mpegts http://localhost:1984/api/stream.ts?dst=camera1\n</code></pre> </li> \n</ul> \n<h3>Incoming: Browser</h3> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>You can turn the browser of any PC or mobile into an IP camera with support for video and two-way audio. Or even broadcast your PC screen:</p> \n<ol> \n <li>Create empty stream in the <code>go2rtc.yaml</code></li> \n <li>Go to go2rtc WebUI</li> \n <li>Open <code>links</code> page for your stream</li> \n <li>Select <code>camera+microphone</code> or <code>display+speaker</code> option</li> \n <li>Open <code>webrtc</code> local page (your go2rtc <strong>should work over HTTPS!</strong>) or <code>share link</code> via <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent\">WebTorrent</a> technology (work over HTTPS by default)</li> \n</ol> \n<h3>Incoming: WebRTC/WHIP</h3> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>You can use <strong>OBS Studio</strong> or any other broadcast software with <a href=\"https://www.ietf.org/archive/id/draft-ietf-wish-whip-01.html\">WHIP</a> protocol support. This standard has not yet been approved. But you can download OBS Studio <a href=\"https://github.com/obsproject/obs-studio/actions/runs/3969201209\">dev version</a>:</p> \n<ul> \n <li>Settings &gt; Stream &gt; Service: WHIP &gt; <a href=\"http://192.168.1.123:1984/api/webrtc?dst=camera1\">http://192.168.1.123:1984/api/webrtc?dst=camera1</a></li> \n</ul> \n<h2>Stream to camera</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>go2rtc supports playing audio files (ex. music or <a href=\"https://www.home-assistant.io/integrations/#text-to-speech\">TTS</a>) and live streams (ex. radio) on cameras with <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio\">two-way audio</a> support (RTSP/ONVIF cameras, TP-Link Tapo, Hikvision ISAPI, Roborock vacuums, any Browser).</p> \n<p>API example:</p> \n<pre><code>POST http://localhost:1984/api/streams?dst=camera1&amp;src=ffmpeg:http://example.com/song.mp3#audio=pcma#input=file\n</code></pre> \n<ul> \n <li>you can stream: local files, web files, live streams or any format, supported by FFmpeg</li> \n <li>you should use <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">ffmpeg source</a> for transcoding audio to codec, that your camera supports</li> \n <li>you can check camera codecs on the go2rtc WebUI info page when the stream is active</li> \n <li>some cameras support only low quality <code>PCMA/8000</code> codec (ex. <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo\">Tapo</a>)</li> \n <li>it is recommended to choose higher quality formats if your camera supports them (ex. <code>PCMA/48000</code> for some Dahua cameras)</li> \n <li>if you play files over <code>http</code> link, you need to add <code>#input=file</code> params for transcoding, so the file will be transcoded and played in real time</li> \n <li>if you play live streams, you should skip <code>#input</code> param, because it is already in real time</li> \n <li>you can stop active playback by calling the API with the empty <code>src</code> parameter</li> \n <li>you will see one active producer and one active consumer in go2rtc WebUI info page during streaming</li> \n</ul> \n<h2>Publish stream</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0\">New in v1.8.0</a></em></p> \n<p>You can publish any stream to streaming services (YouTube, Telegram, etc.) via RTMP/RTMPS. Important:</p> \n<ul> \n <li>Supported codecs: H264 for video and AAC for audio</li> \n <li>AAC audio is required for YouTube; videos without audio will not work</li> \n <li>You don't need to enable <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp\">RTMP module</a> listening for this task</li> \n</ul> \n<p>You can use the API:</p> \n<pre><code>POST http://localhost:1984/api/streams?src=camera1&amp;dst=rtmps://...\n</code></pre> \n<p>Or config file:</p> \n<pre><code class=\"language-yaml\">publish:\n  # publish stream \"video_audio_transcode\" to Telegram\n  video_audio_transcode:\n    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx\n  # publish stream \"audio_transcode\" to Telegram and YouTube\n  audio_transcode:\n    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx\n    - rtmp://xxx.rtmp.youtube.com/live2/xxxx-xxxx-xxxx-xxxx-xxxx\n\nstreams:\n  video_audio_transcode:\n    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=h264#hardware#audio=aac\n  audio_transcode:\n    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=copy#audio=aac\n</code></pre> \n<ul> \n <li><strong>Telegram Desktop App</strong> &gt; Any public or private channel or group (where you admin) &gt; Live stream &gt; Start with... &gt; Start streaming.</li> \n <li><strong>YouTube</strong> &gt; Create &gt; Go live &gt; Stream latency: Ultra low-latency &gt; Copy: Stream URL + Stream key.</li> \n</ul> \n<h2>Preload stream</h2> \n<p>You can preload any stream on go2rtc start. This is useful for cameras that take a long time to start up.</p> \n<pre><code class=\"language-yaml\">preload:\n  camera1:                                     # default: video&amp;audio = ANY\n  camera2: \"video\"                             # preload only video track\n  camera3: \"video=h264&amp;audio=opus\"             # preload H264 video and OPUS audio\n\nstreams:\n  camera1: \n    - rtsp://192.168.1.100/stream\n  camera2: \n    - rtsp://192.168.1.101/stream  \n  camera3: \n    - rtsp://192.168.1.102/h265stream\n    - ffmpeg:camera3#video=h264#audio=opus#hardware\n</code></pre> \n<h2>Module: API</h2> \n<p>The HTTP API is the main part for interacting with the application. Default address: <code>http://localhost:1984/</code>.</p> \n<p><strong>Important!</strong> go2rtc passes requests from localhost and from Unix sockets without HTTP authorisation, even if you have it configured! It is your responsibility to set up secure external access to the API. If not properly configured, an attacker can gain access to your cameras and even your server.</p> \n<p><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/api/README.md\">API description</a>.</p> \n<p><strong>Module config</strong></p> \n<ul> \n <li>you can disable HTTP API with <code>listen: \"\"</code> and use, for example, only RTSP client/server protocol</li> \n <li>you can enable HTTP API only on localhost with <code>listen: \"127.0.0.1:1984\"</code> setting</li> \n <li>you can change the API <code>base_path</code> and host go2rtc on your main app webserver suburl</li> \n <li>all files from <code>static_dir</code> hosted on root path: <code>/</code></li> \n <li>you can use raw TLS cert/key content or path to files</li> \n</ul> \n<pre><code class=\"language-yaml\">api:\n  listen: \":1984\"    # default \":1984\", HTTP API port (\"\" - disabled)\n  username: \"admin\"  # default \"\", Basic auth for WebUI\n  password: \"pass\"   # default \"\", Basic auth for WebUI\n  local_auth: true   # default false, Enable auth check for localhost requests\n  base_path: \"/rtc\"  # default \"\", API prefix for serving on suburl (/api =&gt; /rtc/api)\n  static_dir: \"www\"  # default \"\", folder for static files (custom web interface)\n  origin: \"*\"        # default \"\", allow CORS requests (only * supported)\n  tls_listen: \":443\" # default \"\", enable HTTPS server\n  tls_cert: |        # default \"\", PEM-encoded fullchain certificate for HTTPS\n    -----BEGIN CERTIFICATE-----\n    ...\n    -----END CERTIFICATE-----\n  tls_key: |         # default \"\", PEM-encoded private key for HTTPS\n    -----BEGIN PRIVATE KEY-----\n    ...\n    -----END PRIVATE KEY-----\n  unix_listen: \"/tmp/go2rtc.sock\"  # default \"\", unix socket listener for API\n</code></pre> \n<p><strong>PS:</strong></p> \n<ul> \n <li>MJPEG over WebSocket plays better than native MJPEG because Chrome <a href=\"https://bugs.chromium.org/p/chromium/issues/detail?id=527446\">bug</a></li> \n <li>MP4 over WebSocket was created only for Apple iOS because it doesn't support MSE and native MP4</li> \n</ul> \n<h2>Module: RTSP</h2> \n<p>You can get any stream as RTSP-stream: <code>rtsp://192.168.1.123:8554/{stream_name}</code></p> \n<p>You can enable external password protection for your RTSP streams. Password protection is always disabled for localhost calls (ex. FFmpeg or Hass on the same server).</p> \n<pre><code class=\"language-yaml\">rtsp:\n  listen: \":8554\"    # RTSP Server TCP port, default - 8554\n  username: \"admin\"  # optional, default - disabled\n  password: \"pass\"   # optional, default - disabled\n  default_query: \"video&amp;audio\"  # optional, default codecs filters \n</code></pre> \n<p>By default go2rtc provide RTSP-stream with only one first video and only one first audio. You can change it with the <code>default_query</code> setting:</p> \n<ul> \n <li><code>default_query: \"mp4\"</code> - MP4 compatible codecs (H264, H265, AAC)</li> \n <li><code>default_query: \"video=all&amp;audio=all\"</code> - all tracks from all source (not all players can handle this)</li> \n <li><code>default_query: \"video=h264,h265\"</code> - only one video track (H264 or H265)</li> \n <li><code>default_query: \"video&amp;audio=all\"</code> - only one first any video and all audio as separate tracks</li> \n</ul> \n<p>Read more about <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters\">codecs filters</a>.</p> \n<h2>Module: RTMP</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0\">New in v1.8.0</a></em></p> \n<p>You can get any stream as RTMP-stream: <code>rtmp://192.168.1.123/{stream_name}</code>. Only H264/AAC codecs supported right now.</p> \n<p><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources\">Incoming stream</a> in RTMP format tested only with <a href=\"https://obsproject.com/\">OBS Studio</a> and a Dahua camera. Different FFmpeg versions have different problems with this format.</p> \n<pre><code class=\"language-yaml\">rtmp:\n  listen: \":1935\"  # by default - disabled!\n</code></pre> \n<h2>Module: WebRTC</h2> \n<p>In most cases, <a href=\"https://en.wikipedia.org/wiki/WebRTC\">WebRTC</a> uses a direct peer-to-peer connection from your browser to go2rtc and sends media data via UDP. It <strong>can't pass</strong> media data through your Nginx or Cloudflare or <a href=\"https://www.nabucasa.com/\">Nabu Casa</a> HTTP TCP connection! It can automatically detect your external IP via a public <a href=\"https://en.wikipedia.org/wiki/STUN\">STUN</a> server. It can establish an external direct connection via <a href=\"https://en.wikipedia.org/wiki/UDP_hole_punching\">UDP hole punching</a> technology even if you do not open your server to the World.</p> \n<p>But about 10-20% of users may need to configure additional settings for external access if <strong>mobile phone</strong> or <strong>go2rtc server</strong> is behind <a href=\"https://tomchen.github.io/symmetric-nat-test/\">Symmetric NAT</a>.</p> \n<ul> \n <li>by default, WebRTC uses both TCP and UDP on port 8555 for connections</li> \n <li>you can use this port for external access</li> \n <li>you can change the port in YAML config:</li> \n</ul> \n<pre><code class=\"language-yaml\">webrtc:\n  listen: \":8555\"  # address of your local server and port (TCP/UDP)\n</code></pre> \n<p><strong>Static public IP</strong></p> \n<ul> \n <li>forward the port 8555 on your router (you can use the same 8555 port or any other as external port)</li> \n <li>add your external IP address and external port to the YAML config</li> \n</ul> \n<pre><code class=\"language-yaml\">webrtc:\n  candidates:\n    - 216.58.210.174:8555  # if you have a static public IP address\n</code></pre> \n<p><strong>Dynamic public IP</strong></p> \n<ul> \n <li>forward the port 8555 on your router (you can use the same 8555 port or any other as the external port)</li> \n <li>add <code>stun</code> word and external port to YAML config \n  <ul> \n   <li>go2rtc automatically detects your external address with STUN server</li> \n  </ul> </li> \n</ul> \n<pre><code class=\"language-yaml\">webrtc:\n  candidates:\n    - stun:8555  # if you have a dynamic public IP address\n</code></pre> \n<p><strong>Hard tech way 1. Own TCP-tunnel</strong></p> \n<p>If you have a personal <a href=\"https://en.wikipedia.org/wiki/Virtual_private_server\">VPS</a>, you can create a TCP tunnel and setup in the same way as \"Static public IP\". But use your VPS IP address in the YAML config.</p> \n<p><strong>Hard tech way 2. Using TURN-server</strong></p> \n<p>If you have personal <a href=\"https://en.wikipedia.org/wiki/Virtual_private_server\">VPS</a>, you can install TURN server (e.g. <a href=\"https://github.com/coturn/coturn\">coturn</a>, config <a href=\"https://github.com/AlexxIT/WebRTC/wiki/Coturn-Example\">example</a>).</p> \n<pre><code class=\"language-yaml\">webrtc:\n  ice_servers:\n    - urls: [stun:stun.l.google.com:19302]\n    - urls: [turn:123.123.123.123:3478]\n      username: your_user\n      credential: your_pass\n</code></pre> \n<h2>Module: HomeKit</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0\">New in v1.7.0</a></em></p> \n<p>HomeKit module can work in two modes:</p> \n<ul> \n <li>export any H264 camera to Apple HomeKit</li> \n <li>transparent proxy any Apple HomeKit camera (Aqara, Eve, Eufy, etc.) back to Apple HomeKit, so you will have all camera features in Apple Home and also will have RTSP/WebRTC/MP4/etc. from your HomeKit camera</li> \n</ul> \n<p><strong>Important</strong></p> \n<ul> \n <li>HomeKit cameras support only H264 video and OPUS audio</li> \n</ul> \n<p><strong>Minimal config</strong></p> \n<pre><code class=\"language-yaml\">streams:\n  dahua1: rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0\nhomekit:\n  dahua1:  # same stream ID from streams list, default PIN - 19550224\n</code></pre> \n<p><strong>Full config</strong></p> \n<pre><code class=\"language-yaml\">streams:\n  dahua1:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0\n    - ffmpeg:dahua1#video=h264#hardware  # if your camera doesn't support H264, important for HomeKit\n    - ffmpeg:dahua1#audio=opus           # only OPUS audio supported by HomeKit\n\nhomekit:\n  dahua1:                   # same stream ID from streams list\n    pin: 12345678           # custom PIN, default: 19550224\n    name: Dahua camera      # custom camera name, default: generated from stream ID\n    device_id: dahua1       # custom ID, default: generated from stream ID\n    device_private: dahua1  # custom key, default: generated from stream ID\n</code></pre> \n<p><strong>Proxy HomeKit camera</strong></p> \n<ul> \n <li>Video stream from HomeKit camera to Apple device (iPhone, AppleTV) will be transmitted directly</li> \n <li>Video stream from HomeKit camera to RTSP/WebRTC/MP4/etc. will be transmitted via go2rtc</li> \n</ul> \n<pre><code class=\"language-yaml\">streams:\n  aqara1:\n    - homekit://...\n    - ffmpeg:aqara1#audio=aac#audio=opus  # optional audio transcoding\n\nhomekit:\n  aqara1:  # same stream ID from streams list\n</code></pre> \n<h2>Module: WebTorrent</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0\">New in v1.3.0</a></em></p> \n<p>This module supports:</p> \n<ul> \n <li>Share any local stream via <a href=\"https://webtorrent.io/\">WebTorrent</a> technology</li> \n <li>Get any <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-browser\">incoming stream</a> from PC or mobile via <a href=\"https://webtorrent.io/\">WebTorrent</a> technology</li> \n <li>Get any remote <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent\">go2rtc source</a> via <a href=\"https://webtorrent.io/\">WebTorrent</a> technology</li> \n</ul> \n<p>Securely and freely. You do not need to open a public access to the go2rtc server. But in some cases (Symmetric NAT), you may need to set up external access to <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">WebRTC module</a>.</p> \n<p>To generate a sharing link or incoming link, go to the go2rtc WebUI (stream links page). This link is <strong>temporary</strong> and will stop working after go2rtc is restarted!</p> \n<p>You can create permanent external links in the go2rtc config:</p> \n<pre><code class=\"language-yaml\">webtorrent:\n  shares:\n    super-secret-share:  # share name, should be unique among all go2rtc users!\n      pwd: super-secret-password\n      src: rtsp-dahua1   # stream name from streams section\n</code></pre> \n<p>Link example: <a href=\"https://go2rtc.org/webtorrent/#share=02SNtgjKXY&amp;pwd=wznEQqznxW&amp;media=video+audio\">https://go2rtc.org/webtorrent/#share=02SNtgjKXY&amp;pwd=wznEQqznxW&amp;media=video+audio</a></p> \n<h2>Module: ngrok</h2> \n<p>With <a href=\"https://ngrok.com/\">ngrok</a> integration, you can get external access to your streams in situations when you have Internet with a private IP address.</p> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/ngrok/README.md\">read more</a></em></p> \n<h2>Module: Hass</h2> \n<p>The best and easiest way to use go2rtc inside Home Assistant is to install the custom integration <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration\">WebRTC Camera</a> and custom Lovelace card.</p> \n<p>But go2rtc is also compatible and can be used with the <a href=\"https://www.home-assistant.io/integrations/rtsp_to_webrtc/\">RTSPtoWebRTC</a> built-in integration.</p> \n<p>You have several options on how to add a camera to Home Assistant:</p> \n<ol> \n <li>Camera RTSP source =&gt; <a href=\"https://www.home-assistant.io/integrations/generic/\">Generic Camera</a></li> \n <li>Camera <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams\">any source</a> =&gt; <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration\">go2rtc config</a> =&gt; <a href=\"https://www.home-assistant.io/integrations/generic/\">Generic Camera</a> \n  <ul> \n   <li>Install any <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start\">go2rtc</a></li> \n   <li>Add your stream to <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration\">go2rtc config</a></li> \n   <li>Hass &gt; Settings &gt; Integrations &gt; Add Integration &gt; <a href=\"https://my.home-assistant.io/redirect/config_flow_start/?domain=onvif\">ONVIF</a> &gt; Host: <code>127.0.0.1</code>, Port: <code>1984</code></li> \n   <li>Hass &gt; Settings &gt; Integrations &gt; Add Integration &gt; <a href=\"https://my.home-assistant.io/redirect/config_flow_start/?domain=generic\">Generic Camera</a> &gt; Stream Source URL: <code>rtsp://127.0.0.1:8554/camera1</code> (change to your stream name, leave everything else as is)</li> \n  </ul> </li> \n</ol> \n<p>You have several options on how to watch the stream from the cameras in Home Assistant:</p> \n<ol> \n <li><code>Camera Entity</code> =&gt; <code>Picture Entity Card</code> =&gt; Technology <code>HLS</code>, codecs: <code>H264/H265/AAC</code>, poor latency.</li> \n <li><code>Camera Entity</code> =&gt; <a href=\"https://www.home-assistant.io/integrations/rtsp_to_webrtc/\">RTSPtoWebRTC</a> =&gt; <code>Picture Entity Card</code> =&gt; Technology <code>WebRTC</code>, codecs: <code>H264/PCMU/PCMA/OPUS</code>, best latency. \n  <ul> \n   <li>Install any <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start\">go2rtc</a></li> \n   <li>Hass &gt; Settings &gt; Integrations &gt; Add Integration &gt; <a href=\"https://my.home-assistant.io/redirect/config_flow_start/?domain=rtsp_to_webrtc\">RTSPtoWebRTC</a> &gt; <code>http://127.0.0.1:1984/</code></li> \n   <li>RTSPtoWebRTC &gt; Configure &gt; STUN server: <code>stun.l.google.com:19302</code></li> \n   <li>Use Picture Entity or Picture Glance Lovelace card</li> \n  </ul> </li> \n <li><code>Camera Entity</code> or <code>Camera URL</code> =&gt; <a href=\"https://github.com/AlexxIT/WebRTC\">WebRTC Camera</a> =&gt; Technology: <code>WebRTC/MSE/MP4/MJPEG</code>, codecs: <code>H264/H265/AAC/PCMU/PCMA/OPUS</code>, best latency, best compatibility. \n  <ul> \n   <li>Install and add <a href=\"https://github.com/AlexxIT/WebRTC\">WebRTC Camera</a> custom integration</li> \n   <li>Use WebRTC Camera custom Lovelace card</li> \n  </ul> </li> \n</ol> \n<p>You can add camera <code>entity_id</code> to <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration\">go2rtc config</a> if you need transcoding:</p> \n<pre><code class=\"language-yaml\">streams:\n  \"camera.hall\": ffmpeg:{input}#video=copy#audio=opus\n</code></pre> \n<p><strong>PS.</strong> Default Home Assistant lovelace cards don't support two-way audio. You can use 2-way audio from <a href=\"https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons\">Add-on Web UI</a>, but you need to use HTTPS to access the microphone. This is a browser restriction and cannot be avoided.</p> \n<p><strong>PS.</strong> There is also another nice card with go2rtc support - <a href=\"https://github.com/dermotduffy/frigate-hass-card\">Frigate Lovelace Card</a>.</p> \n<h2>Module: MP4</h2> \n<p>Provides several features:</p> \n<ol> \n <li>MSE stream (fMP4 over WebSocket)</li> \n <li>Camera snapshots in MP4 format (single frame), can be sent to <a href=\"https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram\">Telegram</a></li> \n <li>HTTP progressive streaming (MP4 file stream) - bad format for streaming because of high start delay. This format doesn't work in all Safari browsers, but go2rtc will automatically redirect it to HLS/fMP4 in this case.</li> \n</ol> \n<p>API examples:</p> \n<ul> \n <li>MP4 snapshot: <code>http://192.168.1.123:1984/api/frame.mp4?src=camera1</code> (H264, H265)</li> \n <li>MP4 stream: <code>http://192.168.1.123:1984/api/stream.mp4?src=camera1</code> (H264, H265, AAC)</li> \n <li>MP4 file: <code>http://192.168.1.123:1984/api/stream.mp4?src=camera1</code> (H264, H265*, AAC, OPUS, MP3, PCMA, PCMU, PCM) \n  <ul> \n   <li>You can use <code>mp4</code>, <code>mp4=flac</code> and <code>mp4=all</code> param for codec filters</li> \n   <li>You can use <code>duration</code> param in seconds (ex. <code>duration=15</code>)</li> \n   <li>You can use <code>filename</code> param (ex. <code>filename=record.mp4</code>)</li> \n   <li>You can use <code>rotate</code> param with <code>90</code>, <code>180</code> or <code>270</code> values</li> \n   <li>You can use <code>scale</code> param with positive integer values (ex. <code>scale=4:3</code>)</li> \n  </ul> </li> \n</ul> \n<p>Read more about <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters\">codecs filters</a>.</p> \n<p><strong>PS.</strong> Rotate and scale params don't use transcoding and change video using metadata.</p> \n<h2>Module: HLS</h2> \n<p><em><a href=\"https://github.com/AlexxIT/go2rtc/releases/tag/v1.1.0\">New in v1.1.0</a></em></p> \n<p><a href=\"https://en.wikipedia.org/wiki/HTTP_Live_Streaming\">HLS</a> is the worst technology for real-time streaming. It can only be useful on devices that do not support more modern technology, like <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">WebRTC</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">MSE/MP4</a>.</p> \n<p>The go2rtc implementation differs from the standards and may not work with all players.</p> \n<p>API examples:</p> \n<ul> \n <li>HLS/TS stream: <code>http://192.168.1.123:1984/api/stream.m3u8?src=camera1</code> (H264)</li> \n <li>HLS/fMP4 stream: <code>http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;mp4</code> (H264, H265, AAC)</li> \n</ul> \n<p>Read more about <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters\">codecs filters</a>.</p> \n<h2>Module: MJPEG</h2> \n<ul> \n <li>This module can provide and receive streams in MJPEG format.</li> \n <li>This module is also responsible for receiving snapshots in JPEG format.</li> \n <li>This module also supports streaming to the server console (terminal) in the <strong>animated ASCII art</strong> format.</li> \n</ul> \n<p><em><a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/internal/mjpeg/README.md\">read more</a></em></p> \n<h2>Module: Log</h2> \n<p>You can set different log levels for different modules.</p> \n<pre><code class=\"language-yaml\">log:\n  level: info  # default level\n  api: trace\n  exec: debug\n  rtsp: warn\n  streams: error\n  webrtc: fatal\n</code></pre> \n<h1>Security</h1> \n<blockquote> \n <p>[!IMPORTANT] If an attacker gains access to the API, you are in danger. Through the API, an attacker can use insecure sources such as echo and exec. And get full access to your server.</p> \n</blockquote> \n<p>For maximum (paranoid) security, go2rtc has special settings:</p> \n<pre><code class=\"language-yaml\">app:\n  # use only allowed modules\n  modules: [api, rtsp, webrtc, exec, ffmpeg, mjpeg]\n\napi:\n  # use only allowed API paths\n  allow_paths: [/api, /api/streams, /api/webrtc, /api/frame.jpeg]\n  # enable auth for localhost (used together with username and password)\n  local_auth: true\n\nexec:\n  # use only allowed exec paths\n  allow_paths: [ffmpeg]\n</code></pre> \n<p>By default, <code>go2rtc</code> starts the Web interface on port <code>1984</code> and RTSP on port <code>8554</code>, as well as uses port <code>8555</code> for WebRTC connections. The three ports are accessible from your local network. So anyone on your local network can watch video from your cameras without authorization. The same rule applies to the Home Assistant Add-on.</p> \n<p>This is not a problem if you trust your local network as much as I do. But you can change this behaviour with a <code>go2rtc.yaml</code> config:</p> \n<pre><code class=\"language-yaml\">api:\n  listen: \"127.0.0.1:1984\" # localhost\n\nrtsp:\n  listen: \"127.0.0.1:8554\" # localhost\n\nwebrtc:\n  listen: \":8555\" # external TCP/UDP port\n</code></pre> \n<ul> \n <li>local access to RTSP is not a problem for <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg</a> integration, because it runs locally on your server</li> \n <li>local access to API is not a problem for the <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on\">Home Assistant add-on</a>, because Hass runs locally on the same server, and the add-on web UI is protected with Hass authorization (<a href=\"https://www.home-assistant.io/blog/2019/04/15/hassio-ingress/\">Ingress feature</a>)</li> \n <li>external access to WebRTC TCP port is not a problem, because it is used only for transmitting encrypted media data \n  <ul> \n   <li>anyway you need to open this port to your local network and to the Internet for WebRTC to work</li> \n  </ul> </li> \n</ul> \n<p>If you need web interface protection without the Home Assistant add-on, you need to use a reverse proxy, like <a href=\"https://nginx.org/\">Nginx</a>, <a href=\"https://caddyserver.com/\">Caddy</a>, etc.</p> \n<p>PS. Additionally, WebRTC will try to use the 8555 UDP port to transmit encrypted media. It works without problems on the local network, and sometimes also works for external access, even if you haven't opened this port on your router (<a href=\"https://en.wikipedia.org/wiki/UDP_hole_punching\">read more</a>). But for stable external WebRTC access, you need to open the 8555 port on your router for both TCP and UDP.</p> \n<h1>Codecs filters</h1> \n<p>go2rtc can automatically detect which codecs your device supports for <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc\">WebRTC</a> and <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">MSE</a> technologies.</p> \n<p>But it cannot be done for <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp\">RTSP</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4\">HTTP progressive streaming</a>, <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls\">HLS</a> technologies. You can manually add a codec filter when you create a link to a stream. The filters work the same for all three technologies. Filters do not create a new codec. They only select the suitable codec from existing sources. You can add new codecs to the stream using the <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg transcoding</a>.</p> \n<p>Without filters:</p> \n<ul> \n <li>RTSP will provide only the first video and only the first audio (any codec)</li> \n <li>MP4 will include only compatible codecs (H264, H265, AAC)</li> \n <li>HLS will output in the legacy TS format (H264 without audio)</li> \n</ul> \n<p>Some examples:</p> \n<ul> \n <li><code>rtsp://192.168.1.123:8554/camera1?mp4</code> - useful for recording as MP4 files (e.g. Hass or Frigate)</li> \n <li><code>rtsp://192.168.1.123:8554/camera1?video=h264,h265&amp;audio=aac</code> - full version of the filter above</li> \n <li><code>rtsp://192.168.1.123:8554/camera1?video=h264&amp;audio=aac&amp;audio=opus</code> - H264 video codec and two separate audio tracks</li> \n <li><code>rtsp://192.168.1.123:8554/camera1?video&amp;audio=all</code> - any video codec and all audio codecs as separate tracks</li> \n <li><code>http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;mp4</code> - HLS stream with MP4 compatible codecs (HLS/fMP4)</li> \n <li><code>http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;mp4=flac</code> - HLS stream with PCMA/PCMU/PCM audio support (HLS/fMP4), won't work on old devices</li> \n <li><code>http://192.168.1.123:1984/api/stream.mp4?src=camera1&amp;mp4=flac</code> - MP4 file with PCMA/PCMU/PCM audio support, won't work on old devices (ex. iOS 12)</li> \n <li><code>http://192.168.1.123:1984/api/stream.mp4?src=camera1&amp;mp4=all</code> - MP4 file with non-standard audio codecs, won't work on some players</li> \n</ul> \n<h1>Codecs madness</h1> \n<p><code>AVC/H.264</code> video can be played almost anywhere. But <code>HEVC/H.265</code> has many limitations in supporting different devices and browsers.</p> \n<table> \n <thead> \n  <tr> \n   <th>Device</th> \n   <th>WebRTC</th> \n   <th>MSE</th> \n   <th>HTTP*</th> \n   <th>HLS</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td><em>latency</em></td> \n   <td>best</td> \n   <td>medium</td> \n   <td>bad</td> \n   <td>bad</td> \n  </tr> \n  <tr> \n   <td>Desktop Chrome 136+ <br /> Desktop Edge <br /> Android Chrome 136+</td> \n   <td>H264, H265* <br /> PCMU, PCMA <br /> OPUS</td> \n   <td>H264, H265* <br /> AAC, FLAC* <br /> OPUS</td> \n   <td>H264, H265* <br /> AAC, FLAC* <br /> OPUS, MP3</td> \n   <td>no</td> \n  </tr> \n  <tr> \n   <td>Desktop Firefox</td> \n   <td>H264 <br /> PCMU, PCMA <br /> OPUS</td> \n   <td>H264 <br /> AAC, FLAC* <br /> OPUS</td> \n   <td>H264 <br /> AAC, FLAC* <br /> OPUS</td> \n   <td>no</td> \n  </tr> \n  <tr> \n   <td>Desktop Safari 14+ <br /> iPad Safari 14+ <br /> iPhone Safari 17.1+</td> \n   <td>H264, H265* <br /> PCMU, PCMA <br /> OPUS</td> \n   <td>H264, H265 <br /> AAC, FLAC*</td> \n   <td><strong>no!</strong></td> \n   <td>H264, H265 <br /> AAC, FLAC*</td> \n  </tr> \n  <tr> \n   <td>iPhone Safari 14+</td> \n   <td>H264, H265* <br /> PCMU, PCMA <br /> OPUS</td> \n   <td><strong>no!</strong></td> \n   <td><strong>no!</strong></td> \n   <td>H264, H265 <br /> AAC, FLAC*</td> \n  </tr> \n  <tr> \n   <td>macOS <a href=\"https://apps.apple.com/app/home-assistant/id1099568401\">Hass App</a></td> \n   <td>no</td> \n   <td>no</td> \n   <td>no</td> \n   <td>H264, H265 <br /> AAC, FLAC*</td> \n  </tr> \n </tbody> \n</table> \n<ul> \n <li><code>HTTP*</code> - HTTP Progressive Streaming, not related to <a href=\"https://en.wikipedia.org/wiki/Progressive_download\">progressive download</a>, because the file has no size and no end</li> \n <li><code>WebRTC H265</code> - supported in <a href=\"https://developer.chrome.com/release-notes/136\">Chrome 136+</a>, supported in <a href=\"https://developer.apple.com/documentation/safari-release-notes/safari-18-release-notes\">Safari 18+</a></li> \n <li><code>MSE iPhone</code> - supported in <a href=\"https://webkit.org/blog/14735/webkit-features-in-safari-17-1/\">iOS 17.1+</a></li> \n</ul> \n<p><strong>Audio</strong></p> \n<ul> \n <li>Go2rtc support <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#built-in-transcoding\">automatic repack</a> <code>PCMA/PCMU/PCM</code> codecs to <code>FLAC</code> for MSE/MP4/HLS so they will work almost anywhere</li> \n <li><strong>WebRTC</strong> audio codecs: <code>PCMU/8000</code>, <code>PCMA/8000</code>, <code>OPUS/48000/2</code></li> \n <li><code>OPUS</code> and <code>MP3</code> inside <strong>MP4</strong> are part of the standard, but some players do not support them anyway (especially Apple)</li> \n</ul> \n<p><strong>Apple devices</strong></p> \n<ul> \n <li>all Apple devices don't support HTTP progressive streaming</li> \n <li>old iPhone firmwares don't support MSE technology because it competes with the HTTP Live Streaming (HLS) technology, invented by Apple</li> \n <li>HLS is the worst technology for <strong>live</strong> streaming, it still exists only because of iPhones</li> \n</ul> \n<p><strong>Codec names</strong></p> \n<ul> \n <li>H264 = H.264 = AVC (Advanced Video Coding)</li> \n <li>H265 = H.265 = HEVC (High Efficiency Video Coding)</li> \n <li>PCMA = G.711 PCM (A-law) = PCM A-law (<code>alaw</code>)</li> \n <li>PCMU = G.711 PCM (µ-law) = PCM mu-law (<code>mulaw</code>)</li> \n <li>PCM = L16 = PCM signed 16-bit big-endian (<code>s16be</code>)</li> \n <li>AAC = MPEG4-GENERIC</li> \n <li>MP3 = MPEG-1 Audio Layer III or MPEG-2 Audio Layer III</li> \n</ul> \n<h1>Built-in transcoding</h1> \n<p>There are no plans to embed complex transcoding algorithms inside go2rtc. <a href=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg\">FFmpeg source</a> does a great job with this. Including <a href=\"https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration\">hardware acceleration</a> support.</p> \n<p>But go2rtc has some simple algorithms. They are turned on automatically; you do not need to set them up additionally.</p> \n<p><strong>PCM for MSE/MP4/HLS</strong></p> \n<p>Go2rtc can pack <code>PCMA</code>, <code>PCMU</code> and <code>PCM</code> codecs into an MP4 container so that they work in all browsers and all built-in players on modern devices. Including Apple QuickTime:</p> \n<pre><code>PCMA/PCMU =&gt; PCM =&gt; FLAC =&gt; MSE/MP4/HLS\n</code></pre> \n<p><strong>Resample PCMA/PCMU for WebRTC</strong></p> \n<p>By default WebRTC supports only <code>PCMA/8000</code> and <code>PCMU/8000</code>. But go2rtc can automatically resample PCMA and PCMU codecs with a different sample rate. Also, go2rtc can transcode <code>PCM</code> codec to <code>PCMA/8000</code>, so WebRTC can play it:</p> \n<pre><code>PCM/xxx =&gt; PCMA/8000 =&gt; WebRTC\nPCMA/xxx =&gt; PCMA/8000 =&gt; WebRTC\nPCMU/xxx =&gt; PCMU/8000 =&gt; WebRTC\n</code></pre> \n<p><strong>Important</strong></p> \n<ul> \n <li>FLAC codec not supported in an RTSP stream. If you are using Frigate or Hass for recording MP4 files with PCMA/PCMU/PCM audio, you should set up transcoding to the AAC codec.</li> \n <li>PCMA and PCMU are VERY low-quality codecs. They support only 256! different sounds. Use them only when you have no other options.</li> \n</ul> \n<h1>Codecs negotiation</h1> \n<p>For example, you want to watch RTSP-stream from <a href=\"https://www.dahuasecurity.com/fr/products/All-Products/Network-Cameras/Wireless-Series/Wi-Fi-Series/4MP/IPC-K42\">Dahua IPC-K42</a> camera in your Chrome browser.</p> \n<ul> \n <li>this camera supports two-way audio standard <strong>ONVIF Profile T</strong></li> \n <li>this camera supports codecs <strong>H264, H265</strong> for send video, and you select <code>H264</code> in camera settings</li> \n <li>this camera supports codecs <strong>AAC, PCMU, PCMA</strong> for sending audio (from mic), and you select <code>AAC/16000</code> in camera settings</li> \n <li>this camera supports codecs <strong>AAC, PCMU, PCMA</strong> for receiving audio (to speaker), you don't need to select them</li> \n <li>your browser supports codecs <strong>H264, VP8, VP9, AV1</strong> for receiving video, you don't need to select them</li> \n <li>your browser supports codecs <strong>OPUS, PCMU, PCMA</strong> for sending and receiving audio, you don't need to select them</li> \n <li>you can't get camera audio directly, because its audio codecs don't match with your browser codecs \n  <ul> \n   <li>so you decide to use transcoding via FFmpeg and add this setting to the config YAML file</li> \n   <li>you have chosen <code>OPUS/48000/2</code> codec, because it is higher quality than the <code>PCMU/8000</code> or <code>PCMA/8000</code></li> \n  </ul> </li> \n</ul> \n<p>Now you have a stream with two sources - <strong>RTSP and FFmpeg</strong>:</p> \n<pre><code class=\"language-yaml\">streams:\n  dahua:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0&amp;unicast=true&amp;proto=Onvif\n    - ffmpeg:rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0#audio=opus\n</code></pre> \n<p><strong>go2rtc</strong> automatically matches codecs for your browser and all your stream sources. This is called <strong>multi-source two-way codec negotiation</strong>. And this is one of the main features of this app.</p> \n<p><img alt=\"\" src=\"https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/codecs.svg?sanitize=true\" /></p> \n<p><strong>PS.</strong> You can select <code>PCMU</code> or <code>PCMA</code> codec in camera settings and not use transcoding at all. Or you can select <code>AAC</code> codec for main stream and <code>PCMU</code> codec for second stream and add both RTSP to YAML config, this also will work fine.</p> \n<h1>Projects using go2rtc</h1> \n<ul> \n <li><a href=\"https://www.home-assistant.io/\">Home Assistant</a> <a href=\"https://www.home-assistant.io/integrations/go2rtc/\">2024.11+</a> - top open-source smart home project</li> \n <li><a href=\"https://frigate.video/\">Frigate</a> <a href=\"https://docs.frigate.video/guides/configuring_go2rtc/\">0.12+</a> - open-source NVR built around real-time AI object detection</li> \n <li><a href=\"https://github.com/dermotduffy/frigate-hass-card\">Frigate Lovelace Card</a> - custom card for Home Assistant</li> \n <li><a href=\"https://github.com/OpenIPC/firmware/tree/master/general/package/go2rtc\">OpenIPC</a> - alternative IP camera firmware from an open community</li> \n <li><a href=\"https://github.com/gtxaspec/wz_mini_hacks\">wz_mini_hacks</a> - custom firmware for Wyze cameras</li> \n <li><a href=\"https://github.com/oischinger/eufyp2pstream\">EufyP2PStream</a> - a small project that provides a video/audio stream from Eufy cameras that don't directly support RTSP</li> \n <li><a href=\"https://github.com/bropat/ioBroker.eusec\">ioBroker.euSec</a> - <a href=\"https://www.iobroker.net/\">ioBroker</a> adapter for controlling Eufy security devices</li> \n <li><a href=\"https://github.com/Anonym-tsk/MMM-go2rtc\">MMM-go2rtc</a> - MagicMirror² module</li> \n <li><a href=\"https://github.com/tsightler/ring-mqtt\">ring-mqtt</a> - Ring-to-MQTT bridge</li> \n <li><a href=\"https://github.com/opensensor/lightNVR\">lightNVR</a></li> \n</ul> \n<p><strong>Distributions</strong></p> \n<ul> \n <li><a href=\"https://pkgs.alpinelinux.org/packages?name=go2rtc\">Alpine Linux</a></li> \n <li><a href=\"https://linux-packages.com/aur/package/go2rtc\">Arch User Repository</a></li> \n <li><a href=\"https://github.com/inode64/inode64-overlay/tree/main/media-video/go2rtc\">Gentoo</a></li> \n <li><a href=\"https://search.nixos.org/packages?query=go2rtc\">NixOS</a></li> \n <li><a href=\"https://github.com/community-scripts/ProxmoxVE/\">Proxmox Helper Scripts</a></li> \n <li><a href=\"https://www.myqnap.org/product/go2rtc/\">QNAP</a></li> \n <li><a href=\"https://synocommunity.com/package/go2rtc\">Synology NAS</a></li> \n <li><a href=\"https://unraid.net/community/apps?q=go2rtc\">Unraid</a></li> \n</ul> \n<h1>Camera experience</h1> \n<ul> \n <li><a href=\"https://www.dahuasecurity.com/\">Dahua</a> - reference implementation streaming protocols, a lot of settings, high stream quality, multiple streaming clients</li> \n <li><a href=\"https://www.ezviz.com/\">EZVIZ</a> - awful RTSP protocol implementation, many bugs in SDP</li> \n <li><a href=\"https://www.hikvision.com/\">Hikvision</a> - a lot of proprietary streaming technologies</li> \n <li><a href=\"https://reolink.com/\">Reolink</a> - some models have an awful, unusable RTSP implementation and not the best RTMP alternative (I recommend that you contact Reolink support for new firmware), few settings</li> \n <li><a href=\"https://sonoff.tech/\">Sonoff</a> - very low stream quality, no settings, not the best protocol implementation</li> \n <li><a href=\"https://www.tp-link.com/\">TP-Link</a> - few streaming clients, packet loss?</li> \n <li>Chinese cheap noname cameras, Wyze Cams, Xiaomi cameras with hacks (usually have <code>/live/ch00_1</code> in RTSP URL) - awful but usable RTSP protocol implementation, low stream quality, few settings, packet loss?</li> \n</ul> \n<h1>TIPS</h1> \n<p><strong>Using apps for low RTSP delay</strong></p> \n<ul> \n <li><code>ffplay -fflags nobuffer -flags low_delay \"rtsp://192.168.1.123:8554/camera1\"</code></li> \n <li>VLC &gt; Preferences &gt; Input / Codecs &gt; Default Caching Level: Lowest Latency</li> \n</ul> \n<p><strong>Snapshots to Telegram</strong></p> \n<p><a href=\"https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram\">read more</a></p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:13.294331Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 6
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 22,
        "timeliness_score": 1,
        "final_score": 7.3,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/viksaaskool/ai-tech-and-society-educated-fools-predictions-5f6n",
        "title": "AI, tech and society: educated fool’s predictions",
        "summary": "<p><em>The original post was written in late 2023, edited and changed in the first months of 2024, but never published, because I was persuaded by some peers that had glimpse into it - too dark and negative. 2 years later and here it is - I published it this as is (only with some small formatting changes). Now, with a bit of pride that I got most thing right (in these 2 years). I plan on writing part two, with more predictions on how the changes might affect society and what are the possible end results (in more details).</em> </p>\n\n<p><a class=\"article-body-image-wrapper\" href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgpc60rugwajarrhc4tnu.png\"><img alt=\"the original timestamp\" height=\"262\" src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgpc60rugwajarrhc4tnu.png\" width=\"800\" /></a></p>\n\n<h2>\n  \n  \n  Intro\n</h2>\n\n<p>I have a bachelor’s and master’s degree in computer science, specializing in intelligent information systems. I have 12 years of experience as a software engineer – started with Web, but quickly switched to the then shiny new(ish) thing: Android Development. I’ve been on different points in the software engineering process, down in the trenches and outside overlooking the deadline release battles. I’ve worked at startups, digital agencies, product based large companies – from “it doesn’t matter – let’s ship it” to “the name of this variable in your unit test is not intuitive enough”. I’ve worked on passion projects, blogging, published a somewhat popular Android library, I’ve doing data science in Python and trying to center a div in CSS. I consider myself a valuable addition to a software engineering team – knowledge, experience, creativity and some bad jokes on stand ups.<br />\n I’m humble enough to know that I’m replicable – as a software engineer or researcher, a very strong and genuine “will be missed”, but still, replicable. Looking in the eyes of the upcoming AI development automation, we, software engineers, will all be humbled and sooner or later will come to the same realization. </p>\n\n<p>Post pandemic tech market was booming, the abundance of job opportunities was overflowing the tech fountain of career perspectives. This has resulted in inflating tech employment and creation of a big cousin of software engineer’s comfort, who has been able to indulge in conspicuous consumption more than ever. Everything started to shift with global political events which was aided by the introduction of ChatGPT. Ever since that moment there has been progress in tooling that erodes, bit by bit, the rock of software engineers’ responsibilities, narrowing down the job description.<br />\nThe aim of the AI iterations is to reach a point where it can do everything a human would do, without emotions and imperfections. The end goal is to create a know-it-all entity also referred to as artificial general intelligence (AGI). </p>\n\n<p>If you look into the software engineering corner of the Internets, the theme playing out loud is “will I be replaced by AI?” – and I’m going to try to answer that and make a prediction. Hopefully a good one. <br />\nDrumroll, the answer is: yes. Let me elaborate.</p>\n\n<h2>\n  \n  \n  Predictions\n</h2>\n\n<p>My predictions are going to be centered around tech and how those changes will affect society. To be noted, there’s no branch of the economy that will not be affected in a substantial manner.</p>\n\n<p>1) <strong>The changes will happen in waves of invention and adoption</strong> – even if the invention moves exponentially the adoption will slow down the pace. How much remains to be seen.</p>\n\n<ul>\n<li><p><strong>First wave.</strong> We’re currently in the first wave, where LLMs are packaged in the form of tools that are good enough to aid the developer in the daily work. Some very repetitive parts of the engineering process are easily replicable with the tools being available. Mainly, it’s just an addon to what developers already do, but helps with productivity and brings value to the shareholders. Jobs like translators, content writers, manual QAs can be rendered obsolete, but are not. The industry sees a shift and is reluctant for new investments into hiring people, rather than developing these tools, or waiting for these tools to be developed. Minor adaptations already have begun, but very few companies have official and firm stances. Data privacy is still not resolved, one of the many reasons why companies are hesitant to start applying the new tech on mass. This is where the people that say “you’re most likely not going to lose your job (because of AI)” are right. We have 1–2 years left from the first wave.</p></li>\n<li><p><strong>Second wave.</strong> Tools like Devin and more to come (AutoDev from Microsoft?) become good enough to replace junior devs and do most of the work. Data privacy is resolved, and more companies start to embrace the “AI dev” tools. First AI Dev digital agencies appear – offering packages to companies for “subscribing” to their dedicated AI team of devs. Very few new openings are going to be posted, low demand, high supply. Layoffs are going to have their moment – each next round will be higher than the previous one. This won’t be happening just in tech, but also in most data-driven industries. The new tech is going to produce tools to replace other job descriptions, while it also eats itself – a truly poetic end. This is when you’d be really worried about your job if you still had one. Getting a job once you got laid off will be harder than ever, close to impossible. The economy shifts are going to be apparent and first “organic” software movements are going to appear. The pushback from developers (and other workers that were laid off) is going to take some form. A lot of talent is going to be unemployed and that talent and experience, with the help of the very same AI that got them in that position, will be able to compete against the now very big companies. If there’s no legal intervention and most of the AI breakthroughs stay open, big tech is going to be under threat in terms of monopoly. Building complex systems will be easier than ever, an opportunity that a sizable chunk of the unemployed devs will take. I expect this wave to last 2025–2035.</p></li>\n<li><p><strong>Third wave.</strong> This is going to be a period that is mostly adaptation and social amortization of the automation consequences. How societies are going to handle the second wave will determine what will happen in the third one and what pace AI adoption will have. Tech is going to be focused on displacing all other jobs that are now considered safe – manual labor jobs that need more context and require multiple models to cooperate. With advancements in robotics this will be achieved. Home robotic appliances for ironing shirts and folding clothes will be good enough that no human assistance will be needed. It’s unlikely, and I’d be very surprised, if by this time we achieve AGI, but some pretty good forms of it are going to be out there. I expect this period to be 2035 until a viable AGI is introduced.</p></li>\n</ul>\n\n<p>2) <strong>NO, AI won’t “create more jobs than it’ll displace”.</strong><br /><br />\nThe “new jobs” that are going to be created will be narrow, harder for novice developers to do and/or to be seen as eligible by companies. The price of labor will drop, and tech won’t be an attractive field to get into.</p>\n\n<h2>\n  \n  \n  Social consequences of automation\n</h2>\n\n<p>Society is built on norms and rules that make the system run. The massive introduction of AI will challenge most of the norms and all the rules that have built modern societies. The very basic rules of setting up the social hierarchy, climbing the social ladder, through actions of acquiring resources because of work, will be diminished or totally nullified. The stability of the system depends on how fast this change is going to happen and how it will be handled. </p>\n\n<p>Almost certainly we're going to see economic turbulence in the short run, followed by very probable social unrest and some dystopian form of new society as the end result. </p>\n\n<p>Most likely outcome will be frozen or very inert social mobility, two main classes: </p>\n\n<ul>\n<li>The \"organic\" oligarch/winners of AI revolution class. They'd be able to enjoy goods and services developed and produced by people, not because they are better, on the contrary because they can afford their costliness. Form of status signaling. Art, movies, food, barbers, designers - everything human made. </li>\n<li>The rest, the synthetic class. The consumers of the \"free\" products of AI - basic goods and services enough to live lives happy enough not to rebel or revolt and not good enough to afford the \"organic\" luxury. </li>\n</ul>",
        "source": "dev.to",
        "published": "Wed, 21 Jan 2026 22:56:21 +0000",
        "fetched_at": "2026-01-21T23:21:19.543355Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "value_redefinition",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 9
          }
        ],
        "structural_score": 17,
        "timeliness_score": 2,
        "final_score": 6.5,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/hacksider/Deep-Live-Cam",
        "title": "hacksider/Deep-Live-Cam",
        "summary": "<p>real time face swap and one-click video deepfake with only a single image</p><hr /><h1 align=\"center\">Deep-Live-Cam 2.0.1c</h1> \n<p align=\"center\"> Real-time face swap and video deepfake with a single click and only a single image. </p> \n<p align=\"center\"> <a href=\"https://trendshift.io/repositories/11395\" target=\"_blank\"><img alt=\"hacksider%2FDeep-Live-Cam | Trendshift\" height=\"55\" src=\"https://trendshift.io/api/badge/repositories/11395\" style=\"width: 250px; height: 55px;\" width=\"250\" /></a> </p> \n<p align=\"center\"> <img alt=\"Demo GIF\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif\" width=\"800\" /> </p> \n<h2>Disclaimer</h2> \n<p>This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.</p> \n<p>We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.</p> \n<ul> \n <li> <p>Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.</p> </li> \n <li> <p>Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.</p> </li> \n <li> <p>Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.</p> </li> \n <li> <p>User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.</p> </li> \n</ul> \n<p>By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.</p> \n<p>Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.</p> \n<h2>Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)</h2> \n<p><a href=\"https://deeplivecam.net/index.php/quickstart\"> <img height=\"77\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png\" width=\"285\" /></a></p>\n<a href=\"https://deeplivecam.net/index.php/quickstart\"> <h5>This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.</h5> <h6>These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.</h6> <h2>TLDR; Live Deepfake in just 3 Clicks</h2> <p><img alt=\"easysteps\" src=\"https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6\" /></p> \n <ol> \n  <li>Select a face</li> \n  <li>Select which camera to use</li> \n  <li>Press live!</li> \n </ol> <h2>Features &amp; Uses - Everything is in real-time</h2> <h3>Mouth Mask</h3> <p><strong>Retain your original mouth for accurate movement using Mouth Mask</strong></p> <p align=\"center\"> <img alt=\"resizable-gif\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif\" /> </p> <h3>Face Mapping</h3> <p><strong>Use different faces on multiple subjects simultaneously</strong></p> <p align=\"center\"> <img alt=\"face_mapping_source\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif\" /> </p> <h3>Your Movie, Your Face</h3> <p><strong>Watch movies with any face in real-time</strong></p> <p align=\"center\"> <img alt=\"movie\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif\" /> </p> <h3>Live Show</h3> <p><strong>Run Live shows and performances</strong></p> <p align=\"center\"> <img alt=\"show\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif\" /> </p> <h3>Memes</h3> <p><strong>Create Your Most Viral Meme Yet</strong></p> <p align=\"center\"> <img alt=\"show\" src=\"https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif\" width=\"450\" /> <br /> <sub>Created using Many Faces feature in Deep-Live-Cam</sub> </p> <h3>Omegle</h3> <p><strong>Surprise people on Omegle</strong></p> <p align=\"center\"> \n  <video controls=\"controls\" src=\"https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0\" width=\"450\"></video> </p> <h2>Installation (Manual)</h2> <p><strong>Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.</strong></p> </a>\n<details>\n <a href=\"https://deeplivecam.net/index.php/quickstart\"> Click to see the process <h3>Installation</h3> <p>This is more likely to work on your computer but will be slower as it utilizes the CPU.</p> <p><strong>1. Set up Your Platform</strong></p> \n  <ul> \n   <li>Python (3.11 recommended)</li> \n   <li>pip</li> \n   <li>git</li> \n   <li><a href=\"https://www.youtube.com/watch?v=OlNWCpFdVMA\">ffmpeg</a> - <code>iex (irm ffmpeg.tc.ht)</code></li> \n   <li><a href=\"https://visualstudio.microsoft.com/visual-cpp-build-tools/\">Visual Studio 2022 Runtimes (Windows)</a></li> \n  </ul></a> \n <p><strong>2. Clone the Repository</strong></p> \n <pre><code class=\"language-bash\">git clone https://github.com/hacksider/Deep-Live-Cam.git\ncd Deep-Live-Cam\n</code></pre> \n <p><strong>3. Download the Models</strong></p> \n <ol> \n  <li><a href=\"https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth\">GFPGANv1.4</a></li> \n  <li><a href=\"https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx\">inswapper_128_fp16.onnx</a></li> \n </ol> \n <p>Place these files in the \"<strong>models</strong>\" folder.</p> \n <p><strong>4. Install Dependencies</strong></p> \n <p>We highly recommend using a <code>venv</code> to avoid issues.</p> \n <p>For Windows:</p> \n <pre><code class=\"language-bash\">python -m venv venv\nvenv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre> \n <p>For Linux:</p> \n <pre><code class=\"language-bash\"># Ensure you use the installed Python 3.10\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> \n <p><strong>For macOS:</strong></p> \n <p>Apple Silicon (M1/M2/M3) requires specific setup:</p> \n <pre><code class=\"language-bash\"># Install Python 3.11 (specific version is important)\nbrew install python@3.11\n\n# Install tkinter package (required for the GUI)\nbrew install python-tk@3.10\n\n# Create and activate virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre> \n <p>** In case something goes wrong and you need to reinstall the virtual environment **</p> \n <pre><code class=\"language-bash\"># Deactivate the virtual environment\nrm -rf venv\n\n# Reinstall the virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# install the dependencies again\npip install -r requirements.txt\n\n# gfpgan and basicsrs issue fix\npip install git+https://github.com/xinntao/BasicSR.git@master\npip uninstall gfpgan -y\npip install git+https://github.com/TencentARC/GFPGAN.git@master\n</code></pre> \n <p><strong>Run:</strong> If you don't have a GPU, you can run Deep-Live-Cam using <code>python run.py</code>. Note that initial execution will download models (~300MB).</p> \n <h3>GPU Acceleration</h3> \n <p><strong>CUDA Execution Provider (Nvidia)</strong></p> \n <ol> \n  <li>Install <a href=\"https://developer.nvidia.com/cuda-12-8-0-download-archive\">CUDA Toolkit 12.8.0</a></li> \n  <li>Install <a href=\"https://developer.nvidia.com/rdp/cudnn-archive\">cuDNN v8.9.7 for CUDA 12.x</a> (required for onnxruntime-gpu): \n   <ul> \n    <li>Download cuDNN v8.9.7 for CUDA 12.x</li> \n    <li>Make sure the cuDNN bin directory is in your system PATH</li> \n   </ul> </li> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\npip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime-gpu==1.21.0\n</code></pre> \n <ol start=\"3\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider cuda\n</code></pre> \n <p><strong>CoreML Execution Provider (Apple Silicon)</strong></p> \n <p>Apple Silicon (M1/M2/M3) specific installation:</p> \n <ol> \n  <li>Make sure you've completed the macOS setup above using Python 3.10.</li> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-silicon\npip install onnxruntime-silicon==1.13.1\n</code></pre> \n <ol start=\"3\"> \n  <li>Usage (important: specify Python 3.10):</li> \n </ol> \n <pre><code class=\"language-bash\">python3.10 run.py --execution-provider coreml\n</code></pre> \n <p><strong>Important Notes for macOS:</strong></p> \n <ul> \n  <li>You <strong>must</strong> use Python 3.10, not newer versions like 3.11 or 3.13</li> \n  <li>Always run with <code>python3.10</code> command not just <code>python</code> if you have multiple Python versions installed</li> \n  <li>If you get error about <code>_tkinter</code> missing, reinstall the tkinter package: <code>brew reinstall python-tk@3.10</code></li> \n  <li>If you get model loading errors, check that your models are in the correct folder</li> \n  <li>If you encounter conflicts with other Python versions, consider uninstalling them: <pre><code class=\"language-bash\"># List all installed Python versions\nbrew list | grep python\n\n# Uninstall conflicting versions if needed\nbrew uninstall --ignore-dependencies python@3.11 python@3.13\n\n# Keep only Python 3.11\nbrew cleanup\n</code></pre> </li> \n </ul> \n <p><strong>CoreML Execution Provider (Apple Legacy)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-coreml\npip install onnxruntime-coreml==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider coreml\n</code></pre> \n <p><strong>DirectML Execution Provider (Windows)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-directml\npip install onnxruntime-directml==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider directml\n</code></pre> \n <p><strong>OpenVINO™ Execution Provider (Intel)</strong></p> \n <ol> \n  <li>Install dependencies:</li> \n </ol> \n <pre><code class=\"language-bash\">pip uninstall onnxruntime onnxruntime-openvino\npip install onnxruntime-openvino==1.21.0\n</code></pre> \n <ol start=\"2\"> \n  <li>Usage:</li> \n </ol> \n <pre><code class=\"language-bash\">python run.py --execution-provider openvino\n</code></pre> \n</details> \n<h2>Usage</h2> \n<p><strong>1. Image/Video Mode</strong></p> \n<ul> \n <li>Execute <code>python run.py</code>.</li> \n <li>Choose a source face image and a target image/video.</li> \n <li>Click \"Start\".</li> \n <li>The output will be saved in a directory named after the target video.</li> \n</ul> \n<p><strong>2. Webcam Mode</strong></p> \n<ul> \n <li>Execute <code>python run.py</code>.</li> \n <li>Select a source face image.</li> \n <li>Click \"Live\".</li> \n <li>Wait for the preview to appear (10-30 seconds).</li> \n <li>Use a screen capture tool like OBS to stream.</li> \n <li>To change the face, select a new source image.</li> \n</ul> \n<h2>Command Line Arguments (Unmaintained)</h2> \n<pre><code>options:\n  -h, --help                                               show this help message and exit\n  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image\n  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video\n  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory\n  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)\n  --keep-fps                                               keep original fps\n  --keep-audio                                             keep original audio\n  --keep-frames                                            keep temporary frames\n  --many-faces                                             process every face\n  --map-faces                                              map source target faces\n  --mouth-mask                                             mask the mouth region\n  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder\n  --video-quality [0-51]                                   adjust output video quality\n  --live-mirror                                            the live camera display as you see it in the front-facing camera frame\n  --live-resizable                                         the live camera frame is resizable\n  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB\n  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)\n  --execution-threads EXECUTION_THREADS                    number of execution threads\n  -v, --version                                            show program's version number and exit\n</code></pre> \n<p>Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.</p> \n<h2>Press</h2> \n<p><strong>We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.</strong></p> \n<ul> \n <li><a href=\"https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/\"><em>\"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger\"</em></a> - Ars Technica</li> \n <li><a href=\"https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/\"><em>\"Thanks Deep Live Cam, shapeshifters are among us now\"</em></a> - Dataconomy</li> \n <li><a href=\"https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story\"><em>\"This free AI tool lets you become anyone during video-calls\"</em></a> - NewsBytes</li> \n <li><a href=\"https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying\"><em>\"OK, this viral AI live stream software is truly terrifying\"</em></a> - Creative Bloq</li> \n <li><a href=\"https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/\"><em>\"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo\"</em></a> - PetaPixel</li> \n <li><a href=\"https://www.techeblog.com/deep-live-cam-ai-transform-face/\"><em>\"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included\"</em></a> - TechEBlog</li> \n <li><a href=\"https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/\"><em>\"An AI tool that \"makes you look like anyone\" during a video call is going viral online\"</em></a> - Telegrafi</li> \n <li><a href=\"https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts\"><em>\"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts\"</em></a> - Emerge</li> \n <li><a href=\"https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/\"><em>\"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces\"</em></a> - Digital Music News</li> \n <li><a href=\"https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/\"><em>\"This real-time webcam deepfake tool raises alarms about the future of identity theft\"</em></a> - DIYPhotography</li> \n <li><a href=\"https://www.youtube.com/watch?time_continue=1074&amp;v=py4Tc-Y8BcY\"><em>\"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude\"</em></a> - SomeOrdinaryGamers</li> \n <li><a href=\"https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;t=2686\"><em>\"Alright look look look, now look chat, we can do any face we want to look like chat\"</em></a> - IShowSpeed</li> \n <li><a href=\"https://www.youtube.com/watch?v=wnCghLjqv3s&amp;t=551s\"><em>\"They do a pretty good job matching poses, expression and even the lighting\"</em></a> - TechLinked (LTT)</li> \n <li><a href=\"https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html\"><em>\"Als Sean Connery an der Redaktionskonferenz teilnahm\"</em></a> - Golem.de (German)</li> \n <li><a href=\"https://youtu.be/JbUPRmXRUtE?t=3964\"><em>\"What the F</em>**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! \"*</a> - IShowSpeed</li> \n</ul> \n<h2>Credits</h2> \n<ul> \n <li><a href=\"https://ffmpeg.org/\">ffmpeg</a>: for making video-related operations easy</li> \n <li><a href=\"https://github.com/henryruhs\">Henry</a>: One of the major contributor in this repo</li> \n <li><a href=\"https://github.com/deepinsight\">deepinsight</a>: for their <a href=\"https://github.com/deepinsight/insightface\">insightface</a> project which provided a well-made library and models. Please be reminded that the <a href=\"https://github.com/deepinsight/insightface?tab=readme-ov-file#license\">use of the model is for non-commercial research purposes only</a>.</li> \n <li><a href=\"https://github.com/havok2-htwo\">havok2-htwo</a>: for sharing the code for webcam</li> \n <li><a href=\"https://github.com/GosuDRM\">GosuDRM</a>: for the open version of roop</li> \n <li><a href=\"https://github.com/pereiraroland26\">pereiraroland26</a>: Multiple faces support</li> \n <li><a href=\"https://github.com/vic4key\">vic4key</a>: For supporting/contributing to this project</li> \n <li><a href=\"https://github.com/kier007\">kier007</a>: for improving the user experience</li> \n <li><a href=\"https://github.com/qitianai\">qitianai</a>: for multi-lingual support</li> \n <li>and <a href=\"https://github.com/hacksider/Deep-Live-Cam/graphs/contributors\">all developers</a> behind libraries used in this project.</li> \n <li>Footnote: Please be informed that the base author of the code is <a href=\"https://github.com/s0md3v/roop\">s0md3v</a></li> \n <li>All the wonderful users who helped make this project go viral by starring the repo ❤️</li> \n</ul> \n<p><a href=\"https://github.com/hacksider/Deep-Live-Cam/stargazers\"><img alt=\"Stargazers\" src=\"https://reporoster.com/stars/hacksider/Deep-Live-Cam\" /></a></p> \n<h2>Contributions</h2> \n<p><img alt=\"Alt\" src=\"https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true\" title=\"Repobeats analytics image\" /></p> \n<h2>Stars to the Moon 🚀</h2> \n<a href=\"https://star-history.com/#hacksider/deep-live-cam&amp;Date\"> \n  \n  <source media=\"(prefers-color-scheme: dark)\" /> \n  <source media=\"(prefers-color-scheme: light)\" /> \n  <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;type=Date\" /> \n  </a>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:14.549219Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 7
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 18,
        "timeliness_score": 1,
        "final_score": 6.1,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://dev.to/alanvarghese-dev/from-learner-to-architect-my-journey-building-a-resilient-e-commerce-platform-with-load-balancing-1na",
        "title": "From Learner to Architect: My Journey Building a Resilient E-commerce Platform with Load Balancing, Grafana, and Prometheus",
        "summary": "<h2>\n  \n  \n  <strong>Introduction: Charting My Path Through Distributed Systems</strong>\n</h2>\n\n<p>Every developer has a story, a pivotal project that shaped their understanding and propelled their career forward. For me, that project was building a resilient e-commerce platform, complete with robust load balancing and comprehensive monitoring using Grafana and Prometheus. This isn't just a technical deep dive; it's a reflection on how tackling complex challenges transformed my approach to software engineering and operations. Join me as I recount the journey, the technical hurdles, and the invaluable lessons learned along the way.</p>\n\n<h2>\n  \n  \n  <strong>The Genesis of a Project: Why E-commerce?</strong>\n</h2>\n\n<p>The idea for this e-commerce platform wasn't just about building another online store. It was about exploring the intricacies of modern web architecture, understanding how to handle traffic, ensure high availability, and gain deep insights into system performance. My career aspirations leaned heavily towards DevOps and distributed systems, and this project became the perfect sandbox to hone those skills.</p>\n\n<p>The platform itself is a straightforward web application: a <code>frontend</code> (simple HTML/JS), a <code>backend</code> (Node.js/Express) handling API requests, and a database (though not explicitly detailed in this post, assume a standard setup). The real learning began when considering how to scale and manage this basic setup for production-like scenarios.</p>\n\n<h2>\n  \n  \n  <strong>Navigating the Traffic: Implementing Load Balancing</strong>\n</h2>\n\n<p>In a real-world e-commerce scenario, traffic can be unpredictable. A sudden sale, a marketing campaign, or even a trending product can bring a flood of users. Without proper load balancing, a single backend instance would quickly become a bottleneck, leading to slow responses or even outages. This is where <strong>HAProxy</strong> (or Nginx) came into play.</p>\n\n<p>My <code>loadbalancer</code> directory contains configuration files like <code>haproxy.cfg</code> and <code>nginx-loadbalancer.conf</code>. I chose HAProxy for its powerful load balancing algorithms and robust health checks, ensuring that traffic is always directed to healthy backend instances.</p>\n\n<p><strong>Key Load Balancing Takeaways:</strong></p>\n\n<ul>\n<li>  <strong>Distribution Strategies</strong>: Experimented with round-robin, least connections, and source-based persistence to understand their impact on performance and user experience.</li>\n<li>  <strong>Health Checks</strong>: Implementing active and passive health checks was crucial. HAProxy continuously pings backend servers, removing unhealthy ones from the pool and reintroducing them when they recover. This was a game-changer for maintaining high availability.</li>\n<li>  <strong>SSL Termination</strong>: Handled SSL termination at the load balancer level, offloading this CPU-intensive task from the backend servers and simplifying certificate management.</li>\n</ul>\n\n<p><strong>(Imagine a simple diagram here illustrating traffic flow through HAProxy to multiple backend instances)</strong></p>\n\n<h2>\n  \n  \n  The Eyes and Ears: Monitoring with Prometheus and Grafana\n</h2>\n\n<p>Building a system is one thing; understanding how it performs in real-time is another. This is where <strong>Prometheus</strong> and <strong>Grafana</strong> became indispensable. Prometheus acts as my time-series database, scraping metrics from various components, while Grafana provides the beautiful, intuitive dashboards to visualize this data.</p>\n\n<p>My <code>monitoring</code> directory is structured with <code>prometheus.yml</code> for Prometheus configuration and <code>grafana</code> containing dashboard and datasource provisioning files.</p>\n\n<p><strong>Backend Metrics (<code>backend/metrics.js</code>):</strong></p>\n\n<p>To get meaningful data, I instrumented my Node.js backend to expose custom metrics. This involved using a Prometheus client library to track things like:</p>\n\n<ul>\n<li>  Request rates and latencies for different API endpoints.</li>\n<li>  Error rates (e.g., 5xx responses).</li>\n<li>  Event loop lag and memory usage of the Node.js process.\n</li>\n</ul>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight javascript\"><code><span class=\"c1\">// A snippet from backend/metrics.js (simplified)</span>\n<span class=\"kd\">const</span> <span class=\"nx\">client</span> <span class=\"o\">=</span> <span class=\"nf\">require</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">prom-client</span><span class=\"dl\">'</span><span class=\"p\">);</span>\n<span class=\"kd\">const</span> <span class=\"nx\">collectDefaultMetrics</span> <span class=\"o\">=</span> <span class=\"nx\">client</span><span class=\"p\">.</span><span class=\"nx\">collectDefaultMetrics</span><span class=\"p\">;</span>\n<span class=\"kd\">const</span> <span class=\"nx\">register</span> <span class=\"o\">=</span> <span class=\"nx\">client</span><span class=\"p\">.</span><span class=\"nx\">register</span><span class=\"p\">;</span>\n\n<span class=\"c1\">// Collect default Node.js metrics</span>\n<span class=\"nf\">collectDefaultMetrics</span><span class=\"p\">({</span> <span class=\"nx\">register</span> <span class=\"p\">});</span>\n\n<span class=\"c1\">// Custom metric: HTTP request duration</span>\n<span class=\"kd\">const</span> <span class=\"nx\">httpRequestDurationMicroseconds</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">client</span><span class=\"p\">.</span><span class=\"nc\">Histogram</span><span class=\"p\">({</span>\n  <span class=\"na\">name</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">http_request_duration_seconds</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n  <span class=\"na\">help</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">Duration of HTTP requests in seconds</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n  <span class=\"na\">labelNames</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"dl\">'</span><span class=\"s1\">method</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"dl\">'</span><span class=\"s1\">route</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"dl\">'</span><span class=\"s1\">code</span><span class=\"dl\">'</span><span class=\"p\">],</span>\n  <span class=\"na\">buckets</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">]</span>\n<span class=\"p\">});</span>\n\n<span class=\"c1\">// Middleware to track request duration</span>\n<span class=\"kd\">function</span> <span class=\"nf\">observeMetrics</span><span class=\"p\">(</span><span class=\"nx\">req</span><span class=\"p\">,</span> <span class=\"nx\">res</span><span class=\"p\">,</span> <span class=\"nx\">next</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">const</span> <span class=\"nx\">end</span> <span class=\"o\">=</span> <span class=\"nx\">httpRequestDurationMicroseconds</span><span class=\"p\">.</span><span class=\"nf\">startTimer</span><span class=\"p\">();</span>\n  <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nf\">on</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">finish</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"p\">()</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n    <span class=\"nf\">end</span><span class=\"p\">({</span> <span class=\"na\">method</span><span class=\"p\">:</span> <span class=\"nx\">req</span><span class=\"p\">.</span><span class=\"nx\">method</span><span class=\"p\">,</span> <span class=\"na\">route</span><span class=\"p\">:</span> <span class=\"nx\">req</span><span class=\"p\">.</span><span class=\"nx\">url</span><span class=\"p\">,</span> <span class=\"na\">code</span><span class=\"p\">:</span> <span class=\"nx\">res</span><span class=\"p\">.</span><span class=\"nx\">statusCode</span> <span class=\"p\">});</span>\n  <span class=\"p\">});</span>\n  <span class=\"nf\">next</span><span class=\"p\">();</span>\n<span class=\"p\">}</span>\n\n<span class=\"nx\">module</span><span class=\"p\">.</span><span class=\"nx\">exports</span> <span class=\"o\">=</span> <span class=\"p\">{</span> <span class=\"nx\">register</span><span class=\"p\">,</span> <span class=\"nx\">observeMetrics</span> <span class=\"p\">};</span>\n</code></pre>\n\n</div>\n\n\n\n<p>This instrumentation allowed me to expose an <code>/metrics</code> endpoint from my backend, which Prometheus then scrapes.</p>\n\n<p><strong>Prometheus Configuration (<code>monitoring/prometheus/prometheus.yml</code>):</strong></p>\n\n<p>Prometheus was configured to scrape metrics from my backend instances and HAProxy.<br />\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight yaml\"><code><span class=\"c1\"># A snippet from monitoring/prometheus/prometheus.yml (simplified)</span>\n<span class=\"na\">scrape_configs</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"na\">job_name</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">backend-app'</span>\n    <span class=\"na\">static_configs</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">targets</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"s1\">'</span><span class=\"s\">backend-service-1:9090'</span><span class=\"pi\">,</span> <span class=\"s1\">'</span><span class=\"s\">backend-service-2:9090'</span><span class=\"pi\">]</span> <span class=\"c1\"># Replace with actual service discovery or IP addresses</span>\n  <span class=\"pi\">-</span> <span class=\"na\">job_name</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">haproxy'</span>\n    <span class=\"na\">static_configs</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">targets</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"s1\">'</span><span class=\"s\">haproxy-loadbalancer:8080'</span><span class=\"pi\">]</span> <span class=\"c1\"># HAProxy statistics endpoint</span>\n</code></pre>\n\n</div>\n\n\n\n<p><strong>Grafana Dashboards (<code>monitoring/grafana/provisioning/dashboards/ecommerce.json</code>):</strong></p>\n\n<p>With data flowing into Prometheus, Grafana became my single pane of glass. I created dashboards to visualize:</p>\n\n<ul>\n<li>  Overall system health (CPU, memory, disk usage).</li>\n<li>  Backend request rates, error rates, and latency percentiles.</li>\n<li>  Load balancer statistics (active connections, backend status).</li>\n<li>  Application-specific metrics (e.g., number of successful orders, failed payments).</li>\n</ul>\n\n<p><strong>(Envision a beautiful Grafana dashboard screenshot here, showcasing key e-commerce metrics)</strong></p>\n\n<p><strong>Monitoring Learnings:</strong></p>\n\n<ul>\n<li><p><strong>Proactive vs. Reactive</strong>: Monitoring shifted my mindset from reacting to outages to proactively identifying and resolving issues before they impact users.</p></li>\n<li><p><strong>Alerting</strong>: Setting up intelligent alerts in Prometheus (Alertmanager) for critical thresholds (e.g., high error rates, low disk space) is vital.</p></li>\n<li><p><strong>Correlation</strong>: Grafana's ability to overlay metrics from different sources (backend, load balancer, infrastructure) was crucial for root cause analysis.</p></li>\n<li><p><strong>The \"Golden Signals\"</strong>: Focusing on latency, traffic, errors, and saturation gave me a solid foundation for what to monitor.</p></li>\n</ul>\n\n<h2>\n  \n  \n  The Power of Docker and <code>docker-compose</code>\n</h2>\n\n<p>The entire project is orchestrated using Docker and <code>docker-compose</code>. This allowed me to define all services (frontend, backend, loadbalancer, Prometheus, Grafana) in <code>docker-compose.yml</code> files, ensuring consistent environments across development and deployment.</p>\n\n<p>For example, <code>docker-compose.dev.yml</code> sets up the development environment, <code>docker-compose.monitoring.yml</code> brings up the monitoring stack, and <code>docker-compose.prod-full.yml</code> defines the full production-like setup.</p>\n\n<h2>\n  \n  \n  My Career Trajectory: From Concepts to Concrete Implementations\n</h2>\n\n<p>This project was a significant milestone in my career journey. It allowed me to:</p>\n\n<ul>\n<li>  <strong>Deepen understanding of distributed systems</strong>: Moved beyond theoretical knowledge to practical implementation of scaling, resilience, and observability.</li>\n<li>  <strong>Master essential DevOps tools</strong>: Gained hands-on experience with Docker, HAProxy/Nginx, Prometheus, and Grafana, which are core components of modern infrastructure.</li>\n<li>  <strong>Embrace observability</strong>: Learned to instrument applications for metrics, understand alert fatigue, and build actionable dashboards.</li>\n<li>  <strong>Problem-solving under pressure</strong>: Faced and overcame challenges related to network configuration, service discovery, and metric aggregation.</li>\n</ul>\n\n<p>Each line of configuration, every dashboard panel, and every metric scraped contributed to a deeper understanding of how robust, scalable applications are built and maintained. It wasn't just about making the e-commerce site functional, but making it observable and resilient.</p>\n\n<h2>\n  \n  \n  Conclusion: The Continuous Journey of Learning\n</h2>\n\n<p>Setting up this e-commerce platform with load balancing and a comprehensive monitoring stack was an arduous yet incredibly rewarding experience. It solidified my foundational knowledge in DevOps, strengthened my problem-solving skills, and provided a tangible demonstration of my capabilities in building and managing distributed systems.</p>\n\n<p>The journey of learning in tech is continuous. This project was a significant chapter, but it also opened doors to new questions and future explorations – perhaps delving into Kubernetes for orchestration, implementing CI/CD pipelines, or exploring advanced security measures.</p>\n\n<p>What are your experiences with building resilient systems? What tools have you found indispensable in your own career journey? Share your thoughts in the comments below!</p>\n\n\n\n\n<p><em>Connect with me on <a href=\"https://linkedin.com/in/alanvarghese-dev/\" rel=\"noopener noreferrer\">LinkedIn</a> or <a href=\"https://github.com/alanvarghese-dev/\" rel=\"noopener noreferrer\">GitHub</a> to discuss more about DevOps and distributed systems!</em></p>",
        "source": "dev.to",
        "published": "Wed, 21 Jan 2026 22:15:53 +0000",
        "fetched_at": "2026-01-21T23:21:19.543370Z",
        "tags": [
          {
            "name": "transformation",
            "score": 3
          },
          {
            "name": "boundary_crossing",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 8
          }
        ],
        "structural_score": 15,
        "timeliness_score": 2,
        "final_score": 5.9,
        "reddit_score": null,
        "reddit_comments": null
      },
      {
        "url": "https://github.com/microsoft/agent-lightning",
        "title": "microsoft/agent-lightning",
        "summary": "<p>The absolute trainer to light up AI agents.</p><hr /><p align=\"center\"> <img alt=\"Agent-lightning-banner\" src=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true\" style=\"width: 600px;\" /> </p> \n<h1>Agent Lightning⚡</h1> \n<p><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml\"><img alt=\"Unit Tests\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true\" /></a> <a href=\"https://microsoft.github.io/agent-lightning/\"><img alt=\"Documentation\" src=\"https://img.shields.io/badge/GitHub%20Pages-Documentation-blue\" /></a> <a href=\"https://badge.fury.io/py/agentlightning\"><img alt=\"PyPI version\" src=\"https://badge.fury.io/py/agentlightning.svg?sanitize=true\" /></a> <a href=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true\" /></a> <a href=\"https://deepwiki.com/microsoft/agent-lightning\"><img alt=\"Ask DeepWiki\" src=\"https://deepwiki.com/badge.svg?sanitize=true\" /></a> <a href=\"https://discord.gg/RYk7CdvDR7\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;logoColor=white\" /></a></p> \n<p><strong>The absolute trainer to light up AI agents.</strong></p> \n<p>Join our <a href=\"https://discord.gg/RYk7CdvDR7\">Discord community</a> to connect with other users and contributors.</p> \n<h2>⚡ Core Features</h2> \n<ul> \n <li>Turn your agent into an optimizable beast with <strong>ZERO CODE CHANGE</strong> (almost)! 💤</li> \n <li>Build with <strong>ANY</strong> agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! 🤖</li> \n <li><strong>Selectively</strong> optimize one or more agents in a multi-agent system. 🎯</li> \n <li>Embraces <strong>Algorithms</strong> like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. 🤗</li> \n</ul> \n<p>Read more on our <a href=\"https://microsoft.github.io/agent-lightning/\">documentation website</a>.</p> \n<p align=\"center\"> <img alt=\"Agent-Lightning Core Quickstart\" src=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true\" style=\"width: 100%;\" /> </p> \n<h2>⚡ Installation</h2> \n<pre><code class=\"language-bash\">pip install agentlightning\n</code></pre> \n<p>For the latest nightly build (cutting-edge features), you can install from Test PyPI:</p> \n<pre><code class=\"language-bash\">pip install --upgrade --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --pre agentlightning\n</code></pre> \n<p>Please refer to our <a href=\"https://microsoft.github.io/agent-lightning/stable/tutorials/installation/\">installation guide</a> for more details.</p> \n<p>To start using Agent-lightning, check out our <a href=\"https://microsoft.github.io/agent-lightning/\">documentation</a> and <a href=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples\">examples</a>.</p> \n<h2>⚡ Articles</h2> \n<ul> \n <li>12/17/2025 <a href=\"https://agent-lightning.github.io/posts/trajectory_level_aggregation/\">Adopting the Trajectory Level Aggregation for Faster Training</a> Agent-lightning blog.</li> \n <li>11/4/2025 <a href=\"https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e\">Tuning ANY AI agent with Tinker ✕ Agent-lightning</a> Medium. See also <a href=\"https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc\">Part 2</a>.</li> \n <li>10/22/2025 <a href=\"https://blog.vllm.ai/2025/10/22/agent-lightning.html\">No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL</a> vLLM blog. See also <a href=\"https://zhuanlan.zhihu.com/p/1965067274642785725\">Zhihu writeup</a>.</li> \n <li>8/11/2025 <a href=\"https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad\">Training AI Agents to Write and Self-correct SQL with Reinforcement Learning</a> Medium.</li> \n <li>8/5/2025 <a href=\"https://arxiv.org/abs/2508.03680\">Agent Lightning: Train ANY AI Agents with Reinforcement Learning</a> arXiv paper.</li> \n <li>7/26/2025 <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/\">We discovered an approach to train any AI agent with RL, with (almost) zero code changes.</a> Reddit.</li> \n <li>6/6/2025 <a href=\"https://www.microsoft.com/en-us/research/project/agent-lightning/\">Agent Lightning - Microsoft Research</a> Project page.</li> \n</ul> \n<h2>⚡ Community Projects</h2> \n<ul> \n <li><a href=\"https://github.com/af-74413592/DeepWerewolf\">DeepWerewolf</a> — A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.</li> \n <li><a href=\"https://agentflow.stanford.edu/\">AgentFlow</a> — A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.</li> \n <li><a href=\"https://github.com/TencentCloudADP/Youtu-agent\">Youtu-Agent</a> — Youtu-Agent lets you build and train your agent with ease. Built with <a href=\"https://github.com/microsoft/agent-lightning/tree/contrib/youtu-agent-lightning\">a modified branch</a> of Agent Lightning, Youtu-Agent has verified up to 128 GPUs RL training on maths/code and search capabilities with steady convergence. Also check <a href=\"https://github.com/TencentCloudADP/youtu-agent/tree/rl/agl\">the recipe</a> and their blog <a href=\"https://spotted-coconut-df8.notion.site/Stop-Wrestling-with-Your-Agent-RL-How-Youtu-Agent-Achieved-Stable-128-GPU-Scaling-Without-Breaking-2ca5e8f089ba80539a98c582b65e0233\"><em>Stop Wrestling with Your Agent RL: How Youtu-Agent Achieved Stable, 128-GPU Scaling Without Breaking a Sweat</em></a>.</li> \n</ul> \n<h2>⚡ Architecture</h2> \n<p>Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight <code>agl.emit_xxx()</code> helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.</p> \n<p>On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.</p> \n<p>No rewrites, no lock-in, just a clear path from first rollout to steady improvement.</p> \n<p align=\"center\"> <img alt=\"Agent-lightning Architecture\" src=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true\" style=\"width: 100%;\" /> </p> \n<h2>⚡ CI Status</h2> \n<table> \n <thead> \n  <tr> \n   <th>Workflow</th> \n   <th>Status</th> \n  </tr> \n </thead> \n <tbody> \n  <tr> \n   <td>CPU Tests</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml\"><img alt=\"tests workflow status\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n  <tr> \n   <td>Full Tests</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml\"><img alt=\"tests summary workflow status\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n  <tr> \n   <td>UI Tests</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml\"><img alt=\"UI Tests\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n  <tr> \n   <td>Examples Integration</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml\"><img alt=\"examples summary workflow status\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n  <tr> \n   <td>Latest Dependency Compatibility</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml\"><img alt=\"latest summary workflow status\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n  <tr> \n   <td>Legacy Examples Compatibility</td> \n   <td><a href=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml\"><img alt=\"compat summary workflow status\" src=\"https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml/badge.svg?sanitize=true\" /></a></td> \n  </tr> \n </tbody> \n</table> \n<h2>⚡ Citation</h2> \n<p>If you find Agent Lightning useful in your research or projects, please cite our paper:</p> \n<pre><code class=\"language-bibtex\">@misc{luo2025agentlightningtrainai,\n      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},\n      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},\n      year={2025},\n      eprint={2508.03680},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2508.03680},\n}\n</code></pre> \n<h2>⚡ Contributing</h2> \n<p>This project welcomes contributions and suggestions. Start by reading the <a href=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md\">Contributing Guide</a> for recommended contribution points, environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit <a href=\"https://cla.opensource.microsoft.com\">https://cla.opensource.microsoft.com</a>.</p> \n<p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</p> \n<p>This project has adopted the <a href=\"https://opensource.microsoft.com/codeofconduct/\">Microsoft Open Source Code of Conduct</a>. For more information see the <a href=\"https://opensource.microsoft.com/codeofconduct/faq/\">Code of Conduct FAQ</a> or contact <a href=\"mailto:opencode@microsoft.com\">opencode@microsoft.com</a> with any additional questions or comments.</p> \n<h2>⚡ Trademarks</h2> \n<p>This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow <a href=\"https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general\">Microsoft's Trademark &amp; Brand Guidelines</a>. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.</p> \n<h2>⚡ Responsible AI</h2> \n<p>This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.</p> \n<h2>⚡ License</h2> \n<p>This project is licensed under the MIT License. See the <a href=\"https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE\">LICENSE</a> file for details.</p>",
        "source": "mshibanami.github.io",
        "published": "",
        "fetched_at": "2026-01-21T23:21:13.294325Z",
        "tags": [
          {
            "name": "boundary_crossing",
            "score": 9
          },
          {
            "name": "visibility_gain",
            "score": 4
          },
          {
            "name": "scale_shift",
            "score": 4
          }
        ],
        "structural_score": 17,
        "timeliness_score": 1,
        "final_score": 5.8,
        "reddit_score": null,
        "reddit_comments": null
      }
    ]
  }
}